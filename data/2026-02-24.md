<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 212]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.NI](#cs.NI) [Total: 9]
- [cs.DS](#cs.DS) [Total: 16]
- [cs.RO](#cs.RO) [Total: 63]
- [cs.AI](#cs.AI) [Total: 69]
- [cs.DC](#cs.DC) [Total: 15]
- [cs.SE](#cs.SE) [Total: 27]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Replication Study: Federated Text-Driven Prompt Generation for Vision-Language Models](https://arxiv.org/abs/2602.18439)
*Suraj Prasad,Anubha Pant*

Main category: cs.CV

TL;DR: A replication of FedTPG validates its text-driven prompt generation for better generalization in federated learning, achieving near-original accuracy and improved unseen class performance.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of adapting vision-language models like CLIP to federated learning scenarios, particularly in generalizing to unseen classes, and to validate the original FedTPG paper's claims.

Method: The study involves a faithful replication of FedTPG, evaluating the pre-trained model on six diverse vision datasets to assess its zero-shot capabilities and generalization performance.

Result: The evaluation achieved results within 0.2% of the original paper's reported accuracies, with an average accuracy of 74.58% on seen classes and 76.00% on unseen classes, showing a +1.43 percentage point improvement in generalization.

Conclusion: The replication study confirms the robustness and reproducibility of the FedTPG approach, validating its core claims regarding superior generalization to unseen classes and high performance across diverse visual domains without sharing private data.

Abstract: Vision-language models like CLIP have demonstrated remarkable zero-shot capabilities, yet their adaptation to federated learning scenarios presents significant challenges, particularly regarding generalization to unseen classes. The original FedTPG paper \cite{Qiu2024} addresses this limitation by introducing a text driven prompt generation network that dynamically creates prompts conditioned on class names, enabling better cross-class generalization in federated settings. In this work, we present a faithful replication study of FedTPG, evaluating the pre-trained model on six diverse vision datasets: Caltech101, Oxford Flowers, FGVC Aircraft, Oxford Pets, Food-101, and DTD. Our evaluation achieves results within 0.2\% of the original paper's reported accuracies, with an average accuracy of 74.58\% on seen (base) classes and 76.00\% on unseen (new) classes, demonstrating a +1.43 percentage point improvement in generalization. These results validate the original paper's core claims: (1) text-driven prompt generation enables superior generalization to unseen classes compared to static prompt learning methods, and (2) federated training of prompt generators maintains high performance across diverse visual domains without sharing private data. Our successful replication confirms the robustness and reproducibility of the FedTPG approach.

</details>


### [2] [A Patient-Specific Digital Twin for Adaptive Radiotherapy of Non-Small Cell Lung Cancer](https://arxiv.org/abs/2602.18496)
*Anvi Sud,Jialu Huang,Gregory R. Hart,Keshav Saxena,John Kim,Lauren Tressel,Jun Deng*

Main category: cs.CV

TL;DR: COMPASS利用AI建模动态生物反应，为精准放疗提供早期预警和个性化指导。


<details>
  <summary>Details</summary>
Motivation: 当前临床决策主要依赖静态、基于群体的NTCP模型，忽视了序列数据中动态、独特的生物轨迹。

Method: 采用GRU自编码器学习器官特异性潜在轨迹，并通过逻辑回归分类预测最终CTCAE 1级或更高毒性。

Result: 尽管样本量小，密集的时间表型分析揭示了个体剂量反应动态，发现AI驱动的早期预警窗口。

Conclusion: COMPASS展示了AI驱动的适应性放疗的概念验证，通过持续更新的数字孪生跟踪患者的生物反应，为治疗提供指导。

Abstract: Radiotherapy continues to become more precise and data dense, with current treatment regimens generating high frequency imaging and dosimetry streams ideally suited for AI driven temporal modeling to characterize how normal tissues evolve with time. Each fraction in biologically guided radiotherapy(BGRT) treated non small cell lung cancer (NSCLC) patients records new metabolic, anatomical, and dose information. However, clinical decision making is largely informed by static, population based NTCP models which overlook the dynamic, unique biological trajectories encoded in sequential data. We developed COMPASS (Comprehensive Personalized Assessment System) for safe radiotherapy, functioning as a temporal digital twin architecture utilizing per fraction PET, CT, dosiomics, radiomics, and cumulative biologically equivalent dose (BED) kinetics to model normal tissue biology as a dynamic time series process. A GRU autoencoder was employed to learn organ specific latent trajectories, which were classified via logistic regression to predict eventual CTCAE grade 1 or higher toxicity. Eight NSCLC patients undergoing BGRT contributed to the 99 organ fraction observations covering 24 organ trajectories (spinal cord, heart, and esophagus). Despite the small cohort, intensive temporal phenotyping allowed for comprehensive analysis of individual dose response dynamics. Our findings revealed a viable AI driven early warning window, as increasing risk ratings occurred from several fractions before clinical toxicity. The dense BED driven representation revealed biologically relevant spatial dose texture characteristics that occur before toxicity and are averaged out with traditional volume based dosimetry. COMPASS establishes a proof of concept for AI enabled adaptive radiotherapy, where treatment is guided by a continually updated digital twin that tracks each patients evolving biological response.

</details>


### [3] [Scaling Ultrasound Volumetric Reconstruction via Mobile Augmented Reality](https://arxiv.org/abs/2602.18500)
*Kian Wei Ng,Yujia Gao,Deborah Khoo,Ying Zhen Tan,Chengzheng Mao,Haojie Cheng,Andrew Makmur,Kee Yuan Ngiam,Serene Goh,Eng Tat Khoo*

Main category: cs.CV

TL;DR: MARVUS是一种资源高效的移动增强现实系统，显著提升超声体积评估的准确性和一致性，适用于癌症筛查和治疗规划。


<details>
  <summary>Details</summary>
Motivation: 解决2D超声体积估计的高用户间变异性和现有3D超声解决方案成本高、便携性差的问题。

Method: 使用移动增强现实技术（MARVUS），结合基础模型，与常规超声系统兼容，减少硬件需求。

Result: 在乳腺模型上，MARVUS显著提高了体积估计准确性（平均差异：0.469 cm³）并降低了用户间变异性（平均差异：0.417 cm³）。

Conclusion: MARVUS 系统通过增强现实和资源高效的设计，显著提高了超声体积评估的准确性和可重复性，有望在癌症筛查、诊断和治疗规划中广泛应用。

Abstract: Accurate volumetric characterization of lesions is essential for oncologic diagnosis, risk stratification, and treatment planning. While imaging modalities such as Computed Tomography provide high-quality 3D data, 2D ultrasound (2D-US) remains the preferred first-line modality for breast and thyroid imaging due to cost, portability, and safety factors. However, volume estimates derived from 2D-US suffer from high inter-user variability even among experienced clinicians. Existing 3D ultrasound (3D-US) solutions use specialized probes or external tracking hardware, but such configurations increase costs and diminish portability, constraining widespread clinical use. To address these limitations, we present Mobile Augmented Reality Volumetric Ultrasound (MARVUS), a resource-efficient system designed to increase accessibility to accurate and reproducible volumetric assessment. MARVUS is interoperable with conventional ultrasound (US) systems, using a foundation model to enhance cross-specialty generalization while minimizing hardware requirements relative to current 3D-US solutions. In a user study involving experienced clinicians performing measurements on breast phantoms, MARVUS yielded a substantial improvement in volume estimation accuracy (mean difference: 0.469 cm3) with reduced inter-user variability (mean difference: 0.417 cm3). Additionally, we prove that augmented reality (AR) visualizations enhance objective performance metrics and clinician-reported usability. Collectively, our findings suggests that MARVUS can enhance US-based cancer screening, diagnostic workflows, and treatment planning in a scalable, cost-conscious, and resource-efficient manner. Usage video demonstration available (https://youtu.be/m4llYcZpqmM).

</details>


### [4] [Mitigating Shortcut Learning via Feature Disentanglement in Medical Imaging: A Benchmark Study](https://arxiv.org/abs/2602.18502)
*Sarah Müller,Philipp Berens*

Main category: cs.CV

TL;DR: 研究评估了特征解耦方法缓解医学影像中快捷学习的效果，发现结合数据重新平衡和模型解耦的方法表现最佳，能有效提高分类性能并减少对虚假相关性的依赖。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在医学影像中常依赖快捷学习，利用与目标任务无因果关系的虚假相关性或混杂因素，这在临床环境中存在风险。特征解耦是一种有前景的方法，可分离潜在表示中任务相关信息与混杂因素相关特征。

Method: 本研究系统地评估了特征解耦方法，包括对抗学习和基于依赖最小化的潜在空间分割，以缓解医学影像中的快捷学习。通过潜在空间分析评估分类性能和解耦质量，涵盖一个人工和两个医学数据集。

Result: 快捷缓解方法在训练期间强虚假相关性下提高了分类性能。潜在空间分析揭示了分类指标未捕捉到的表示质量差异，凸显了每种方法的优缺点。模型对快捷的依赖程度取决于训练数据中的混杂程度。

Conclusion: 最佳性能模型结合了数据中心的重新平衡和模型中心的特征解耦，比单独使用重新平衡实现了更强健的快捷缓解，同时保持了相似的计算效率。

Abstract: Although deep learning models in medical imaging often achieve excellent classification performance, they can rely on shortcut learning, exploiting spurious correlations or confounding factors that are not causally related to the target task. This poses risks in clinical settings, where models must generalize across institutions, populations, and acquisition conditions. Feature disentanglement is a promising approach to mitigate shortcut learning by separating task-relevant information from confounder-related features in latent representations. In this study, we systematically evaluated feature disentanglement methods for mitigating shortcuts in medical imaging, including adversarial learning and latent space splitting based on dependence minimization. We assessed classification performance and disentanglement quality using latent space analyses across one artificial and two medical datasets with natural and synthetic confounders. We also examined robustness under varying levels of confounding and compared computational efficiency across methods. We found that shortcut mitigation methods improved classification performance under strong spurious correlations during training. Latent space analyses revealed differences in representation quality not captured by classification metrics, highlighting the strengths and limitations of each method. Model reliance on shortcuts depended on the degree of confounding in the training data. The best-performing models combine data-centric rebalancing with model-centric disentanglement, achieving stronger and more robust shortcut mitigation than rebalancing alone while maintaining similar computational efficiency.

</details>


### [5] [Optimizing ID Consistency in Multimodal Large Models: Facial Restoration via Alignment, Entanglement, and Disentanglement](https://arxiv.org/abs/2602.18752)
*Yuran Dong,Hang Dai,Mang Ye*

Main category: cs.CV

TL;DR: EditedID是一种无需训练、即插即用的解决方案，通过新框架解决了人像编辑中的面部身份一致性问题。


<details>
  <summary>Details</summary>
Motivation: 由于人类对面部特征高度敏感，现有方法在面部身份和编辑元素一致性恢复上存在局限性，阻碍了模型的实用部署。

Method: 提出了EditedID框架，包含自适应混合策略、混合求解器和注意力门控机制三个关键组件。

Result: EditedID在保持原始面部身份和编辑元素一致性方面达到了最先进的性能。

Conclusion: EditedID通过提出的Alignment-Disentanglement-Entanglement框架，成功解决了多模态编辑大模型在人像编辑中面部身份一致性下降的问题，为实际应用提供了可靠解决方案。

Abstract: Multimodal editing large models have demonstrated powerful editing capabilities across diverse tasks. However, a persistent and long-standing limitation is the decline in facial identity (ID) consistency during realistic portrait editing. Due to the human eye's high sensitivity to facial features, such inconsistency significantly hinders the practical deployment of these models. Current facial ID preservation methods struggle to achieve consistent restoration of both facial identity and edited element IP due to Cross-source Distribution Bias and Cross-source Feature Contamination. To address these issues, we propose EditedID, an Alignment-Disentanglement-Entanglement framework for robust identity-specific facial restoration. By systematically analyzing diffusion trajectories, sampler behaviors, and attention properties, we introduce three key components: 1) Adaptive mixing strategy that aligns cross-source latent representations throughout the diffusion process. 2) Hybrid solver that disentangles source-specific identity attributes and details. 3) Attentional gating mechanism that selectively entangles visual elements. Extensive experiments show that EditedID achieves state-of-the-art performance in preserving original facial ID and edited element IP consistency. As a training-free and plug-and-play solution, it establishes a new benchmark for practical and reliable single/multi-person facial identity restoration in open-world settings, paving the way for the deployment of multimodal editing large models in real-person editing scenarios. The code is available at https://github.com/NDYBSNDY/EditedID.

</details>


### [6] [A Computer Vision Framework for Multi-Class Detection and Tracking in Soccer Broadcast Footage](https://arxiv.org/abs/2602.18504)
*Daniel Tshiani*

Main category: cs.CV

TL;DR: 本文开发了一种基于单摄像头的计算机视觉系统，用于从广播视频中提取足球比赛数据，使低预算球队也能进行数据驱动分析。


<details>
  <summary>Details</summary>
Motivation: 解决低预算球队无法获取昂贵多摄像机或GPS跟踪系统数据的困境，探索是否可以从标准广播视频中提取类似数据。

Method: 结合YOLO目标检测器和ByteTrack跟踪算法，开发了一个端到端系统，用于识别和跟踪比赛中的球员、裁判、守门员和球。

Result: 实验结果表明，该系统在检测和跟踪球员及官员方面表现优异，具有较高的精确度、召回率和mAP50分数，但球检测仍是主要挑战。

Conclusion: AI技术能够从单一广播摄像机中提取有意义的球员级空间信息，降低对专业硬件的依赖，使大学、学院和业余俱乐部也能采用可扩展的数据驱动分析方法。

Abstract: Clubs with access to expensive multi-camera setups or GPS tracking systems gain a competitive advantage through detailed data, whereas lower-budget teams are often unable to collect similar information. This paper examines whether such data can instead be extracted directly from standard broadcast footage using a single-camera computer vision pipeline. This project develops an end-to-end system that combines a YOLO object detector with the ByteTrack tracking algorithm to identify and track players, referees, goalkeepers, and the ball throughout a match. Experimental results show that the pipeline achieves high performance in detecting and tracking players and officials, with strong precision, recall, and mAP50 scores, while ball detection remains the primary challenge. Despite this limitation, our findings demonstrate that AI can extract meaningful player-level spatial information from a single broadcast camera. By reducing reliance on specialized hardware, the proposed approach enables colleges, academies, and amateur clubs to adopt scalable, data-driven analysis methods previously accessible only to professional teams, highlighting the potential for affordable computer vision-based soccer analytics.

</details>


### [7] [PhysConvex: Physics-Informed 3D Dynamic Convex Radiance Fields for Reconstruction and Simulation](https://arxiv.org/abs/2602.18886)
*Dan Wang,Xinrui Cui,Serge Belongie,Ravi Ramamoorthi*

Main category: cs.CV

TL;DR: PhysConvex是一种物理驱动的3D动态凸辐射场，统一了视觉渲染与物理模拟，通过凸原语和降阶模拟实现高效高保真重建。


<details>
  <summary>Details</summary>
Motivation: 现有神经表示（如NeRFs和3DGS）在视觉重建上表现优异，但在捕捉复杂材料变形和动态方面存在不足。

Method: PhysConvex采用基于物理的凸原语表示可变形辐射场，引入边界驱动的动态凸表示，并通过神经蒙皮特征模态作为形状和材料感知的变形基进行降阶凸模拟。

Result: 实验证明，PhysConvex能够高效模拟复杂几何和异质材料，实现高保真重建。

Conclusion: PhysConvex成功地将视觉渲染与物理模拟统一起来，实现了高保真的几何、外观和物理属性重建，优于现有方法。

Abstract: Reconstructing and simulating dynamic 3D scenes with both visual realism and physical consistency remains a fundamental challenge. Existing neural representations, such as NeRFs and 3DGS, excel in appearance reconstruction but struggle to capture complex material deformation and dynamics. We propose PhysConvex, a Physics-informed 3D Dynamic Convex Radiance Field that unifies visual rendering and physical simulation. PhysConvex represents deformable radiance fields using physically grounded convex primitives governed by continuum mechanics. We introduce a boundary-driven dynamic convex representation that models deformation through vertex and surface dynamics, capturing spatially adaptive, non-uniform deformation, and evolving boundaries. To efficiently simulate complex geometries and heterogeneous materials, we further develop a reduced-order convex simulation that advects dynamic convex fields using neural skinning eigenmodes as shape- and material-aware deformation bases with time-varying reduced DOFs under Newtonian dynamics. Convex dynamics also offers compact, gap-free volumetric coverage, enhancing both geometric efficiency and simulation fidelity. Experiments demonstrate that PhysConvex achieves high-fidelity reconstruction of geometry, appearance, and physical properties from videos, outperforming existing methods.

</details>


### [8] [Suppression or Deletion: A Restoration-Based Representation-Level Analysis of Machine Unlearning](https://arxiv.org/abs/2602.18505)
*Yurim Jang,Jaeung Lee,Dohyun Kim,Jaemin Jo,Simon S. Woo*

Main category: cs.CV

TL;DR: 论文提出了一种新的框架来评估机器学习遗忘方法，发现多数方法仅抑制而非真正删除信息，并建议新的评估准则以关注表示层面的验证。


<details>
  <summary>Details</summary>
Motivation: 随着预训练模型在网上的广泛共享，确保模型能够应请求遗忘或删除敏感、受版权保护或私人信息变得至关重要。当前遗忘方法的评估依赖于基于输出的指标，无法验证信息是否被完全删除或仅在表示层面被抑制。

Method: 使用稀疏自编码器识别中间层的类特定专家特征，并通过推理时间引导定量区分抑制和删除。

Result: 研究发现，大多数方法在图像分类任务中实现了较高的未学习信息恢复率，表明它们仅在决策边界层面抑制信息，而保留了中间表示中的语义特征。即使是重新训练也无法移除预训练继承的鲁棒语义特征。

Conclusion: 该论文提出了一种新的基于恢复的分析框架，用于评估机器学习中的遗忘方法，揭示了当前方法主要在决策边界层面抑制信息而非真正删除，并提出了新的评估准则以优先考虑表示层面的验证。

Abstract: As pretrained models are increasingly shared on the web, ensuring that models can forget or delete sensitive, copyrighted, or private information upon request has become crucial. Machine unlearning has been proposed to address this challenge. However, current evaluations for unlearning methods rely on output-based metrics, which cannot verify whether information is completely deleted or merely suppressed at the representation level, where suppression is insufficient for true unlearning. To address this gap, we propose a novel restoration-based analysis framework that uses Sparse Autoencoders to identify class-specific expert features in intermediate layers and applies inference-time steering to quantitatively distinguish between suppression and deletion. Applying our framework to 12 major unlearning methods in image classification tasks, we find that most methods achieve high restoration rates of unlearned information, indicating that they only suppress information at the decision-boundary level, while preserving semantic features in intermediate representations. Notably, even retraining from pretrained checkpoints shows high restoration, revealing that robust semantic features inherited from pretraining are not removed by retraining. These results demonstrate that representation-level retention poses significant risks overlooked by output-based metrics, highlighting the need for new unlearning evaluation criteria. We propose new evaluation guidelines that prioritize representation-level verification, especially for privacy-critical applications in the era of pre-trained models.

</details>


### [9] [Ani3DHuman: Photorealistic 3D Human Animation with Self-guided Stochastic Sampling](https://arxiv.org/abs/2602.19089)
*Qi Sun,Can Wang,Jiaxiang Shang,Yingchun Liu,Jing Liao*

Main category: cs.CV

TL;DR: Ani3DHuman结合运动学和视频扩散先验，通过分层运动表示和自引导随机采样，生成逼真3D人体动画，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前3D人体动画方法在逼真度上存在不足：基于运动学的方法缺乏非刚性动态，而基于视频扩散先验的方法虽能合成非刚性运动，但存在质量伪影和身份丢失问题。

Method: 提出了一个分层运动表示方法，分离刚性运动和非刚性运动。刚性运动由运动学方法生成，然后通过视频扩散模型生成视频序列以恢复非刚性运动。为了解决初始渲染的分布外问题，提出了一种自引导随机采样方法。

Result: 实验证明Ani3DHuman能够生成逼真的3D人体动画，优于现有方法。

Conclusion: Ani3DHuman通过结合基于运动学的方法和视频扩散先验，成功生成了逼真的3D人体动画，解决了现有方法在非刚性动态和身份保持上的不足。

Abstract: Current 3D human animation methods struggle to achieve photorealism: kinematics-based approaches lack non-rigid dynamics (e.g., clothing dynamics), while methods that leverage video diffusion priors can synthesize non-rigid motion but suffer from quality artifacts and identity loss. To overcome these limitations, we present Ani3DHuman, a framework that marries kinematics-based animation with video diffusion priors. We first introduce a layered motion representation that disentangles rigid motion from residual non-rigid motion. Rigid motion is generated by a kinematic method, which then produces a coarse rendering to guide the video diffusion model in generating video sequences that restore the residual non-rigid motion. However, this restoration task, based on diffusion sampling, is highly challenging, as the initial renderings are out-of-distribution, causing standard deterministic ODE samplers to fail. Therefore, we propose a novel self-guided stochastic sampling method, which effectively addresses the out-of-distribution problem by combining stochastic sampling (for photorealistic quality) with self-guidance (for identity fidelity). These restored videos provide high-quality supervision, enabling the optimization of the residual non-rigid motion field. Extensive experiments demonstrate that \MethodName can generate photorealistic 3D human animation, outperforming existing methods. Code is available in https://github.com/qiisun/ani3dhuman.

</details>


### [10] [Depth from Defocus via Direct Optimization](https://arxiv.org/abs/2602.18509)
*Holly Jackson,Caleb Adams,Ignacio Lopez-Francos,Benjamin Recht*

Main category: cs.CV

TL;DR: 本文提出一种交替最小化方法，结合凸优化和并行网格搜索，有效解决高分辨率离焦深度恢复问题，并在基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管基于光学物理的模糊前向模型已存在，但从离焦图像中恢复深度仍是一个计算复杂的优化问题。本文旨在证明，利用现代优化方法和合理计算资源，全局优化方法在离焦深度恢复中是可行的。

Method: 采用交替最小化策略：固定深度图时，使用线性前向模型计算全聚焦图像；固定全聚焦图像时，通过并行网格搜索独立计算每个像素的深度。

Result: 在合成和真实离焦模糊的基准数据集上，该方法在高分辨率下表现优于现有深度学习方法，展示了有前景的结果。

Conclusion: 本文通过交替最小化方法，结合凸优化和并行网格搜索，成功解决了高分辨率下的离焦深度恢复问题，并在合成和真实离焦模糊的基准数据集上展示了优于现有方法的结果。

Abstract: Though there exists a reasonable forward model for blur based on optical physics, recovering depth from a collection of defocused images remains a computationally challenging optimization problem. In this paper, we show that with contemporary optimization methods and reasonable computing resources, a global optimization approach to depth from defocus is feasible. Our approach rests on alternating minimization. When holding the depth map fixed, the forward model is linear with respect to the all-in-focus image. When holding the all-in-focus image fixed, the depth at each pixel can be computed independently, enabling embarrassingly parallel computation. We show that alternating between convex optimization and parallel grid search can effectively solve the depth-from-defocus problem at higher resolutions than current deep learning methods. We demonstrate our approach on benchmark datasets with synthetic and real defocus blur and show promising results compared to prior approaches. Our code is available at github.com/hollyjackson/dfd.

</details>


### [11] [BayesFusion-SDF: Probabilistic Signed Distance Fusion with View Planning on CPU](https://arxiv.org/abs/2602.19697)
*Soumya Mazumdar,Vineet Kumar Rakesh,Tapas Samanta*

Main category: cs.CV

TL;DR: BayesFusion-SDF是一种基于CPU的概率符号距离融合框架，通过稀疏高斯随机场和贝叶斯方法实现高效且可解释的3D重建，优于传统TSDF和神经方法。


<details>
  <summary>Details</summary>
Motivation: 传统的体积融合技术依赖启发式加权且无法系统性地传达不确定性，而神经隐式方法虽保真度高但计算资源需求大且不易理解。

Method: 首先使用粗略的TSDF重建创建自适应窄带域，然后通过异方差贝叶斯公式结合深度观测，使用稀疏线性代数和预处理共轭梯度求解，并通过随机对角线估计器快速估计后验不确定性。

Result: 在受控消融场景和CO3D对象序列上的测试表明，新方法在几何精度上优于TSDF基线，并提供了有用的不确定性估计以支持主动感知。

Conclusion: BayesFusion-SDF 提供了一种清晰且易于使用的替代方案，能够在保持概率可解释性和行为可预测性的同时，避免对GPU密集型神经重建方法的依赖。

Abstract: Key part of robotics, augmented reality, and digital inspection is dense 3D reconstruction from depth observations. Traditional volumetric fusion techniques, including truncated signed distance functions (TSDF), enable efficient and deterministic geometry reconstruction; however, they depend on heuristic weighting and fail to transparently convey uncertainty in a systematic way. Recent neural implicit methods, on the other hand, get very high fidelity but usually need a lot of GPU power for optimization and aren't very easy to understand for making decisions later on. This work presents BayesFusion-SDF, a CPU-centric probabilistic signed distance fusion framework that conceptualizes geometry as a sparse Gaussian random field with a defined posterior distribution over voxel distances. First, a rough TSDF reconstruction is used to create an adaptive narrow-band domain. Then, depth observations are combined using a heteroscedastic Bayesian formulation that is solved using sparse linear algebra and preconditioned conjugate gradients. Randomized diagonal estimators are a quick way to get an idea of posterior uncertainty. This makes it possible to extract surfaces and plan the next best view while taking into account uncertainty. Tests on a controlled ablation scene and a CO3D object sequence show that the new method is more accurate geometrically than TSDF baselines and gives useful estimates of uncertainty for active sensing. The proposed formulation provides a clear and easy-to-use alternative to GPU-heavy neural reconstruction methods while still being able to be understood in a probabilistic way and acting in a predictable way. GitHub: https://mazumdarsoumya.github.io/BayesFusionSDF

</details>


### [12] [Sketch2Feedback: Grammar-in-the-Loop Framework for Rubric-Aligned Feedback on Student STEM Diagrams](https://arxiv.org/abs/2602.18520)
*Aayam Bansal*

Main category: cs.CV

TL;DR: Sketch2Feedback通过语法规则约束LMMs，减少幻觉并提升反馈质量，适用于STEM教育中的绘图评估。


<details>
  <summary>Details</summary>
Motivation: 解决STEM教育中及时、符合评分标准的反馈问题，同时减少大型多模态模型（LMMs）的幻觉现象。

Method: 框架分为四个阶段：混合感知、符号图构建、约束检查和受限VLM反馈，利用上游规则引擎验证语言模型的输出。

Result: Qwen2-VL-7B在微F1得分上表现最佳，但幻觉率极高；语法管道在电路反馈上表现更优（4.85/5 vs 3.11/5）。

Conclusion: Sketch2Feedback框架通过结合语法规则和视觉语言模型，有效减少了幻觉现象，并生成了更具操作性的反馈，适用于STEM教育中的学生绘图评估。

Abstract: Providing timely, rubric-aligned feedback on student-drawn diagrams is a persistent challenge in STEM education. While large multimodal models (LMMs) can jointly parse images and generate explanations, their tendency to hallucinate undermines trust in classroom deployments. We present Sketch2Feedback, a grammar-in-the-loop framework that decomposes the problem into four stages -- hybrid perception, symbolic graph construction, constraint checking, and constrained VLM feedback -- so that the language model verbalizes only violations verified by an upstream rule engine. We evaluate on two synthetic micro-benchmarks, FBD-10 (free-body diagrams) and Circuit-10 (circuit schematics), each with 500 images spanning standard and hard noise augmentation tiers, comparing our pipeline against end-to-end LMMs (LLaVA-1.5-7B, Qwen2-VL-7B), a vision-only detector, a YOLOv8-nano learned detector, and an ensemble oracle. On n=100 test samples per benchmark with 95% bootstrap CIs, results are mixed and instructive: Qwen2-VL-7B achieves the highest micro-F1 on both FBDs (0.570) and circuits (0.528), but with extreme hallucination rates (0.78, 0.98). An ensemble oracle that selects the best prediction per sample reaches F1=0.556 with hallucination 0.320 on FBDs, demonstrating exploitable complementarity between grammar and end-to-end approaches. Confidence thresholding at tau=0.7 reduces circuit hallucination from 0.970 to 0.880 with no F1 loss. Hard noise augmentation reveals domain-dependent robustness: FBD detection is resilient while circuit detection degrades sharply. An LLM-as-judge evaluation confirms that the grammar pipeline produces more actionable circuit feedback (4.85/5) than the end-to-end LMM (3.11/5). We release all code, datasets, and evaluation scripts.

</details>


### [13] [RAP: Fast Feedforward Rendering-Free Attribute-Guided Primitive Importance Score Prediction for Efficient 3D Gaussian Splatting Processing](https://arxiv.org/abs/2602.19753)
*Kaifa Yang,Qi Yang,Yiling Xu,Zhu Li*

Main category: cs.CV

TL;DR: RAP是一种快速、无需渲染的方法，通过MLP预测3D高斯泼溅中原始的重要性分数，解决了现有方法的计算和可扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖渲染分析，计算时间长且对视图选择和数量敏感，难以作为即插即用模块集成。RAP旨在解决这些问题，提供高效的重要性预测。

Method: RAP通过从内在高斯属性和局部邻域统计中直接推断原始重要性，避免了基于渲染或依赖可见性的计算。使用紧凑的MLP结合渲染损失、修剪感知损失和重要性分布正则化来预测每个原始的重要性分数。

Result: RAP在少量场景训练后能有效泛化到未见数据，并可无缝集成到重建、压缩和传输流程中。

Conclusion: RAP提出了一种快速、前馈且无需渲染的方法，用于高效预测3D高斯泼溅（3DGS）中的原始重要性分数，解决了现有方法的计算复杂性和可扩展性问题。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading technology for high-quality 3D scene reconstruction. However, the iterative refinement and densification process leads to the generation of a large number of primitives, each contributing to the reconstruction to a substantially different extent. Estimating primitive importance is thus crucial, both for removing redundancy during reconstruction and for enabling efficient compression and transmission. Existing methods typically rely on rendering-based analyses, where each primitive is evaluated through its contribution across multiple camera viewpoints. However, such methods are sensitive to the number and selection of views, rely on specialized differentiable rasterizers, and have long calculation times that grow linearly with view count, making them difficult to integrate as plug-and-play modules and limiting scalability and generalization. To address these issues, we propose RAP, a fast feedforward rendering-free attribute-guided method for efficient importance score prediction in 3DGS. RAP infers primitive significance directly from intrinsic Gaussian attributes and local neighborhood statistics, avoiding rendering-based or visibility-dependent computations. A compact MLP predicts per-primitive importance scores using rendering loss, pruning-aware loss, and significance distribution regularization. After training on a small set of scenes, RAP generalizes effectively to unseen data and can be seamlessly integrated into reconstruction, compression, and transmission pipelines. Our code is publicly available at https://github.com/yyyykf/RAP.

</details>


### [14] [Do Generative Metrics Predict YOLO Performance? An Evaluation Across Models, Augmentation Ratios, and Dataset Complexity](https://arxiv.org/abs/2602.18525)
*Vasile Marian,Yong-Bin Kang,Alexander Buddery*

Main category: cs.CV

TL;DR: 合成数据增强在复杂检测场景（如行人、植物）中显著提升性能，但指标与性能的关联性依赖场景且需控制增强量。


<details>
  <summary>Details</summary>
Motivation: 解决合成数据在目标检测训练中评估困难的问题，尤其是标准生成指标（如FID）无法有效预测下游检测性能的局限性。

Method: 通过控制实验评估了六种生成器（GAN、扩散模型及混合模型）在不同增强比例（10%-150%）下的表现，使用YOLOv11进行训练（从头训练和预训练初始化），并在真实测试集上评估（mAP@0.50:0.95）。计算了预训练数据集指标，包括全局特征空间指标和以目标为中心的分布距离。

Result: 在行人检测和植物检测中，合成数据增强分别带来相对mAP提升7.6%和30.6%，但在交通标志检测中效果有限。指标与性能的关联性因场景而异，且控制增强量后部分关联减弱。

Conclusion: 合成数据增强在更具挑战性的检测场景（如行人检测和多实例植物检测）中能显著提升性能，但在交通标志检测和预训练微调中效果有限。此外，指标与性能的关联性高度依赖具体场景，且许多表面关联在控制增强量后会减弱。

Abstract: Synthetic images are increasingly used to augment object-detection training sets, but reliably evaluating a synthetic dataset before training remains difficult: standard global generative metrics (e.g., FID) often do not predict downstream detection mAP. We present a controlled evaluation of synthetic augmentation for YOLOv11 across three single-class detection regimes -- Traffic Signs (sparse/near-saturated), Cityscapes Pedestrian (dense/occlusion-heavy), and COCO PottedPlant (multi-instance/high-variability). We benchmark six GAN-, diffusion-, and hybrid-based generators over augmentation ratios from 10% to 150% of the real training split, and train YOLOv11 both from scratch and with COCO-pretrained initialization, evaluating on held-out real test splits (mAP@0.50:0.95). For each dataset-generator-augmentation configuration, we compute pre-training dataset metrics under a matched-size bootstrap protocol, including (i) global feature-space metrics in both Inception-v3 and DINOv2 embeddings and (ii) object-centric distribution distances over bounding-box statistics. Synthetic augmentation yields substantial gains in the more challenging regimes (up to +7.6% and +30.6% relative mAP in Pedestrian and PottedPlant, respectively) but is marginal in Traffic Signs and under pretrained fine-tuning. To separate metric signal from augmentation quantity, we report both raw and augmentation-controlled (residualized) correlations with multiple-testing correction, showing that metric-performance alignment is strongly regime-dependent and that many apparent raw associations weaken after controlling for augmentation level.

</details>


### [15] [ExpPortrait: Expressive Portrait Generation via Personalized Representation](https://arxiv.org/abs/2602.19900)
*Junyi Wang,Yudong Guo,Boyang Guo,Shengming Yang,Juyong Zhang*

Main category: cs.CV

TL;DR: 提出高保真个性化头部表示和表情转移模块，结合DiT生成器，显著提升肖像视频生成的表达性和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有肖像生成方法因稀疏或低秩表示的限制，难以准确保持主题身份和表情，阻碍了高表达性肖像视频的生成。

Method: 提出了一种高保真个性化头部表示，结合静态和动态细节，并引入表情转移模块，使用扩散变换器（DiT）生成器合成细节丰富的肖像视频。

Result: 在自重现和跨重现任务中，该方法在身份保持、表情准确性和时间稳定性方面表现优异，尤其在复杂运动的细粒度细节捕捉上。

Conclusion: 该方法通过提出一种高保真个性化头部表示，显著提升了肖像视频生成的表达能力、一致性和可控性，尤其在身份保持、表情准确性和时间稳定性方面优于现有模型。

Abstract: While diffusion models have shown great potential in portrait generation, generating expressive, coherent, and controllable cinematic portrait videos remains a significant challenge. Existing intermediate signals for portrait generation, such as 2D landmarks and parametric models, have limited disentanglement capabilities and cannot express personalized details due to their sparse or low-rank representation. Therefore, existing methods based on these models struggle to accurately preserve subject identity and expressions, hindering the generation of highly expressive portrait videos. To overcome these limitations, we propose a high-fidelity personalized head representation that more effectively disentangles expression and identity. This representation captures both static, subject-specific global geometry and dynamic, expression-related details. Furthermore, we introduce an expression transfer module to achieve personalized transfer of head pose and expression details between different identities. We use this sophisticated and highly expressive head model as a conditional signal to train a diffusion transformer (DiT)-based generator to synthesize richly detailed portrait videos. Extensive experiments on self- and cross-reenactment tasks demonstrate that our method outperforms previous models in terms of identity preservation, expression accuracy, and temporal stability, particularly in capturing fine-grained details of complex motion.

</details>


### [16] [JAEGER: Joint 3D Audio-Visual Grounding and Reasoning in Simulated Physical Environments](https://arxiv.org/abs/2602.18527)
*Zhan Liu,Changli Tang,Yuxin Wang,Zhiyuan Zhu,Youjun Chen,Yiwen Shao,Tianzi Wang,Lei Ke,Zengrui Jin,Chao Zhang*

Main category: cs.CV

TL;DR: JAEGER通过3D建模和Neural IV，显著提升了AV-LLMs在3D环境中的空间感知和推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前AV-LLMs主要局限于2D感知，无法在复杂3D环境中实现可靠的空间定位和推理，因此需要扩展到3D空间。

Method: 提出了JAEGER框架，引入了神经强度向量（Neural IV）作为空间音频表示，并开发了SpatialSceneQA基准数据集用于训练和评估。

Result: 实验表明，JAEGER在多样化的空间感知和推理任务中 consistently 超越2D-centric基线模型。

Conclusion: JAEGER框架通过整合RGB-D观测和多通道一阶Ambisonics，成功扩展了AV-LLMs到3D空间，显著提升了复杂3D环境中的空间感知和推理能力。

Abstract: Current audio-visual large language models (AV-LLMs) are predominantly restricted to 2D perception, relying on RGB video and monaural audio. This design choice introduces a fundamental dimensionality mismatch that precludes reliable source localization and spatial reasoning in complex 3D environments. We address this limitation by presenting JAEGER, a framework that extends AV-LLMs to 3D space, to enable joint spatial grounding and reasoning through the integration of RGB-D observations and multi-channel first-order ambisonics. A core contribution of our work is the neural intensity vector (Neural IV), a learned spatial audio representation that encodes robust directional cues to enhance direction-of-arrival estimation, even in adverse acoustic scenarios with overlapping sources. To facilitate large-scale training and systematic evaluation, we propose SpatialSceneQA, a benchmark of 61k instruction-tuning samples curated from simulated physical environments. Extensive experiments demonstrate that our approach consistently surpasses 2D-centric baselines across diverse spatial perception and reasoning tasks, underscoring the necessity of explicit 3D modelling for advancing AI in physical environments. Our source code, pre-trained model checkpoints and datasets will be released upon acceptance.

</details>


### [17] [Augmented Radiance Field: A General Framework for Enhanced Gaussian Splatting](https://arxiv.org/abs/2602.19916)
*Yixin Yang,Bojian Wu,Yang Zhou,Hui Huang*

Main category: cs.CV

TL;DR: 提出了一种增强高斯核方法，通过视点依赖不透明度和误差驱动补偿策略，显著提升了3DGS在复杂反射场景下的渲染效果和参数效率。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）虽在实时渲染性能上领先，但其依赖球谐函数进行颜色编码的方式限制了漫反射和镜面反射的分离能力，难以准确表示复杂反射。

Method: 通过引入视点依赖的不透明度来显式建模镜面反射效果，并采用误差驱动补偿策略优化现有3DGS场景的渲染质量。

Result: 实验表明，该方法不仅在渲染性能上超越现有NeRF方法，还实现了更高的参数效率。

Conclusion: 本文提出的增强高斯核方法在渲染性能和参数效率上均优于现有技术，特别是在处理复杂反射场景时表现突出。

Abstract: Due to the real-time rendering performance, 3D Gaussian Splatting (3DGS) has emerged as the leading method for radiance field reconstruction. However, its reliance on spherical harmonics for color encoding inherently limits its ability to separate diffuse and specular components, making it challenging to accurately represent complex reflections. To address this, we propose a novel enhanced Gaussian kernel that explicitly models specular effects through view-dependent opacity. Meanwhile, we introduce an error-driven compensation strategy to improve rendering quality in existing 3DGS scenes. Our method begins with 2D Gaussian initialization and then adaptively inserts and optimizes enhanced Gaussian kernels, ultimately producing an augmented radiance field. Experiments demonstrate that our method not only surpasses state-of-the-art NeRF methods in rendering performance but also achieves greater parameter efficiency. Project page at: https://xiaoxinyyx.github.io/augs.

</details>


### [18] [Image-Based Classification of Olive Varieties Native to Turkiye Using Multiple Deep Learning Architectures: Analysis of Performance, Complexity, and Generalization](https://arxiv.org/abs/2602.18530)
*Hatice Karatas,Irfan Atabas*

Main category: cs.CV

TL;DR: 本研究比较了十种深度学习架构对土耳其五种黑橄榄品种的图像分类效果，发现EfficientNetV2-S准确率最高（95.8%），而EfficientNetB0在准确率和计算效率上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 比较多种深度学习架构在土耳其五种本地栽培黑橄榄品种（Gemlik、Ayvalik、Uslu、Erkence和Celebi）的自动化图像分类中的表现，以确定在有限数据条件下的最佳模型。

Method: 本研究使用了十种深度学习架构（MobileNetV2、EfficientNetB0、EfficientNetV2-S、ResNet50、ResNet101、DenseNet121、InceptionV3、ConvNeXt-Tiny、ViT-B16和Swin-T），通过迁移学习对2500张图像进行训练。模型性能通过准确率、精确率、召回率、F1分数、Matthews相关系数（MCC）、Cohen's Kappa、ROC-AUC、参数数量、FLOPs、推理时间和泛化差距进行评估。

Result: EfficientNetV2-S实现了最高的分类准确率（95.8%），而EfficientNetB0在准确率和计算复杂度之间提供了最佳平衡。

Conclusion: 研究表明，在数据有限的条件下，参数效率比模型深度更为关键。EfficientNetV2-S实现了最高的分类准确率（95.8%），而EfficientNetB0在准确率和计算复杂度之间提供了最佳平衡。

Abstract: This study compares multiple deep learning architectures for the automated, image-based classification of five locally cultivated black table olive varieties in Turkey: Gemlik, Ayvalik, Uslu, Erkence, and Celebi. Using a dataset of 2500 images, ten architectures - MobileNetV2, EfficientNetB0, EfficientNetV2-S, ResNet50, ResNet101, DenseNet121, InceptionV3, ConvNeXt-Tiny, ViT-B16, and Swin-T - were trained using transfer learning. Model performance was evaluated using accuracy, precision, recall, F1-score, Matthews Correlation Coefficient (MCC), Cohen's Kappa, ROC-AUC, number of parameters, FLOPs, inference time, and generalization gap. EfficientNetV2-S achieved the highest classification accuracy (95.8%), while EfficientNetB0 provided the best trade-off between accuracy and computational complexity. Overall, the results indicate that under limited data conditions, parametric efficiency plays a more critical role than model depth alone.

</details>


### [19] [VLANeXt: Recipes for Building Strong VLA Models](https://arxiv.org/abs/2602.18532)
*Xiao-Ming Wu,Bin Fan,Kang Liao,Jian-Jian Jiang,Runze Yang,Yihang Luo,Zhonghua Wu,Wei-Shi Zheng,Chen Change Loy*

Main category: cs.CV

TL;DR: VLANeXt是一个简单有效的VLA模型，通过统一框架分析设计空间，提炼12个关键发现，在基准测试和真实实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前VLA领域的研究分散且探索性较强，缺乏统一的训练协议和评估设置，难以确定哪些设计选择真正有效。

Method: 研究从类似RT-2和OpenVLA的简单VLA基线出发，系统地分析了设计选择的三个维度：基础组件、感知要素和动作建模视角。

Result: VLANeXt模型在LIBERO和LIBERO-plus基准测试中超越了先前的最先进方法，并在真实世界实验中表现出强大的泛化能力。

Conclusion: VLANeXt模型通过统一的框架和评估设置，系统地分析了VLA设计空间，并提炼出12个关键发现，为构建强大的VLA模型提供了实用指南。该模型在LIBERO和LIBERO-plus基准测试中表现优异，并在真实世界实验中展现出强大的泛化能力。

Abstract: Following the rise of large foundation models, Vision-Language-Action models (VLAs) emerged, leveraging strong visual and language understanding for general-purpose policy learning. Yet, the current VLA landscape remains fragmented and exploratory. Although many groups have proposed their own VLA models, inconsistencies in training protocols and evaluation settings make it difficult to identify which design choices truly matter. To bring structure to this evolving space, we reexamine the VLA design space under a unified framework and evaluation setup. Starting from a simple VLA baseline similar to RT-2 and OpenVLA, we systematically dissect design choices along three dimensions: foundational components, perception essentials, and action modelling perspectives. From this study, we distill 12 key findings that together form a practical recipe for building strong VLA models. The outcome of this exploration is a simple yet effective model, VLANeXt. VLANeXt outperforms prior state-of-the-art methods on the LIBERO and LIBERO-plus benchmarks and demonstrates strong generalization in real-world experiments. We will release a unified, easy-to-use codebase that serves as a common platform for the community to reproduce our findings, explore the design space, and build new VLA variants on top of a shared foundation.

</details>


### [20] [Morphological Addressing of Identity Basins in Text-to-Image Diffusion Models](https://arxiv.org/abs/2602.18533)
*Andrew Fraser*

Main category: cs.CV

TL;DR: 形态结构在文本到图像生成中创造了可导航的梯度，LoRA训练和音韵结构分别验证了其在身份盆地和视觉连贯性中的系统性影响。


<details>
  <summary>Details</summary>
Motivation: 探索形态压力在文本到图像生成流程中如何创造可导航的梯度，并验证其在身份盆地和音韵结构中的系统性影响。

Method: 研究1通过形态描述符在Stable Diffusion 1.5中导航身份盆地，并通过自蒸馏循环训练LoRA；研究2扩展至提示层面的形态学，生成200个无意义词汇并分析其视觉连贯性。

Result: 研究1中，LoRA训练实现了向特定身份的收敛，并产生了“恐怖谷”效应；研究2中，音韵候选词显著提升了视觉连贯性，部分词汇实现了完美的视觉一致性。

Conclusion: 研究表明，形态结构（无论是特征描述符还是提示层面的音韵形式）在扩散模型的潜在空间中创造了系统的导航梯度。

Abstract: We demonstrate that morphological pressure creates navigable gradients at multiple levels of the text-to-image generative pipeline. In Study~1, identity basins in Stable Diffusion 1.5 can be navigated using morphological descriptors -- constituent features like platinum blonde,'' beauty mark,'' and 1950s glamour'' -- without the target's name or photographs. A self-distillation loop (generating synthetic images from descriptor prompts, then training a LoRA on those outputs) achieves consistent convergence toward a specific identity as measured by ArcFace similarity. The trained LoRA creates a local coordinate system shaping not only the target identity but also its inverse: maximal away-conditioning produces eldritch'' structural breakdown in base SD1.5, while the LoRA-equipped model produces ``uncanny valley'' outputs -- coherent but precisely wrong. In Study~2, we extend this to prompt-level morphology. Drawing on phonestheme theory, we generate 200 novel nonsense words from English sound-symbolic clusters (e.g., \emph{cr-}, \emph{sn-}, \emph{-oid}, \emph{-ax}) and find that phonestheme-bearing candidates produce significantly more visually coherent outputs than random controls (mean Purity@1 = 0.371 vs.\ 0.209, p<0.00001p < 0.00001 p<0.00001, Cohen's d=0.55d = 0.55 d=0.55). Three candidates -- \emph{snudgeoid}, \emph{crashax}, and \emph{broomix} -- achieve perfect visual consistency (Purity@1 = 1.0) with zero training data contamination, each generating a distinct, coherent visual identity from phonesthetic structure alone. Together, these studies establish that morphological structure -- whether in feature descriptors or prompt-level phonological form -- creates systematic navigational gradients through diffusion model latent spaces. We document phase transitions in identity basins, CFG-invariant identity stability, and novel visual concepts emerging from sub-lexical sound patterns.

</details>


### [21] [Rodent-Bench](https://arxiv.org/abs/2602.18540)
*Thomas Heap,Laurence Aitchison,Emma Cahill,Adriana Casado Rodriguez*

Main category: cs.CV

TL;DR: Rodent-Bench是一个评估MLLMs在啮齿类动物行为视频标注任务中的新基准测试，结果显示当前模型表现不足，尤其是在时间分割和长视频处理方面。该基准为未来模型开发提供了方向。


<details>
  <summary>Details</summary>
Motivation: 开发Rodent-Bench旨在解决当前MLLMs在科学视频标注任务中的局限性，尤其是在时间分割、长视频序列处理和细微行为状态区分方面的挑战。

Method: 通过评估Gemini-2.5-Pro、Gemini-2.5-Flash和Qwen-VL-Max等先进MLLMs，使用Rodent-Bench基准测试，涵盖社交互动、梳理、抓挠和冻结行为等多种行为范式。提供两个版本以适应不同模型能力，并采用秒级准确率、宏观F1、平均精度、互信息和马修斯相关系数等标准化评估指标。

Result: 评估结果显示，现有模型在Rodent-Bench上的表现普遍不足，仅在梳理行为检测等特定任务上表现尚可。整体上，模型在时间分割和长视频处理方面存在显著困难。

Conclusion: Rodent-Bench是一个用于评估多模态大语言模型（MLLMs）在啮齿类动物行为视频标注任务中表现的新基准测试。尽管当前模型在特定数据集上表现尚可（如梳理行为检测），但整体表现不足以作为辅助工具。该基准为未来模型开发提供了方向，并奠定了神经科学研究中自动化行为标注的基础。

Abstract: We present Rodent-Bench, a novel benchmark designed to evaluate the ability of Multimodal Large Language Models (MLLMs) to annotate rodent behaviour footage. We evaluate state-of-the-art MLLMs, including Gemini-2.5-Pro, Gemini-2.5-Flash and Qwen-VL-Max, using this benchmark and find that none of these models perform strongly enough to be used as an assistant for this task. Our benchmark encompasses diverse datasets spanning multiple behavioral paradigms including social interactions, grooming, scratching, and freezing behaviors, with videos ranging from 10 minutes to 35 minutes in length. We provide two benchmark versions to accommodate varying model capabilities and establish standardized evaluation metrics including second-wise accuracy, macro F1, mean average precision, mutual information, and Matthew's correlation coefficient. While some models show modest performance on certain datasets (notably grooming detection), overall results reveal significant challenges in temporal segmentation, handling extended video sequences, and distinguishing subtle behavioral states. Our analysis identifies key limitations in current MLLMs for scientific video annotation and provides insights for future model development. Rodent-Bench serves as a foundation for tracking progress toward reliable automated behavioral annotation in neuroscience research.

</details>


### [22] [BloomNet: Exploring Single vs. Multiple Object Annotation for Flower Recognition Using YOLO Variants](https://arxiv.org/abs/2602.18585)
*Safwat Nusrat,Prithwiraj Bhattacharjee*

Main category: cs.CV

TL;DR: 论文比较了多种YOLO模型在花卉检测中的性能，发现SGD优化器表现最佳，适用于不同密度的花卉检测场景。


<details>
  <summary>Details</summary>
Motivation: 精确的花卉定位与识别对自动化农业至关重要，尤其是在植物表型分析、作物估算和产量监测中。

Method: 论文比较了多种YOLO架构（如YOLOv5s、YOLOv8n/s/m、YOLOv12n）在两种标注方式（SISBB和SIMBB）下的性能，并使用Precision、Recall和mAP等指标进行评估。

Result: 在SISBB下，YOLOv8m（SGD）表现最佳；在SIMBB下，YOLOv12n（SGD）表现最优。结果显示标注密度、IoU阈值和模型大小之间存在交互作用。

Conclusion: 论文展示了不同YOLO架构在花卉检测中的性能差异，特别是在不同标注密度和IoU阈值下的表现。SGD优化器在所有情况下均表现最佳，为自动化农业中的非破坏性作物分析、生长跟踪等应用提供了有力工具。

Abstract: Precise localization and recognition of flowers are crucial for advancing automated agriculture, particularly in plant phenotyping, crop estimation, and yield monitoring. This paper benchmarks several YOLO architectures such as YOLOv5s, YOLOv8n/s/m, and YOLOv12n for flower object detection under two annotation regimes: single-image single-bounding box (SISBB) and single-image multiple-bounding box (SIMBB). The FloralSix dataset, comprising 2,816 high-resolution photos of six different flower species, is also introduced. It is annotated for both dense (clustered) and sparse (isolated) scenarios. The models were evaluated using Precision, Recall, and Mean Average Precision (mAP) at IoU thresholds of 0.5 (mAP@0.5) and 0.5-0.95 (mAP@0.5:0.95). In SISBB, YOLOv8m (SGD) achieved the best results with Precision 0.956, Recall 0.951, mAP@0.5 0.978, and mAP@0.5:0.95 0.865, illustrating strong accuracy in detecting isolated flowers. With mAP@0.5 0.934 and mAP@0.5:0.95 0.752, YOLOv12n (SGD) outperformed the more complicated SIMBB scenario, proving robustness in dense, multi-object detection. Results show how annotation density, IoU thresholds, and model size interact: recall-optimized models perform better in crowded environments, whereas precision-oriented models perform best in sparse scenarios. In both cases, the Stochastic Gradient Descent (SGD) optimizer consistently performed better than alternatives. These density-sensitive sensors are helpful for non-destructive crop analysis, growth tracking, robotic pollination, and stress evaluation.

</details>


### [23] [Effect of Patch Size on Fine-Tuning Vision Transformers in Two-Dimensional and Three-Dimensional Medical Image Classification](https://arxiv.org/abs/2602.18614)
*Massoud Dehghan,Ramona Woitek,Amirreza Mahbod*

Main category: cs.CV

TL;DR: ViT模型在医学影像分类中，较小的patch size性能更优，集成策略可进一步提升效果。


<details>
  <summary>Details</summary>
Motivation: 探索patch size对ViT模型在医学影像分类任务中的影响，填补该领域的研究空白。

Method: 使用12个医学影像数据集（7个2D和5个3D），在不同patch size（1、2、4、7、14、28）下微调ViT模型，评估其对分类性能的影响。

Result: 较小的patch size（1、2和4）在所有数据集中表现最佳，2D数据集平衡准确率提升高达12.78%（patch size 2 vs. 28），3D数据集提升高达23.78%（patch size 1 vs. 14）。集成策略进一步提升了性能。

Conclusion: 研究发现，在医学影像分类任务中，较小的patch size（1、2和4）能显著提升ViT模型的性能，尽管计算成本增加。通过简单的集成策略（融合patch size为1、2和4的模型预测），可以进一步优化性能，尤其在2D数据集上。

Abstract: Vision Transformers (ViTs) and their variants have become state-of-the-art in many computer vision tasks and are widely used as backbones in large-scale vision and vision-language foundation models. While substantial research has focused on architectural improvements, the impact of patch size, a crucial initial design choice in ViTs, remains underexplored, particularly in medical domains where both two-dimensional (2D) and three-dimensional (3D) imaging modalities exist.
  In this study, using 12 medical imaging datasets from various imaging modalities (including seven 2D and five 3D datasets), we conduct a thorough evaluation of how different patch sizes affect ViT classification performance. Using a single graphical processing unit (GPU) and a range of patch sizes (1, 2, 4, 7, 14, 28), we fine-tune ViT models and observe consistent improvements in classification performance with smaller patch sizes (1, 2, and 4), which achieve the best results across nearly all datasets. More specifically, our results indicate improvements in balanced accuracy of up to 12.78% for 2D datasets (patch size 2 vs. 28) and up to 23.78% for 3D datasets (patch size 1 vs. 14), at the cost of increased computational expense. Moreover, by applying a straightforward ensemble strategy that fuses the predictions of the models trained with patch sizes 1, 2, and 4, we demonstrate a further boost in performance in most cases, especially for the 2D datasets. Our implementation is publicly available on GitHub: https://github.com/HealMaDe/MedViT

</details>


### [24] [Narrating For You: Prompt-guided Audio-visual Narrating Face Generation Employing Multi-entangled Latent Space](https://arxiv.org/abs/2602.18618)
*Aashish Chandra,Aashutosh A,Abhijit Das*

Main category: cs.CV

TL;DR: 提出一种新方法，通过静态图像、语音和目标文本生成逼真说话面部，利用多纠缠潜在空间实现音频和视频模态的高效合成。


<details>
  <summary>Details</summary>
Motivation: 旨在从静态图像和语音配置文件中生成逼真的说话和表情面部，以提升虚拟人物的真实感和交互体验。

Method: 模型通过编码提示/驱动文本、驱动图像和个体的语音配置文件，并将它们结合传递到多纠缠潜在空间，以促进音频和视频模态生成管道的键值对和查询。

Result: 通过多纠缠潜在空间成功实现了音频和视频模态的生成，并建立了模态间的时空人物特定特征。

Conclusion: 该论文提出了一种通过静态图像、语音配置文件和目标文本来生成逼真说话和表情面部的新方法，通过多纠缠潜在空间实现了音频和视频模态的高效生成。

Abstract: We present a novel approach for generating realistic speaking and talking faces by synthesizing a person's voice and facial movements from a static image, a voice profile, and a target text. The model encodes the prompt/driving text, the driving image, and the voice profile of an individual and then combines them to pass them to the multi-entangled latent space to foster key-value pairs and queries for the audio and video modality generation pipeline. The multi-entangled latent space is responsible for establishing the spatiotemporal person-specific features between the modalities. Further, entangled features are passed to the respective decoder of each modality for output audio and video generation.

</details>


### [25] [Deep LoRA-Unfolding Networks for Image Restoration](https://arxiv.org/abs/2602.18697)
*Xiangming Wang,Haijin Zeng,Benteng Sun,Jiezhang Cao,Kai Zhang,Qiangqiang Shen,Yongyong Chen*

Main category: cs.CV

TL;DR: LoRun是一种新型DUNs方法，通过共享基础去噪器和动态LoRA适配器，解决了传统方法的适应性和参数冗余问题，提升了图像恢复效率。


<details>
  <summary>Details</summary>
Motivation: 现有的DUNs存在两个关键问题：阶段间去噪目标缺乏适应性，以及结构重复导致的参数冗余和内存消耗高。

Method: LoRun采用了一个预训练的基础去噪器，并在每个阶段注入轻量级的LoRA适配器，动态调整去噪行为以适应不同阶段的噪声水平。

Result: 实验验证了LoRun在三个图像恢复任务中的高效性，实现了参数的大幅减少且性能相当或更好。

Conclusion: LoRun通过引入LoRA适配器，解决了传统DUNs在阶段间缺乏适应性和参数冗余的问题，显著提升了图像恢复的效率和性能。

Abstract: Deep unfolding networks (DUNs), combining conventional iterative optimization algorithms and deep neural networks into a multi-stage framework, have achieved remarkable accomplishments in Image Restoration (IR), such as spectral imaging reconstruction, compressive sensing and super-resolution.It unfolds the iterative optimization steps into a stack of sequentially linked blocks.Each block consists of a Gradient Descent Module (GDM) and a Proximal Mapping Module (PMM) which is equivalent to a denoiser from a Bayesian perspective, operating on Gaussian noise with a known level.However, existing DUNs suffer from two critical limitations: (i) their PMMs share identical architectures and denoising objectives across stages, ignoring the need for stage-specific adaptation to varying noise levels; and (ii) their chain of structurally repetitive blocks results in severe parameter redundancy and high memory consumption, hindering deployment in large-scale or resource-constrained scenarios.To address these challenges, we introduce generalized Deep Low-rank Adaptation (LoRA) Unfolding Networks for image restoration, named LoRun, harmonizing denoising objectives and adapting different denoising levels between stages with compressed memory usage for more efficient DUN.LoRun introduces a novel paradigm where a single pretrained base denoiser is shared across all stages, while lightweight, stage-specific LoRA adapters are injected into the PMMs to dynamically modulate denoising behavior according to the noise level at each unfolding step.This design decouples the core restoration capability from task-specific adaptation, enabling precise control over denoising intensity without duplicating full network parameters and achieving up to $N$ times parameter reduction for an $N$-stage DUN with on-par or better performance.Extensive experiments conducted on three IR tasks validate the efficiency of our method.

</details>


### [26] [Think with Grounding: Curriculum Reinforced Reasoning with Video Grounding for Long Video Understanding](https://arxiv.org/abs/2602.18702)
*Houlun Chen,Xin Wang,Guangyao Li,Yuwei Zhou,Yihan Chen,Jia Jia,Wenwu Zhu*

Main category: cs.CV

TL;DR: Video-TwG通过动态视频接地和强化课程策略，有效解决了长视频理解中的幻觉问题，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因固定视频上下文下的纯文本推理容易忽略关键细节，导致幻觉问题，需改进以提升长视频理解能力。

Method: 提出了Video-TwG框架，采用Think-with-Grounding范式，结合两阶段强化课程策略和TwG-GRPO算法，实现了端到端训练。

Result: 在Video-MME、LongVideoBench和MLVU等基准测试中，Video-TwG均优于现有基线方法。

Conclusion: Video-TwG框架通过引入Think-with-Grounding范式和两阶段强化课程策略，显著提升了长视频理解能力，并在多个基准测试中表现优异。

Abstract: Long video understanding is challenging due to rich and complicated multimodal clues in long temporal range.Current methods adopt reasoning to improve the model's ability to analyze complex video clues in long videos via text-form reasoning.However,the existing literature suffers from the fact that the text-only reasoning under fixed video context may exacerbate hallucinations since detailed crucial clues are often ignored under limited video context length due to the temporal redundancy of long videos.To address this gap,we propose Video-TwG,a curriculum reinforced framework that employs a novel Think-with-Grounding paradigm,enabling video LLMs to actively decide when to perform on-demand grounding during interleaved text-video reasoning, selectively zooming into question-relevant clips only when necessary.Video-TwG can be trained end-to-end in a straightforward manner, without relying on complex auxiliary modules or heavily annotated reasoning tracesIn detail,we design a Two-stage Reinforced Curriculum Strategy, where the model first learns think-with-grounding behavior on a small short-video GQA dataset with grounding labels,and then scales to diverse general QA data with videos of diverse domains to encourage generalization. Further, to handle complex think-with-grounding reasoning for various kinds of data,we propose TwG-GRPO algorithm which features the fine-grained grounding reward, self-confirmed pseudo reward and accuracy-gated mechanism.Finally,we propose to construct a new TwG-51K dataset that facilitates training. Experiments on Video-MME, LongVideoBench, and MLVU show that Video-TwG consistently outperforms strong LVU baselines.Further ablation validates the necessity of our Two-stage Reinforced Curriculum Strategy and shows our TwG-GRPO better leverages diverse unlabeled data to improve grounding quality and reduce redundant groundings without sacrificing QA performance.

</details>


### [27] [IRIS-SLAM: Unified Geo-Instance Representations for Robust Semantic Localization and Mapping](https://arxiv.org/abs/2602.18709)
*Tingyang Xiao,Liu Liu,Wei Feng,Zhengyu Zou,Xiaolin Zhou,Wei Sui,Hao Li,Dingwen Zhang,Zhizhong Su*

Main category: cs.CV

TL;DR: IRIS-SLAM利用统一几何-实例表示改进语义SLAM，提升地图一致性和闭环可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有几何基础模型缺乏深层语义理解与鲁棒闭环能力，而语义映射方法常受限于解耦架构和脆弱数据关联。

Method: 提出IRIS-SLAM，基于实例扩展的基础模型，同时预测密集几何和跨视角一致的实例嵌入，实现语义协同关联和实例引导的闭环检测。

Result: 实验表明IRIS-SLAM在地图一致性和宽基线闭环可靠性上显著优于现有方法。

Conclusion: IRIS-SLAM通过统一的几何-实例表示和语义协同关联机制，显著提升了语义SLAM系统的地图一致性和闭环检测可靠性，优于现有方法。

Abstract: Geometry foundation models have significantly advanced dense geometric SLAM, yet existing systems often lack deep semantic understanding and robust loop closure capabilities. Meanwhile, contemporary semantic mapping approaches are frequently hindered by decoupled architectures and fragile data association. We propose IRIS-SLAM, a novel RGB semantic SLAM system that leverages unified geometric-instance representations derived from an instance-extended foundation model. By extending a geometry foundation model to concurrently predict dense geometry and cross-view consistent instance embeddings, we enable a semantic-synergized association mechanism and instance-guided loop closure detection. Our approach effectively utilizes viewpoint-agnostic semantic anchors to bridge the gap between geometric reconstruction and open-vocabulary mapping. Experimental results demonstrate that IRIS-SLAM significantly outperforms state-of-the-art methods, particularly in map consistency and wide-baseline loop closure reliability.

</details>


### [28] [HIME: Mitigating Object Hallucinations in LVLMs via Hallucination Insensitivity Model Editing](https://arxiv.org/abs/2602.18711)
*Ahmed Akl,Abdelwahed Khamis,Ali Cheraghian,Zhe Wang,Sara Khalifa,Kewen Wang*

Main category: cs.CV

TL;DR: HIME是一种无训练、层自适应的权重编辑方法，显著减少LVLMs的物体幻觉，不增加额外成本。


<details>
  <summary>Details</summary>
Motivation: LVLMs存在物体幻觉问题，现有微调方法成本高且难以实施，需要无训练的替代方案。

Method: 提出了Hallucination Insensitivity Score (HIS)作为量化层敏感性的指标，并基于此开发了Hallucination Insensitivity Model Editing (HIME)，一种层自适应权重编辑方法。

Result: HIME在开放生成基准测试中平均减少了61.8%的幻觉，且不影响预训练知识。

Conclusion: HIME通过层自适应的权重编辑方法有效减少了LVLMs的物体幻觉，平均减少了61.8%，且不增加额外参数或计算开销。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated impressive multimodal understanding capabilities, yet they remain prone to object hallucination, where models describe non-existent objects or attribute incorrect factual information, raising serious concerns for reliable real-world deployment. While fine-tuning is a commonly adopted mitigation strategy, its high computational cost and practical difficulty motivate the need for training-free alternatives, among which model editing has recently emerged as a promising direction. However, indiscriminate editing risks disrupting the rich implicit knowledge encoded in pre-trained LVLMs, leading to a fundamental question: how much intervention is necessary at each layer to suppress hallucinations while preserving pre-trained knowledge? To address this question, we present a systematic analysis of LVLM decoders built on three widely used large language model backbones-Qwen, LLaMA, and Vicuna-revealing clear layer-wise differences in susceptibility to object hallucination. Building on these insights, we introduce the Hallucination Insensitivity Score (HIS), a principled metric that quantifies each layer's sensitivity to hallucination and provides guidance for targeted intervention. Leveraging HIS, we propose Hallucination Insensitivity Model Editing (HIME), a simple yet effective layer-adaptive weight editing approach that selectively modifies latent features to suppress hallucinations while preserving pre-trained knowledge. Extensive experiments demonstrate that HIME reduces hallucinations by an average of 61.8% across open-ended generation benchmarks, including CHAIR, MME, and GPT-4V-aided evaluation, without introducing additional parameters, inference-time latency, or computational overhead.

</details>


### [29] [NeXt2Former-CD: Efficient Remote Sensing Change Detection with Modern Vision Architectures](https://arxiv.org/abs/2602.18717)
*Yufan Wang,Sokratis Makrogiannis,Chandra Kambhamettu*

Main category: cs.CV

TL;DR: NeXt2Former-CD框架结合卷积和注意力机制，在变化检测任务中表现优异，优于SSM方法。


<details>
  <summary>Details</summary>
Motivation: 探索现代卷积和注意力架构作为SSMs的竞争替代方案，以更好地处理配准噪声、小物体空间偏移和语义模糊性。

Method: 提出NeXt2Former-CD框架，结合Siamese ConvNeXt编码器（DINOv3权重初始化）、可变形注意力时序融合模块和Mask2Former解码器。

Result: 在LEVIR-CD、WHU-CD和CDD数据集上取得最佳性能，F1分数和IoU均优于基线方法。

Conclusion: NeXt2Former-CD框架在多个数据集上表现优异，优于基于Mamba的基线方法，且推理延迟与基于SSM的方法相当，适合高分辨率变化检测任务。

Abstract: State Space Models (SSMs) have recently gained traction in remote sensing change detection (CD) for their favorable scaling properties. In this paper, we explore the potential of modern convolutional and attention-based architectures as a competitive alternative. We propose NeXt2Former-CD, an end-to-end framework that integrates a Siamese ConvNeXt encoder initialized with DINOv3 weights, a deformable attention-based temporal fusion module, and a Mask2Former decoder. This design is intended to better tolerate residual co-registration noise and small object-level spatial shifts, as well as semantic ambiguity in bi-temporal imagery. Experiments on LEVIR-CD, WHU-CD, and CDD datasets show that our method achieves the best results among the evaluated methods, improving over recent Mamba-based baselines in both F1 score and IoU. Furthermore, despite a larger parameter count, our model maintains inference latency comparable to SSM-based approaches, suggesting it is practical for high-resolution change detection tasks.

</details>


### [30] [Subtle Motion Blur Detection and Segmentation from Static Image Artworks](https://arxiv.org/abs/2602.18720)
*Ganesh Samarth,Sibendu Paul,Solale Tabarestani,Caren Chen*

Main category: cs.CV

TL;DR: SMBlurDetect是一个结合高质量数据集生成和端到端检测的框架，显著提升运动模糊检测性能。


<details>
  <summary>Details</summary>
Motivation: 静态图像中的细微运动模糊普遍存在，影响视觉清晰度和用户体验，但现有方法和数据集对此研究不足。

Method: 提出SMBlurDetect框架，结合高质量运动模糊数据集生成和端到端检测器，采用U-Net架构和ImageNet预训练编码器，结合课程学习、硬负样本、焦点损失等技术。

Result: 在GoPro和CUHK数据集上分别达到89.68%准确率和59.77% Mean IoU，分割性能提升6.6倍。

Conclusion: SMBlurDetect框架在零样本检测和多粒度检测方面表现出色，显著提升了运动模糊检测的准确性和分割性能，适用于自动化低质量帧过滤和智能裁剪。

Abstract: Streaming services serve hundreds of millions of viewers worldwide, where visual assets such as thumbnails, box art, and cover images are critical for engagement. Subtle motion blur remains a pervasive quality issue, reducing visual clarity and negatively affecting user trust and click-through rates. However, motion blur detection from static images is underexplored, as existing methods and datasets focus on severe blur and lack fine-grained pixel-level annotations needed for quality-critical applications. Benchmarks such as GOPRO and NFS are dominated by strong synthetic blur and often contain residual blur in their sharp references, leading to ambiguous supervision. We propose SMBlurDetect, a unified framework combining high-quality motion blur specific dataset generation with an end-to-end detector capable of zero-shot detection at multiple granularities. Our pipeline synthesizes realistic motion blur from super high resolution aesthetic images using controllable camera and object motion simulations over SAM segmented regions, enhanced with alpha-aware compositing and balanced sampling to generate subtle, spatially localized blur with precise ground truth masks. We train a U-Net based detector with ImageNet pretrained encoders using a hybrid mask and image centric strategy incorporating curriculum learning, hard negatives, focal loss, blur frequency channels, and resolution aware augmentation.Our method achieves strong zero-shot generalization, reaching 89.68% accuracy on GoPro (vs 66.50% baseline) and 59.77% Mean IoU on CUHK (vs 9.00% baseline), demonstrating 6.6x improvement in segmentation. Qualitative results show accurate localization of subtle blur artifacts, enabling automated filtering of low quality frames and precise region of interest extraction for intelligent cropping.

</details>


### [31] [WiCompass: Oracle-driven Data Scaling for mmWave Human Pose Estimation](https://arxiv.org/abs/2602.18726)
*Bo Liang,Chen Gong,Haobo Wang,Qirui Liu,Rungui Zhou,Fengzhi Shao,Yubo Wang,Wei Gao,Kaichen Zhou,Guolong Cui,Chenren Xu*

Main category: cs.CV

TL;DR: WiCompass通过覆盖感知数据收集框架，利用运动捕捉数据识别缺失样本，显著提升毫米波姿态估计的OOD鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 毫米波人体姿态估计（mmWave HPE）在隐私保护方面有优势，但在分布变化下泛化能力差。研究表明，暴力数据扩展对分布外（OOD）鲁棒性无效，效率和覆盖才是真正的瓶颈。

Method: 引入了WiCompass，一个覆盖感知的数据收集框架，利用大规模运动捕捉语料库构建通用姿势空间“oracle”，量化数据集冗余并识别未被充分代表的动作。

Result: 实验表明，WiCompass在匹配预算下持续提高OOD准确性，并展现出优于传统收集策略的扩展行为。

Conclusion: 通过将重点从暴力扩展转向覆盖感知的数据采集，本研究为稳健的毫米波感知提供了一条实用路径。

Abstract: Millimeter-wave Human Pose Estimation (mmWave HPE) promises privacy but suffers from poor generalization under distribution shifts. We demonstrate that brute-force data scaling is ineffective for out-of-distribution (OOD) robustness; efficiency and coverage are the true bottlenecks. To address this, we introduce WiCompass, a coverage-aware data-collection framework. WiCompass leverages large-scale motion-capture corpora to build a universal pose space ``oracle'' that quantifies dataset redundancy and identifies underrepresented motions. Guided by this oracle, WiCompass employs a closed-loop policy to prioritize collecting informative missing samples. Experiments show that WiCompass consistently improves OOD accuracy at matched budgets and exhibits superior scaling behavior compared to conventional collection strategies. By shifting focus from brute-force scaling to coverage-aware data acquisition, this work offers a practical path toward robust mmWave sensing.

</details>


### [32] [MiSCHiEF: A Benchmark in Minimal-Pairs of Safety and Culture for Holistic Evaluation of Fine-Grained Image-Caption Alignment](https://arxiv.org/abs/2602.18729)
*Sagarika Banerjee,Tangatar Madi,Advait Swaminathan,Nguyen Dao Minh Anh,Shivank Garg,Kevin Zhu,Vasu Sharma*

Main category: cs.CV

TL;DR: MiSCHiEF基准数据集评估显示，当前VLMs在细粒度图像-文本对齐任务中仍面临模态错位挑战，尤其在安全和文化代理场景中。


<details>
  <summary>Details</summary>
Motivation: 细粒度图像-文本对齐对视觉语言模型至关重要，尤其在涉及安全和文化代理等社会关键场景中，细微的误解可能导致严重后果。

Method: 提出了MiSCHiEF基准数据集（包含MiS和MiC两个子集），采用对比对设计，评估四种VLMs在细粒度图像-文本对齐任务中的表现。

Result: 模型在确认正确的图像-文本对上表现较好，但在拒绝错误对上表现较差；且在给定图像下选择正确文本比反之任务更准确。

Conclusion: 当前视觉语言模型（VLMs）在细粒度图像-文本对齐任务中仍存在模态错位挑战，尤其是在需要精确跨模态接地的应用中。

Abstract: Fine-grained image-caption alignment is crucial for vision-language models (VLMs), especially in socially critical contexts such as identifying real-world risk scenarios or distinguishing cultural proxies, where correct interpretation hinges on subtle visual or linguistic clues and where minor misinterpretations can lead to significant real-world consequences. We present MiSCHiEF, a set of two benchmarking datasets based on a contrastive pair design in the domains of safety (MiS) and culture (MiC), and evaluate four VLMs on tasks requiring fine-grained differentiation of paired images and captions. In both datasets, each sample contains two minimally differing captions and corresponding minimally differing images. In MiS, the image-caption pairs depict a safe and an unsafe scenario, while in MiC, they depict cultural proxies in two distinct cultural contexts. We find that models generally perform better at confirming the correct image-caption pair than rejecting incorrect ones. Additionally, models achieve higher accuracy when selecting the correct caption from two highly similar captions for a given image, compared to the converse task. The results, overall, highlight persistent modality misalignment challenges in current VLMs, underscoring the difficulty of precise cross-modal grounding required for applications with subtle semantic and visual distinctions.

</details>


### [33] [LaS-Comp: Zero-shot 3D Completion with Latent-Spatial Consistency](https://arxiv.org/abs/2602.18735)
*Weilong Yan,Haipeng Li,Hao Xu,Nianjin Ye,Yihao Ai,Shuaicheng Liu,Jingyu Hu*

Main category: cs.CV

TL;DR: LaS-Comp是一种零样本、类别无关的3D形状补全方法，通过两阶段设计和无训练框架，在多样化部分观测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 利用3D基础模型的丰富几何先验，解决多样化部分观测下的3D形状补全问题。

Method: 采用两阶段设计：显式替换阶段保留部分观测几何，隐式细化阶段确保观测与合成区域边界无缝；框架无训练且兼容多种3D基础模型。

Result: 定量和定性实验表明，LaS-Comp优于现有最先进方法。

Conclusion: LaS-Comp通过利用3D基础模型的几何先验，提出了一种零样本且类别无关的3D形状补全方法，其两阶段设计和无训练特性使其在多样化的部分观测中表现优异，并通过Omni-Comp基准验证了其优越性。

Abstract: This paper introduces LaS-Comp, a zero-shot and category-agnostic approach that leverages the rich geometric priors of 3D foundation models to enable 3D shape completion across diverse types of partial observations. Our contributions are threefold: First, \ourname{} harnesses these powerful generative priors for completion through a complementary two-stage design: (i) an explicit replacement stage that preserves the partial observation geometry to ensure faithful completion; and (ii) an implicit refinement stage ensures seamless boundaries between the observed and synthesized regions. Second, our framework is training-free and compatible with different 3D foundation models. Third, we introduce Omni-Comp, a comprehensive benchmark combining real-world and synthetic data with diverse and challenging partial patterns, enabling a more thorough and realistic evaluation. Both quantitative and qualitative experiments demonstrate that our approach outperforms previous state-of-the-art approaches. Our code and data will be available at \href{https://github.com/DavidYan2001/LaS-Comp}{LaS-Comp}.

</details>


### [34] [Synthesizing Multimodal Geometry Datasets from Scratch and Enabling Visual Alignment via Plotting Code](https://arxiv.org/abs/2602.18745)
*Haobo Lin,Tianyi Bai,Chen Chen,Jiajun Zhang,Bohan Zeng,Wentao Zhang,Binhang Yuan*

Main category: cs.CV

TL;DR: GeoCode是一个通过合成复杂几何问题构建的数据集，通过代码预测对齐视觉与符号推理，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言模型由于训练数据有限和视觉-符号对齐较弱，难以处理复杂的几何构造。

Method: 提出了一种从零开始合成复杂多模态几何问题的流程，包括符号种子构建、基于验证的实例化和基于代码的图表渲染，确保结构、文本、推理和图像的一致性。进一步引入了代码预测作为显式对齐目标，将视觉理解转化为有监督的结构化预测任务。

Result: GeoCode在结构复杂性和推理难度上显著优于现有基准，同时通过多阶段验证保持数学正确性。实验表明，基于GeoCode训练的模型在多个几何基准测试中表现一致提升。

Conclusion: GeoCode数据集通过多阶段验证确保了数学正确性，显著提升了模型在多个几何基准测试中的表现，证明了数据集和对齐策略的有效性。

Abstract: Multimodal geometry reasoning requires models to jointly understand visual diagrams and perform structured symbolic inference, yet current vision--language models struggle with complex geometric constructions due to limited training data and weak visual--symbolic alignment. We propose a pipeline for synthesizing complex multimodal geometry problems from scratch and construct a dataset named \textbf{GeoCode}, which decouples problem generation into symbolic seed construction, grounded instantiation with verification, and code-based diagram rendering, ensuring consistency across structure, text, reasoning, and images. Leveraging the plotting code provided in GeoCode, we further introduce code prediction as an explicit alignment objective, transforming visual understanding into a supervised structured prediction task. GeoCode exhibits substantially higher structural complexity and reasoning difficulty than existing benchmarks, while maintaining mathematical correctness through multi-stage validation. Extensive experiments show that models trained on GeoCode achieve consistent improvements on multiple geometry benchmarks, demonstrating both the effectiveness of the dataset and the proposed alignment strategy. The code will be available at https://github.com/would1920/GeoCode.

</details>


### [35] [DD-CAM: Minimal Sufficient Explanations for Vision Models Using Delta Debugging](https://arxiv.org/abs/2602.19274)
*Krishna Khadka,Yu Lei,Raghu N. Kacker,D. Richard Kuhn*

Main category: cs.CV

TL;DR: DD-CAM通过梯度自由框架识别最小预测保留单元子集，生成更简洁、准确的显著性图。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常聚合所有单元，导致显著性图杂乱，难以识别最关键的特征。

Method: 采用delta调试策略，根据分类器头中单元的交互情况配置搜索策略，测试单个单元或单元组合以识别最小充分子集。

Result: 实验证明DD-CAM能生成更忠实的解释，并在定位准确性上优于现有CAM方法。

Conclusion: DD-CAM框架通过识别最小的、预测保留的激活子集，提供了更忠实和定位准确的解释，优于现有的CAM方法。

Abstract: We introduce a gradient-free framework for identifying minimal, sufficient, and decision-preserving explanations in vision models by isolating the smallest subset of representational units whose joint activation preserves predictions. Unlike existing approaches that aggregate all units, often leading to cluttered saliency maps, our approach, DD-CAM, identifies a 1-minimal subset whose joint activation suffices to preserve the prediction (i.e., removing any unit from the subset alters the prediction). To efficiently isolate minimal sufficient subsets, we adapt delta debugging, a systematic reduction strategy from software debugging, and configure its search strategy based on unit interactions in the classifier head: testing individual units for models with non-interacting units and testing unit combinations for models in which unit interactions exist. We then generate minimal, prediction-preserving saliency maps that highlight only the most essential features. Our experimental evaluation demonstrates that our approach can produce more faithful explanations and achieve higher localization accuracy than the state-of-the-art CAM-based approaches.

</details>


### [36] [MIRROR: Multimodal Iterative Reasoning via Reflection on Visual Regions](https://arxiv.org/abs/2602.18746)
*Haoyu Zhang,Yuwei Wu,Pengxiang Li,Xintong Zhang,Zhi Gao,Rui Gao,Mingyang Gao,Che Sun,Yunde Jia*

Main category: cs.CV

TL;DR: MIRROR框架通过闭环视觉反射机制提升多模态推理，减少幻觉，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型在处理模糊或复杂视觉输入时产生的幻觉或逻辑错误问题。

Method: 提出了MIRROR框架，包含起草、批判、基于区域的验证和修订的闭环过程。

Result: 在通用和代表性视觉语言推理基准测试中，MIRROR提高了正确性并减少了视觉幻觉。

Conclusion: MIRROR框架通过视觉反射机制显著提升了多模态推理的正确性，减少了视觉幻觉现象。

Abstract: In the era of Vision-Language Models (VLMs), enhancing multimodal reasoning capabilities remains a critical challenge, particularly in handling ambiguous or complex visual inputs, where initial inferences often lead to hallucinations or logic errors. Existing VLMs often produce plausible yet ungrounded answers, and even when prompted to "reflect", their corrections may remain detached from the image evidence. To address this, we propose the MIRROR framework for Multimodal Iterative Reasoning via Reflection On visual Regions. By embedding visual reflection as a core mechanism, MIRROR is formulated as a closed-loop process comprising draft, critique, region-based verification, and revision, which are repeated until the output is visually grounded. To facilitate training of this model, we construct **ReflectV**, a visual reflective dataset for multi-turn supervision that explicitly contains reflection triggers, region-based verification actions, and answer revision grounded in visual evidence. Experiments on both general vision-language benchmarks and representative vision-language reasoning benchmarks show that MIRROR improves correctness and reduces visual hallucinations, demonstrating the value of training reflection as an evidence-seeking, region-aware verification process rather than a purely textual revision step.

</details>


### [37] [Benchmarking Computational Pathology Foundation Models For Semantic Segmentation](https://arxiv.org/abs/2602.18747)
*Lavish Ramchandani,Aashay Tinaikar,Dev Kumar Das,Rohit Garg,Tijo Thomas*

Main category: cs.CV

TL;DR: 本研究评估了10种基础模型在组织病理学分割任务中的表现，发现CONCH表现最佳，且集成多模型特征可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管基础模型（如CLIP、DINO和CONCH）在多样化的成像任务中表现出色，但针对组织病理学像素级语义分割的系统性独立评估仍不足。

Method: 提出了一种基于基础模型注意力图的像素级特征提取方法，并使用XGBoost进行分类，实现了快速、可解释且无需微调的模型无关评估。

Result: 视觉语言基础模型CONCH在多个数据集上表现最佳，PathDino紧随其后。结合不同模型的特征可捕获互补的形态学表示，显著提升分割性能。

Conclusion: 集成多个基础模型（如CONCH、PathDino和CellViT）的特征可以显著提升组织病理学分割任务的性能，平均提升7.95%，表明基础模型组合能更好地适应多样化的分割任务。

Abstract: In recent years, foundation models such as CLIP, DINO,and CONCH have demonstrated remarkable domain generalization and unsupervised feature extraction capabilities across diverse imaging tasks. However, systematic and independent evaluations of these models for pixel-level semantic segmentation in histopathology remain scarce. In this study, we propose a robust benchmarking approach to asses 10 foundational models on four histopathological datasets covering both morphological tissue-region and cellular/nuclear segmentation tasks. Our method leverages attention maps of foundation models as pixel-wise features, which are then classified using a machine learning algorithm, XGBoost, enabling fast, interpretable, and model-agnostic evaluation without finetuning. We show that the vision language foundation model, CONCH performed the best across datasets when compared to vision-only foundation models, with PathDino as close second. Further analysis shows that models trained on distinct histopathology cohorts capture complementary morphological representations, and concatenating their features yields superior segmentation performance. Concatenating features from CONCH, PathDino and CellViT outperformed individual models across all the datasets by 7.95% (averaged across the datasets), suggesting that ensembles of foundation models can better generalize to diverse histopathological segmentation tasks.

</details>


### [38] [Driving with A Thousand Faces: A Benchmark for Closed-Loop Personalized End-to-End Autonomous Driving](https://arxiv.org/abs/2602.18757)
*Xiaoru Dong,Ruiqin Li,Xiao Han,Zhenxuan Wu,Jiamin Wang,Jian Chen,Qi Jiang,SM Yiu,Xinge Zhu,Yuexin Ma*

Main category: cs.CV

TL;DR: Person2Drive是一个个性化端到端自动驾驶平台，解决了数据集、评估和算法问题，实现了安全个性化驾驶。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统忽视个体驾驶风格的多样性，缺乏个性化数据集、评估指标和学习算法。

Method: 提出了Person2Drive平台，包括数据收集系统、基于风格向量的评估指标和个性化端到端自动驾驶框架。

Result: 实验证明Person2Drive能实现细粒度分析、可复现评估和有效个性化。

Conclusion: Person2Drive平台成功解决了端到端自动驾驶系统中个性化驾驶风格的缺失问题，通过提供数据集、评估指标和算法框架，实现了安全且个性化的驾驶。

Abstract: Human driving behavior is inherently diverse, yet most end-to-end autonomous driving (E2E-AD) systems learn a single average driving style, neglecting individual differences. Achieving personalized E2E-AD faces challenges across three levels: limited real-world datasets with individual-level annotations, a lack of quantitative metrics for evaluating personal driving styles, and the absence of algorithms that can learn stylized representations from users' trajectories. To address these gaps, we propose Person2Drive, a comprehensive personalized E2E-AD platform and benchmark. It includes an open-source, flexible data collection system that simulates realistic scenarios to generate scalable and diverse personalized driving datasets; style vector-based evaluation metrics with Maximum Mean Discrepancy and KL divergence to comprehensively quantify individual driving behaviors; and a personalized E2E-AD framework with a style reward model that efficiently adapts E2E models for safe and individualized driving. Extensive experiments demonstrate that Person2Drive enables fine-grained analysis, reproducible evaluation, and effective personalization in end-to-end autonomous driving. Our dataset and code will be released after acceptance.

</details>


### [39] [TAG: Thinking with Action Unit Grounding for Facial Expression Recognition](https://arxiv.org/abs/2602.18763)
*Haobo Lin,Tianyi Bai,Jiajun Zhang,Xuanhao Chang,Sheng Lu,Fangming Gu,Zengjie Hu,Wentao Zhang*

Main category: cs.CV

TL;DR: TAG是一个结合AU的多模态框架，通过监督微调和强化学习提升FER的鲁棒性和解释可信度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（VLMs）在面部表情识别（FER）中常产生未经验证的解释，缺乏视觉证据支持且易产生幻觉，导致跨数据集鲁棒性差。

Method: TAG框架结合了监督微调（基于AU的推理轨迹）和强化学习（使用AU感知奖励），以对齐预测区域与外部AU检测器。

Result: 在RAF-DB、FERPlus和AffectNet数据集上，TAG表现优于开源和闭源VLM基线，同时提高了视觉可信度。消融和偏好研究表明，基于AU的奖励稳定了推理并减少了幻觉。

Conclusion: TAG框架通过将多模态推理显式地约束在面部动作单元（AUs）上，显著提升了面部表情识别的鲁棒性和视觉可信度。

Abstract: Facial Expression Recognition (FER) is a fine-grained visual understanding task where reliable predictions require reasoning over localized and meaningful facial cues. Recent vision--language models (VLMs) enable natural language explanations for FER, but their reasoning is often ungrounded, producing fluent yet unverifiable rationales that are weakly tied to visual evidence and prone to hallucination, leading to poor robustness across different datasets. We propose TAG (Thinking with Action Unit Grounding), a vision--language framework that explicitly constrains multimodal reasoning to be supported by facial Action Units (AUs). TAG requires intermediate reasoning steps to be grounded in AU-related facial regions, yielding predictions accompanied by verifiable visual evidence. The model is trained via supervised fine-tuning on AU-grounded reasoning traces followed by reinforcement learning with an AU-aware reward that aligns predicted regions with external AU detectors. Evaluated on RAF-DB, FERPlus, and AffectNet, TAG consistently outperforms strong open-source and closed-source VLM baselines while simultaneously improving visual faithfulness. Ablation and preference studies further show that AU-grounded rewards stabilize reasoning and mitigate hallucination, demonstrating the importance of structured grounded intermediate representations for trustworthy multimodal reasoning in FER. The code will be available at https://github.com/would1920/FER_TAG .

</details>


### [40] [A high-resolution nationwide urban village mapping product for 342 Chinese cities based on foundation models](https://arxiv.org/abs/2602.18765)
*Lubin Bai,Sheng Xiao,Ziyu Yin,Haoyu Wang,Siyang Wu,Xiuyuan Zhang,Shihong Du*

Main category: cs.CV

TL;DR: GeoLink-UV是一个全国性高分辨率城中村制图产品，基于多源地理空间数据和基础模型框架生成，解决了泛化问题，为城市研究和可持续发展目标提供了可靠数据支持。


<details>
  <summary>Details</summary>
Motivation: 由于中国城市中城中村（UVs）的显著异质性和多样性，缺乏一致且可靠的全国性数据集，影响了城市治理、更新和可持续发展。

Method: 利用多源地理空间数据（包括光学遥感图像和地理矢量数据），通过基础模型驱动的制图框架生成，解决了泛化问题并提高了产品质量。

Result: GeoLink-UV数据集清晰地标定了中国342个城市中UVs的位置和边界，地理分层准确性评估证实了其在不同城市环境中的可靠性和科学可信度。分析显示UVs占建成区土地的平均比例为8%，且在中部和南部地区有显著聚集。

Conclusion: GeoLink-UV数据集为城市研究、非正式住区监测和基于证据的城市更新规划提供了开放且系统验证的地理空间基础，并直接支持与可持续发展目标11一致的大规模评估。

Abstract: Urban Villages (UVs) represent a distinctive form of high-density informal settlement embedded within China's rapidly urbanizing cities. Accurate identification of UVs is critical for urban governance, renewal, and sustainable development. But due to the pronounced heterogeneity and diversity of UVs across China's vast territory, a consistent and reliable nationwide dataset has been lacking. In this work, we present GeoLink-UV, a high-resolution nationwide UV mapping product that clearly delineates the locations and boundaries of UVs in 342 Chinese cities. The dataset is derived from multisource geospatial data, including optical remote sensing images and geo-vector data, and is generated through a foundation model-driven mapping framework designed to address the generalization issues and improve the product quality. A geographically stratified accuracy assessment based on independent samples from 28 cities confirms the reliability and scientific credibility of the nationwide dataset across heterogeneous urban contexts. Based on this nationwide product, we reveal substantial interregional disparities in UV prevalence and spatial configuration. On average, UV areas account for 8 % of built-up land, with marked clustering in central and south China. Building-level analysis further confirms a consistent low-rise, high-density development pattern of UVs nationwide, while highlighting regionally differentiated morphological characteristics. The GeoLink-UV dataset provides an open and systematically validated geospatial foundation for urban studies, informal settlement monitoring, and evidence-based urban renewal planning, and contributes directly to large-scale assessments aligned with Sustainable Development Goal 11. The GeoLink-UV dataset introduced in this article is freely available at https://doi.org/10.5281/zenodo.18688062.

</details>


### [41] [Initialization matters in few-shot adaptation of vision-language models for histopathological image classification](https://arxiv.org/abs/2602.18766)
*Pablo Meseguer,Rocío del Amor,Valery Naranjo*

Main category: cs.CV

TL;DR: ZS-MIL利用VLM文本编码器的类级嵌入初始化分类层，显著提升少样本学习下的MIL性能。


<details>
  <summary>Details</summary>
Motivation: 解决随机初始化分类器在MIL问题中表现不佳的问题，提升少样本学习场景下的性能。

Method: 提出Zero-Shot Multiple-Instance Learning (ZS-MIL)，利用VLM文本编码器的类级嵌入初始化分类层，计算样本的袋级概率。

Result: 实验表明，ZS-MIL在性能和稳定性上均优于已知的权重初始化技术。

Conclusion: ZS-MIL通过利用VLM文本编码器的类级嵌入作为分类层的起点，显著提升了MIL问题中的性能，优于随机初始化方法。

Abstract: Vision language models (VLM) pre-trained on datasets of histopathological image-caption pairs enabled zero-shot slide-level classification. The ability of VLM image encoders to extract discriminative features also opens the door for supervised fine-tuning for whole-slide image (WSI) classification, ideally using few labeled samples. Slide-level prediction frameworks require the incorporation of multiple instance learning (MIL) due to the gigapixel size of the WSI. Following patch-level feature extraction and aggregation, MIL frameworks rely on linear classifiers trained on top of the slide-level aggregated features. Classifier weight initialization has a large influence on Linear Probing performance in efficient transfer learning (ETL) approaches based on few-shot learning. In this work, we propose Zero-Shot Multiple-Instance Learning (ZS-MIL) to address the limitations of random classifier initialization that underperform zero-shot prediction in MIL problems. ZS-MIL uses the class-level embeddings of the VLM text encoder as the classification layer's starting point to compute each sample's bag-level probabilities. Through multiple experiments, we demonstrate the robustness of ZS-MIL compared to well-known weight initialization techniques both in terms of performance and variability in an ETL few-shot scenario for subtyping prediction.

</details>


### [42] [MaskDiME: Adaptive Masked Diffusion for Precise and Efficient Visual Counterfactual Explanations](https://arxiv.org/abs/2602.18792)
*Changlu Guo,Anders Nymark Christensen,Anders Bjorholm Dahl,Morten Rieger Hannemose*

Main category: cs.CV

TL;DR: MaskDiME是一种快速、高效的反事实解释生成框架，通过局部化采样解决现有方法的计算和精度问题，在多个数据集中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的反事实生成方法计算成本高、采样速度慢且在定位修改区域时不精确，MaskDiME旨在解决这些限制。

Method: MaskDiME是一个无需训练的框架，通过自适应聚焦于决策相关区域，实现局部化和语义一致的反事实生成，同时保持高图像保真度。

Result: MaskDiME在五个基准数据集上实现了比基线方法快30倍以上的推理速度，并在多样视觉领域中达到可比或最先进的性能。

Conclusion: MaskDiME提出了一种简单、快速且有效的扩散框架，通过局部化采样统一了语义一致性和空间精确性，实现了高效的反事实解释生成。

Abstract: Visual counterfactual explanations aim to reveal the minimal semantic modifications that can alter a model's prediction, providing causal and interpretable insights into deep neural networks. However, existing diffusion-based counterfactual generation methods are often computationally expensive, slow to sample, and imprecise in localizing the modified regions. To address these limitations, we propose MaskDiME, a simple, fast, and effective diffusion framework that unifies semantic consistency and spatial precision through localized sampling. Our approach adaptively focuses on decision-relevant regions to achieve localized and semantically consistent counterfactual generation while preserving high image fidelity. Our training-free framework, MaskDiME, achieves over 30x faster inference than the baseline method and achieves comparable or state-of-the-art performance across five benchmark datasets spanning diverse visual domains, establishing a practical and generalizable solution for efficient counterfactual explanation.

</details>


### [43] [Rethinking Preference Alignment for Diffusion Models with Classifier-Free Guidance](https://arxiv.org/abs/2602.18799)
*Zhou Jiang,Yandong Wen,Zhen Liu*

Main category: cs.CV

TL;DR: 研究提出了一种改进文本到图像扩散模型与人类偏好对齐的简单方法，通过解耦偏好学习并形成对比引导向量，在Stable Diffusion上实现了更好的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型与细微人类偏好的对齐仍具挑战性，直接偏好优化（DPO）虽简单有效，但大规模微调常显示泛化差距。

Method: 研究提出了一种将偏好学习解耦为两个模块的方法，分别训练于正负数据，并在推理时通过减去它们的预测形成对比引导向量，以用户选择的强度缩放并添加到基础预测中。

Result: 在Stable Diffusion 1.5和XL上使用Pick-a-Pic v2和HPDv3进行评估，展示了定量和定性的一致提升。

Conclusion: 通过将偏好对齐视为分类器自由引导（CFG），并提出一种简单的方法来改进对齐而无需重新训练基础模型，本研究在Stable Diffusion 1.5和XL上展示了定量和定性的一致提升。

Abstract: Aligning large-scale text-to-image diffusion models with nuanced human preferences remains challenging. While direct preference optimization (DPO) is simple and effective, large-scale finetuning often shows a generalization gap. We take inspiration from test-time guidance and cast preference alignment as classifier-free guidance (CFG): a finetuned preference model acts as an external control signal during sampling. Building on this view, we propose a simple method that improves alignment without retraining the base model. To further enhance generalization, we decouple preference learning into two modules trained on positive and negative data, respectively, and form a \emph{contrastive guidance} vector at inference by subtracting their predictions (positive minus negative), scaled by a user-chosen strength and added to the base prediction at each step. This yields a sharper and controllable alignment signal. We evaluate on Stable Diffusion 1.5 and Stable Diffusion XL with Pick-a-Pic v2 and HPDv3, showing consistent quantitative and qualitative gains.

</details>


### [44] [Learning Multi-Modal Prototypes for Cross-Domain Few-Shot Object Detection](https://arxiv.org/abs/2602.18811)
*Wanqi Wang,Jingcai Guo,Yuxiang Cai,Zhi Chen*

Main category: cs.CV

TL;DR: LMP是一种双分支检测器，结合文本和视觉信息，通过多模态原型学习提升跨域少样本目标检测性能，在多个基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇检测器主要依赖文本提示，缺乏目标域特有的视觉信息，影响了在少样本监督下的精确定位能力。

Method: 提出了一种双分支检测器LMP，结合文本引导和视觉示例，通过视觉原型构建模块动态生成硬负样本原型，并在视觉引导分支中注入这些原型，同时保持文本引导分支的开放词汇语义。

Result: 在六个跨域基准数据集和标准1/5/10-shot设置下，LMP方法达到了最先进或极具竞争力的mAP。

Conclusion: LMP方法通过结合文本引导和视觉示例，在跨域少样本目标检测任务中实现了最先进的性能，证明了多模态原型学习的有效性。

Abstract: Cross-Domain Few-Shot Object Detection (CD-FSOD) aims to detect novel classes in unseen target domains given only a few labeled examples. While open-vocabulary detectors built on vision-language models (VLMs) transfer well, they depend almost entirely on text prompts, which encode domain-invariant semantics but miss domain-specific visual information needed for precise localization under few-shot supervision. We propose a dual-branch detector that Learns Multi-modal Prototypes, dubbed LMP, by coupling textual guidance with visual exemplars drawn from the target domain. A Visual Prototype Construction module aggregates class-level prototypes from support RoIs and dynamically generates hard-negative prototypes in query images via jittered boxes, capturing distractors and visually similar backgrounds. In the visual-guided branch, we inject these prototypes into the detection pipeline with components mirrored from the text branch as the starting point for training, while a parallel text-guided branch preserves open-vocabulary semantics. The branches are trained jointly and ensembled at inference by combining semantic abstraction with domain-adaptive details. On six cross-domain benchmark datasets and standard 1/5/10-shot settings, our method achieves state-of-the-art or highly competitive mAP.

</details>


### [45] [HeRO: Hierarchical 3D Semantic Representation for Pose-aware Object Manipulation](https://arxiv.org/abs/2602.18817)
*Chongyang Xu,Shen Cheng,Haipeng Li,Haoqiang Fan,Ziliang Feng,Shuaicheng Liu*

Main category: cs.CV

TL;DR: HeRO结合几何与语义的分层扩散策略，显著提升机器人姿态感知操作性能。


<details>
  <summary>Details</summary>
Motivation: 解决纯几何策略缺乏部分级语义的问题，以支持姿态感知操作（如区分鞋的趾部和跟部）。

Method: 采用密集语义提升技术，融合DINOv2的几何敏感特征和Stable Diffusion的全局一致对应关系，构建全局和局部语义场，并通过层次条件模块生成控制策略。

Result: 在Place Dual Shoes任务中成功率提升12.3%，六项姿态感知任务平均提升6.5%。

Conclusion: HeRO通过结合几何和语义信息，利用分层语义场和扩散策略，显著提升了机器人操作的性能，特别是在姿态感知任务中。

Abstract: Imitation learning for robotic manipulation has progressed from 2D image policies to 3D representations that explicitly encode geometry. Yet purely geometric policies often lack explicit part-level semantics, which are critical for pose-aware manipulation (e.g., distinguishing a shoe's toe from heel). In this paper, we present HeRO, a diffusion-based policy that couples geometry and semantics via hierarchical semantic fields. HeRO employs dense semantics lifting to fuse discriminative, geometry-sensitive features from DINOv2 with the smooth, globally coherent correspondences from Stable Diffusion, yielding dense features that are both fine-grained and spatially consistent. These features are processed and partitioned to construct a global field and a set of local fields. A hierarchical conditioning module conditions the generative denoiser on global and local fields using permutation-invariant network architecture, thereby avoiding order-sensitive bias and producing a coherent control policy for pose-aware manipulation. In various tests, HeRO establishes a new state-of-the-art, improving success on Place Dual Shoes by 12.3% and averaging 6.5% gains across six challenging pose-aware tasks. Code is available at https://github.com/Chongyang-99/HeRO.

</details>


### [46] [Robust Self-Supervised Cross-Modal Super-Resolution against Real-World Misaligned Observations](https://arxiv.org/abs/2602.18822)
*Xiaoyu Dong,Jiahuan Li,Ziteng Cui,Naoto Yokoya*

Main category: cs.CV

TL;DR: RobSelf 是一种自监督模型，无需对齐数据即可处理错位的跨模态超分辨率任务，性能优越。


<details>
  <summary>Details</summary>
Motivation: 研究真实世界中错位的跨模态超分辨率（SR）问题，现有方法通常需要大量对齐数据或预对齐步骤，而 RobSelf 旨在解决这一挑战。

Method: RobSelf 是一个完全自监督的模型，无需训练数据、真实监督或预对齐，通过两个关键技术实现：错位感知特征翻译器和内容感知参考过滤器。

Result: RobSelf 在各种任务中表现出色，实现了高分辨率和高保真的 SR 预测。

Conclusion: RobSelf 在多种任务中实现了最先进的性能和卓越的效率，并引入了 RealMisSR 数据集以推动该领域的研究。

Abstract: We study cross-modal super-resolution (SR) on real-world misaligned data, where only a limited number of low-resolution (LR) source and high-resolution (HR) guide image pairs with complex spatial misalignments are available. To address this challenge, we propose RobSelf--a fully self-supervised model that is optimized online, requiring no training data, ground-truth supervision, or pre-alignment. RobSelf features two key techniques: a misalignment-aware feature translator and a content-aware reference filter. The translator reformulates unsupervised cross-modal and cross-resolution alignment as a weakly-supervised, misalignment-aware translation subtask, producing an aligned guide feature with inherent redundancy. Guided by this feature, the filter performs reference-based discriminative self-enhancement on the source, enabling SR predictions with high resolution and high fidelity. Across a variety of tasks, we demonstrate that RobSelf achieves state-of-the-art performance and superior efficiency. Additionally, we introduce a real-world dataset, RealMisSR, to advance research on this topic. Dataset and code: https://github.com/palmdong/RobSelf.

</details>


### [47] [Spatial-Temporal State Propagation Autoregressive Model for 4D Object Generation](https://arxiv.org/abs/2602.18830)
*Liying Yang,Jialun Liu,Jiakui Hu,Chenhao Guan,Haibin Huang,Fangqiu Yi,Chi Zhang,Yanyan Liang*

Main category: cs.CV

TL;DR: 4DSTAR通过动态空间-时间状态传播自回归模型和4D VQ-VAE，解决了4D对象生成的时空一致性问题，性能媲美扩散模型。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的方法在生成4D对象时存在时空不一致问题，未能充分利用历史时间步的输出指导当前生成。

Method: 4DSTAR模型包含两个关键组件：动态空间-时间状态传播自回归模型（STAR）和4D VQ-VAE。STAR通过分组预测令牌并传播历史空间-时间状态特征来保持一致性，4D VQ-VAE则将4D结构隐式编码为离散空间。

Result: 实验表明，4DSTAR生成的4D对象具有时空一致性，性能与扩散模型竞争。

Conclusion: 4DSTAR模型通过动态空间-时间状态传播自回归模型和4D VQ-VAE的联合设计，成功生成了具有时空一致性的4D对象，性能与扩散模型相当。

Abstract: Generating high-quality 4D objects with spatial-temporal consistency is still formidable. Existing diffusion-based methods often struggle with spatial-temporal inconsistency, as they fail to leverage outputs from all previous timesteps to guide the generation at the current timestep. Therefore, we propose a Spatial-Temporal State Propagation AutoRegressive Model (4DSTAR), which generates 4D objects maintaining temporal-spatial consistency. 4DSTAR formulates the generation problem as the prediction of tokens that represent the 4D object. It consists of two key components: (1) The dynamic spatial-temporal state propagation autoregressive model (STAR) is proposed, which achieves spatial-temporal consistent generation. Unlike standard autoregressive models, STAR divides prediction tokens into groups based on timesteps. It models long-term dependencies by propagating spatial-temporal states from previous groups and utilizes these dependencies to guide generation at the next timestep. To this end, a spatial-temporal container is proposed, which dynamically updating the effective spatial-temporal state features from all historical groups, then updated features serve as conditional features to guide the prediction of the next token group. (2) The 4D VQ-VAE is proposed, which implicitly encodes the 4D structure into discrete space and decodes the discrete tokens predicted by STAR into temporally coherent dynamic 3D Gaussians. Experiments demonstrate that 4DSTAR generates spatial-temporal consistent 4D objects, and achieves performance competitive with diffusion models.

</details>


### [48] [IDperturb: Enhancing Variation in Synthetic Face Generation via Angular Perturbation](https://arxiv.org/abs/2602.18831)
*Fadi Boutros,Eduarda Caldeira,Tahar Chettaoui,Naser Damer*

Main category: cs.CV

TL;DR: IDPERTURB是一种几何驱动的采样策略，通过扰动身份嵌入增强合成人脸图像的多样性，提升人脸识别系统的训练效果。


<details>
  <summary>Details</summary>
Motivation: 由于隐私和法律问题限制了真实生物特征数据的使用，合成数据成为训练人脸识别系统的实用替代方案。然而，现有模型在类内多样性上存在不足，影响了模型的鲁棒性和泛化能力。

Method: 提出IDPERTURB，一种几何驱动的采样策略，通过在单位超球面的受限角度区域内扰动身份嵌入，生成多样化的嵌入向量，无需修改底层生成模型。

Result: 实验结果表明，使用IDPERTURB生成的合成数据训练的人脸识别系统在多个基准测试中表现优于现有方法。

Conclusion: IDPERTURB通过几何驱动的采样策略增强了合成人脸图像的多样性，从而提升了人脸识别系统的训练效果，优于现有的合成数据生成方法。

Abstract: Synthetic data has emerged as a practical alternative to authentic face datasets for training face recognition (FR) systems, especially as privacy and legal concerns increasingly restrict the use of real biometric data. Recent advances in identity-conditional diffusion models have enabled the generation of photorealistic and identity-consistent face images. However, many of these models suffer from limited intra-class variation, an essential property for training robust and generalizable FR models. In this work, we propose IDPERTURB, a simple yet effective geometric-driven sampling strategy to enhance diversity in synthetic face generation. IDPERTURB perturbs identity embeddings within a constrained angular region of the unit hyper-sphere, producing a diverse set of embeddings without modifying the underlying generative model. Each perturbed embedding serves as a conditioning vector for a pre-trained diffusion model, enabling the synthesis of visually varied yet identity-coherent face images suitable for training generalizable FR systems. Empirical results demonstrate that training FR on datasets generated using IDPERTURB yields improved performance across multiple FR benchmarks, compared to existing synthetic data generation approaches.

</details>


### [49] [CLAP Convolutional Lightweight Autoencoder for Plant Disease Classification](https://arxiv.org/abs/2602.18833)
*Asish Bera,Subhajit Roy,Sudiptendu Banerjee*

Main category: cs.CV

TL;DR: CLAP是一种轻量级自动编码器，用于植物病害分类，性能优越且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型难以捕捉植物健康、生长和病害的细微差异，现有深度学习方法计算成本高。

Method: 提出了一种轻量级自动编码器（CLAP），使用可分离卷积层构建编码器-解码器块，并通过sigmoid门控增强特征判别能力。

Result: 在三个公共植物数据集上取得改进或竞争性准确率，性能与计算成本达到平衡。

Conclusion: CLAP模型在植物病害分类任务中实现了性能与计算成本的平衡，参数仅需500万，训练时间20毫秒，推理时间1毫秒每图像。

Abstract: Convolutional neural networks have remarkably progressed the performance of distinguishing plant diseases, severity grading, and nutrition deficiency prediction using leaf images. However, these tasks become more challenging in a realistic in-situ field condition. Often, a traditional machine learning model may fail to capture and interpret discriminative characteristics of plant health, growth and diseases due to subtle variations within leaf subcategories. A few deep learning methods have used additional preprocessing stages or network modules to address the problem, whereas several other methods have utilized pre-trained backbone CNNs, most of which are computationally intensive. Therefore, to address the challenge, we propose a lightweight autoencoder using separable convolutional layers in its encoder decoder blocks. A sigmoid gating is applied for refining the prowess of the encoders feature discriminability, which is improved further by the decoder. Finally, the feature maps of the encoder decoder are combined for rich feature representation before classification. The proposed Convolutional Lightweight Autoencoder for Plant disease classification, called CLAP, has been experimented on three public plant datasets consisting of cassava, tomato, maize, groundnut, grapes, etc. for determining plant health conditions. The CLAP has attained improved or competitive accuracies on the Integrated Plant Disease, Groundnut, and CCMT datasets balancing a tradeoff between the performance, and little computational cost requiring 5 million parameters. The training time is 20 milliseconds and inference time is 1 ms per image.

</details>


### [50] [Detecting AI-Generated Forgeries via Iterative Manifold Deviation Amplification](https://arxiv.org/abs/2602.18842)
*Jiangling Zhang,Shuxuan Gao,Bofan Liu,Siqiang Feng,Jirui Huang,Yaxiong Chen,Ziyu Chen*

Main category: cs.CV

TL;DR: IFA-Net利用MAE作为真实性先验，通过两阶段处理定位AI生成图像的篡改区域，在基准测试中表现优异且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 针对现有方法难以应对新型篡改技术的局限性，提出从学习'什么是假的'转向建模'什么是真的'，利用自然图像流形的偏差定位篡改区域。

Method: 提出迭代伪造放大器网络（IFA-Net），利用预训练的掩码自编码器（MAE）作为真实性先验，通过双流分割网络（DSSN）和任务自适应先验注入（TAPI）模块实现篡改区域的粗定位与精炼。

Result: 在四个扩散修复基准测试中，IFA-Net的平均IoU和F1分数分别比次优方法提高了6.5%和8.1%，且对传统篡改类型表现出强泛化性。

Conclusion: IFA-Net通过两阶段闭环处理显著提升了AI生成图像篡改区域的定位精度，并在扩散修复基准测试中表现优异，展现了强大的泛化能力。

Abstract: The proliferation of highly realistic AI-generated images poses critical challenges for digital forensics, demanding precise pixel-level localization of manipulated regions. Existing methods predominantly learn discriminative patterns of specific forgeries and often struggle with novel manipulations as editing techniques continue to evolve. We propose the Iterative Forgery Amplifier Network (IFA-Net), which shifts from learning "what is fake" to modeling "what is real". Grounded in the principle that all manipulations deviate from the natural image manifold, IFA-Net leverages a frozen Masked Autoencoder (MAE) pretrained on real images as a universal realness prior. Our framework operates through a two-stage closed-loop process: an initial Dual-Stream Segmentation Network (DSSN) fuses the original image with MAE reconstruction residuals for coarse localization, followed by a Task-Adaptive Prior Injection (TAPI) module that converts this coarse prediction into guiding prompts to steer the MAE decoder and amplify reconstruction failures in suspicious regions for precise refinement. Extensive experiments on four diffusion-based inpainting benchmarks show that IFA-Net achieves an average improvement of 6.5% in IoU and 8.1% in F1-score over the second-best method, while demonstrating strong generalization to traditional manipulation types.

</details>


### [51] [Echoes of Ownership: Adversarial-Guided Dual Injection for Copyright Protection in MLLMs](https://arxiv.org/abs/2602.18845)
*Chengwei Xia,Fan Ma,Ruijie Quan,Yunqiu Xu,Kun Zhan,Yi Yang*

Main category: cs.CV

TL;DR: 提出一种为MLLMs生成版权触发器的框架，通过双注入对抗优化嵌入所有权信息，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着多模态大语言模型（MLLMs）的快速部署和广泛采用，模型版本归属和所有权的争议日益频繁，亟需解决知识产权保护问题。

Method: 通过将图像视为可学习张量，进行对抗优化，并结合所有权相关语义信息的双注入（文本一致性和CLIP特征距离最小化），并引入辅助模型的对抗训练阶段。

Result: 实验证明，双注入方法能在不同微调和领域迁移场景下有效追踪模型衍生版本。

Conclusion: 该论文提出的双注入框架在多种微调和领域迁移场景下，能有效追踪多模态大语言模型的衍生版本，验证了其在知识产权保护中的实用性。

Abstract: With the rapid deployment and widespread adoption of multimodal large language models (MLLMs), disputes regarding model version attribution and ownership have become increasingly frequent, raising significant concerns about intellectual property protection. In this paper, we propose a framework for generating copyright triggers for MLLMs, enabling model publishers to embed verifiable ownership information into the model. The goal is to construct trigger images that elicit ownership-related textual responses exclusively in fine-tuned derivatives of the original model, while remaining inert in other non-derivative models. Our method constructs a tracking trigger image by treating the image as a learnable tensor, performing adversarial optimization with dual-injection of ownership-relevant semantic information. The first injection is achieved by enforcing textual consistency between the output of an auxiliary MLLM and a predefined ownership-relevant target text; the consistency loss is backpropagated to inject this ownership-related information into the image. The second injection is performed at the semantic-level by minimizing the distance between the CLIP features of the image and those of the target text. Furthermore, we introduce an additional adversarial training stage involving the auxiliary model derived from the original model itself. This auxiliary model is specifically trained to resist generating ownership-relevant target text, thereby enhancing robustness in heavily fine-tuned derivative models. Extensive experiments demonstrate the effectiveness of our dual-injection approach in tracking model lineage under various fine-tuning and domain-shift scenarios.

</details>


### [52] [DUET-VLM: Dual stage Unified Efficient Token reduction for VLM Training and Inference](https://arxiv.org/abs/2602.18846)
*Aditya Kumar Singh,Hitesh Kandala,Pratik Prabhanjan Brahma,Zicheng Liu,Emad Barsoum*

Main category: cs.CV

TL;DR: DUET-VLM通过双阶段压缩框架，在减少视觉令牌的同时保持高精度，显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉令牌压缩中常以牺牲精度为代价，需一种更高效的解决方案。

Method: 提出DUET-VLM，包含视觉冗余感知压缩和文本引导的逐层令牌丢弃，实现协调的令牌管理。

Result: 在LLaVA-1.5-7B上，保持99%基线精度且减少67%令牌；在Video-LLaVA-7B中甚至超越基线。

Conclusion: DUET-VLM通过双阶段压缩框架在保持高精度的同时显著减少视觉令牌数量，实现了高效的视觉语言模型计算。

Abstract: Vision-language models (VLMs) have achieved remarkable multimodal understanding and reasoning capabilities, yet remain computationally expensive due to dense visual tokenization. Existing efficiency approaches either merge redundant visual tokens or drop them progressively in language backbone, often trading accuracy for speed. In this work, we propose DUET-VLM, a versatile plug-and-play dual compression framework that consists of (a) vision-only redundancy aware compression of vision encoder's output into information-preserving tokens, followed by (b) layer-wise, salient text-guided dropping of visual tokens within the language backbone to progressively prune less informative tokens. This coordinated token management enables aggressive compression while retaining critical semantics. On LLaVA-1.5-7B, our approach maintains over 99% of baseline accuracy with 67% fewer tokens, and still retains >97% even at 89% reduction. With this dual-stage compression during training, it achieves 99.7% accuracy at 67% and 97.6% at 89%, surpassing prior SoTA visual token reduction methods across multiple benchmarks. When integrated into Video-LLaVA-7B, it even surpasses the baseline -- achieving >100% accuracy with a substantial 53.1% token reduction and retaining 97.6% accuracy under an extreme 93.4% setting. These results highlight end-to-end training with DUET-VLM, enabling robust adaptation to reduced visual (image/video) input without sacrificing accuracy, producing compact yet semantically rich representations within the same computational budget. Our code is available at https://github.com/AMD-AGI/DUET-VLM.

</details>


### [53] [Open-Vocabulary Domain Generalization in Urban-Scene Segmentation](https://arxiv.org/abs/2602.18853)
*Dong Zhao,Qi Zang,Nan Pu,Wenjing Li,Nicu Sebe,Zhun Zhong*

Main category: cs.CV

TL;DR: 提出OVDG-SS新任务和S2-Corr机制，解决开放词汇语义分割中的领域泛化问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇语义分割模型对领域偏移敏感，尤其在自动驾驶场景中表现不佳，需同时解决未见领域和类别的问题。

Method: 提出了S2-Corr，一种基于状态空间的文本-图像相关性优化机制。

Result: 在构建的基准测试中，S2-Corr在跨域性能和效率上优于现有方法。

Conclusion: 提出的S2-Corr机制有效缓解了领域偏移对文本-图像相关性的扭曲，提升了模型在未见领域和类别中的泛化性能。

Abstract: Domain Generalization in Semantic Segmentation (DG-SS) aims to enable segmentation models to perform robustly in unseen environments. However, conventional DG-SS methods are restricted to a fixed set of known categories, limiting their applicability in open-world scenarios. Recent progress in Vision-Language Models (VLMs) has advanced Open-Vocabulary Semantic Segmentation (OV-SS) by enabling models to recognize a broader range of concepts. Yet, these models remain sensitive to domain shifts and struggle to maintain robustness when deployed in unseen environments, a challenge that is particularly severe in urban-driving scenarios. To bridge this gap, we introduce Open-Vocabulary Domain Generalization in Semantic Segmentation (OVDG-SS), a new setting that jointly addresses unseen domains and unseen categories. We introduce the first benchmark for OVDG-SS in autonomous driving, addressing a previously unexplored problem and covering both synthetic-to-real and real-to-real generalization across diverse unseen domains and unseen categories. In OVDG-SS, we observe that domain shifts often distort text-image correlations in pre-trained VLMs, which hinders the performance of OV-SS models. To tackle this challenge, we propose S2-Corr, a state-space-driven text-image correlation refinement mechanism that mitigates domain-induced distortions and produces more consistent text-image correlations under distribution changes. Extensive experiments on our constructed benchmark demonstrate that the proposed method achieves superior cross-domain performance and efficiency compared to existing OV-SS approaches.

</details>


### [54] [Joint Post-Training Quantization of Vision Transformers with Learned Prompt-Guided Data Generation](https://arxiv.org/abs/2602.18861)
*Shile Li,Markus Karmann,Onay Urfalioglu*

Main category: cs.CV

TL;DR: 提出一种无需标记数据的端到端联合量化框架，在ViT模型上实现高效低比特量化，并通过数据无关校准策略达到与真实数据校准相当的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有后训练或块级重建方法在Vision Transformers量化中的局限性，实现高效且准确的低比特量化。

Method: 通过联合优化所有层和块间依赖关系，无需标记数据，并引入基于Stable Diffusion Turbo的数据无关校准策略，生成多样化的无标签样本。

Result: 在ImageNet上实现了W4A4和W3A3的最先进准确率，并在极低比特设置（W1.58A8）下首次展示了强准确性。

Conclusion: 该论文提出了一种端到端的联合量化框架，能够在极低比特设置下保持ViT、DeiT和Swin-T模型的强准确性，展示了在边缘设备高效部署的潜力。

Abstract: We present a framework for end-to-end joint quantization of Vision Transformers trained on ImageNet for the purpose of image classification. Unlike prior post-training or block-wise reconstruction methods, we jointly optimize over the entire set of all layers and inter-block dependencies without any labeled data, scaling effectively with the number of samples and completing in just one hour on a single GPU for ViT-small. We achieve state-of-the-art W4A4 and W3A3 accuracies on ImageNet and, to the best of our knowledge, the first PTQ results that maintain strong accuracy on ViT, DeiT, and Swin-T models under extremely low-bit settings (W1.58A8), demonstrating the potential for efficient edge deployment. Furthermore, we introduce a data-free calibration strategy that synthesizes diverse, label-free samples using Stable Diffusion Turbo guided by learned multi-mode prompts. By encouraging diversity in both the learned prompt embeddings and the generated image features, our data-free approach achieves performance on par with real-data ImageNet calibration and surpasses simple text-prompt baselines such as "a <adjective> photo of <adjective> <cls>".

</details>


### [55] [Similarity-as-Evidence: Calibrating Overconfident VLMs for Interpretable and Label-Efficient Medical Active Learning](https://arxiv.org/abs/2602.18867)
*Zhuofan Xie,Zishan Lin,Jinliang Lin,Jie Qi,Shaohua Hong,Shuo Li*

Main category: cs.CV

TL;DR: SaE通过校准文本-图像相似性并量化不确定性，优化了医学影像中的主动学习样本选择，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决主动学习在医学影像中因冷启动和过自信导致的样本选择效率低下问题。

Method: SaE框架重新解释相似性向量为证据，并参数化标签的Dirichlet分布，同时采用双因素获取策略优先选择高真空度（vacuity）和高冲突（dissonance）样本。

Result: 在10个公共医学影像数据集上，SaE以20%的标注预算达到了82.57%的宏平均准确率；在BTMRI数据集上，NLL为0.425，表现出优异的校准性能。

Conclusion: SaE框架通过引入相似性证据头（SEH）和双因素获取策略，有效解决了主动学习中的冷启动问题和过自信问题，在医学影像数据集上实现了最先进的性能。

Abstract: Active Learning (AL) reduces annotation costs in medical imaging by selecting only the most informative samples for labeling, but suffers from cold-start when labeled data are scarce. Vision-Language Models (VLMs) address the cold-start problem via zero-shot predictions, yet their temperature-scaled softmax outputs treat text-image similarities as deterministic scores while ignoring inherent uncertainty, leading to overconfidence. This overconfidence misleads sample selection, wasting annotation budgets on uninformative cases. To overcome these limitations, the Similarity-as-Evidence (SaE) framework calibrates text-image similarities by introducing a Similarity Evidence Head (SEH), which reinterprets the similarity vector as evidence and parameterizes a Dirichlet distribution over labels. In contrast to a standard softmax that enforces confident predictions even under weak signals, the Dirichlet formulation explicitly quantifies lack of evidence (vacuity) and conflicting evidence (dissonance), thereby mitigating overconfidence caused by rigid softmax normalization. Building on this, SaE employs a dual-factor acquisition strategy: high-vacuity samples (e.g., rare diseases) are prioritized in early rounds to ensure coverage, while high-dissonance samples (e.g., ambiguous diagnoses) are prioritized later to refine boundaries, providing clinically interpretable selection rationales. Experiments on ten public medical imaging datasets with a 20% label budget show that SaE attains state-of-the-art macro-averaged accuracy of 82.57%. On the representative BTMRI dataset, SaE also achieves superior calibration, with a negative log-likelihood (NLL) of 0.425.

</details>


### [56] [Enhancing 3D LiDAR Segmentation by Shaping Dense and Accurate 2D Semantic Predictions](https://arxiv.org/abs/2602.18869)
*Xiaoyu Dong,Tiankui Xian,Wanshui Gan,Naoto Yokoya*

Main category: cs.CV

TL;DR: MM2D3D模型通过结合相机图像，改进LiDAR点云的2D语义预测稀疏性问题，显著提升3D语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR点云投影和3D语义标签映射为稀疏2D图时导致的中间2D语义预测稀疏和不准确问题，从而提升最终3D精度。

Method: 开发了多模态分割模型MM2D3D，利用相机图像作为辅助数据，通过跨模态引导滤波和动态交叉伪监督技术，克服LiDAR和标签图的稀疏性问题。

Result: 实验表明，该模型能够生成分布密集且更准确的中间2D语义预测，有效提升了最终3D精度，且在2D和3D空间均优于现有方法。

Conclusion: 通过引入跨模态引导滤波和动态交叉伪监督，MM2D3D模型在2D和3D空间均表现出优越性能，显著提升了3D语义分割的准确性。

Abstract: Semantic segmentation of 3D LiDAR point clouds is important in urban remote sensing for understanding real-world street environments. This task, by projecting LiDAR point clouds and 3D semantic labels as sparse maps, can be reformulated as a 2D problem. However, the intrinsic sparsity of the projected LiDAR and label maps can result in sparse and inaccurate intermediate 2D semantic predictions, which in return limits the final 3D accuracy. To address this issue, we enhance this task by shaping dense and accurate 2D predictions. Specifically, we develop a multi-modal segmentation model, MM2D3D. By leveraging camera images as auxiliary data, we introduce cross-modal guided filtering to overcome label map sparsity by constraining intermediate 2D semantic predictions with dense semantic relations derived from the camera images; and we introduce dynamic cross pseudo supervision to overcome LiDAR map sparsity by encouraging the 2D predictions to emulate the dense distribution of the semantic predictions from the camera images. Experiments show that our techniques enable our model to achieve intermediate 2D semantic predictions with dense distribution and higher accuracy, which effectively enhances the final 3D accuracy. Comparisons with previous methods demonstrate our superior performance in both 2D and 3D spaces.

</details>


### [57] [BiMotion: B-spline Motion for Text-guided Dynamic 3D Character Generation](https://arxiv.org/abs/2602.18873)
*Miaowei Wang,Qingxuan Yan,Zhi Cao,Yayuan Li,Oisin Mac Aodha,Jason J. Corso,Amir Vaxman*

Main category: cs.CV

TL;DR: BiMotion通过B样条曲线和多种优化策略，显著提升文本引导的3D角色动态生成质量，生成更连贯、高质量的运动。


<details>
  <summary>Details</summary>
Motivation: 现有方法因固定长度时间输入和离散帧表示导致生成运动有限或不连贯，无法捕捉丰富运动语义。

Method: 采用连续可微的B样条曲线表示运动，提出闭式Laplacian正则化B样条求解器压缩变长运动序列，并引入法线融合策略、对应感知和局部刚性损失函数。

Result: BiMotion在BIMO数据集上评估显示，其生成的3D运动比现有方法更具表现力、质量更高且与文本提示更一致，同时生成速度更快。

Conclusion: BiMotion框架通过连续可微的B样条曲线表示运动，结合Laplacian正则化求解器和多种损失函数，显著提升了文本引导的3D角色动态生成质量，生成的运动更具表现力、质量更高且与提示更一致。

Abstract: Text-guided dynamic 3D character generation has advanced rapidly, yet producing high-quality motion that faithfully reflects rich textual descriptions remains challenging. Existing methods tend to generate limited sub-actions or incoherent motion due to fixed-length temporal inputs and discrete frame-wise representations that fail to capture rich motion semantics. We address these limitations by representing motion with continuous differentiable B-spline curves, enabling more effective motion generation without modifying the capabilities of the underlying generative model. Specifically, our closed-form, Laplacian-regularized B-spline solver efficiently compresses variable-length motion sequences into compact representations with a fixed number of control points. Further, we introduce a normal-fusion strategy for input shape adherence along with correspondence-aware and local-rigidity losses for motion-restoration quality. To train our model, we collate BIMO, a new dataset containing diverse variable-length 3D motion sequences with rich, high-quality text annotations. Extensive evaluations show that our feed-forward framework BiMotion generates more expressive, higher-quality, and better prompt-aligned motions than existing state-of-the-art methods, while also achieving faster generation. Our project page is at: https://wangmiaowei.github.io/BiMotion.github.io/.

</details>


### [58] [Structure-Level Disentangled Diffusion for Few-Shot Chinese Font Generation](https://arxiv.org/abs/2602.18874)
*Jie Li,Suorong Yang,Jian Zhao,Furao Shen*

Main category: cs.CV

TL;DR: SLD-Font通过结构级解耦和双通道处理，显著提升少样本中文字体生成的风格保真度。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在特征级解耦后重新纠缠导致的内容失真和风格保真度下降问题。

Method: 采用结构级解耦扩散模型（SLD-Font），通过双通道分别处理内容和风格信息，结合CLIP模型提取风格特征，并训练背景噪声去除模块。

Result: 实验结果表明，SLD-Font在风格保真度上显著优于现有方法，同时保持内容准确性。

Conclusion: SLD-Font通过结构级解耦和高效的参数微调策略，在保持内容准确性的同时显著提升了风格保真度。

Abstract: Few-shot Chinese font generation aims to synthesize new characters in a target style using only a handful of reference images. Achieving accurate content rendering and faithful style transfer requires effective disentanglement between content and style. However, existing approaches achieve only feature-level disentanglement, allowing the generator to re-entangle these features, leading to content distortion and degraded style fidelity. We propose the Structure-Level Disentangled Diffusion Model (SLD-Font), which receives content and style information from two separate channels. SimSun-style images are used as content templates and concatenated with noisy latent features as the input. Style features extracted by a CLIP model from target-style images are integrated via cross-attention. Additionally, we train a Background Noise Removal module in the pixel space to remove background noise in complex stroke regions. Based on theoretical validation of disentanglement effectiveness, we introduce a parameter-efficient fine-tuning strategy that updates only the style-related modules. This allows the model to better adapt to new styles while avoiding overfitting to the reference images' content. We further introduce the Grey and OCR metrics to evaluate the content quality of generated characters. Experimental results show that SLD-Font achieves significantly higher style fidelity while maintaining comparable content accuracy to existing state-of-the-art methods.

</details>


### [59] [FOCA: Frequency-Oriented Cross-Domain Forgery Detection, Localization and Explanation via Multi-Modal Large Language Model](https://arxiv.org/abs/2602.18880)
*Zhou Liu,Tonghua Su,Hongshi Zhang,Fuxiang Yang,Donglin Di,Yang Song,Lei Fan*

Main category: cs.CV

TL;DR: FOCA是一种基于多模态大语言模型的框架，通过整合RGB空间和频域特征提升图像伪造检测性能，并提供可解释的跨域解释。


<details>
  <summary>Details</summary>
Motivation: 现有图像伪造检测方法过度依赖语义内容且缺乏对纹理线索的关注，同时低级别篡改痕迹的解释性不足。

Method: 提出FOCA框架，结合RGB空间和频域的多模态特征，通过交叉注意力融合模块实现检测和定位。

Result: FOCA在检测性能和可解释性上均优于现有方法，并在空间和频域中表现优异。

Conclusion: FOCA框架通过整合RGB空间和频域的判别特征，显著提升了图像伪造检测和定位的性能，并提供了可解释的跨域解释。

Abstract: Advances in image tampering techniques, particularly generative models, pose significant challenges to media verification, digital forensics, and public trust. Existing image forgery detection and localization (IFDL) methods suffer from two key limitations: over-reliance on semantic content while neglecting textural cues, and limited interpretability of subtle low-level tampering traces. To address these issues, we propose FOCA, a multimodal large language model-based framework that integrates discriminative features from both the RGB spatial and frequency domains via a cross-attention fusion module. This design enables accurate forgery detection and localization while providing explicit, human-interpretable cross-domain explanations. We further introduce FSE-Set, a large-scale dataset with diverse authentic and tampered images, pixel-level masks, and dual-domain annotations. Extensive experiments show that FOCA outperforms state-of-the-art methods in detection performance and interpretability across both spatial and frequency domains.

</details>


### [60] [SceneTok: A Compressed, Diffusable Token Space for 3D Scenes](https://arxiv.org/abs/2602.18882)
*Mohammad Asim,Christopher Wewer,Jan Eric Lenssen*

Main category: cs.CV

TL;DR: SceneTok 是一种新型令牌化方法，通过无序令牌高效编码3D场景，实现高质量、快速生成。


<details>
  <summary>Details</summary>
Motivation: 现有3D场景表示方法通常依赖3D数据结构或视角对齐场，存在效率和质量限制。

Method: 使用多视角分词器将场景信息编码为一组无序、排列不变的令牌，并通过轻量级整流流解码器渲染新视角。

Result: SceneTok 的压缩率比其他表示方法高1-3个数量级，同时保持最先进的重建质量，并支持快速场景生成（5秒内）。

Conclusion: SceneTok 提供了一种高效、高质量的3D场景表示和生成方法，显著提升了压缩率和生成速度。

Abstract: We present SceneTok, a novel tokenizer for encoding view sets of scenes into a compressed and diffusable set of unstructured tokens. Existing approaches for 3D scene representation and generation commonly use 3D data structures or view-aligned fields. In contrast, we introduce the first method that encodes scene information into a small set of permutation-invariant tokens that is disentangled from the spatial grid. The scene tokens are predicted by a multi-view tokenizer given many context views and rendered into novel views by employing a light-weight rectified flow decoder. We show that the compression is 1-3 orders of magnitude stronger than for other representations while still reaching state-of-the-art reconstruction quality. Further, our representation can be rendered from novel trajectories, including ones deviating from the input trajectory, and we show that the decoder gracefully handles uncertainty. Finally, the highly-compressed set of unstructured latent scene tokens enables simple and efficient scene generation in 5 seconds, achieving a much better quality-speed trade-off than previous paradigms.

</details>


### [61] [SafeDrive: Fine-Grained Safety Reasoning for End-to-End Driving in a Sparse World](https://arxiv.org/abs/2602.18887)
*Jungho Kim,Jiyong Oh,Seunghoon Yu,Hongjae Shin,Donghyuk Kwak,Jun Won Choi*

Main category: cs.CV

TL;DR: SafeDrive是一种端到端自动驾驶规划框架，通过稀疏世界模型进行安全推理，显著提升了安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 确保端到端自动驾驶框架中的安全性是一个关键挑战，SafeDrive旨在通过显式和可解释的安全推理来解决这一问题。

Method: SafeDrive由两个互补的网络组成：稀疏世界网络（SWNet）和细粒度推理网络（FRNet）。SWNet构建轨迹条件的稀疏世界，模拟关键动态代理和道路实体的未来行为；FRNet评估代理特定的碰撞风险和可驾驶区域的时间遵守情况。

Result: 在NAVSIM上，SafeDrive实现了91.6的PDMS和87.5的EPDMS，仅在12,146个场景中发生61次碰撞（0.5%）。在Bench2Drive上，驾驶得分为66.8%。

Conclusion: SafeDrive提出了一种端到端的规划框架，通过轨迹条件的稀疏世界模型进行显式和可解释的安全推理，显著提升了自动驾驶的安全性和性能。

Abstract: The end-to-end (E2E) paradigm, which maps sensor inputs directly to driving decisions, has recently attracted significant attention due to its unified modeling capability and scalability. However, ensuring safety in this unified framework remains one of the most critical challenges. In this work, we propose SafeDrive, an E2E planning framework designed to perform explicit and interpretable safety reasoning through a trajectory-conditioned Sparse World Model. SafeDrive comprises two complementary networks: the Sparse World Network (SWNet) and the Fine-grained Reasoning Network (FRNet). SWNet constructs trajectory-conditioned sparse worlds that simulate the future behaviors of critical dynamic agents and road entities, providing interaction-centric representations for downstream reasoning. FRNet then evaluates agent-specific collision risks and temporal adherence to drivable regions, enabling precise identification of safety-critical events across future timesteps. SafeDrive achieves state-of-the-art performance on both open-loop and closed-loop benchmarks. On NAVSIM, it records a PDMS of 91.6 and an EPDMS of 87.5, with only 61 collisions out of 12,146 scenarios (0.5%). On Bench2Drive, SafeDrive attains a 66.8% driving score.

</details>


### [62] [Beyond Stationarity: Rethinking Codebook Collapse in Vector Quantization](https://arxiv.org/abs/2602.18896)
*Hao Lu,Onur C. Koyun,Yongxin Guo,Zhengjie Zhu,Abbas Alili,Metin Nafi Gurcan*

Main category: cs.CV

TL;DR: 论文解释了VQ中码书坍塌的非平稳性原因，提出了NSVQ和TransVQ两种方法，显著提升了码书利用率和重建质量。


<details>
  <summary>Details</summary>
Motivation: VQ在生成框架中广泛应用，但存在码书坍塌问题，即大量码向量在训练中未被使用。

Method: 提出了两种新方法：NSVQ通过基于核的规则传播编码器漂移，TransVQ使用轻量级映射自适应变换整个码书。

Result: 在CelebA-HQ数据集上，两种方法均实现了近乎完全的码书利用率，并优于基线VQ变体。

Conclusion: 论文提出了NSVQ和TransVQ两种方法，有效解决了VQ中的码书坍塌问题，并在CelebA-HQ数据集上验证了其优越性。

Abstract: Vector Quantization (VQ) underpins many modern generative frameworks such as VQ-VAE, VQ-GAN, and latent diffusion models. Yet, it suffers from the persistent problem of codebook collapse, where a large fraction of code vectors remains unused during training. This work provides a new theoretical explanation by identifying the nonstationary nature of encoder updates as the fundamental cause of this phenomenon. We show that as the encoder drifts, unselected code vectors fail to receive updates and gradually become inactive. To address this, we propose two new methods: Non-Stationary Vector Quantization (NSVQ), which propagates encoder drift to non-selected codes through a kernel-based rule, and Transformer-based Vector Quantization (TransVQ), which employs a lightweight mapping to adaptively transform the entire codebook while preserving convergence to the k-means solution. Experiments on the CelebA-HQ dataset demonstrate that both methods achieve near-complete codebook utilization and superior reconstruction quality compared to baseline VQ variants, providing a principled and scalable foundation for future VQ-based generative models. The code is available at: https://github.com/CAIR- LAB- WFUSM/NSVQ-TransVQ.git

</details>


### [63] [SCHEMA for Gemini 3 Pro Image: A Structured Methodology for Controlled AI Image Generation on Google's Native Multimodal Model](https://arxiv.org/abs/2602.18903)
*Luca Cazzaniga*

Main category: cs.CV

TL;DR: SCHEMA是一个专为Google Gemini 3 Pro Image设计的结构化提示工程框架，显著提升了提示的合规性和生成一致性。


<details>
  <summary>Details</summary>
Motivation: 针对Google Gemini 3 Pro Image，开发一个系统化的提示工程方法，以替代通用的提示指南。

Method: SCHEMA是一个三层次渐进系统（BASE、MEDIO、AVANZATO），包含7个核心和5个可选模块化组件，以及明确的决策树和工作区规则。

Result: 在621个结构化提示中，强制合规率为91%，禁止合规率为94%，且在批量一致性测试中表现优异。

Conclusion: SCHEMA框架显著提升了结构化提示的合规性和一致性，适用于多个专业领域。

Abstract: This paper presents SCHEMA (Structured Components for Harmonized Engineered Modular Architecture), a structured prompt engineering methodology specifically developed for Google Gemini 3 Pro Image. Unlike generic prompt guidelines or model-agnostic tips, SCHEMA is an engineered framework built on systematic professional practice encompassing 850 verified API predictions within an estimated corpus of approximately 4,800 generated images, spanning six professional domains: real estate photography, commercial product photography, editorial content, storyboards, commercial campaigns, and information design. The methodology introduces a three-tier progressive system (BASE, MEDIO, AVANZATO) that scales practitioner control from exploratory (approximately 5%) to directive (approximately 95%), a modular label architecture with 7 core and 5 optional structured components, a decision tree with explicit routing rules to alternative tools, and systematically documented model limitations with corresponding workarounds. Key findings include an observed 91% Mandatory compliance rate and 94% Prohibitions compliance rate across 621 structured prompts, a comparative batch consistency test demonstrating substantially higher inter-generation coherence for structured prompts, independent practitioner validation (n=40), and a dedicated Information Design validation demonstrating >95% first-generation compliance for spatial and typographical control across approximately 300 publicly verifiable infographics. Previously published on Zenodo (doi:10.5281/zenodo.18721380).

</details>


### [64] [Marginalized Bundle Adjustment: Multi-View Camera Pose from Monocular Depth Estimates](https://arxiv.org/abs/2602.18906)
*Shengjie Zhu,Ahmed Abdelkader,Mark J. Matthews,Xiaoming Liu,Wen-Sheng Chu*

Main category: cs.CV

TL;DR: MBA方法通过边缘化束调整整合MDE深度图，显著提升了SfM和相机重定位的性能。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在单目深度估计（MDE）方面取得了进展，但如何将MDE的密集深度图有效整合到传统的SfM流程中仍是一个挑战。

Method: 提出了边缘化束调整（MBA）方法，利用MDE深度图的密度特性来降低其误差方差，从而将其整合到SfM中。

Result: 通过广泛的评估，MBA方法在不同规模的数据集上均表现出鲁棒性，从少量帧到数千张图像的多视角系统。

Conclusion: 本文展示了单目深度估计（MDE）在多视角3D视觉中的巨大潜力，通过MBA方法有效整合MDE深度图，实现了在SfM和相机重定位任务中的先进或竞争性结果。

Abstract: Structure-from-Motion (SfM) is a fundamental 3D vision task for recovering camera parameters and scene geometry from multi-view images. While recent deep learning advances enable accurate Monocular Depth Estimation (MDE) from single images without depending on camera motion, integrating MDE into SfM remains a challenge. Unlike conventional triangulated sparse point clouds, MDE produces dense depth maps with significantly higher error variance. Inspired by modern RANSAC estimators, we propose Marginalized Bundle Adjustment (MBA) to mitigate MDE error variance leveraging its density. With MBA, we show that MDE depth maps are sufficiently accurate to yield SoTA or competitive results in SfM and camera relocalization tasks. Through extensive evaluations, we demonstrate consistently robust performance across varying scales, ranging from few-frame setups to large multi-view systems with thousands of images. Our method highlights the significant potential of MDE in multi-view 3D vision.

</details>


### [65] [CRAFT-LoRA: Content-Style Personalization via Rank-Constrained Adaptation and Training-Free Fusion](https://arxiv.org/abs/2602.18936)
*Yu Li,Yujun Cai,Chi Zhang*

Main category: cs.CV

TL;DR: CRAFT-LoRA通过秩约束微调、提示引导的专家编码器和训练无关的引导方案，解决了LoRA组合中的内容-风格纠缠和不稳定问题，实现了高保真生成。


<details>
  <summary>Details</summary>
Motivation: 现有技术在内容与风格表示的纠缠、控制元素影响的指导不足以及不稳定的权重融合方面存在持续挑战。

Method: 该方法包括三个互补组件：秩约束的主干微调、提示引导的专家编码器以及训练无关的时间步依赖分类器自由引导方案。

Result: CRAFT-LoRA显著提高了内容与风格的解耦能力，实现了对LoRA模块组合的灵活语义控制，并实现了高保真生成。

Conclusion: CRAFT-LoRA显著改善了内容与风格的解耦，实现了对LoRA模块组合的灵活语义控制，并在无需额外重新训练的情况下实现了高保真生成。

Abstract: Personalized image generation requires effectively balancing content fidelity with stylistic consistency when synthesizing images based on text and reference examples. Low-Rank Adaptation (LoRA) offers an efficient personalization approach, with potential for precise control through combining LoRA weights on different concepts. However, existing combination techniques face persistent challenges: entanglement between content and style representations, insufficient guidance for controlling elements' influence, and unstable weight fusion that often require additional training. We address these limitations through CRAFT-LoRA, with complementary components: (1) rank-constrained backbone fine-tuning that injects low-rank projection residuals to encourage learning decoupled content and style subspaces; (2) a prompt-guided approach featuring an expert encoder with specialized branches that enables semantic extension and precise control through selective adapter aggregation; and (3) a training-free, timestep-dependent classifier-free guidance scheme that enhances generation stability by strategically adjusting noise predictions across diffusion steps. Our method significantly improves content-style disentanglement, enables flexible semantic control over LoRA module combinations, and achieves high-fidelity generation without additional retraining overhead.

</details>


### [66] [Global Commander and Local Operative: A Dual-Agent Framework for Scene Navigation](https://arxiv.org/abs/2602.18941)
*Kaiming Jin,Yuefan Wu,Shengqiong Wu,Bobo Li,Shuicheng Yan,Tat-Seng Chua*

Main category: cs.CV

TL;DR: DACo通过解耦全局规划和局部执行，显著提升了长视野导航的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因多智能体协调成本高或单智能体认知过载导致的推理能力下降和指令漂移问题。

Method: DACo采用全局指挥官（Global Commander）进行高层战略规划，局部执行者（Local Operative）负责局部感知和细粒度执行，并结合动态子目标规划和自适应重规划。

Result: 在R2R、REVERIE和R4R上，DACo在零样本设置中分别实现了4.9%、6.5%和5.4%的绝对性能提升，并能有效泛化到不同骨干模型。

Conclusion: DACo通过解耦全局规划和局部执行，提供了一个可扩展且稳健的长视野导航范式，显著提升了导航性能。

Abstract: Vision-and-Language Scene navigation is a fundamental capability for embodied human-AI collaboration, requiring agents to follow natural language instructions to execute coherent action sequences in complex environments. Existing approaches either rely on multiple agents, incurring high coordination and resource costs, or adopt a single-agent paradigm, which overloads the agent with both global planning and local perception, often leading to degraded reasoning and instruction drift in long-horizon settings. To address these issues, we introduce DACo, a planning-grounding decoupled architecture that disentangles global deliberation from local grounding. Concretely, it employs a Global Commander for high-level strategic planning and a Local Operative for egocentric observing and fine-grained execution. By disentangling global reasoning from local action, DACo alleviates cognitive overload and improves long-horizon stability. The framework further integrates dynamic subgoal planning and adaptive replanning to enable structured and resilient navigation. Extensive evaluations on R2R, REVERIE, and R4R demonstrate that DACo achieves 4.9%, 6.5%, 5.4% absolute improvements over the best-performing baselines in zero-shot settings, and generalizes effectively across both closed-source (e.g., GPT-4o) and open-source (e.g., Qwen-VL Series) backbones. DACo provides a principled and extensible paradigm for robust long-horizon navigation. Project page: https://github.com/ChocoWu/DACo

</details>


### [67] [YOLOv10-Based Multi-Task Framework for Hand Localization and Laterality Classification in Surgical Videos](https://arxiv.org/abs/2602.18959)
*Kedi Sun,Le Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于YOLOv10的实时手部追踪框架，用于创伤外科手术中的手部定位和左右性分类，表现出良好的分类准确率和实时性能。


<details>
  <summary>Details</summary>
Motivation: 实时手部追踪在创伤外科手术中对于支持快速和精确的术中决策至关重要。

Method: 提出了一个基于YOLOv10的框架，用于在复杂手术场景中同时定位手并分类其左右性（左或右）。模型在Trauma THOMPSON Challenge 2025 Task 2数据集上进行训练，该数据集包含带有标注手部边界框的第一人称手术视频。通过广泛的数据增强和多任务检测设计，提高了对运动模糊、光照变化和多样化手部外观的鲁棒性。

Result: 评估显示，左手的分类准确率为67%，右手的分类准确率为71%，但从背景中区分手部仍具有挑战性。模型实现了0.33的$mAP_{[0.5:0.95]}$，并保持实时推理能力，突显了其在术中部署的潜力。

Conclusion: 本研究为紧急外科手术中手与器械交互的高级分析奠定了基础。

Abstract: Real-time hand tracking in trauma surgery is essential for supporting rapid and precise intraoperative decisions. We propose a YOLOv10-based framework that simultaneously localizes hands and classifies their laterality (left or right) in complex surgical scenes. The model is trained on the Trauma THOMPSON Challenge 2025 Task 2 dataset, consisting of first-person surgical videos with annotated hand bounding boxes. Extensive data augmentation and a multi-task detection design improve robustness against motion blur, lighting variations, and diverse hand appearances. Evaluation demonstrates accurate left-hand (67\%) and right-hand (71\%) classification, while distinguishing hands from the background remains challenging. The model achieves an $mAP_{[0.5:0.95]}$ of 0.33 and maintains real-time inference, highlighting its potential for intraoperative deployment. This work establishes a foundation for advanced hand-instrument interaction analysis in emergency surgical procedures.

</details>


### [68] [Depth-Enhanced YOLO-SAM2 Detection for Reliable Ballast Insufficiency Identification](https://arxiv.org/abs/2602.18961)
*Shiyu Liu,Dylan Lester,Husnu Narman,Ammar Alzarrad,Pingping Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度校正的YOLO-SAM2框架，显著提升了铁路道砟不足检测的性能，召回率和F1分数均有大幅提升。


<details>
  <summary>Details</summary>
Motivation: 尽管YOLOv8在定位上表现可靠，但仅基于RGB的模型在安全性能上有限（高精度但低召回率），尤其在道砟不足时易过度预测充足类别。

Method: 提出了一种基于RGB-D数据的深度增强YOLO-SAM2框架，结合了基于深度的几何分析（通过枕木对齐的深度校正管道实现）和SAM2分割来优化感兴趣区域掩码。

Result: 实验表明，深度增强配置显著提升了道砟不足的检测性能，召回率从0.49提升至0.80，F1分数从0.66提升至超过0.80。

Conclusion: 整合深度校正与YOLO-SAM2的方法显著提升了铁路道砟不足检测的鲁棒性和可靠性，特别是在视觉模糊或安全关键场景中。

Abstract: This paper presents a depth-enhanced YOLO-SAM2 framework for detecting ballast insufficiency in railway tracks using RGB-D data. Although YOLOv8 provides reliable localization, the RGB-only model shows limited safety performance, achieving high precision (0.99) but low recall (0.49) due to insufficient ballast, as it tends to over-predict the sufficient class. To improve reliability, we incorporate depth-based geometric analysis enabled by a sleeper-aligned depth-correction pipeline that compensates for RealSense spatial distortion using polynomial modeling, RANSAC, and temporal smoothing. SAM2 segmentation further refines region-of-interest masks, enabling accurate extraction of sleeper and ballast profiles for geometric classification.
  Experiments on field-collected top-down RGB-D data show that depth-enhanced configurations substantially improve the detection of insufficient ballast. Depending on bounding-box sampling (AABB or RBB) and geometric criteria, recall increases from 0.49 to as high as 0.80, and F1-score improves from 0.66 to over 0.80. These results demonstrate that integrating depth correction with YOLO-SAM2 yields a more robust and reliable approach for automated railway ballast inspection, particularly in visually ambiguous or safety-critical scenarios.

</details>


### [69] [Face Presentation Attack Detection via Content-Adaptive Spatial Operators](https://arxiv.org/abs/2602.18965)
*Shujaat Khan*

Main category: cs.CV

TL;DR: CASO-PAD 是一种轻量级、单帧的 RGB 面部呈现攻击检测模型，通过内容自适应空间算子提升性能，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 面部呈现攻击检测（FacePAD）对于保护面部认证免受打印、重放和基于掩码的欺骗至关重要。

Method: 本文提出了一种基于 MobileNetV3 的改进模型 CASO-PAD，通过内容自适应空间算子（involution）增强局部欺骗线索的捕捉能力。该算子生成位置特定、通道共享的核，提高了空间选择性，同时保持轻量级（3.6M 参数；0.64 GFLOPs）。

Result: 在多个数据集（Replay-Attack、Replay-Mobile、ROSE-Youtu、OULU-NPU）上表现出色，测试准确率分别为 100/100/98.9/99.7%，AUC 为 1.00/1.00/0.9995/0.9999，HTER 为 0.00/0.00/0.82/0.44%。在 SiW-Mv2 Protocol-1 基准测试中，准确率为 95.45%，HTER 为 3.11%，EER 为 3.13%。

Conclusion: CASO-PAD 提供了一种实用的方法，用于在移动设备上实现稳健的面部呈现攻击检测，无需辅助传感器或时间堆栈。

Abstract: Face presentation attack detection (FacePAD) is critical for securing facial authentication against print, replay, and mask-based spoofing. This paper proposes CASO-PAD, an RGB-only, single-frame model that enhances MobileNetV3 with content-adaptive spatial operators (involution) to better capture localized spoof cues. Unlike spatially shared convolution kernels, the proposed operator generates location-specific, channel-shared kernels conditioned on the input, improving spatial selectivity with minimal overhead. CASO-PAD remains lightweight (3.6M parameters; 0.64 GFLOPs at $256\times256$) and is trained end-to-end using a standard binary cross-entropy objective. Extensive experiments on Replay-Attack, Replay-Mobile, ROSE-Youtu, and OULU-NPU demonstrate strong performance, achieving 100/100/98.9/99.7\% test accuracy, AUC of 1.00/1.00/0.9995/0.9999, and HTER of 0.00/0.00/0.82/0.44\%, respectively. On the large-scale SiW-Mv2 Protocol-1 benchmark, CASO-PAD further attains 95.45\% accuracy with 3.11\% HTER and 3.13\% EER, indicating improved robustness under diverse real-world attacks. Ablation studies show that placing the adaptive operator near the network head and using moderate group sharing yields the best accuracy--efficiency balance. Overall, CASO-PAD provides a practical pathway for robust, on-device FacePAD with mobile-class compute and without auxiliary sensors or temporal stacks.

</details>


### [70] [Frame2Freq: Spectral Adapters for Fine-Grained Video Understanding](https://arxiv.org/abs/2602.18977)
*Thinesh Thiyakesan Ponbagavathi,Constantin Seibold,Alina Roitberg*

Main category: cs.CV

TL;DR: Frame2Freq是一种频率感知适配器，通过FFT和频段特定嵌入提升图像到视频迁移中的细粒度动作识别性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有时间域适配器仅关注单一时间尺度，忽略了中速运动，而多时间尺度的动态捕捉对细粒度时间分析至关重要。

Method: 提出了Frame2Freq，一种频率感知适配器，利用快速傅里叶变换（FFT）进行频谱编码，学习特定频段的嵌入以自适应突出最具区分性的频率范围。

Result: 在五个细粒度活动识别数据集上，Frame2Freq优于先前的PEFT方法，并在四个数据集上超越了完全微调的模型。

Conclusion: Frame2Freq通过频率分析显著提升了图像到视频迁移中的细粒度动作识别性能，证明了频域方法在建模时间动态中的有效性。

Abstract: Adapting image-pretrained backbones to video typically relies on time-domain adapters tuned to a single temporal scale. Our experiments show that these modules pick up static image cues and very fast flicker changes, while overlooking medium-speed motion. Capturing dynamics across multiple time-scales is, however, crucial for fine-grained temporal analysis (i.e., opening vs. closing bottle).
  To address this, we introduce Frame2Freq -- a family of frequency-aware adapters that perform spectral encoding during image-to-video adaptation of pretrained Vision Foundation Models (VFMs), improving fine-grained action recognition. Frame2Freq uses Fast Fourier Transform (FFT) along time and learns frequency-band specific embeddings that adaptively highlight the most discriminative frequency ranges. Across five fine-grained activity recognition datasets, Frame2Freq outperforms prior PEFT methods and even surpasses fully fine-tuned models on four of them. These results provide encouraging evidence that frequency analysis methods are a powerful tool for modeling temporal dynamics in image-to-video transfer. Code is available at https://github.com/th-nesh/Frame2Freq.

</details>


### [71] [IDSelect: A RL-Based Cost-Aware Selection Agent for Video-based Multi-Modal Person Recognition](https://arxiv.org/abs/2602.18990)
*Yuyang Ji,Yixuan Shen,Kien Nguyen,Lifeng Zhou,Feng Liu*

Main category: cs.CV

TL;DR: IDSelect利用强化学习动态选择模型，显著提升视频人物识别的效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有系统固定使用重型多模态集成，计算资源浪费严重，需优化准确性与效率的平衡。

Method: 采用基于强化学习的成本感知选择器（IDSelect），通过演员-评论家算法训练轻量级代理，动态选择每个模态的预训练模型。

Result: 在CCVID数据集上，IDSelect以92.4%的计算节省实现95.9% Rank-1准确率，提升1.8%；在MEVID上节省41.3%计算量，性能保持竞争力。

Conclusion: IDSelect通过强化学习选择最优模型组合，显著提升了视频人物识别的计算效率与准确性。

Abstract: Video-based person recognition achieves robust identification by integrating face, body, and gait. However, current systems waste computational resources by processing all modalities with fixed heavyweight ensembles regardless of input complexity. To address these limitations, we propose IDSelect, a reinforcement learning-based cost-aware selector that chooses one pre-trained model per modality per-sequence to optimize the accuracy-efficiency trade-off. Our key insight is that an input-conditioned selector can discover complementary model choices that surpass fixed ensembles while using substantially fewer resources. IDSelect trains a lightweight agent end-to-end using actor-critic reinforcement learning with budget-aware optimization. The reward balances recognition accuracy with computational cost, while entropy regularization prevents premature convergence. At inference, the policy selects the most probable model per modality and fuses modality-specific similarities for the final score. Extensive experiments on challenging video-based datasets demonstrate IDSelect's superior efficiency: on CCVID, it achieves 95.9% Rank-1 accuracy with 92.4% less computation than strong baselines while improving accuracy by 1.8%; on MEVID, it reduces computation by 41.3% while maintaining competitive performance.

</details>


### [72] [SeaCache: Spectral-Evolution-Aware Cache for Accelerating Diffusion Models](https://arxiv.org/abs/2602.18993)
*Jiwoo Chung,Sangeek Hyun,MinKyu Lee,Byeongju Han,Geonho Cha,Dongyoon Wee,Youngjun Hong,Jae-Pil Heo*

Main category: cs.CV

TL;DR: SeaCache是一种光谱演化感知的缓存策略，通过动态调度提升扩散模型推理速度，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视觉生成中表现强大，但其固有的顺序去噪过程导致推理速度慢。现有缓存策略基于原始特征差异，忽略了光谱演化（低频结构早期出现，高频细节后期细化）的影响。

Method: 提出了一种名为SeaCache的免训练缓存调度方法，利用光谱对齐表示来决定缓存的重用决策。通过理论和实证分析，推导出一个光谱演化感知（SEA）过滤器，用于保留内容相关组件并抑制噪声。

Result: 在多种视觉生成模型和基线上的大量实验表明，SeaCache实现了最先进的延迟-质量权衡。

Conclusion: SeaCache通过引入光谱演化感知的缓存策略，显著提升了扩散模型的推理速度，同时保持了生成质量，实现了最佳的延迟-质量权衡。

Abstract: Diffusion models are a strong backbone for visual generation, but their inherently sequential denoising process leads to slow inference. Previous methods accelerate sampling by caching and reusing intermediate outputs based on feature distances between adjacent timesteps. However, existing caching strategies typically rely on raw feature differences that entangle content and noise. This design overlooks spectral evolution, where low-frequency structure appears early and high-frequency detail is refined later. We introduce Spectral-Evolution-Aware Cache (SeaCache), a training-free cache schedule that bases reuse decisions on a spectrally aligned representation. Through theoretical and empirical analysis, we derive a Spectral-Evolution-Aware (SEA) filter that preserves content-relevant components while suppressing noise. Employing SEA-filtered input features to estimate redundancy leads to dynamic schedules that adapt to content while respecting the spectral priors underlying the diffusion model. Extensive experiments on diverse visual generative models and the baselines show that SeaCache achieves state-of-the-art latency-quality trade-offs.

</details>


### [73] [TeFlow: Enabling Multi-frame Supervision for Self-Supervised Feed-forward Scene Flow Estimation](https://arxiv.org/abs/2602.19053)
*Qingwen Zhang,Chenhan Jiang,Xiaomeng Zhu,Yunqi Miao,Yushan Zhang,Olov Andersson,Patric Jensfelt*

Main category: cs.CV

TL;DR: TeFlow通过时间集成策略实现多帧监督，显著提升自监督前馈场景流估计性能，速度快150倍。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督前馈方法在两帧点对应监督下不可靠且易受遮挡影响，多帧监督虽潜力巨大，但简单的两帧目标扩展效果不佳。

Method: TeFlow采用时间集成策略，从多帧构建的候选池中聚合最一致的运动线索，形成可靠的监督信号。

Result: TeFlow在Argoverse 2和nuScenes数据集上实现了33%的性能提升，与领先的优化方法性能相当，但速度快150倍。

Conclusion: TeFlow通过引入时间集成策略，在多帧监督下显著提升了自监督前馈模型的场景流估计性能，达到了与领先的基于优化的方法相当的效果，同时速度提升了150倍。

Abstract: Self-supervised feed-forward methods for scene flow estimation offer real-time efficiency, but their supervision from two-frame point correspondences is unreliable and often breaks down under occlusions. Multi-frame supervision has the potential to provide more stable guidance by incorporating motion cues from past frames, yet naive extensions of two-frame objectives are ineffective because point correspondences vary abruptly across frames, producing inconsistent signals. In the paper, we present TeFlow, enabling multi-frame supervision for feed-forward models by mining temporally consistent supervision. TeFlow introduces a temporal ensembling strategy that forms reliable supervisory signals by aggregating the most temporally consistent motion cues from a candidate pool built across multiple frames. Extensive evaluations demonstrate that TeFlow establishes a new state-of-the-art for self-supervised feed-forward methods, achieving performance gains of up to 33\% on the challenging Argoverse 2 and nuScenes datasets. Our method performs on par with leading optimization-based methods, yet speeds up 150 times. The code is open-sourced at https://github.com/KTH-RPL/OpenSceneFlow along with trained model weights.

</details>


### [74] [Learning Cross-View Object Correspondence via Cycle-Consistent Mask Prediction](https://arxiv.org/abs/2602.18996)
*Shannan Yan,Leqi Zheng,Keyu Lv,Jingchen Ni,Hongyang Wei,Jiajun Zhang,Guangting Wang,Jing Lyu,Chun Yuan,Fengyun Rao*

Main category: cs.CV

TL;DR: 通过条件二元分割和循环一致性训练，实现跨视角物体对应，无需标注，性能最优。


<details>
  <summary>Details</summary>
Motivation: 研究跨视角（尤其是第一人称到第三人称及反之）的物体级视觉对应任务，解决视角差异带来的挑战。

Method: 采用条件二元分割框架，将物体查询掩码编码为潜在表示以指导目标视频中的物体定位，并通过循环一致性训练目标（预测掩码回投影至源视图以重建原始查询掩码）增强鲁棒性。

Result: 在Ego-Exo4D和HANDAL-X基准测试中表现优异，实现了最先进的性能。

Conclusion: 该论文提出了一种基于条件二元分割的框架，通过循环一致性训练目标实现了跨视角的物体级视觉对应，无需真实标注，且在Ego-Exo4D和HANDAL-X基准测试中达到了最先进性能。

Abstract: We study the task of establishing object-level visual correspondence across different viewpoints in videos, focusing on the challenging egocentric-to-exocentric and exocentric-to-egocentric scenarios. We propose a simple yet effective framework based on conditional binary segmentation, where an object query mask is encoded into a latent representation to guide the localization of the corresponding object in a target video. To encourage robust, view-invariant representations, we introduce a cycle-consistency training objective: the predicted mask in the target view is projected back to the source view to reconstruct the original query mask. This bidirectional constraint provides a strong self-supervisory signal without requiring ground-truth annotations and enables test-time training (TTT) at inference. Experiments on the Ego-Exo4D and HANDAL-X benchmarks demonstrate the effectiveness of our optimization objective and TTT strategy, achieving state-of-the-art performance. The code is available at https://github.com/shannany0606/CCMP.

</details>


### [75] [A Benchmark and Knowledge-Grounded Framework for Advanced Multimodal Personalization Study](https://arxiv.org/abs/2602.19001)
*Xia Hu,Honglei Zhuang,Brian Potetz,Alireza Fathi,Bo Hu,Babak Samari,Howard Zhou*

Main category: cs.CV

TL;DR: Life-Bench是一个基于模拟用户数字足迹的综合多模态基准，评估从人物理解到历史数据复杂推理的能力。LifeGraph框架通过知识图谱提升性能，但高级个性化任务仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型的强大推理能力为高级个性化研究开辟了新领域，但缺乏合适的基准严重阻碍了这一领域的进展。

Method: 我们提出了LifeGraph，一个端到端的框架，将个人上下文组织成知识图谱，以促进结构化检索和推理。

Result: 在Life-Bench上的实验显示，现有方法在复杂个性化任务上表现不佳，尤其是在关系、时间和聚合推理方面存在较大性能差距。LifeGraph通过利用结构化知识显著缩小了这一差距。

Conclusion: LifeGraph通过结构化知识缩小了性能差距，展示了有前景的方向，但高级个性化任务仍是一个关键的开放挑战，需要进一步研究。

Abstract: The powerful reasoning of modern Vision Language Models open a new frontier for advanced personalization study. However, progress in this area is critically hampered by the lack of suitable benchmarks. To address this gap, we introduce Life-Bench, a comprehensive, synthetically generated multimodal benchmark built on simulated user digital footprints. Life-Bench features over questions evaluating a wide spectrum of capabilities, from persona understanding to complex reasoning over historical data. These capabilities expand far beyond prior benchmarks, reflecting the critical demands essential for real-world applications. Furthermore, we propose LifeGraph, an end-to-end framework that organizes personal context into a knowledge graph to facilitate structured retrieval and reasoning. Our experiments on Life-Bench reveal that existing methods falter significantly on complex personalized tasks, exposing a large performance headroom, especially in relational, temporal and aggregative reasoning. While LifeGraph closes this gap by leveraging structured knowledge and demonstrates a promising direction, these advanced personalization tasks remain a critical open challenge, motivating new research in this area.

</details>


### [76] [Universal Pose Pretraining for Generalizable Vision-Language-Action Policies](https://arxiv.org/abs/2602.19710)
*Haitao Lin,Hanyang Yu,Jingshun Huang,He Zhang,Yonggen Ling,Ping Tan,Xiangyang Xue,Yanwei Fu*

Main category: cs.CV

TL;DR: Pose-VLA 通过解耦训练范式，解决了VLA模型的效率问题，并在多个测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因将高级感知与稀疏的、特定于实体的动作监督纠缠在一起，导致特征崩溃和训练效率低下。

Method: Pose-VLA 采用两阶段预训练流程，首先通过离散姿态令牌提取通用3D空间先验，随后在机器人特定动作空间中进行高效的实体对齐。

Result: Pose-VLA 在RoboTwin 2.0上取得了79.5%的平均成功率，在LIBERO上达到了96.0%的竞争性性能，并在现实世界中展示了强大的泛化能力。

Conclusion: Pose-VLA 通过解耦训练范式，有效解决了现有VLA模型的特征崩溃和训练效率低下的问题，并在多个基准测试中取得了最先进的性能。

Abstract: Existing Vision-Language-Action (VLA) models often suffer from feature collapse and low training efficiency because they entangle high-level perception with sparse, embodiment-specific action supervision. Since these models typically rely on VLM backbones optimized for Visual Question Answering (VQA), they excel at semantic identification but often overlook subtle 3D state variations that dictate distinct action patterns.
  To resolve these misalignments, we propose Pose-VLA, a decoupled paradigm that separates VLA training into a pre-training phase for extracting universal 3D spatial priors in a unified camera-centric space, and a post-training phase for efficient embodiment alignment within robot-specific action space. By introducing discrete pose tokens as a universal representation, Pose-VLA seamlessly integrates spatial grounding from diverse 3D datasets with geometry-level trajectories from robotic demonstrations. Our framework follows a two-stage pre-training pipeline, establishing fundamental spatial grounding via poses followed by motion alignment through trajectory supervision.
  Extensive evaluations demonstrate that Pose-VLA achieves state-of-the-art results on RoboTwin 2.0 with a 79.5% average success rate and competitive performance on LIBERO at 96.0%. Real-world experiments further showcase robust generalization across diverse objects using only 100 demonstrations per task, validating the efficiency of our pre-training paradigm.

</details>


### [77] [MoBind: Motion Binding for Fine-Grained IMU-Video Pose Alignment](https://arxiv.org/abs/2602.19004)
*Duc Duy Nguyen,Tat-Jun Chin,Minh Hoai*

Main category: cs.CV

TL;DR: MoBind is a hierarchical contrastive learning framework for joint representation of IMU and 2D pose sequences, excelling in cross-modal tasks.


<details>
  <summary>Details</summary>
Motivation: To learn a joint representation between IMU signals and 2D pose sequences for accurate cross-modal retrieval, temporal synchronization, subject and body-part localization, and action recognition.

Method: MoBind, a hierarchical contrastive learning framework, aligns IMU signals with skeletal motion sequences, decomposes full-body motion into local body-part trajectories, and employs a hierarchical contrastive strategy for detailed temporal correspondence.

Result: Evaluated on mRi, TotalCapture, and EgoHumans, MoBind shows superior performance in all tasks.

Conclusion: MoBind consistently outperforms strong baselines across all four tasks, demonstrating robust fine-grained temporal alignment while preserving coarse semantic consistency across modalities.

Abstract: We aim to learn a joint representation between inertial measurement unit (IMU) signals and 2D pose sequences extracted from video, enabling accurate cross-modal retrieval, temporal synchronization, subject and body-part localization, and action recognition. To this end, we introduce MoBind, a hierarchical contrastive learning framework designed to address three challenges: (1) filtering out irrelevant visual background, (2) modeling structured multi-sensor IMU configurations, and (3) achieving fine-grained, sub-second temporal alignment. To isolate motion-relevant cues, MoBind aligns IMU signals with skeletal motion sequences rather than raw pixels. We further decompose full-body motion into local body-part trajectories, pairing each with its corresponding IMU to enable semantically grounded multi-sensor alignment. To capture detailed temporal correspondence, MoBind employs a hierarchical contrastive strategy that first aligns token-level temporal segments, then fuses local (body-part) alignment with global (body-wide) motion aggregation. Evaluated on mRi, TotalCapture, and EgoHumans, MoBind consistently outperforms strong baselines across all four tasks, demonstrating robust fine-grained temporal alignment while preserving coarse semantic consistency across modalities. Code is available at https://github.com/bbvisual/ MoBind.

</details>


### [78] [MeanFuser: Fast One-Step Multi-Modal Trajectory Generation and Adaptive Reconstruction via MeanFlow for End-to-End Autonomous Driving](https://arxiv.org/abs/2602.20060)
*Junli Wang,Xueyi Liu,Yinan Zheng,Zebing Xing,Pengfei Li,Guang Li,Kun Ma,Guang Chen,Hangjun Ye,Zhongpu Xia,Long Chen,Qichao Zhang*

Main category: cs.CV

TL;DR: MeanFuser通过GMN、MeanFlow Identity和ARM设计，解决了离散锚词汇模型的局限性，提升了自动驾驶轨迹规划的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散锚词汇的生成模型在轨迹规划中存在词汇量大小与模型性能的权衡问题，限制了模型的鲁棒性和效率。

Method: 1. 引入高斯混合噪声（GMN）指导生成采样，实现轨迹空间的连续表示；2. 采用MeanFlow Identity建模GMN与轨迹分布之间的平均速度场，消除ODE求解器的数值误差；3. 设计轻量级自适应重建模块（ARM），通过注意力权重选择或重建轨迹。

Result: MeanFuser在NAVSIM闭环基准测试中表现优异，无需PDM Score监督，且推理效率显著提升。

Conclusion: MeanFuser提出了一种端到端的自动驾驶方法，通过高斯混合噪声（GMN）、MeanFlow Identity和自适应重建模块（ARM）的设计，显著提升了模型的效率和鲁棒性。实验表明，MeanFuser在NAVSIM闭环基准测试中表现出色，无需PDM Score监督，且推理效率高。

Abstract: Generative models have shown great potential in trajectory planning. Recent studies demonstrate that anchor-guided generative models are effective in modeling the uncertainty of driving behaviors and improving overall performance. However, these methods rely on discrete anchor vocabularies that must sufficiently cover the trajectory distribution during testing to ensure robustness, inducing an inherent trade-off between vocabulary size and model performance. To overcome this limitation, we propose MeanFuser, an end-to-end autonomous driving method that enhances both efficiency and robustness through three key designs. (1) We introduce Gaussian Mixture Noise (GMN) to guide generative sampling, enabling a continuous representation of the trajectory space and eliminating the dependency on discrete anchor vocabularies. (2) We adapt ``MeanFlow Identity" to end-to-end planning, which models the mean velocity field between GMN and trajectory distribution instead of the instantaneous velocity field used in vanilla flow matching methods, effectively eliminating numerical errors from ODE solvers and significantly accelerating inference. (3) We design a lightweight Adaptive Reconstruction Module (ARM) that enables the model to implicitly select from all sampled proposals or reconstruct a new trajectory when none is satisfactory via attention weights. Experiments on the NAVSIM closed-loop benchmark demonstrate that MeanFuser achieves outstanding performance without the supervision of the PDM Score. and exceptional inference efficiency, offering a robust and efficient solution for end-to-end autonomous driving. Our code and model are available at https://github.com/wjl2244/MeanFuser.

</details>


### [79] [GUIDE-US: Grade-Informed Unpaired Distillation of Encoder Knowledge from Histopathology to Micro-UltraSound](https://arxiv.org/abs/2602.19005)
*Emma Willis,Tarek Elghareb,Paul F. R. Wilson,Minh Nguyen Nhat To,Mohammad Mahdi Abootorabi,Amoon Jamzad,Brian Wodlinger,Parvin Mousavi,Purang Abolmaesumi*

Main category: cs.CV

TL;DR: 该论文提出了一种无配对的病理学知识蒸馏方法，通过微超声模拟病理学模型嵌入分布，显著提升了前列腺癌分级的敏感性和临床可行性。


<details>
  <summary>Details</summary>
Motivation: 非侵入性前列腺癌（PCa）分级可从微超声（micro-US）中加速分诊并引导活检至最具侵袭性的区域，但现有模型难以在粗糙成像分辨率下推断组织微结构。

Method: 引入了一种无配对的病理学知识蒸馏策略，训练微超声编码器以模拟预训练的病理学基础模型的嵌入分布，条件基于国际泌尿病理学会（ISUP）分级。训练无需患者级配对或图像配准，且在推理时不使用病理学输入。

Result: 与当前最先进技术相比，该方法在60%特异性下对临床显著PCa（csPCa）的敏感性提高了3.5%，整体敏感性提高了1.2%。

Conclusion: 通过仅从影像中实现更早、更可靠的癌症风险分层，该方法提升了临床可行性。源代码将在发表后公开。

Abstract: Purpose: Non-invasive grading of prostate cancer (PCa) from micro-ultrasound (micro-US) could expedite triage and guide biopsies toward the most aggressive regions, yet current models struggle to infer tissue micro-structure at coarse imaging resolutions.
  Methods: We introduce an unpaired histopathology knowledge-distillation strategy that trains a micro-US encoder to emulate the embedding distribution of a pretrained histopathology foundation model, conditioned on International Society of Urological Pathology (ISUP) grades. Training requires no patient-level pairing or image registration, and histopathology inputs are not used at inference.
  Results: Compared to the current state of the art, our approach increases sensitivity to clinically significant PCa (csPCa) at 60% specificity by 3.5% and improves overall sensitivity at 60% specificity by 1.2%.
  Conclusion: By enabling earlier and more dependable cancer risk stratification solely from imaging, our method advances clinical feasibility. Source code will be publicly released upon publication.

</details>


### [80] [DEFNet: Multitasks-based Deep Evidential Fusion Network for Blind Image Quality Assessment](https://arxiv.org/abs/2507.19418)
*Yiwei Lou,Yuanpeng He,Rongchao Zhang,Yongzhi Cao,Hanpin Wang,Yu Huang*

Main category: cs.CV

TL;DR: DEFNet通过多任务优化和可信信息融合策略，提升了盲图像质量评估性能，实验验证了其有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有盲图像质量评估方法因集成不足和缺乏灵活的不确定性估计而性能不佳，DEFNet旨在解决这些问题。

Method: 提出了一种基于多任务的深度证据融合网络（DEFNet），结合场景和失真类型分类任务进行优化，设计了可信信息融合策略，并利用正态-逆伽马分布混合进行不确定性估计。

Result: 在合成和真实失真数据集上的广泛实验证明了DEFNet的有效性和鲁棒性，展示了其强大的泛化能力和对未知场景的适应性。

Conclusion: DEFNet通过多任务优化和可信信息融合策略，显著提升了盲图像质量评估的性能，并在合成和真实失真数据集上验证了其有效性和鲁棒性。

Abstract: Blind image quality assessment (BIQA) methods often incorporate auxiliary tasks to improve performance. However, existing approaches face limitations due to insufficient integration and a lack of flexible uncertainty estimation, leading to suboptimal performance. To address these challenges, we propose a multitasks-based Deep Evidential Fusion Network (DEFNet) for BIQA, which performs multitask optimization with the assistance of scene and distortion type classification tasks. To achieve a more robust and reliable representation, we design a novel trustworthy information fusion strategy. It first combines diverse features and patterns across sub-regions to enhance information richness, and then performs local-global information fusion by balancing fine-grained details with coarse-grained context. Moreover, DEFNet exploits advanced uncertainty estimation technique inspired by evidential learning with the help of normal-inverse gamma distribution mixture. Extensive experiments on both synthetic and authentic distortion datasets demonstrate the effectiveness and robustness of the proposed framework. Additional evaluation and analysis are carried out to highlight its strong generalization capability and adaptability to previously unseen scenarios.

</details>


### [81] [A Very Big Video Reasoning Suite](https://arxiv.org/abs/2602.20159)
*Maijunxian Wang,Ruisi Wang,Juyi Lin,Ran Ji,Thaddäus Wiedemer,Qingying Gao,Dezhi Luo,Yaoyao Qian,Lianyu Huang,Zelong Hong,Jiahui Ge,Qianli Ma,Hang He,Yifan Zhou,Lingzi Guo,Lantao Mei,Jiachen Li,Hanwen Xing,Tianqi Zhao,Fengyuan Yu,Weihang Xiao,Yizheng Jiao,Jianheng Hou,Danyang Zhang,Pengcheng Xu,Boyang Zhong,Zehong Zhao,Gaoyun Fang,John Kitaoka,Yile Xu,Hua Xu,Kenton Blacutt,Tin Nguyen,Siyuan Song,Haoran Sun,Shaoyue Wen,Linyang He,Runming Wang,Yanzhi Wang,Mengyue Yang,Ziqiao Ma,Raphaël Millière,Freda Shi,Nuno Vasconcelos,Daniel Khashabi,Alan Yuille,Yilun Du,Ziming Liu,Bo Li,Dahua Lin,Ziwei Liu,Vikash Kumar,Yijiang Li,Lei Yang,Zhongang Cai,Hokin Deng*

Main category: cs.CV

TL;DR: VBVR数据集和评估框架填补了视频推理研究的空白，支持大规模扩展研究并观察到泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视频模型的快速发展主要集中在视觉质量上，而推理能力未被充分探索。缺乏大规模训练数据阻碍了视频推理及其扩展行为的系统性研究。

Method: 引入了VBVR数据集，包含200个推理任务和超过100万个视频片段，并开发了VBVR-Bench评估框架，结合基于规则和人类对齐的评分器。

Result: VBVR数据集和VBVR-Bench框架填补了大规模视频推理数据的空白，支持了可扩展性研究，并展示了早期泛化能力。

Conclusion: VBVR数据集和VBVR-Bench评估框架为视频推理研究奠定了基础，支持大规模扩展研究，并观察到对未见推理任务的早期泛化迹象。

Abstract: Rapid progress in video models has largely focused on visual quality, leaving their reasoning capabilities underexplored. Video reasoning grounds intelligence in spatiotemporally consistent visual environments that go beyond what text can naturally capture, enabling intuitive reasoning over spatiotemporal structure such as continuity, interaction, and causality. However, systematically studying video reasoning and its scaling behavior is hindered by the lack of large-scale training data. To address this gap, we introduce the Very Big Video Reasoning (VBVR) Dataset, an unprecedentedly large-scale resource spanning 200 curated reasoning tasks following a principled taxonomy and over one million video clips, approximately three orders of magnitude larger than existing datasets. We further present VBVR-Bench, a verifiable evaluation framework that moves beyond model-based judging by incorporating rule-based, human-aligned scorers, enabling reproducible and interpretable diagnosis of video reasoning capabilities. Leveraging the VBVR suite, we conduct one of the first large-scale scaling studies of video reasoning and observe early signs of emergent generalization to unseen reasoning tasks. Together, VBVR lays a foundation for the next stage of research in generalizable video reasoning. The data, benchmark toolkit, and models are publicly available at https://video-reason.com/ .

</details>


### [82] [TokenTrace: Multi-Concept Attribution through Watermarked Token Recovery](https://arxiv.org/abs/2602.19019)
*Li Zhang,Shruti Agarwal,John Collomosse,Pengtao Xie,Vishal Asnani*

Main category: cs.CV

TL;DR: TokenTrace 是一种新型水印框架，通过语义域嵌入和查询机制实现多概念归属，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 生成式 AI 模型可能未经授权复制独特艺术风格和概念，现有水印方法在复杂场景中难以解耦和归属多概念。

Method: 通过同时扰动文本提示嵌入和初始潜在噪声，在语义域中嵌入秘密签名，并使用基于查询的 TokenTrace 模块进行检索。

Result: TokenTrace 在单概念和多概念归属任务中均达到最先进性能，同时保持高视觉质量和鲁棒性。

Conclusion: TokenTrace 是一种新颖的水印框架，能够在复杂场景中实现多概念归属，显著优于现有基线方法。

Abstract: Generative AI models pose a significant challenge to intellectual property (IP), as they can replicate unique artistic styles and concepts without attribution. While watermarking offers a potential solution, existing methods often fail in complex scenarios where multiple concepts (e.g., an object and an artistic style) are composed within a single image. These methods struggle to disentangle and attribute each concept individually. In this work, we introduce TokenTrace, a novel proactive watermarking framework for robust, multi-concept attribution. Our method embeds secret signatures into the semantic domain by simultaneously perturbing the text prompt embedding and the initial latent noise that guide the diffusion model's generation process. For retrieval, we propose a query-based TokenTrace module that takes the generated image and a textual query specifying which concepts need to be retrieved (e.g., a specific object or style) as inputs. This query-based mechanism allows the module to disentangle and independently verify the presence of multiple concepts from a single generated image. Extensive experiments show that our method achieves state-of-the-art performance on both single-concept (object and style) and multi-concept attribution tasks, significantly outperforming existing baselines while maintaining high visual quality and robustness to common transformations.

</details>


### [83] [NI-Tex: Non-isometric Image-based Garment Texture Generation](https://arxiv.org/abs/2511.18765)
*Hui Shan,Ming Li,Haitao Yang,Kai Zheng,Sizhe Zheng,Yanwei Fu,Xiangru Huang*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过构建数据集和迭代烘焙技术，解决了非等距图像服装纹理生成的挑战，生成了高质量的PBR材质。


<details>
  <summary>Details</summary>
Motivation: 现有工业3D服装网格的纹理多样性有限，且现有方法对输入图像和3D网格的拓扑一致性要求严格，限制了纹理生成的灵活性和质量。

Method: 构建了3D Garment Videos数据集，利用物理模拟提供一致的几何和材质监督；采用Nano Banana进行高质量非等距图像编辑；提出基于不确定性引导的视图选择和重加权迭代烘焙方法。

Result: 实现了非等距图像-几何对之间的跨拓扑纹理生成，生成了无缝、可直接用于生产的PBR纹理。

Conclusion: 通过大量实验验证，本文提出的前馈双分支架构能够生成适用于工业级3D服装设计的多样化且空间对齐的PBR材质。

Abstract: Existing industrial 3D garment meshes already cover most real-world clothing geometries, yet their texture diversity remains limited. To acquire more realistic textures, generative methods are often used to extract Physically-based Rendering (PBR) textures and materials from large collections of wild images and project them back onto garment meshes. However, most image-conditioned texture generation approaches require strict topological consistency between the input image and the input 3D mesh, or rely on accurate mesh deformation to match to the image poses, which significantly constrains the texture generation quality and flexibility. To address the challenging problem of non-isometric image-based garment texture generation, we construct 3D Garment Videos, a physically simulated, garment-centric dataset that provides consistent geometry and material supervision across diverse deformations, enabling robust cross-pose texture learning. We further employ Nano Banana for high-quality non-isometric image editing, achieving reliable cross-topology texture generation between non-isometric image-geometry pairs. Finally, we propose an iterative baking method via uncertainty-guided view selection and reweighting that fuses multi-view predictions into seamless, production-ready PBR textures. Through extensive experiments, we demonstrate that our feedforward dual-branch architecture generates versatile and spatially aligned PBR materials suitable for industry-level 3D garment design.

</details>


### [84] [An interpretable framework using foundation models for fish sex identification](https://arxiv.org/abs/2602.19022)
*Zheng Miao,Tien-Chieh Hung*

Main category: cs.CV

TL;DR: FishProtoNet是一种非侵入性计算机视觉框架，用于三角洲胡瓜鱼的性别鉴定，在产卵阶段表现良好，但亚成体阶段仍有挑战。


<details>
  <summary>Details</summary>
Motivation: 现有鱼类性别鉴定方法多为侵入性或应激性，可能增加濒危鱼类的死亡率，因此需要开发非侵入性且稳健的方法。

Method: FishProtoNet结合了视觉基础模型提取鱼类感兴趣区域（ROIs）、特征提取及基于可解释原型网络的性别鉴定。

Result: FishProtoNet在早期产卵和产卵后阶段的性别鉴定准确率分别为74.40%和81.16%，F1分数为74.27%和79.43%，但在亚成体阶段表现较差。

Conclusion: FishProtoNet是一种非侵入性的计算机视觉框架，用于濒危鱼类三角洲胡瓜鱼（Hypomesus transpacificus）的性别鉴定，展示了在不同生命阶段的良好性能，但在亚成体阶段仍存在挑战。

Abstract: Accurate sex identification in fish is vital for optimizing breeding and management strategies in aquaculture, particularly for species at the risk of extinction. However, most existing methods are invasive or stressful and may cause additional mortality, posing severe risks to threatened or endangered fish populations. To address these challenges, we propose FishProtoNet, a robust, non-invasive computer vision-based framework for sex identification of delta smelt (Hypomesus transpacificus), an endangered fish species native to California, across its full life cycle. Unlike the traditional deep learning methods, FishProtoNet provides interpretability through learned prototype representations while improving robustness by leveraging foundation models to reduce the influence of background noise. Specifically, the FishProtoNet framework consists of three key components: fish regions of interest (ROIs) extraction using visual foundation model, feature extraction from fish ROIs and fish sex identification based on an interpretable prototype network. FishProtoNet demonstrates strong performance in delta smelt sex identification during early spawning and post-spawning stages, achieving the accuracies of 74.40% and 81.16% and corresponding F1 scores of 74.27% and 79.43% respectively. In contrast, delta smelt sex identification at the subadult stage remains challenging for current computer vision methods, likely due to less pronounced morphological differences in immature fish. The source code of FishProtoNet is publicly available at: https://github.com/zhengmiao1/Fish_sex_identification

</details>


### [85] [Towards Calibrating Prompt Tuning of Vision-Language Models](https://arxiv.org/abs/2602.19024)
*Ashshak Sharifdeen,Fahad Shamshad,Muhammad Akhtar Munir,Abhishek Basu,Mohamed Insaf Ismithdeen,Jeyapriyan Jeyamohan,Chathurika Sewwandi Silva,Karthik Nandakumar,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: 提出一种校准框架，通过两种正则化器提升CLIP提示调优的预测可靠性，显著降低ECE。


<details>
  <summary>Details</summary>
Motivation: 解决大规模视觉语言模型（如CLIP）在提示调优中常出现的置信度校准不佳和预测不确定性不可靠的问题。

Method: 通过两种互补的正则化器扩展标准交叉熵损失：1）均值-方差边际惩罚，通过最大化平均值并最小化离散度来稳定类间logit边际；2）文本矩匹配损失，调整文本嵌入的第一和第二矩与冻结CLIP对应项对齐。

Result: 在7种提示调优方法和11个不同数据集上的广泛实验表明，该方法在基类和新型类上均显著降低了ECE。

Conclusion: 提出的校准框架显著降低了预期校准误差（ECE），同时保持了预训练CLIP嵌入空间的几何结构，提升了预测可靠性。

Abstract: Prompt tuning of large-scale vision-language models such as CLIP enables efficient task adaptation without updating model weights. However, it often leads to poor confidence calibration and unreliable predictive uncertainty. We address this problem by proposing a calibration framework that enhances predictive reliability while preserving the geometry of the pretrained CLIP embedding space, which is required for robust generalization. Our approach extends the standard cross-entropy loss with two complementary regularizers: (1) a mean-variance margin penalty that stabilizes inter-class logit margins by maximizing their average while minimizing dispersion, mitigating underconfidence and overconfidence spikes; and (2) a text moment-matching loss that aligns the first and second moments of tuned text embeddings with their frozen CLIP counterparts, preserving semantic dispersion crucial for generalization. Through extensive experiments across 7 prompt-tuning methods and 11 diverse datasets, we demonstrate that our approach significantly reduces the Expected Calibration Error (ECE) compared to competitive calibration techniques on both base and novel classes

</details>


### [86] [OpenVO: Open-World Visual Odometry with Temporal Dynamics Awareness](https://arxiv.org/abs/2602.19035)
*Phuc D. A. Nguyen,Anh N. Nhu,Ming C. Lin*

Main category: cs.CV

TL;DR: OpenVO是一种新颖的开放世界视觉里程计框架，通过编码时间动态信息和利用3D几何先验，显著提升了在未校准相机和变化观测频率下的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VO方法在固定观测频率下训练，忽略了时间动态信息，且许多方法需要已知内参的校准相机，这限制了其在未见过观测频率或未校准相机下的泛化能力。

Method: OpenVO 通过在两帧姿态回归框架中显式编码时间动态信息，并利用基础模型衍生的3D几何先验，解决了现有VO方法的局限性。

Result: 在KITTI、nuScenes和Argoverse 2三个主要自动驾驶基准测试中，OpenVO比最先进方法性能提升超过20%，在变化观测率设置下误差降低46%-92%。

Conclusion: OpenVO 展示了其在现实世界3D重建和多样化下游应用中的多功能性，显著提升了性能并降低了误差。

Abstract: We introduce OpenVO, a novel framework for Open-world Visual Odometry (VO) with temporal awareness under limited input conditions. OpenVO effectively estimates real-world-scale ego-motion from monocular dashcam footage with varying observation rates and uncalibrated cameras, enabling robust trajectory dataset construction from rare driving events recorded in dashcam. Existing VO methods are trained on fixed observation frequency (e.g., 10Hz or 12Hz), completely overlooking temporal dynamics information. Many prior methods also require calibrated cameras with known intrinsic parameters. Consequently, their performance degrades when (1) deployed under unseen observation frequencies or (2) applied to uncalibrated cameras. These significantly limit their generalizability to many downstream tasks, such as extracting trajectories from dashcam footage. To address these challenges, OpenVO (1) explicitly encodes temporal dynamics information within a two-frame pose regression framework and (2) leverages 3D geometric priors derived from foundation models. We validate our method on three major autonomous-driving benchmarks - KITTI, nuScenes, and Argoverse 2 - achieving more than 20 performance improvement over state-of-the-art approaches. Under varying observation rate settings, our method is significantly more robust, achieving 46%-92% lower errors across all metrics. These results demonstrate the versatility of OpenVO for real-world 3D reconstruction and diverse downstream applications.

</details>


### [87] [Direction-aware 3D Large Multimodal Models](https://arxiv.org/abs/2602.19063)
*Quan Liu,Weihao Xuan,Junjue Wang,Naoto Yokoya,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: 本文通过补充自我姿态和调整点云数据，解决了3D LMMs中方向感知的问题，提出两种新设计并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有3D LMMs依赖自我姿态进行方向性问答和空间推理，但大多数点云基准缺乏对应的自我姿态，导致问题定义不严谨。

Method: 提出了PoseRecover（自动姿态恢复管道）和PoseAlign（点云数据对齐）两种新设计，用于识别和补充自我姿态并调整点云数据。

Result: 实验表明，该方法在多个3D LMM骨干模型（如LL3DA、LL3DA-SONATA等）上均取得一致改进，ScanRefer mIoU提升30.0%，Scan2Cap LLM-as-judge准确率提升11.7%。

Conclusion: 本文提出了一种新的范式，通过补充点云基准中的自我姿态并调整点云数据，实现了方向感知的3D大型多模态模型（3D LMMs）。该方法简单、通用且训练高效，仅需指令调整即可建立强基线。

Abstract: 3D large multimodal models (3D LMMs) rely heavily on ego poses for enabling directional question-answering and spatial reasoning. However, most existing point cloud benchmarks contain rich directional queries but lack the corresponding ego poses, making them inherently ill-posed in 3D large multimodal modelling. In this work, we redefine a new and rigorous paradigm that enables direction-aware 3D LMMs by identifying and supplementing ego poses into point cloud benchmarks and transforming the corresponding point cloud data according to the identified ego poses. We enable direction-aware 3D LMMs with two novel designs. The first is PoseRecover, a fully automatic pose recovery pipeline that matches questions with ego poses from RGB-D video extrinsics via object-frustum intersection and visibility check with Z-buffers. The second is PoseAlign that transforms the point cloud data to be aligned with the identified ego poses instead of either injecting ego poses into textual prompts or introducing pose-encoded features in the projection layers. Extensive experiments show that our designs yield consistent improvements across multiple 3D LMM backbones such as LL3DA, LL3DA-SONATA, Chat-Scene, and 3D-LLAVA, improving ScanRefer mIoU by 30.0% and Scan2Cap LLM-as-judge accuracy by 11.7%. In addition, our approach is simple, generic, and training-efficient, requiring only instruction tuning while establishing a strong baseline for direction-aware 3D-LMMs.

</details>


### [88] [L3DR: 3D-aware LiDAR Diffusion and Rectification](https://arxiv.org/abs/2602.19064)
*Quan Liu,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: L3DR是一个3D感知的LiDAR扩散和校正框架，通过3D残差回归网络和Welsch Loss提升几何真实感，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基于Range-view的LiDAR扩散方法在2D照片真实感方面取得了进展，但忽视了3D几何真实感，导致出现深度渗漏和波浪表面等伪影。

Method: 设计了一个3D残差回归网络，用于预测3D空间中的点级偏移，以纠正RV伪影，并结合Welsch Loss来有效关注局部几何结构。

Result: 在KITTI、KITTI360、nuScenes和Waymo等多个基准测试中，L3DR实现了最先进的生成效果和卓越的几何真实感。

Conclusion: L3DR框架通过3D残差回归网络和Welsch Loss的设计，显著提升了LiDAR扩散模型的几何真实感，并在多个基准测试中达到了最先进的生成效果。

Abstract: Range-view (RV) based LiDAR diffusion has recently made huge strides towards 2D photo-realism. However, it neglects 3D geometry realism and often generates various RV artifacts such as depth bleeding and wavy surfaces. We design L3DR, a 3D-aware LiDAR Diffusion and Rectification framework that can regress and cancel RV artifacts in 3D space and restore local geometry accurately. Our theoretical and empirical analysis reveals that 3D models are inherently superior to 2D models in generating sharp and authentic boundaries. Leveraging such analysis, we design a 3D residual regression network that rectifies RV artifacts and achieves superb geometry realism by predicting point-level offsets in 3D space. On top of that, we design a Welsch Loss that helps focus on local geometry and ignore anomalous regions effectively. Extensive experiments over multiple benchmarks including KITTI, KITTI360, nuScenes and Waymo show that the proposed L3DR achieves state-of-the-art generation and superior geometry-realism consistently. In addition, L3DR is generally applicable to different LiDAR diffusion models with little computational overhead.

</details>


### [89] [ChordEdit: One-Step Low-Energy Transport for Image Editing](https://arxiv.org/abs/2602.19083)
*Liangsi Lu,Xuhang Chen,Minzhe Guo,Shichu Li,Jingchao Wang,Yang Shi*

Main category: cs.CV

TL;DR: ChordEdit是一种无需训练、无需反演的通用方法，通过动态最优传输理论实现高效单步图像编辑，解决了现有方法在单步推理中的失真问题。


<details>
  <summary>Details</summary>
Motivation: 现有的一步文本到图像（T2I）模型在文本引导的图像编辑中因单步推理导致对象严重失真和非编辑区域一致性丢失，亟需解决。

Method: 将编辑问题重新定义为源和目标文本提示定义的分布之间的传输问题，并利用动态最优传输理论推导出低能量控制策略，生成平滑、方差减少的编辑场。

Result: ChordEdit能够实现高保真度的单步编辑，提供快速、轻量且精确的编辑效果，最终在这些具有挑战性的模型上实现真正的实时编辑。

Conclusion: ChordEdit通过动态最优传输理论提供了一种稳定、高效的单步图像编辑方法，成功解决了现有方法在单步推理中的失真问题，实现了真正的实时编辑。

Abstract: The advent of one-step text-to-image (T2I) models offers unprecedented synthesis speed. However, their application to text-guided image editing remains severely hampered, as forcing existing training-free editors into a single inference step fails. This failure manifests as severe object distortion and a critical loss of consistency in non-edited regions, resulting from the high-energy, erratic trajectories produced by naive vector arithmetic on the models' structured fields. To address this problem, we introduce ChordEdit, a model agnostic, training-free, and inversion-free method that facilitates high-fidelity one-step editing. We recast editing as a transport problem between the source and target distributions defined by the source and target text prompts. Leveraging dynamic optimal transport theory, we derive a principled, low-energy control strategy. This strategy yields a smoothed, variance-reduced editing field that is inherently stable, facilitating the field to be traversed in a single, large integration step. A theoretically grounded and experimentally validated approach allows ChordEdit to deliver fast, lightweight and precise edits, finally achieving true real-time editing on these challenging models.

</details>


### [90] [Restoration-Guided Kuzushiji Character Recognition Framework under Seal Interference](https://arxiv.org/abs/2602.19086)
*Rui-Yang Ju,Kohei Yamashita,Hirotaka Kameko,Shinsuke Mori*

Main category: cs.CV

TL;DR: 本文提出RG-KCR框架，通过三阶段设计解决印章干扰下的Kuzushiji字符识别问题，实验显示其在检测和分类任务中性能优越。


<details>
  <summary>Details</summary>
Motivation: 由于Kuzushiji字符的高度草书形式和广泛字形变化，现代读者难以直接解读。现有方法在印章干扰下识别准确率下降，而印章在历史文档中频繁出现，因此需要解决这一挑战。

Method: 采用三阶段恢复引导的Kuzushiji字符识别（RG-KCR）框架，包括字符检测（Stage 1）、恢复（Stage 2）和分类（Stage 3）。具体使用了YOLOv12-medium模型进行检测，基于ViT的Metom模型进行分类。

Result: YOLOv12-medium模型在测试集上达到98.0%的精确率和93.3%的召回率。恢复阶段（Stage 2）显著提升了分类模型的Top-1准确率，从93.45%提高到95.33%。

Conclusion: 本文提出的RG-KCR框架通过三个阶段的设计有效缓解了印章干扰对Kuzushiji字符识别的影响，实验结果表明该方法在检测和分类任务上均取得了显著提升。

Abstract: Kuzushiji was one of the most popular writing styles in pre-modern Japan and was widely used in both personal letters and official documents. However, due to its highly cursive forms and extensive glyph variations, most modern Japanese readers cannot directly interpret Kuzushiji characters. Therefore, recent research has focused on developing automated Kuzushiji character recognition methods, which have achieved satisfactory performance on relatively clean Kuzushiji document images. However, existing methods struggle to maintain recognition accuracy under seal interference (e.g., when seals overlap characters), despite the frequent occurrence of seals in pre-modern Japanese documents. To address this challenge, we propose a three-stage restoration-guided Kuzushiji character recognition (RG-KCR) framework specifically designed to mitigate seal interference. We construct datasets for evaluating Kuzushiji character detection (Stage 1) and classification (Stage 3). Experimental results show that the YOLOv12-medium model achieves a precision of 98.0% and a recall of 93.3% on the constructed test set. We quantitatively evaluate the restoration performance of Stage 2 using PSNR and SSIM. In addition, we conduct an ablation study to demonstrate that Stage 2 improves the Top-1 accuracy of Metom, a Vision Transformer (ViT)-based Kuzushiji classifier employed in Stage 3, from 93.45% to 95.33%. The implementation code of this work is available at https://ruiyangju.github.io/RG-KCR.

</details>


### [91] [CREM: Compression-Driven Representation Enhancement for Multimodal Retrieval and Comprehension](https://arxiv.org/abs/2602.19091)
*Lihao Liu,Yan Wang,Biao Yang,Da Li,Jiangxia Cao,Yuxiao Luo,Xiang Chen,Xiangyu Wu,Wei Yuan,Fan Yang,Guiguang Ding,Tingting Gao,Guorui Zhou*

Main category: cs.CV

TL;DR: CREM是一个统一框架，通过压缩驱动的方法提升多模态检索性能，同时保留生成能力，实验证明其在检索和生成任务上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在检索任务中表现不佳，且传统方法通过对比微调会损失生成能力。作者认为生成和嵌入任务共享认知机制，因此需要一个统一框架来兼顾两者。

Method: 提出了CREM（压缩驱动的表示增强模型），采用基于压缩的提示设计和可学习的chorus tokens来聚合多模态语义，并通过压缩感知注意力整合对比和生成目标。

Result: CREM在MMEB上实现了最先进的检索性能，同时在多个理解基准上保持了强大的生成性能。

Conclusion: CREM模型通过压缩驱动的范式，在保持生成能力的同时提升了多模态检索性能，证明了生成监督可以进一步提高MLLMs的表征质量。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable success in comprehension tasks such as visual description and visual question answering. However, their direct application to embedding-based tasks like retrieval remains challenging due to the discrepancy between output formats and optimization objectives. Previous approaches often employ contrastive fine-tuning to adapt MLLMs for retrieval, but at the cost of losing their generative capabilities. We argue that both generative and embedding tasks fundamentally rely on shared cognitive mechanisms, specifically cross-modal representation alignment and contextual comprehension. To this end, we propose CREM (Compression-driven Representation Enhanced Model), with a unified framework that enhances multimodal representations for retrieval while preserving generative ability. Specifically, we introduce a compression-based prompt design with learnable chorus tokens to aggregate multimodal semantics and a compression-driven training strategy that integrates contrastive and generative objectives through compression-aware attention. Extensive experiments demonstrate that CREM achieves state-of-the-art retrieval performance on MMEB while maintaining strong generative performance on multiple comprehension benchmarks. Our findings highlight that generative supervision can further improve the representational quality of MLLMs under the proposed compression-driven paradigm.

</details>


### [92] [Universal 3D Shape Matching via Coarse-to-Fine Language Guidance](https://arxiv.org/abs/2602.19112)
*Qinfeng Xiao,Guofeng Mei,Bo Yang,Liying Zhang,Jian Zhang,Kit-lun Yick*

Main category: cs.CV

TL;DR: UniMatch 是一个语义感知的从粗到细框架，用于构建强非等距形状间的密集语义对应，不限制对象类别，通过类无关分割和语言引导实现通用匹配。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖近等距假设和同类对象（如仅适用于人体形状），而跨类别对象的语义对应构建具有挑战性且研究较少。

Method: UniMatch 采用从粗到细的两阶段框架：粗阶段通过类无关3D分割和大型语言模型识别语义部分，构建匹配的语义部分；细阶段利用粗对应关系通过基于排名的对比方案指导密集对应学习。

Result: 大量实验表明，UniMatch 在各种挑战性场景中 consistently 优于竞争方法。

Conclusion: UniMatch 通过类无关分割、语言引导和基于排名的对比学习，实现了跨类别和非等距形状的通用匹配，并在各种挑战性场景中表现优于现有方法。

Abstract: Establishing dense correspondences between shapes is a crucial task in computer vision and graphics, while prior approaches depend on near-isometric assumptions and homogeneous subject types (i.e., only operate for human shapes). However, building semantic correspondences for cross-category objects remains challenging and has received relatively little attention. To achieve this, we propose UniMatch, a semantic-aware, coarse-to-fine framework for constructing dense semantic correspondences between strongly non-isometric shapes without restricting object categories. The key insight is to lift "coarse" semantic cues into "fine" correspondence, which is achieved through two stages. In the "coarse" stage, we perform class-agnostic 3D segmentation to obtain non-overlapping semantic parts and prompt multimodal large language models (MLLMs) to identify part names. Then, we employ pretrained vision language models (VLMs) to extract text embeddings, enabling the construction of matched semantic parts. In the "fine" stage, we leverage these coarse correspondences to guide the learning of dense correspondences through a dedicated rank-based contrastive scheme. Thanks to class-agnostic segmentation, language guiding, and rank-based contrastive learning, our method is versatile for universal object categories and requires no predefined part proposals, enabling universal matching for inter-class and non-isometric shapes. Extensive experiments demonstrate UniMatch consistently outperforms competing methods in various challenging scenarios.

</details>


### [93] [Keep it SymPL: Symbolic Projective Layout for Allocentric Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2602.19117)
*Jaeyun Jang,Seunghui Shin,Taeho Park,Hyoseok Hwang*

Main category: cs.CV

TL;DR: SymPL框架通过符号化布局转换，有效提升视觉语言模型在异中心空间推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在异中心视角下的空间推理表现较差，而这一视角在现实场景中具有重要意义，因此需要一种有效的方法来提升其性能。

Method: 引入Symbolic Projective Layout（SymPL）框架，通过投影、抽象、二分和定位四个关键因素，将异中心问题转化为结构化符号布局表示。

Result: 实验表明，SymPL显著提升了模型在异中心和自我中心任务中的表现，并增强了鲁棒性，各组件对性能提升均有关键贡献。

Conclusion: SymPL框架通过将异中心空间推理转化为符号布局形式，显著提升了视觉语言模型在异中心和自我中心任务中的表现，并增强了在视觉错觉和多视角场景下的鲁棒性。

Abstract: Perspective-aware spatial reasoning involves understanding spatial relationships from specific viewpoints-either egocentric (observer-centered) or allocentric (object-centered). While vision-language models (VLMs) perform well in egocentric settings, their performance deteriorates when reasoning from allocentric viewpoints, where spatial relations must be inferred from the perspective of objects within the scene. In this study, we address this underexplored challenge by introducing Symbolic Projective Layout (SymPL), a framework that reformulates allocentric reasoning into symbolic-layout forms that VLMs inherently handle well. By leveraging four key factors-projection, abstraction, bipartition, and localization-SymPL converts allocentric questions into structured symbolic-layout representations. Extensive experiments demonstrate that this reformulation substantially improves performance in both allocentric and egocentric tasks, enhances robustness under visual illusions and multi-view scenarios, and that each component contributes critically to these gains. These results show that SymPL provides an effective and principled approach for addressing complex perspective-aware spatial reasoning.

</details>


### [94] [StreetTree: A Large-Scale Global Benchmark for Fine-Grained Tree Species Classification](https://arxiv.org/abs/2602.19123)
*Jiapeng Li,Yingjing Huang,Fan Zhang,Yu liu*

Main category: cs.CV

TL;DR: StreetTree是首个专为细粒度街道树木分类设计的大规模基准数据集，包含1200万张图像，覆盖8300多种树种，来自133个国家，旨在解决该领域数据缺乏的问题，并通过实验展示了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏专门针对街道树木的大规模、地理多样且公开可用的基准数据集，细粒度街道树木分类领域的发展受到严重阻碍。

Method: 引入了StreetTree数据集，包含来自133个国家、超过8300种常见街道树种的1200万张图像，并辅以专家验证的观测数据。

Result: 通过多种视觉模型的广泛实验，建立了强大的基线，并揭示了现有方法在处理现实世界复杂性方面的局限性。

Conclusion: StreetTree数据集将成为城市街道树木精细化管理和研究的关键资源，并推动计算机视觉与城市科学交叉领域的新进展。

Abstract: The fine-grained classification of street trees is a crucial task for urban planning, streetscape management, and the assessment of urban ecosystem services. However, progress in this field has been significantly hindered by the lack of large-scale, geographically diverse, and publicly available benchmark datasets specifically designed for street trees. To address this critical gap, we introduce StreetTree, the world's first large-scale benchmark dataset dedicated to fine-grained street tree classification. The dataset contains over 12 million images covering more than 8,300 common street tree species, collected from urban streetscapes across 133 countries spanning five continents, and supplemented with expert-verified observational data. StreetTree poses substantial challenges for pretrained vision models under complex urban environments: high inter-species visual similarity, long-tailed natural distributions, significant intra-class variations caused by seasonal changes, and diverse imaging conditions such as lighting, occlusions from buildings, and varying camera angles. In addition, we provide a hierarchical taxonomy (order-family-genus-species) to support research in hierarchical classification and representation learning. Through extensive experiments with various visual models, we establish strong baselines and reveal the limitations of existing methods in handling such real-world complexities. We believe that StreetTree will serve as a key resource for the refined management and research of urban street trees, while also driving new advancements at the intersection of computer vision and urban science.

</details>


### [95] [Mapping Networks](https://arxiv.org/abs/2602.19134)
*Lord Sen,Shyamapada Mukherjee*

Main category: cs.CV

TL;DR: Mapping Networks用低维潜在向量替代高维权重空间，减少99.5%参数并保持性能，解决过拟合和训练效率问题。


<details>
  <summary>Details</summary>
Motivation: 现代深度学习模型参数数量激增，导致训练效率低下和过拟合问题严重，需要一种高效的方法来减少参数数量并保持性能。

Method: 提出Mapping Networks，基于大网络训练参数位于平滑低维流形的假设，通过Mapping Loss强制映射定理，实现从潜在空间到目标权重空间的映射。

Result: 在复杂视觉和序列任务（如图像分类、Deepfake检测等）中，Mapping Networks减少了99.5%的可训练参数（约500倍），性能与目标网络相当或更好。

Conclusion: Mapping Networks通过将高维权重空间替换为紧凑的可训练潜在向量，显著减少了过拟合并实现了与目标网络相当或更好的性能，同时大幅降低了可训练参数数量。

Abstract: The escalating parameter counts in modern deep learning models pose a fundamental challenge to efficient training and resolution of overfitting. We address this by introducing the \emph{Mapping Networks} which replace the high dimensional weight space by a compact, trainable latent vector based on the hypothesis that the trained parameters of large networks reside on smooth, low-dimensional manifolds. Henceforth, the Mapping Theorem enforced by a dedicated Mapping Loss, shows the existence of a mapping from this latent space to the target weight space both theoretically and in practice. Mapping Networks significantly reduce overfitting and achieve comparable to better performance than target network across complex vision and sequence tasks, including Image Classification, Deepfake Detection etc, with $\mathbf{99.5\%}$, i.e., around $500\times$ reduction in trainable parameters.

</details>


### [96] [CaReFlow: Cyclic Adaptive Rectified Flow for Multimodal Fusion](https://arxiv.org/abs/2602.19140)
*Sijie Mai,Shiqin Han*

Main category: cs.CV

TL;DR: 提出一种基于修正流的多模态融合方法，通过一对多映射和自适应对齐策略减少模态差距，效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常专注于一对一对齐，未能充分利用目标模态的全局分布信息，限制了多模态融合的效果。

Method: 扩展修正流用于模态分布映射，采用‘一对多映射’策略，设计‘自适应松弛对齐’和‘循环修正流’以防止信息丢失。

Result: 在多模态情感计算任务中取得了竞争性结果，可视化验证了模态差距的有效减少。

Conclusion: 通过引入修正流和自适应松弛对齐策略，该方法在多模态情感计算任务中显著减少了模态差距，并取得了竞争性的结果。

Abstract: Modality gap significantly restricts the effectiveness of multimodal fusion. Previous methods often use techniques such as diffusion models and adversarial learning to reduce the modality gap, but they typically focus on one-to-one alignment without exposing the data points of the source modality to the global distribution information of the target modality. To this end, leveraging the characteristic of rectified flow that can map one distribution to another via a straight trajectory, we extend rectified flow for modality distribution mapping. Specifically, we leverage the `one-to-many mapping' strategy in rectified flow that allows each data point of the source modality to observe the overall target distribution. This also alleviates the issue of insufficient paired data within each sample, enabling a more robust distribution transformation. Moreover, to achieve more accurate distribution mapping and address the ambiguous flow directions in one-to-many mapping, we design `adaptive relaxed alignment', enforcing stricter alignment for modality pairs belonging to the same sample, while applying relaxed mapping for pairs not belonging to the same sample or category. Additionally, to prevent information loss during distribution mapping, we introduce `cyclic rectified flow' to ensure the transferred features can be translated back to the original features, allowing multimodal representations to learn sufficient modality-specific information. After distribution alignment, our approach achieves very competitive results on multiple tasks of multimodal affective computing even with a simple fusion method, and visualizations verify that it can effectively reduce the modality gap.

</details>


### [97] [VIGiA: Instructional Video Guidance via Dialogue Reasoning and Retrieval](https://arxiv.org/abs/2602.19146)
*Diogo Glória-Silva,David Semedo,João Maglhães*

Main category: cs.CV

TL;DR: VIGiA 是一种多模态对话模型，通过多模态计划推理和基于计划的检索，显著提升了对教学视频动作计划的理解和对话能力。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注纯文本指导或将视觉与语言分离，VIGiA 旨在支持基于视觉和语言的多模态、计划感知的对话。

Method: VIGiA 结合了多模态计划推理和基于计划的检索能力，支持对视觉输入、教学计划和用户交互的联合推理。

Result: 在烹饪和 DIY 教学视频对话数据集上，VIGiA 在对话计划指导任务中表现优异，计划感知 VQA 准确率超过 90%。

Conclusion: VIGiA 是一种新型多模态对话模型，能够在复杂的多步骤教学视频动作计划中进行理解和推理，显著优于现有最先进模型。

Abstract: We introduce VIGiA, a novel multimodal dialogue model designed to understand and reason over complex, multi-step instructional video action plans. Unlike prior work which focuses mainly on text-only guidance, or treats vision and language in isolation, VIGiA supports grounded, plan-aware dialogue that requires reasoning over visual inputs, instructional plans, and interleaved user interactions. To this end, VIGiA incorporates two key capabilities: (1) multimodal plan reasoning, enabling the model to align uni- and multimodal queries with the current task plan and respond accurately; and (2) plan-based retrieval, allowing it to retrieve relevant plan steps in either textual or visual representations. Experiments were done on a novel dataset with rich Instructional Video Dialogues aligned with Cooking and DIY plans. Our evaluation shows that VIGiA outperforms existing state-of-the-art models on all tasks in a conversational plan guidance setting, reaching over 90\% accuracy on plan-aware VQA.

</details>


### [98] [Artefact-Aware Fungal Detection in Dermatophytosis: A Real-Time Transformer-Based Approach for KOH Microscopy](https://arxiv.org/abs/2602.19156)
*Rana Gursoy,Abdurrahim Yilmaz,Baris Kizilyaprak,Esmahan Caglar,Burak Temelkuran,Huseyin Uvet,Ayse Esra Koku Aksu,Gulsum Gencoglan*

Main category: cs.CV

TL;DR: 该研究开发了一种基于RT-DETR模型的AI系统，用于高精度定位KOH显微镜图像中的真菌结构，表现出极高的诊断准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 由于KOH显微镜检查中真菌菌丝的准确识别受到伪影、异质性角质清除和显著的观察者间变异性的阻碍，研究旨在开发一种精确的、查询驱动的方法来定位高分辨率KOH图像中的真菌结构。

Method: 研究采用基于RT-DETR模型的变压器检测框架，通过形态保留增强技术训练模型，以保持薄菌丝的结构完整性。数据集包含2,540张常规采集的显微镜图像，并采用多类策略手动注释以区分真菌元素与混淆伪影。

Result: 在独立测试集上，模型表现出强大的对象级性能，召回率为0.9737，精确度为0.8043，AP@0.50为93.56%。图像级诊断的灵敏度为100%，准确度为98.8%，且未漏诊任何阳性病例。

Conclusion: 该研究表明，基于RT-DETR模型的AI系统可以作为高度可靠的自动化筛查工具，有效填补皮肤真菌学中图像级分析与临床决策之间的差距。

Abstract: Dermatophytosis is commonly assessed using potassium hydroxide (KOH) microscopy, yet accurate recognition of fungal hyphae is hindered by artefacts, heterogeneous keratin clearance, and notable inter-observer variability. This study presents a transformer-based detection framework using the RT-DETR model architecture to achieve precise, query-driven localization of fungal structures in high-resolution KOH images. A dataset of 2,540 routinely acquired microscopy images was manually annotated using a multi-class strategy to explicitly distinguish fungal elements from confounding artefacts. The model was trained with morphology-preserving augmentations to maintain the structural integrity of thin hyphae. Evaluation on an independent test set demonstrated robust object-level performance, with a recall of 0.9737, precision of 0.8043, and an AP@0.50 of 93.56%. When aggregated for image-level diagnosis, the model achieved 100% sensitivity and 98.8% accuracy, correctly identifying all positive cases without missing a single diagnosis. Qualitative outputs confirmed the robust localization of low-contrast hyphae even in artefact-rich fields. These results highlight that an artificial intelligence (AI) system can serve as a highly reliable, automated screening tool, effectively bridging the gap between image-level analysis and clinical decision-making in dermatomycology.

</details>


### [99] [Flash-VAED: Plug-and-Play VAE Decoders for Efficient Video Generation](https://arxiv.org/abs/2602.19161)
*Lunjie Zhu,Yushi Huang,Xingtong Ge,Yufei Xue,Zhening Liu,Yumeng Zhang,Zehong Lin,Jun Zhang*

Main category: cs.CV

TL;DR: 提出Flash-VAED框架，通过通道剪枝和算子优化加速VAE解码器，保持质量的同时实现6倍加速，端到端流程提速36%。


<details>
  <summary>Details</summary>
Motivation: 潜在扩散模型的推理成本高且耗时，VAE解码器成为新的延迟瓶颈，需在保持质量的同时降低延迟。

Method: 提出了一种独立性感知的通道剪枝方法和阶段式主导算子优化策略，构建了Flash-VAED家族，并设计了动态蒸馏框架。

Result: 实验表明，Flash-VAED在质量和速度上均优于基线，实现了约6倍的加速，重建性能保持在96.9%，端到端生成流程加速达36%。

Conclusion: Flash-VAED框架显著提升了VAE解码器的推理速度，同时保持了原始潜在分布的对齐和质量，为高质高效的视频合成提供了可行方案。

Abstract: Latent diffusion models have enabled high-quality video synthesis, yet their inference remains costly and time-consuming. As diffusion transformers become increasingly efficient, the latency bottleneck inevitably shifts to VAE decoders. To reduce their latency while maintaining quality, we propose a universal acceleration framework for VAE decoders that preserves full alignment with the original latent distribution. Specifically, we propose (1) an independence-aware channel pruning method to effectively mitigate severe channel redundancy, and (2) a stage-wise dominant operator optimization strategy to address the high inference cost of the widely used causal 3D convolutions in VAE decoders. Based on these innovations, we construct a Flash-VAED family. Moreover, we design a three-phase dynamic distillation framework that efficiently transfers the capabilities of the original VAE decoder to Flash-VAED. Extensive experiments on Wan and LTX-Video VAE decoders demonstrate that our method outperforms baselines in both quality and speed, achieving approximately a 6$\times$ speedup while maintaining the reconstruction performance up to 96.9%. Notably, Flash-VAED accelerates the end-to-end generation pipeline by up to 36% with negligible quality drops on VBench-2.0.

</details>


### [100] [JavisDiT++: Unified Modeling and Optimization for Joint Audio-Video Generation](https://arxiv.org/abs/2602.19163)
*Kai Liu,Yanhao Zheng,Kai Wang,Shengqiong Wu,Rongjunchen Zhang,Jiebo Luo,Dimitrios Hatzinakos,Ziwei Liu,Hao Fei,Tat-Seng Chua*

Main category: cs.CV

TL;DR: JavisDiT++通过创新设计提升音视频联合生成质量，成为开源领域SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有开源方法在生成质量、时间同步性和人类偏好对齐方面仍落后于商业模型（如Veo3），需填补这一差距。

Method: 引入模态特定混合专家（MS-MoE）设计、时间对齐RoPE（TA-RoPE）策略和音视频直接偏好优化（AV-DPO）方法。

Result: 基于Wan2.1-1.3B-T2V的模型仅用约100万公开训练数据即达到SOTA性能，显著优于先前方法。

Conclusion: JavisDiT++通过MS-MoE设计、TA-RoPE策略和AV-DPO方法，显著提升了联合音视频生成的质量、同步性和人类偏好对齐，成为当前最先进的开源解决方案。

Abstract: AIGC has rapidly expanded from text-to-image generation toward high-quality multimodal synthesis across video and audio. Within this context, joint audio-video generation (JAVG) has emerged as a fundamental task that produces synchronized and semantically aligned sound and vision from textual descriptions. However, compared with advanced commercial models such as Veo3, existing open-source methods still suffer from limitations in generation quality, temporal synchrony, and alignment with human preferences. To bridge the gap, this paper presents JavisDiT++, a concise yet powerful framework for unified modeling and optimization of JAVG. First, we introduce a modality-specific mixture-of-experts (MS-MoE) design that enables cross-modal interaction efficacy while enhancing single-modal generation quality. Then, we propose a temporal-aligned RoPE (TA-RoPE) strategy to achieve explicit, frame-level synchronization between audio and video tokens. Besides, we develop an audio-video direct preference optimization (AV-DPO) method to align model outputs with human preference across quality, consistency, and synchrony dimensions. Built upon Wan2.1-1.3B-T2V, our model achieves state-of-the-art performance merely with around 1M public training entries, significantly outperforming prior approaches in both qualitative and quantitative evaluations. Comprehensive ablation studies have been conducted to validate the effectiveness of our proposed modules. All the code, model, and dataset are released at https://JavisVerse.github.io/JavisDiT2-page.

</details>


### [101] [BriMA: Bridged Modality Adaptation for Multi-Modal Continual Action Quality Assessment](https://arxiv.org/abs/2602.19170)
*Kanglei Zhou,Chang Li,Qingyi Pan,Liyuan Wang*

Main category: cs.CV

TL;DR: BriMA是一种针对模态缺失问题的多模态持续AQA方法，通过桥接填补和模态感知重放机制，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有持续AQA方法假设所有模态始终完整且稳定，忽视了实际部署中模态缺失的问题，限制了其实用性。

Method: BriMA包括一个基于记忆的桥接填补模块（重建缺失模态）和一个模态感知重放机制（优先处理信息丰富的样本）。

Result: 在三个多模态AQA数据集上，BriMA在不同模态缺失条件下均提升了性能，平均相关性提高6-8%，误差降低12-15%。

Conclusion: BriMA方法在多模态缺失条件下显著提升了AQA系统的性能，展示了在实际部署中实现鲁棒多模态AQA的潜力。

Abstract: Action Quality Assessment (AQA) aims to score how well an action is performed and is widely used in sports analysis, rehabilitation assessment, and human skill evaluation. Multi-modal AQA has recently achieved strong progress by leveraging complementary visual and kinematic cues, yet real-world deployments often suffer from non-stationary modality imbalance, where certain modalities become missing or intermittently available due to sensor failures or annotation gaps. Existing continual AQA methods overlook this issue and assume that all modalities remain complete and stable throughout training, which restricts their practicality. To address this challenge, we introduce Bridged Modality Adaptation (BriMA), an innovative approach to multi-modal continual AQA under modality-missing conditions. BriMA consists of a memory-guided bridging imputation module that reconstructs missing modalities using both task-agnostic and task-specific representations, and a modality-aware replay mechanism that prioritizes informative samples based on modality distortion and distribution drift. Experiments on three representative multi-modal AQA datasets (RG, Fis-V, and FS1000) show that BriMA consistently improves performance under different modality-missing conditions, achieving 6--8\% higher correlation and 12--15\% lower error on average. These results demonstrate a step toward robust multi-modal AQA systems under real-world deployment constraints.

</details>


### [102] [EMAD: Evidence-Centric Grounded Multimodal Diagnosis for Alzheimer's Disease](https://arxiv.org/abs/2602.19178)
*Qiuhui Chen,Xuancheng Yao,Zhenglei Zhou,Xinyue Hu,Yi Hong*

Main category: cs.CV

TL;DR: EMAD是一个视觉语言框架，通过分层证据机制生成结构化AD诊断报告，结合强化学习确保临床一致性，显著提升诊断透明度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在医学图像分析中缺乏透明性、与临床指南不一致的问题，特别是在阿尔茨海默病（AD）诊断中需要结合解剖和临床证据的需求。

Method: EMAD采用分层句子-证据-解剖结构（SEA）机制，结合GTX-Distill减少标注需求，并通过Executable-Rule GRPO强化微调方案确保临床一致性。

Result: 在AD-MultiSense数据集上，EMAD实现了最先进的诊断准确性，并生成比现有方法更透明、解剖学上更准确的报告。

Conclusion: EMAD框架通过生成结构化的AD诊断报告，显著提升了诊断的透明度和解剖学准确性，为未来可信赖的医学视觉语言模型研究提供了支持。

Abstract: Deep learning models for medical image analysis often act as black boxes, seldom aligning with clinical guidelines or explicitly linking decisions to supporting evidence. This is especially critical in Alzheimer's disease (AD), where predictions should be grounded in both anatomical and clinical findings. We present EMAD, a vision-language framework that generates structured AD diagnostic reports in which each claim is explicitly grounded in multimodal evidence. EMAD uses a hierarchical Sentence-Evidence-Anatomy (SEA) grounding mechanism: (i) sentence-to-evidence grounding links generated sentences to clinical evidence phrases, and (ii) evidence-to-anatomy grounding localizes corresponding structures on 3D brain MRI. To reduce dense annotation requirements, we propose GTX-Distill, which transfers grounding behavior from a teacher trained with limited supervision to a student operating on model-generated reports. We further introduce Executable-Rule GRPO, a reinforcement fine-tuning scheme with verifiable rewards that enforces clinical consistency, protocol adherence, and reasoning-diagnosis coherence. On the AD-MultiSense dataset, EMAD achieves state-of-the-art diagnostic accuracy and produces more transparent, anatomically faithful reports than existing methods. We will release code and grounding annotations to support future research in trustworthy medical vision-language models.

</details>


### [103] [VLM-Guided Group Preference Alignment for Diffusion-based Human Mesh Recovery](https://arxiv.org/abs/2602.19180)
*Wenhao Shen,Hao Wang,Wanqi Yin,Fayao Liu,Xulei Yang,Chao Liang,Zhongang Cai,Guosheng Lin*

Main category: cs.CV

TL;DR: 本文提出了一种结合双记忆批判代理和偏好对齐框架的方法，显著提升了单RGB图像3D人体网格恢复的准确性和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于扩散的方法在生成多种假设时往往牺牲准确性，导致预测结果在物理上不合理或与输入图像不一致，尤其是在遮挡或复杂场景中。

Method: 提出了一种双记忆增强的HMR批判代理，通过自反思生成上下文感知的质量评分，并利用这些评分构建组级HMR偏好数据集，进而提出组偏好对齐框架来微调基于扩散的HMR模型。

Result: 实验表明，该方法在生成物理合理且与图像一致的3D人体网格方面优于现有技术。

Conclusion: 该方法通过引入双记忆增强的HMR批判代理和自反思机制，结合偏好对齐框架，显著提升了单RGB图像3D人体网格恢复的准确性和物理合理性。

Abstract: Human mesh recovery (HMR) from a single RGB image is inherently ambiguous, as multiple 3D poses can correspond to the same 2D observation. Recent diffusion-based methods tackle this by generating various hypotheses, but often sacrifice accuracy. They yield predictions that are either physically implausible or drift from the input image, especially under occlusion or in cluttered, in-the-wild scenes. To address this, we introduce a dual-memory augmented HMR critique agent with self-reflection to produce context-aware quality scores for predicted meshes. These scores distill fine-grained cues about 3D human motion structure, physical feasibility, and alignment with the input image. We use these scores to build a group-wise HMR preference dataset. Leveraging this dataset, we propose a group preference alignment framework for finetuning diffusion-based HMR models. This process injects the rich preference signals into the model, guiding it to generate more physically plausible and image-consistent human meshes. Extensive experiments demonstrate that our method achieves superior performance compared to state-of-the-art approaches.

</details>


### [104] [PositionOCR: Augmenting Positional Awareness in Multi-Modal Models via Hybrid Specialist Integration](https://arxiv.org/abs/2602.19188)
*Chen Duan,Zhentao Guo,Pei Fu,Zining Wang,Kai Zhou,Pengfei Yan*

Main category: cs.CV

TL;DR: PositionOCR是一个参数高效的混合架构，结合文本定位专家的位置精确性和LLM的上下文推理能力，在多模态任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: MLLMs在视觉任务中缺乏位置推理能力，而文本定位专家缺乏语义推理能力，这促使研究如何结合两者的优势。

Method: 引入PositionOCR，一个参数高效的混合架构，无缝整合文本定位模型的位置优势与LLM的上下文推理能力。

Result: PositionOCR在多模态处理任务中表现卓越，尤其在文本定位和文本识别方面，显著超越传统MLLMs。

Conclusion: PositionOCR成功结合了文本定位专家的位置精确性和LLM的上下文推理能力，创造了一个参数高效且在多模态任务中表现优异的混合架构。

Abstract: In recent years, Multi-modal Large Language Models (MLLMs) have achieved strong performance in OCR-centric Visual Question Answering (VQA) tasks, illustrating their capability to process heterogeneous data and exhibit adaptability across varied contexts. However, these MLLMs rely on a Large Language Model (LLM) as the decoder, which is primarily designed for linguistic processing, and thus inherently lacks the positional reasoning required for precise visual tasks, such as text spotting and text grounding. Additionally, the extensive parameters of MLLMs necessitate substantial computational resources and large-scale data for effective training. Conversely, text spotting specialists achieve state-of-the-art coordinate predictions but lack semantic reasoning capabilities. This dichotomy motivates our key research question: Can we synergize the efficiency of specialists with the contextual power of LLMs to create a positionally-accurate MLLM? To overcome these challenges, we introduce PositionOCR, a parameter-efficient hybrid architecture that seamlessly integrates a text spotting model's positional strengths with an LLM's contextual reasoning. Comprising 131M trainable parameters, this framework demonstrates outstanding multi-modal processing capabilities, particularly excelling in tasks such as text grounding and text spotting, consistently surpassing traditional MLLMs.

</details>


### [105] [FUSAR-GPT : A Spatiotemporal Feature-Embedded and Two-Stage Decoupled Visual Language Model for SAR Imagery](https://arxiv.org/abs/2602.19190)
*Xiaokun Zhang,Yi Yang,Ziqi Ye,Baiyun,Xiaorong Guo,Qingchen Fang,Ruyi Zhang,Xinpeng Zhou,Haipeng Wang*

Main category: cs.CV

TL;DR: 研究提出FUSAR-GPT模型，通过地理空间基线先验和时空锚点嵌入，解决了SAR图像智能解译的挑战，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 由于SAR成像机制复杂、散射特征敏感及高质量文本语料稀缺，现有视觉语言模型在SAR领域表现受限，亟需针对性解决方案。

Method: 构建了首个SAR图像-文本-AlphaEarth特征三元组数据集，开发了专用于SAR的VLM模型FUSAR-GPT，引入地理空间基线模型作为先验知识，并通过时空锚点嵌入多源遥感时序特征。

Result: FUSAR-GPT在多个典型遥感视觉语言基准测试中达到最优性能，显著超越主流基线模型12%以上。

Conclusion: FUSAR-GPT通过创新的地理空间基线模型和时空锚点嵌入，结合两阶段SFT策略，显著提升了SAR图像智能解译的性能，在多个遥感视觉语言基准测试中表现优异。

Abstract: Research on the intelligent interpretation of all-weather, all-time Synthetic Aperture Radar (SAR) is crucial for advancing remote sensing applications. In recent years, although Visual Language Models (VLMs) have demonstrated strong open-world understanding capabilities on RGB images, their performance is severely limited when directly applied to the SAR field due to the complexity of the imaging mechanism, sensitivity to scattering features, and the scarcity of high-quality text corpora. To systematically address this issue, we constructed the inaugural SAR Image-Text-AlphaEarth feature triplet dataset and developed FUSAR-GPT, a VLM specifically for SAR. FUSAR-GPT innovatively introduces a geospatial baseline model as a 'world knowledge' prior and embeds multi-source remote-sensing temporal features into the model's visual backbone via 'spatiotemporal anchors', enabling dynamic compensation for the sparse representation of targets in SAR images. Furthermore, we designed a two-stage SFT strategy to decouple the knowledge injection and task execution of large models. The spatiotemporal feature embedding and the two-stage decoupling paradigm enable FUSAR-GPT to achieve state-of-the-art performance across several typical remote sensing visual-language benchmark tests, significantly outperforming mainstream baseline models by over 12%.

</details>


### [106] [Prompt Tuning for CLIP on the Pretrained Manifold](https://arxiv.org/abs/2602.19198)
*Xi Yang,Yuanrong Xu,Weigang Zhang,Guangming Lu,David Zhang,Jie Wen*

Main category: cs.CV

TL;DR: ManiPT通过约束提示调优在预训练流形上进行，解决了有限监督下的表征漂移问题，提升了泛化性能。


<details>
  <summary>Details</summary>
Motivation: 传统提示调优在有限监督下会改变预训练表征，导致下游特征偏离预训练流形，从而降低泛化能力。ManiPT旨在解决这一问题。

Method: ManiPT在文本和图像模态中引入余弦一致性约束，将学习到的表征限制在预训练的几何邻域内，并通过结构偏差引导适应过程，避免依赖捷径学习。

Result: 在未见类泛化、少样本分类、跨数据集迁移和领域泛化四种下游任务中，ManiPT平均性能优于基线方法。

Conclusion: ManiPT通过在预训练流形上进行提示调优，并引入余弦一致性约束和结构偏差，有效缓解了有限监督下的过拟合问题，提升了在多种下游任务中的泛化性能。

Abstract: Prompt tuning introduces learnable prompt vectors that adapt pretrained vision-language models to downstream tasks in a parameter-efficient manner. However, under limited supervision, prompt tuning alters pretrained representations and drives downstream features away from the pretrained manifold toward directions that are unfavorable for transfer. This drift degrades generalization. To address this limitation, we propose ManiPT, a framework that performs prompt tuning on the pretrained manifold. ManiPT introduces cosine consistency constraints in both the text and image modalities to confine the learned representations within the pretrained geometric neighborhood. Furthermore, we introduce a structural bias that enforces incremental corrections, guiding the adaptation along transferable directions to mitigate reliance on shortcut learning. From a theoretical perspective, ManiPT alleviates overfitting tendencies under limited data. Our experiments cover four downstream settings: unseen-class generalization, few-shot classification, cross-dataset transfer, and domain generalization. Across these settings, ManiPT achieves higher average performance than baseline methods. Notably, ManiPT provides an explicit perspective on how prompt tuning overfits under limited supervision.

</details>


### [107] [UniE2F: A Unified Diffusion Framework for Event-to-Frame Reconstruction with Video Foundation Models](https://arxiv.org/abs/2602.19202)
*Gang Xu,Zhiyu Zhu,Junhui Hou*

Main category: cs.CV

TL;DR: 利用预训练视频扩散模型的生成先验，从稀疏事件数据重建高保真视频帧，并通过事件帧间残差引导和反向扩散采样调制，实现视频帧插值和预测的统一框架。


<details>
  <summary>Details</summary>
Motivation: 事件相机虽然在高速度、低功耗和高动态范围场景感知方面表现优异，但其仅记录相对强度变化导致空间信息和静态纹理细节丢失，需要解决这一限制。

Method: 首先直接应用事件数据作为条件合成视频建立基线模型，然后基于事件流与视频帧之间的物理相关性引入事件帧间残差引导，最后通过调制反向扩散采样过程扩展至视频帧插值和预测。

Result: 在真实世界和合成数据集上的实验结果表明，该方法在定量和定性上均显著优于先前方法。

Conclusion: 该方法通过结合预训练的视频扩散模型和事件数据，显著提升了从稀疏事件数据重建高保真视频帧的性能，并在视频帧插值和预测任务中展示了零样本学习能力。

Abstract: Event cameras excel at high-speed, low-power, and high-dynamic-range scene perception. However, as they fundamentally record only relative intensity changes rather than absolute intensity, the resulting data streams suffer from a significant loss of spatial information and static texture details. In this paper, we address this limitation by leveraging the generative prior of a pre-trained video diffusion model to reconstruct high-fidelity video frames from sparse event data. Specifically, we first establish a baseline model by directly applying event data as a condition to synthesize videos. Then, based on the physical correlation between the event stream and video frames, we further introduce the event-based inter-frame residual guidance to enhance the accuracy of video frame reconstruction. Furthermore, we extend our method to video frame interpolation and prediction in a zero-shot manner by modulating the reverse diffusion sampling process, thereby creating a unified event-to-frame reconstruction framework. Experimental results on real-world and synthetic datasets demonstrate that our method significantly outperforms previous approaches both quantitatively and qualitatively. We also refer the reviewers to the video demo contained in the supplementary material for video results. The code will be publicly available at https://github.com/CS-GangXu/UniE2F.

</details>


### [108] [GS-CLIP: Zero-shot 3D Anomaly Detection by Geometry-Aware Prompt and Synergistic View Representation Learning](https://arxiv.org/abs/2602.19206)
*Zehao Deng,An Liu,Yan Wang*

Main category: cs.CV

TL;DR: GS-CLIP通过几何感知提示和协同视图学习，解决了3D异常检测中几何细节丢失和模态单一的问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将3D点云投影为2D表示时丢失几何细节，且依赖单一模态，限制了异常检测的多样性。GS-CLIP旨在解决这些问题。

Method: 采用两阶段学习过程：第一阶段动态生成嵌入3D几何先验的文本提示，第二阶段通过协同视图表示学习架构并行处理渲染和深度图像，并通过协同细化模块融合特征。

Result: 在四个大规模公开数据集上的实验表明，GS-CLIP在检测性能上优于现有方法。

Conclusion: GS-CLIP框架通过几何感知提示和协同视图表示学习，显著提升了零样本3D异常检测的性能，尤其在几何细节保留和多模态融合方面表现优异。

Abstract: Zero-shot 3D Anomaly Detection is an emerging task that aims to detect anomalies in a target dataset without any target training data, which is particularly important in scenarios constrained by sample scarcity and data privacy concerns. While current methods adapt CLIP by projecting 3D point clouds into 2D representations, they face challenges. The projection inherently loses some geometric details, and the reliance on a single 2D modality provides an incomplete visual understanding, limiting their ability to detect diverse anomaly types. To address these limitations, we propose the Geometry-Aware Prompt and Synergistic View Representation Learning (GS-CLIP) framework, which enables the model to identify geometric anomalies through a two-stage learning process. In stage 1, we dynamically generate text prompts embedded with 3D geometric priors. These prompts contain global shape context and local defect information distilled by our Geometric Defect Distillation Module (GDDM). In stage 2, we introduce Synergistic View Representation Learning architecture that processes rendered and depth images in parallel. A Synergistic Refinement Module (SRM) subsequently fuses the features of both streams, capitalizing on their complementary strengths. Comprehensive experimental results on four large-scale public datasets show that GS-CLIP achieves superior performance in detection. Code can be available at https://github.com/zhushengxinyue/GS-CLIP.

</details>


### [109] [SegMoTE: Token-Level Mixture of Experts for Medical Image Segmentation](https://arxiv.org/abs/2602.19213)
*Yujie Lu,Jingwen Li,Sibo Ju,Yanzhou Su,he yao,Yisong Liu,Min Zhu,Junlong Cheng*

Main category: cs.CV

TL;DR: SegMoTE 是一个高效自适应的医学图像分割框架，解决了通用模型在医学领域的迁移瓶颈，通过少量参数和渐进式提示机制，在极低标注成本下实现 SOTA 性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割在临床诊断和定量分析中至关重要，但由于成像模态的异质性和像素级标注的高成本，仍面临挑战。现有通用交互式分割模型在医学影像中的迁移存在两个关键瓶颈：缺乏对模态和特定解剖任务的适应性机制，以及现有医学适应方法在大型异构数据集上无选择地微调导致噪声监督、高成本和负迁移。

Method: SegMoTE 保留了 SAM 的原始提示接口、高效推理和零样本泛化能力，同时引入少量可学习参数以动态适应不同模态和任务，并设计了渐进式提示标记机制以实现全自动分割。

Result: 在 MedSeg-HQ（仅占现有大规模数据集的不到 1%）上训练的 SegMoTE 在多样成像模态和解剖任务中实现了最先进的性能。

Conclusion: SegMoTE 是首个在极低标注成本下，将通用分割模型高效、稳健且可扩展地适应医学领域的框架，推动了基础视觉模型在临床应用中的实际部署。

Abstract: Medical image segmentation is vital for clinical diagnosis and quantitative analysis, yet remains challenging due to the heterogeneity of imaging modalities and the high cost of pixel-level annotations. Although general interactive segmentation models like SAM have achieved remarkable progress, their transfer to medical imaging still faces two key bottlenecks: (i) the lack of adaptive mechanisms for modality- and anatomy-specific tasks, which limits generalization in out-of-distribution medical scenarios; and (ii) current medical adaptation methods fine-tune on large, heterogeneous datasets without selection, leading to noisy supervision, higher cost, and negative transfer. To address these issues, we propose SegMoTE, an efficient and adaptive framework for medical image segmentation. SegMoTE preserves SAM's original prompt interface, efficient inference, and zero-shot generalization while introducing only a small number of learnable parameters to dynamically adapt across modalities and tasks. In addition, we design a progressive prompt tokenization mechanism that enables fully automatic segmentation, significantly reducing annotation dependence. Trained on MedSeg-HQ, a curated dataset less than 1% of existing large-scale datasets, SegMoTE achieves SOTA performance across diverse imaging modalities and anatomical tasks. It represents the first efficient, robust, and scalable adaptation of general segmentation models to the medical domain under extremely low annotation cost, advancing the practical deployment of foundation vision models in clinical applications.

</details>


### [110] [No Need For Real Anomaly: MLLM Empowered Zero-Shot Video Anomaly Detection](https://arxiv.org/abs/2602.19248)
*Zunkai Dai,Ke Li,Jiajia Liu,Jie Yang,Yuanyuan Qiao*

Main category: cs.CV

TL;DR: LAVIDA是一个零样本视频异常检测框架，通过伪异常训练和语义增强，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频异常检测方法在开放世界场景中表现不佳的问题，主要由于数据集多样性有限和对上下文依赖的异常语义理解不足。

Method: 提出LAVIDA框架，包含异常暴露采样器、多模态大语言模型和基于反向注意力的令牌压缩方法。

Result: 在四个基准VAD数据集上的评估显示，LAVIDA在零样本设置下实现了SOTA性能。

Conclusion: LAVIDA框架在零样本设置下，在帧级和像素级异常检测中均实现了最先进的性能，证明了其有效性。

Abstract: The collection and detection of video anomaly data has long been a challenging problem due to its rare occurrence and spatio-temporal scarcity. Existing video anomaly detection (VAD) methods under perform in open-world scenarios. Key contributing factors include limited dataset diversity, and inadequate understanding of context-dependent anomalous semantics. To address these issues, i) we propose LAVIDA, an end-to-end zero-shot video anomaly detection framework. ii) LAVIDA employs an Anomaly Exposure Sampler that transforms segmented objects into pseudo-anomalies to enhance model adaptability to unseen anomaly categories. It further integrates a Multimodal Large Language Model (MLLM) to bolster semantic comprehension capabilities. Additionally, iii) we design a token compression approach based on reverse attention to handle the spatio-temporal scarcity of anomalous patterns and decrease computational cost. The training process is conducted solely on pseudo anomalies without any VAD data. Evaluations across four benchmark VAD datasets demonstrate that LAVIDA achieves SOTA performance in both frame-level and pixel-level anomaly detection under the zero-shot setting. Our code is available in https://github.com/VitaminCreed/LAVIDA.

</details>


### [111] [Questions beyond Pixels: Integrating Commonsense Knowledge in Visual Question Generation for Remote Sensing](https://arxiv.org/abs/2602.19217)
*Siran Li,Li Mi,Javiera Castillo-Navarro,Devis Tuia*

Main category: cs.CV

TL;DR: KRSVQG模型通过结合外部知识和图像标题，生成更丰富的问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前自动生成的问题过于简单和模板化，限制了问答或视觉对话系统在实际应用中的部署。

Method: 提出了一种知识感知的遥感视觉问题生成模型（KRSVQG），结合外部知识三元组和图像标题作为中介表示，采用视觉语言预训练和微调策略。

Result: 构建了两个数据集（NWPU-300和TextRS-300），评估显示KRSVQG在生成丰富且基于图像和领域知识的问题上优于现有方法。

Conclusion: KRSVQG模型通过结合外部知识源和图像标题，生成了更丰富、多样化的问题，显著优于现有方法，并推动了知识增强的视觉语言系统的发展。

Abstract: With the rapid development of remote sensing image archives, asking questions about images has become an effective way of gathering specific information or performing semantic image retrieval. However, current automatically generated questions tend to be simplistic and template-based, which hinders the deployment of question answering or visual dialogue systems for real-world applications. To enrich and diversify the questions with both image content and commonsense knowledge, we propose a Knowledge-aware Remote Sensing Visual Question Generation model (KRSVQG). The proposed model incorporates related knowledge triplets from external knowledge sources to broaden the question content, while employing image captioning as an intermediary representation to ground questions to the corresponding images. Moreover, KRSVQG utilizes a vision-language pre-training and fine-tuning strategy, enabling the model's adaptation to low data regimes. To evaluate the proposed KRSVQG model, we construct two knowledge-aware remote sensing visual question generation datasets: the NWPU-300 dataset and the TextRS-300 dataset. Evaluations, including metrics and human assessment, demonstrate that KRSVQG outperforms existing methods and leads to rich questions, grounded in both image and domain knowledge. As a key practice in vision-language research, knowledge-aware visual question generation advances the understanding of image content beyond pixels, facilitating the development of knowledge-enriched vision-language systems with vision-grounded human commonsense.

</details>


### [112] [Controlled Face Manipulation and Synthesis for Data Augmentation](https://arxiv.org/abs/2602.19219)
*Joris Kirchner,Amogh Gudi,Marian Bittner,Chirag Raman*

Main category: cs.CV

TL;DR: 本文提出了一种基于预训练面部生成器的面部操作方法，通过减少语义特征纠缠和去除干扰属性，有效增强了AU检测器的训练数据，提高了检测准确性和解耦性。


<details>
  <summary>Details</summary>
Motivation: 深度学习视觉模型在监督充足时表现优异，但许多应用面临标签稀缺和类别不平衡问题。可控图像编辑可以增强稀缺的标注数据，但现有编辑方法常引入伪影并纠缠非目标属性。

Method: 利用预训练面部生成器（Diffusion Autoencoder）的语义潜在空间，通过轻量级线性模型减少语义特征的纠缠，具体包括依赖感知的条件化（考虑AU共激活）和正交投影（去除干扰属性方向），并结合表情中和步骤实现绝对AU编辑。

Result: 提出的面部操作方法在AU检测器训练中表现优异，编辑效果更强、伪影更少且身份保持更好。通过编辑标注的面部平衡AU出现频率，并通过可控合成多样化身份/人口统计数据。

Conclusion: 通过提出的面部操作方法，在AU检测器训练中使用生成的数据不仅提高了准确性，还减少了共激活的捷径，效果优于其他数据高效训练策略，且效果类似于需要更多标注数据的学习曲线分析。

Abstract: Deep learning vision models excel with abundant supervision, but many applications face label scarcity and class imbalance. Controllable image editing can augment scarce labeled data, yet edits often introduce artifacts and entangle non-target attributes. We study this in facial expression analysis, targeting Action Unit (AU) manipulation where annotation is costly and AU co-activation drives entanglement. We present a facial manipulation method that operates in the semantic latent space of a pre-trained face generator (Diffusion Autoencoder). Using lightweight linear models, we reduce entanglement of semantic features via (i) dependency-aware conditioning that accounts for AU co-activation, and (ii) orthogonal projection that removes nuisance attribute directions (e.g., glasses), together with an expression neutralization step to enable absolute AU edit. We use these edits to balance AU occurrence by editing labeled faces and to diversify identities/demographics via controlled synthesis. Augmenting AU detector training with the generated data improves accuracy and yields more disentangled predictions with fewer co-activation shortcuts, outperforming alternative data-efficient training strategies and suggesting improvements similar to what would require substantially more labeled data in our learning-curve analysis. Compared to prior methods, our edits are stronger, produce fewer artifacts, and preserve identity better.

</details>


### [113] [Knowledge-aware Visual Question Generation for Remote Sensing Images](https://arxiv.org/abs/2602.19224)
*Siran Li,Li Mi,Javiera Castillo-Navarro,Devis Tuia*

Main category: cs.CV

TL;DR: KRSVQG模型结合外部知识生成多样化遥感图像问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动生成的问题过于简单和模板化，限制了问答或视觉对话系统的实际应用，需丰富和多样化问题。

Method: 提出了一种知识感知的遥感视觉问题生成模型KRSVQG，结合图像和外部知识三元组，利用图像描述作为中间表示增强问题生成。

Result: 在NWPU-300和TextRS-300数据集上的实验表明，KRSVQG优于现有方法，生成的问题更具知识性和图像基础。

Conclusion: KRSVQG模型通过结合外部知识显著提升了遥感图像问题生成的多样性和质量，优于现有方法。

Abstract: With the rapid development of remote sensing image archives, asking questions about images has become an effective way of gathering specific information or performing image retrieval. However, automatically generated image-based questions tend to be simplistic and template-based, which hinders the real deployment of question answering or visual dialogue systems. To enrich and diversify the questions, we propose a knowledge-aware remote sensing visual question generation model, KRSVQG, that incorporates external knowledge related to the image content to improve the quality and contextual understanding of the generated questions. The model takes an image and a related knowledge triplet from external knowledge sources as inputs and leverages image captioning as an intermediary representation to enhance the image grounding of the generated questions. To assess the performance of KRSVQG, we utilized two datasets that we manually annotated: NWPU-300 and TextRS-300. Results on these two datasets demonstrate that KRSVQG outperforms existing methods and leads to knowledge-enriched questions, grounded in both image and domain knowledge.

</details>


### [114] [IPv2: An Improved Image Purification Strategy for Real-World Ultra-Low-Dose Lung CT Denoising](https://arxiv.org/abs/2602.19314)
*Guoliang Gong,Man Yu*

Main category: cs.CV

TL;DR: IPv2改进了图像净化策略，通过三个模块增强背景和肺组织去噪能力，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 原始图像净化策略在胸壁和骨骼区域抑制噪声但忽略背景和肺实质的去噪，IPv2旨在解决这些局限性。

Method: IPv2通过系统性地重新设计原始图像净化策略，引入了三个核心模块，并在训练数据构建和测试阶段优化标签构建。

Result: 在真实世界2%辐射剂量的患者肺部CT数据集上，IPv2在多种主流去噪模型中一致提升了背景抑制和肺实质恢复能力。

Conclusion: IPv2通过引入三个核心模块（Remove Background、Add noise、Remove noise），有效解决了原始图像净化策略在背景和肺组织区域的去噪局限性，显著提升了去噪模型的性能。

Abstract: The image purification strategy constructs an intermediate distribution with aligned anatomical structures, which effectively corrects the spatial misalignment between real-world ultra-low-dose CT and normal-dose CT images and significantly enhances the structural preservation ability of denoising models. However, this strategy exhibits two inherent limitations. First, it suppresses noise only in the chest wall and bone regions while leaving the image background untreated. Second, it lacks a dedicated mechanism for denoising the lung parenchyma. To address these issues, we systematically redesign the original image purification strategy and propose an improved version termed IPv2. The proposed strategy introduces three core modules, namely Remove Background, Add noise, and Remove noise. These modules endow the model with denoising capability in both background and lung tissue regions during training data construction and provide a more reasonable evaluation protocol through refined label construction at the testing stage. Extensive experiments on our previously established real-world patient lung CT dataset acquired at 2% radiation dose demonstrate that IPv2 consistently improves background suppression and lung parenchyma restoration across multiple mainstream denoising models. The code is publicly available at https://github.com/MonkeyDadLufy/Image-Purification-Strategy-v2.

</details>


### [115] [RegionRoute: Regional Style Transfer with Diffusion Model](https://arxiv.org/abs/2602.19254)
*Bowen Chen,Jake Zuena,Alan C. Bovik,Divya Kothandaraman*

Main category: cs.CV

TL;DR: 提出了一种注意力监督扩散框架，通过训练中对齐风格标记注意力与物体掩码，实现了无需手工掩码的单对象风格迁移，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在风格迁移中缺乏明确的风格表示空间定位，难以将风格应用限制在特定对象或区域。现有方法依赖手工掩码或多阶段后处理，导致边界伪影和泛化能力受限。

Method: 采用注意力监督扩散框架，通过Focus损失（基于KL散度）和Cover损失（使用二元交叉熵）两个互补目标，联合促进精确定位和密集覆盖。模块化的LoRA-MoE设计进一步支持高效且可扩展的多风格适应。

Result: 实验表明，该方法在推理时实现了无需掩码的单对象风格迁移，生成了区域准确且视觉一致的结果，优于现有方法。

Conclusion: 所提出的注意力监督扩散框架通过训练中对齐风格标记的注意力分数与物体掩码，实现了无需手工掩码的单对象风格迁移，生成了区域准确且视觉一致的结果，优于现有的基于扩散的编辑方法。

Abstract: Precise spatial control in diffusion-based style transfer remains challenging. This challenge arises because diffusion models treat style as a global feature and lack explicit spatial grounding of style representations, making it difficult to restrict style application to specific objects or regions. To our knowledge, existing diffusion models are unable to perform true localized style transfer, typically relying on handcrafted masks or multi-stage post-processing that introduce boundary artifacts and limit generalization. To address this, we propose an attention-supervised diffusion framework that explicitly teaches the model where to apply a given style by aligning the attention scores of style tokens with object masks during training. Two complementary objectives, a Focus loss based on KL divergence and a Cover loss using binary cross-entropy, jointly encourage accurate localization and dense coverage. A modular LoRA-MoE design further enables efficient and scalable multi-style adaptation. To evaluate localized stylization, we introduce the Regional Style Editing Score, which measures Regional Style Matching through CLIP-based similarity within the target region and Identity Preservation via masked LPIPS and pixel-level consistency on unedited areas. Experiments show that our method achieves mask-free, single-object style transfer at inference, producing regionally accurate and visually coherent results that outperform existing diffusion-based editing approaches.

</details>


### [116] [US-JEPA: A Joint Embedding Predictive Architecture for Medical Ultrasound](https://arxiv.org/abs/2602.19322)
*Ashwath Radhachandran,Vedrana Ivezić,Shreeram Athreya,Ronit Anilkumar,Corey W. Arnold,William Speier*

Main category: cs.CV

TL;DR: US-JEPA是一种自监督框架，通过静态教师非对称潜在训练目标，提升超声图像表示学习的稳定性和效率。


<details>
  <summary>Details</summary>
Motivation: 超声成像的低信噪比和随机斑点模式阻碍了依赖像素级重建目标的传统自监督学习方法。

Method: 采用Static-teacher Asymmetric Latent Training (SALT)目标，利用冻结的领域特定教师模型提供稳定的潜在目标，解耦学生-教师优化。

Result: US-JEPA在多样化分类任务的线性探测中，表现优于或与领域特定和通用视觉基础模型基线相当。

Conclusion: US-JEPA通过掩码潜在预测提供了一种稳定且高效的路径，用于构建稳健的超声图像表示。

Abstract: Ultrasound (US) imaging poses unique challenges for representation learning due to its inherently noisy acquisition process. The low signal-to-noise ratio and stochastic speckle patterns hinder standard self-supervised learning methods relying on a pixel-level reconstruction objective. Joint-Embedding Predictive Architectures (JEPAs) address this drawback by predicting masked latent representations rather than raw pixels. However, standard approaches depend on hyperparameter-brittle and computationally expensive online teachers updated via exponential moving average. We propose US-JEPA, a self-supervised framework that adopts the Static-teacher Asymmetric Latent Training (SALT) objective. By using a frozen, domain-specific teacher to provide stable latent targets, US-JEPA decouples student-teacher optimization and pushes the student to expand upon the semantic priors of the teacher. In addition, we provide the first rigorous comparison of all publicly available state-of-the-art ultrasound foundation models on UltraBench, a public dataset benchmark spanning multiple organs and pathological conditions. Under linear probing for diverse classification tasks, US-JEPA achieves performance competitive with or superior to domain-specific and universal vision foundation model baselines. Our results demonstrate that masked latent prediction provides a stable and efficient path toward robust ultrasound representations.

</details>


### [117] [RetinaVision: XAI-Driven Augmented Regulation for Precise Retinal Disease Classification using deep learning framework](https://arxiv.org/abs/2602.19324)
*Mohammad Tahmid Noor,Shayan Abrar,Jannatul Adan Mahi,Md Parvez Mia,Asaduzzaman Hridoy,Samanta Ghosh*

Main category: cs.CV

TL;DR: 提出基于深度学习的视网膜疾病分类方法，使用OCT图像，Xception表现最佳，准确率达95.25%。


<details>
  <summary>Details</summary>
Motivation: 早期准确分类视网膜疾病对防止视力丧失和指导临床管理至关重要。

Method: 使用Xception和InceptionV3两种卷积神经网络架构，结合数据增强技术（CutMix、MixUp），并通过GradCAM和LIME进行可解释性评估。

Result: Xception网络准确率最高（95.25%），InceptionV3紧随其后（94.82%）。

Conclusion: 深度学习方法能有效进行OCT视网膜疾病分类，并强调了在临床应用中实现准确性和可解释性的重要性。

Abstract: Early and accurate classification of retinal diseases is critical to counter vision loss and for guiding clinical management of retinal diseases. In this study, we proposed a deep learning method for retinal disease classification utilizing optical coherence tomography (OCT) images from the Retinal OCT Image Classification - C8 dataset (comprising 24,000 labeled images spanning eight conditions). Images were resized to 224x224 px and tested on convolutional neural network (CNN) architectures: Xception and InceptionV3. Data augmentation techniques (CutMix, MixUp) were employed to enhance model generalization. Additionally, we applied GradCAM and LIME for interpretability evaluation. We implemented this in a real-world scenario via our web application named RetinaVision. This study found that Xception was the most accurate network (95.25%), followed closely by InceptionV3 (94.82%). These results suggest that deep learning methods allow effective OCT retinal disease classification and highlight the importance of implementing accuracy and interpretability for clinical applications.

</details>


### [118] [A Two-Stage Detection-Tracking Framework for Stable Apple Quality Inspection in Dense Conveyor-Belt Environments](https://arxiv.org/abs/2602.19278)
*Keonvin Park,Aditya Pal,Jin Hong Mok*

Main category: cs.CV

TL;DR: 提出两阶段检测-跟踪框架，提升视频流中多苹果质量检测的时间稳定性，适用于工业环境。


<details>
  <summary>Details</summary>
Motivation: 工业水果检测系统需要在密集多目标交互和连续运动下可靠运行，但现有工作大多仅在图像级别评估检测或分类，未确保视频流中的时间稳定性。

Method: 提出了一个两阶段的检测-跟踪框架，包括使用YOLOv8模型进行苹果定位，ByteTrack多目标跟踪保持身份一致性，以及ResNet18缺陷分类器对裁剪的苹果区域进行分类。

Result: 结果表明，与逐帧推理相比，该系统在稳定性上有显著提升。

Conclusion: 整合跟踪技术对于实际自动化水果分级系统至关重要，显著提升了系统的稳定性。

Abstract: Industrial fruit inspection systems must operate reliably under dense multi-object interactions and continuous motion, yet most existing works evaluate detection or classification at the image level without ensuring temporal stability in video streams. We present a two-stage detection-tracking framework for stable multi-apple quality inspection in conveyor-belt environments. An orchard-trained YOLOv8 model performs apple localization, followed by ByteTrack multi-object tracking to maintain persistent identities. A ResNet18 defect classifier, fine-tuned on a healthy-defective fruit dataset, is applied to cropped apple regions. Track-level aggregation is introduced to enforce temporal consistency and reduce prediction oscillation across frames. We define video-level industrial metrics such as track-level defect ratio and temporal consistency to evaluate system robustness under realistic processing conditions. Results demonstrate improved stability compared to frame-wise inference, suggesting that integrating tracking is essential for practical automated fruit grading systems.

</details>


### [119] [MultiDiffSense: Diffusion-Based Multi-Modal Visuo-Tactile Image Generation Conditioned on Object Shape and Contact Pose](https://arxiv.org/abs/2602.19348)
*Sirine Bhouri,Lan Wei,Jian-Qing Zheng,Dandan Zhang*

Main category: cs.CV

TL;DR: MultiDiffSense是一种统一扩散模型，通过双重条件控制合成多模态触觉图像，显著提升数据合成质量并减少真实数据需求。


<details>
  <summary>Details</summary>
Motivation: 获取对齐的视觉-触觉数据集成本高且耗时，现有方法多为单模态，限制了跨模态学习。

Method: 使用基于CAD的深度图和结构化提示进行双重条件控制，实现可控且物理一致的多模态合成。

Result: 在8个物体（5个已知，3个新颖）和未见姿态上，MultiDiffSense在SSIM指标上显著优于Pix2Pix cGAN基线，并在下游3-DoF姿态估计任务中，混合50%合成数据可减少一半真实数据需求。

Conclusion: MultiDiffSense通过统一的扩散模型有效缓解了触觉传感中的数据收集瓶颈，并为机器人应用提供了可扩展、可控的多模态数据集生成方案。

Abstract: Acquiring aligned visuo-tactile datasets is slow and costly, requiring specialised hardware and large-scale data collection. Synthetic generation is promising, but prior methods are typically single-modality, limiting cross-modal learning. We present MultiDiffSense, a unified diffusion model that synthesises images for multiple vision-based tactile sensors (ViTac, TacTip, ViTacTip) within a single architecture. Our approach uses dual conditioning on CAD-derived, pose-aligned depth maps and structured prompts that encode sensor type and 4-DoF contact pose, enabling controllable, physically consistent multi-modal synthesis. Evaluating on 8 objects (5 seen, 3 novel) and unseen poses, MultiDiffSense outperforms a Pix2Pix cGAN baseline in SSIM by +36.3% (ViTac), +134.6% (ViTacTip), and +64.7% (TacTip). For downstream 3-DoF pose estimation, mixing 50% synthetic with 50% real halves the required real data while maintaining competitive performance. MultiDiffSense alleviates the data-collection bottleneck in tactile sensing and enables scalable, controllable multi-modal dataset generation for robotic applications.

</details>


### [120] [MRI Contrast Enhancement Kinetics World Model](https://arxiv.org/abs/2602.19285)
*Jindi Kong,Yuting He,Cong Xia,Rongjun Ge,Shuo Li*

Main category: cs.CV

TL;DR: MRI CEKWorld通过STCL方法（LAL和LDL）解决了MRI对比增强动力学建模中的内容失真和时间不连续问题，实验效果优异。


<details>
  <summary>Details</summary>
Motivation: 解决MRI对比增强动力学建模中因数据稀疏导致的内容失真和时间不连续问题。

Method: 提出了MRI CEKWorld模型，结合SpatioTemporal Consistency Learning (STCL)，包括Latent Alignment Learning (LAL)用于内容对齐和Latent Difference Learning (LDL)用于时间平滑。

Result: 在两个数据集上的实验表明，MRI CEKWorld能够生成更真实的内容和动力学。

Conclusion: MRI CEKWorld模型通过STCL方法（包括LAL和LDL）成功解决了MRI对比增强动力学建模中的内容失真和时间不连续问题，实验证明其在生成真实内容和动力学方面表现优异。

Abstract: Clinical MRI contrast acquisition suffers from inefficient information yield, which presents as a mismatch between the risky and costly acquisition protocol and the fixed and sparse acquisition sequence. Applying world models to simulate the contrast enhancement kinetics in the human body enables continuous contrast-free dynamics. However, the low temporal resolution in MRI acquisition restricts the training of world models, leading to a sparsely sampled dataset. Directly training a generative model to capture the kinetics leads to two limitations: (a) Due to the absence of data on missing time, the model tends to overfit to irrelevant features, leading to content distortion. (b) Due to the lack of continuous temporal supervision, the model fails to learn the continuous kinetics law over time, causing temporal discontinuities. For the first time, we propose MRI Contrast Enhancement Kinetics World model (MRI CEKWorld) with SpatioTemporal Consistency Learning (STCL). For (a), guided by the spatial law that patient-level structures remain consistent during enhancement, we propose Latent Alignment Learning (LAL) that constructs a patient-specific template to constrain contents to align with this template. For (b), guided by the temporal law that the kinetics follow a consistent smooth trend, we propose Latent Difference Learning (LDL) which extends the unobserved intervals by interpolation and constrains smooth variations in the latent space among interpolated sequences. Extensive experiments on two datasets show our MRI CEKWorld achieves better realistic contents and kinetics. Codes will be available at https://github.com/DD0922/MRI-Contrast-Enhancement-Kinetics-World-Model.

</details>


### [121] [UP-Fuse: Uncertainty-guided LiDAR-Camera Fusion for 3D Panoptic Segmentation](https://arxiv.org/abs/2602.19349)
*Rohit Mohan,Florian Drews,Yakov Miron,Daniele Cattaneo,Abhinav Valada*

Main category: cs.CV

TL;DR: UP-Fuse是一种不确定性感知的LiDAR-相机融合框架，能在相机传感器故障时保持鲁棒性，通过动态融合和混合解码实现高性能3D全景分割。


<details>
  <summary>Details</summary>
Motivation: LiDAR-相机融合在恶劣条件下可能因相机传感器退化或故障导致感知系统可靠性下降，需设计鲁棒的融合框架。

Method: UP-Fuse采用不确定性引导的融合模块，动态调节跨模态交互，并通过混合2D-3D变换器解码融合特征，直接预测3D全景分割掩码。

Result: 在Panoptic nuScenes、SemanticKITTI和Panoptic Waymo基准测试中，UP-Fuse表现出色，即使在严重视觉退化或错位情况下仍保持高性能。

Conclusion: UP-Fuse框架通过不确定性感知的融合机制，在相机传感器退化、校准漂移或故障情况下仍保持鲁棒性，适用于安全关键场景的机器人感知。

Abstract: LiDAR-camera fusion enhances 3D panoptic segmentation by leveraging camera images to complement sparse LiDAR scans, but it also introduces a critical failure mode. Under adverse conditions, degradation or failure of the camera sensor can significantly compromise the reliability of the perception system. To address this problem, we introduce UP-Fuse, a novel uncertainty-aware fusion framework in the 2D range-view that remains robust under camera sensor degradation, calibration drift, and sensor failure. Raw LiDAR data is first projected into the range-view and encoded by a LiDAR encoder, while camera features are simultaneously extracted and projected into the same shared space. At its core, UP-Fuse employs an uncertainty-guided fusion module that dynamically modulates cross-modal interaction using predicted uncertainty maps. These maps are learned by quantifying representational divergence under diverse visual degradations, ensuring that only reliable visual cues influence the fused representation. The fused range-view features are decoded by a novel hybrid 2D-3D transformer that mitigates spatial ambiguities inherent to the 2D projection and directly predicts 3D panoptic segmentation masks. Extensive experiments on Panoptic nuScenes, SemanticKITTI, and our introduced Panoptic Waymo benchmark demonstrate the efficacy and robustness of UP-Fuse, which maintains strong performance even under severe visual corruption or misalignment, making it well suited for robotic perception in safety-critical settings.

</details>


### [122] [Pay Attention to CTC: Fast and Robust Pseudo-Labelling for Unified Speech Recognition](https://arxiv.org/abs/2602.19316)
*Alexandros Haliassos,Rodrigo Mira,Stavros Petridis*

Main category: cs.CV

TL;DR: USR 2.0通过CTC驱动的教师强制和混合采样，优化了训练效率和鲁棒性，在多个语音识别基准上取得最佳表现。


<details>
  <summary>Details</summary>
Motivation: USR框架依赖自回归伪标签导致训练成本高，且CTC和注意力分支的解耦监督易在分布偏移时产生自强化错误。

Method: 提出CTC驱动的教师强制方法，利用贪婪解码的CTC伪标签生成注意力目标，并通过混合采样减少解码器的曝光偏差。

Result: USR 2.0将训练时间减半，提高了对噪声和未见域的鲁棒性，在LRS3、LRS2和WildVSR上超越了USR和模态特定的自监督基线。

Conclusion: USR 2.0通过CTC驱动的教师强制和混合采样，显著降低了训练时间，提高了对分布外输入的鲁棒性，并在多个基准测试中实现了最先进的性能。

Abstract: Unified Speech Recognition (USR) has emerged as a semi-supervised framework for training a single model for audio, visual, and audiovisual speech recognition, achieving state-of-the-art results on in-distribution benchmarks. However, its reliance on autoregressive pseudo-labelling makes training expensive, while its decoupled supervision of CTC and attention branches increases susceptibility to self-reinforcing errors, particularly under distribution shifts involving longer sequences, noise, or unseen domains. We propose CTC-driven teacher forcing, where greedily decoded CTC pseudo-labels are fed into the decoder to generate attention targets in a single forward pass. Although these can be globally incoherent, in the pseudo-labelling setting they enable efficient and effective knowledge transfer. Because CTC and CTC-driven attention pseudo-labels have the same length, the decoder can predict both simultaneously, benefiting from the robustness of CTC and the expressiveness of attention without costly beam search. We further propose mixed sampling to mitigate the exposure bias of the decoder relying solely on CTC inputs. The resulting method, USR 2.0, halves training time, improves robustness to out-of-distribution inputs, and achieves state-of-the-art results on LRS3, LRS2, and WildVSR, surpassing USR and modality-specific self-supervised baselines.

</details>


### [123] [Redefining the Down-Sampling Scheme of U-Net for Precision Biomedical Image Segmentation](https://arxiv.org/abs/2602.19412)
*Mingjie Li,Yizheng Chen,Md Tauhidul Islam,Lei Xing*

Main category: cs.CV

TL;DR: 提出Stair Pooling策略，通过优化下采样减少信息损失，提升U-Net在生物医学图像分割中的性能。


<details>
  <summary>Details</summary>
Motivation: 传统下采样方法在计算效率和信息保留之间存在矛盾，导致U-Net在长距离信息捕捉上表现不佳。

Method: 提出了一种称为Stair Pooling的下采样策略，通过调整下采样步长（从1/4改为1/2）和采用多方向的小型窄池化操作，减少信息损失。

Result: 在三个BIS基准测试中，Stair Pooling平均将2D和3D U-Net的Dice分数提高了3.8%。

Conclusion: Stair Pooling策略有效减少了信息损失，提升了U-Net在生物医学图像分割中的性能，特别是在长距离信息捕捉方面。

Abstract: U-Net architectures have been instrumental in advancing biomedical image segmentation (BIS) but often struggle with capturing long-range information. One reason is the conventional down-sampling techniques that prioritize computational efficiency at the expense of information retention. This paper introduces a simple but effective strategy, we call it Stair Pooling, which moderates the pace of down-sampling and reduces information loss by leveraging a sequence of concatenated small and narrow pooling operations in varied orientations. Specifically, our method modifies the reduction in dimensionality within each 2D pooling step from $\frac{1}{4}$ to $\frac{1}{2}$. This approach can also be adapted for 3D pooling to preserve even more information. Such preservation aids the U-Net in more effectively reconstructing spatial details during the up-sampling phase, thereby enhancing its ability to capture long-range information and improving segmentation accuracy. Extensive experiments on three BIS benchmarks demonstrate that the proposed Stair Pooling can increase both 2D and 3D U-Net performance by an average of 3.8\% in Dice scores. Moreover, we leverage the transfer entropy to select the optimal down-sampling paths and quantitatively show how the proposed Stair Pooling reduces the information loss.

</details>


### [124] [FinSight-Net:A Physics-Aware Decoupled Network with Frequency-Domain Compensation for Underwater Fish Detection in Smart Aquaculture](https://arxiv.org/abs/2602.19437)
*Jinsong Yang,Zeyuan Hu,Yichen Li,Hong Yu*

Main category: cs.CV

TL;DR: FinSight-Net是一种针对水下鱼类检测的高效物理感知框架，通过MS-DDSP和EPA-FPN技术，显著提升了检测性能并减少了计算开销。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类检测（UFD）面临波长吸收和浊度散射导致的对比度下降、结构模糊和噪声干扰，现有方法忽略了这些物理限制，导致检测不可靠。

Method: FinSight-Net 采用了多尺度解耦双流处理（MS-DDSP）瓶颈和高效路径聚合FPN（EPA-FPN），通过异质卷积分支和长程跳跃连接等技术，解决了水下环境中的信息丢失和噪声问题。

Result: 在DeepFish、AquaFishSet和UW-BlurredFish基准测试中，FinSight-Net实现了92.8%的mAP，优于YOLOv11s 4.8%，同时参数减少29.0%。

Conclusion: FinSight-Net 提供了一种高效且物理感知的检测框架，专为复杂水产养殖环境设计，显著提升了水下鱼类检测的准确性和效率。

Abstract: Underwater fish detection (UFD) is a core capability for smart aquaculture and marine ecological monitoring. While recent detectors improve accuracy by stacking feature extractors or introducing heavy attention modules, they often incur substantial computational overhead and, more importantly, neglect the physics that fundamentally limits UFD: wavelength-dependent absorption and turbidity-induced scattering significantly degrade contrast, blur fine structures, and introduce backscattering noise, leading to unreliable localization and recognition. To address these challenges, we propose FinSight-Net, an efficient and physics-aware detection framework tailored for complex aquaculture environments. FinSight-Net introduces a Multi-Scale Decoupled Dual-Stream Processing (MS-DDSP) bottleneck that explicitly targets frequency-specific information loss via heterogeneous convolutional branches, suppressing backscattering artifacts while compensating distorted biological cues through scale-aware and channel-weighted pathways. We further design an Efficient Path Aggregation FPN (EPA-FPN) as a detail-filling mechanism: it restores high-frequency spatial information typically attenuated in deep layers by establishing long-range skip connections and pruning redundant fusion routes, enabling robust detection of non-rigid fish targets under severe blur and turbidity. Extensive experiments on DeepFish, AquaFishSet, and our challenging UW-BlurredFish benchmark demonstrate that FinSight-Net achieves state-of-the-art performance. In particular, on UW-BlurredFish, FinSight-Net reaches 92.8% mAP, outperforming YOLOv11s by 4.8% while reducing parameters by 29.0%, providing a strong and lightweight solution for real-time automated monitoring in smart aquaculture.

</details>


### [125] [DefenseSplat: Enhancing the Robustness of 3D Gaussian Splatting via Frequency-Aware Filtering](https://arxiv.org/abs/2602.19323)
*Yiran Qiao,Yiren Lu,Yunlai Zhou,Rui Yang,Linlin Hou,Yu Yin,Jing Ma*

Main category: cs.CV

TL;DR: 论文提出一种频率感知防御策略，通过过滤高频噪声提升3D高斯泼溅的对抗鲁棒性，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）在实时高保真3D重建中表现优异，但其对输入视图中的对抗性扰动极为敏感，导致渲染质量下降、训练和渲染时间增加，甚至引发服务器拒绝服务。

Method: 使用小波变换分析对抗性扰动在高低频成分中的行为，设计频率感知防御策略，通过过滤高频噪声并保留低频内容来重建训练视图。

Result: 实验表明，该方法在多种攻击强度下显著提升了3DGS的鲁棒性，且无需干净的监督数据。

Conclusion: 该论文通过分析对抗性扰动在输入图像高低频成分中的不同行为，设计了一种简单有效的频率感知防御策略，显著提升了3D高斯泼溅（3DGS）的鲁棒性，同时不影响干净数据的训练性能。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful paradigm for real-time and high-fidelity 3D reconstruction from posed images. However, recent studies reveal its vulnerability to adversarial corruptions in input views, where imperceptible yet consistent perturbations can drastically degrade rendering quality, increase training and rendering time, and inflate memory usage, even leading to server denial-of-service. In our work, to mitigate this issue, we begin by analyzing the distinct behaviors of adversarial perturbations in the low- and high-frequency components of input images using wavelet transforms. Based on this observation, we design a simple yet effective frequency-aware defense strategy that reconstructs training views by filtering high-frequency noise while preserving low-frequency content. This approach effectively suppresses adversarial artifacts while maintaining the authenticity of the original scene. Notably, it does not significantly impair training on clean data, achieving a desirable trade-off between robustness and performance on clean inputs. Through extensive experiments under a wide range of attack intensities on multiple benchmarks, we demonstrate that our method substantially enhances the robustness of 3DGS without access to clean ground-truth supervision. By highlighting and addressing the overlooked vulnerabilities of 3D Gaussian Splatting, our work paves the way for more robust and secure 3D reconstructions.

</details>


### [126] [Fore-Mamba3D: Mamba-based Foreground-Enhanced Encoding for 3D Object Detection](https://arxiv.org/abs/2602.19536)
*Zhiwei Ning,Xuanang Gao,Jiaxi Cao,Runze Yang,Huiying Xu,Xinzhong Zhu,Jie Yang,Wei Liu*

Main category: cs.CV

TL;DR: Fore-Mamba3D通过前景增强和上下文优化，提升3D物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有Mamba方法对整个非空体素序列进行双向编码，包含大量无用背景信息，而仅编码前景体素会降低检测性能。

Method: 提出Fore-Mamba3D，包括前景体素采样、区域到全局滑动窗口（RGSW）和语义辅助状态空间融合模块（SASFMamba）。

Result: 在各种基准测试中表现优异，证明了Fore-Mamba3D的有效性。

Conclusion: Fore-Mamba3D通过专注于前景增强并解决线性建模中的响应衰减和上下文表示限制，在3D物体检测任务中表现出色。

Abstract: Linear modeling methods like Mamba have been merged as the effective backbone for the 3D object detection task. However, previous Mamba-based methods utilize the bidirectional encoding for the whole non-empty voxel sequence, which contains abundant useless background information in the scenes. Though directly encoding foreground voxels appears to be a plausible solution, it tends to degrade detection performance. We attribute this to the response attenuation and restricted context representation in the linear modeling for fore-only sequences. To address this problem, we propose a novel backbone, termed Fore-Mamba3D, to focus on the foreground enhancement by modifying Mamba-based encoder. The foreground voxels are first sampled according to the predicted scores. Considering the response attenuation existing in the interaction of foreground voxels across different instances, we design a regional-to-global slide window (RGSW) to propagate the information from regional split to the entire sequence. Furthermore, a semantic-assisted and state spatial fusion module (SASFMamba) is proposed to enrich contextual representation by enhancing semantic and geometric awareness within the Mamba model. Our method emphasizes foreground-only encoding and alleviates the distance-based and causal dependencies in the linear autoregression model. The superior performance across various benchmarks demonstrates the effectiveness of Fore-Mamba3D in the 3D object detection task.

</details>


### [127] [PoseCraft: Tokenized 3D Body Landmark and Camera Conditioning for Photorealistic Human Image Synthesis](https://arxiv.org/abs/2602.19350)
*Zhilin Guo,Jing Yang,Kyle Fogarty,Jingyi Wan,Boqiao Zhang,Tianhao Wu,Weihao Xia,Chenliang Zhou,Sakar Khattar,Fangcheng Zhong,Cristina Nader Vasconcelos,Cengiz Oztireli*

Main category: cs.CV

TL;DR: PoseCraft是一种基于扩散框架的3D标记化接口方法，用于生成真实感人体图像，显著提升质量并保留细节。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于蒙皮的工作流程需要繁琐的手动装配或基于模板的拟合，以及神经体积方法依赖于规范模板和针对每个未见姿势的重新优化的问题。

Method: 采用扩散框架，利用标记化的3D接口（稀疏3D地标和相机外参作为离散条件标记）并通过交叉注意力注入。

Result: PoseCraft在感知质量上显著优于以扩散为中心的方法，并在指标上与最新的体积渲染SOTA相当或更好，同时更好地保留了织物和头发细节。

Conclusion: PoseCraft通过扩散框架和3D标记化接口，显著提升了感知质量，并在保持织物和头发细节方面优于现有方法。

Abstract: Digitizing humans and synthesizing photorealistic avatars with explicit 3D pose and camera controls are central to VR, telepresence, and entertainment. Existing skinning-based workflows require laborious manual rigging or template-based fittings, while neural volumetric methods rely on canonical templates and re-optimization for each unseen pose. We present PoseCraft, a diffusion framework built around tokenized 3D interface: instead of relying only on rasterized geometry as 2D control images, we encode sparse 3D landmarks and camera extrinsics as discrete conditioning tokens and inject them into diffusion via cross-attention. Our approach preserves 3D semantics by avoiding 2D re-projection ambiguity under large pose and viewpoint changes, and produces photorealistic imagery that faithfully captures identity and appearance. To train and evaluate at scale, we also implement GenHumanRF, a data generation workflow that renders diverse supervision from volumetric reconstructions. Our experiments show that PoseCraft achieves significant perceptual quality improvement over diffusion-centric methods, and attains better or comparable metrics to latest volumetric rendering SOTA while better preserving fabric and hair details.

</details>


### [128] [MentalBlackboard: Evaluating Spatial Visualization via Mathematical Transformations](https://arxiv.org/abs/2602.19357)
*Nilay Yilmaz,Maitreya Patel,Naga Sai Abhiram Kusumba,Yixuan He,Yezhou Yang*

Main category: cs.CV

TL;DR: VLMs在空间可视化任务中表现有限，对称和旋转是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型是否具备人类认知中的空间可视化能力。

Method: 开发了MentalBlackboard基准测试，包含纸张折叠和打孔测试，分为预测和规划两个核心任务。

Result: 模型在对称变换和旋转任务中表现不佳，Claude Opus 4.1在规划任务中最高准确率为10%，o3模型在泛化任务中达到71.6%但文本预测任务仅25%。

Conclusion: 当前最先进的视觉语言模型（VLMs）在空间可视化能力上表现有限，尤其在对称变换和多阶段对称过程分析方面存在明显不足。

Abstract: Spatial visualization is the mental ability to imagine, transform, and manipulate the spatial characteristics of objects and actions. This intelligence is a part of human cognition where actions and perception are connected on a mental level. To explore whether state-of-the-art Vision-Language Models (VLMs) exhibit this ability, we develop MentalBlackboard, an open-ended spatial visualization benchmark for Paper Folding and Hole Punching tests within two core tasks: prediction and planning. Our prediction experiments reveal that models struggle with applying symmetrical transformations, even when they predict the sequence of unfolding steps correctly. Also, rotations introduce a significant challenge to the physical situational awareness for models. The planning task reveals limitations of models in analyzing symmetrical relationships and in implementing the multi-stage symmetry process, with Claude Opus 4.1 achieving the highest planning score at an accuracy of 10\%. The top-performing model, o3, attains a peak performance of 71.6\% on the generalization task, which does not require spatial visualization but transfers spatial data; however, it achieves only 25\% accuracy on text-based prediction tasks.

</details>


### [129] [A Green Learning Approach to LDCT Image Restoration](https://arxiv.org/abs/2602.19540)
*Wei Wang,Yixing Wu,C. -C. Jay Kuo*

Main category: cs.CV

TL;DR: 提出绿色学习（GL）方法用于医学图像恢复，相比深度学习（DL）更高效且性能优越。


<details>
  <summary>Details</summary>
Motivation: 低剂量计算机断层扫描（LDCT）图像易受噪声和伪影影响，影响后续医学分析，需要高效的恢复方法。

Method: 采用绿色学习（GL）方法，与传统的深度学习（DL）方法相比，具有更小的模型尺寸和更低的推理复杂度。

Result: 实验表明，GL方法在恢复性能上达到最先进水平，同时模型更小、复杂度更低。

Conclusion: GL方法在医学图像恢复中表现出色，具有数学透明性、计算和内存效率高以及高性能的特点。

Abstract: This work proposes a green learning (GL) approach to restore medical images. Without loss of generality, we use low-dose computed tomography (LDCT) images as examples. LDCT images are susceptible to noise and artifacts, where the imaging process introduces distortion. LDCT image restoration is an important preprocessing step for further medical analysis. Deep learning (DL) methods have been developed to solve this problem. We examine an alternative solution using the Green Learning (GL) methodology. The new restoration method is characterized by mathematical transparency, computational and memory efficiency, and high performance. Experiments show that our GL method offers state-of-the-art restoration performance at a smaller model size and with lower inference complexity.

</details>


### [130] [Referring Layer Decomposition](https://arxiv.org/abs/2602.19358)
*Fangyi Chen,Yaojie Shen,Lu Xu,Ye Yuan,Shu Zhang,Yulei Niu,Longyin Wen*

Main category: cs.CV

TL;DR: 论文提出RLD任务和RefLayer模型，通过分层表示实现可控的图像编辑，实验证明其高效且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常整体处理图像，难以单独操控场景元素，而分层表示能更直观地编辑和理解视觉内容。

Method: 引入了Referring Layer Decomposition (RLD)任务，基于用户提示预测RGBA层，并提出了RefLayer基线模型。

Result: RefLade数据集和RefLayer模型实现了高质量的图像分解，并通过实验验证了其有效性和可靠性。

Conclusion: RefLayer方法在视觉保真度和语义对齐方面表现优异，展示了强大的零样本泛化能力。

Abstract: Precise, object-aware control over visual content is essential for advanced image editing and compositional generation. Yet, most existing approaches operate on entire images holistically, limiting the ability to isolate and manipulate individual scene elements. In contrast, layered representations, where scenes are explicitly separated into objects, environmental context, and visual effects, provide a more intuitive and structured framework for interpreting and editing visual content. To bridge this gap and enable both compositional understanding and controllable editing, we introduce the Referring Layer Decomposition (RLD) task, which predicts complete RGBA layers from a single RGB image, conditioned on flexible user prompts, such as spatial inputs (e.g., points, boxes, masks), natural language descriptions, or combinations thereof. At the core is the RefLade, a large-scale dataset comprising 1.11M image-layer-prompt triplets produced by our scalable data engine, along with 100K manually curated, high-fidelity layers. Coupled with a perceptually grounded, human-preference-aligned automatic evaluation protocol, RefLade establishes RLD as a well-defined and benchmarkable research task. Building on this foundation, we present RefLayer, a simple baseline designed for prompt-conditioned layer decomposition, achieving high visual fidelity and semantic alignment. Extensive experiments show our approach enables effective training, reliable evaluation, and high-quality image decomposition, while exhibiting strong zero-shot generalization capabilities.

</details>


### [131] [DICArt: Advancing Category-level Articulated Object Pose Estimation in Discrete State-Spaces](https://arxiv.org/abs/2602.19565)
*Li Zhang,Mingyu Mei,Ailing Wang,Xianhui Meng,Yan Zhong,Xinyuan Song,Liu Liu,Rujing Wang,Zaixing He,Cewu Lu*

Main category: cs.CV

TL;DR: DICArt是一种新颖的离散扩散框架，用于姿态估计，通过动态去噪和分层运动学耦合，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在连续空间中回归姿态，但难以处理大而复杂的搜索空间，且未能有效利用内在运动学约束。

Method: DICArt将姿态估计建模为条件离散扩散过程，通过学习的反向扩散过程逐步去噪。提出了灵活的流决策器和分层运动学耦合策略。

Result: 实验结果表明DICArt在合成和真实数据集上均表现出优越的性能和鲁棒性。

Conclusion: DICArt通过结合离散生成建模和结构先验，为复杂环境中的可靠类别级6D姿态估计提供了新范式。

Abstract: Articulated object pose estimation is a core task in embodied AI. Existing methods typically regress poses in a continuous space, but often struggle with 1) navigating a large, complex search space and 2) failing to incorporate intrinsic kinematic constraints. In this work, we introduce DICArt (DIsCrete Diffusion for Articulation Pose Estimation), a novel framework that formulates pose estimation as a conditional discrete diffusion process. Instead of operating in a continuous domain, DICArt progressively denoises a noisy pose representation through a learned reverse diffusion procedure to recover the GT pose. To improve modeling fidelity, we propose a flexible flow decider that dynamically determines whether each token should be denoised or reset, effectively balancing the real and noise distributions during diffusion. Additionally, we incorporate a hierarchical kinematic coupling strategy, estimating the pose of each rigid part hierarchically to respect the object's kinematic structure. We validate DICArt on both synthetic and real-world datasets. Experimental results demonstrate its superior performance and robustness. By integrating discrete generative modeling with structural priors, DICArt offers a new paradigm for reliable category-level 6D pose estimation in complex environments.

</details>


### [132] [Detector-in-the-Loop Tracking: Active Memory Rectification for Stable Glottic Opening Localization](https://arxiv.org/abs/2602.19380)
*Huayu Wang,Bahaa Alattar,Cheng-Yen Yang,Hsiang-Wei Huang,Jung Heon Kim,Linda Shapiro,Nathan White,Jenq-Neng Hwang*

Main category: cs.CV

TL;DR: CL-MC通过闭环记忆校正框架，在喉镜视频中有效减少跟踪漂移，提升定位准确性。


<details>
  <summary>Details</summary>
Motivation: 解决单帧检测器缺乏时间上下文和基础模型跟踪器存在记忆漂移的问题，特别是在喉镜视频中快速组织变形、遮挡和视觉模糊的挑战。

Method: 提出了闭环记忆校正（CL-MC）框架，通过高置信度检测触发语义重置，修正跟踪器记忆，无需训练即可在复杂内窥镜场景中减少漂移。

Result: 在紧急插管视频中，CL-MC实现了最先进的性能，显著降低了漂移和漏检率。

Conclusion: CL-MC通过闭环记忆校正显著提升了喉镜视频中声门开口定位的稳定性和准确性，为临床视频跟踪提供了可靠解决方案。

Abstract: Temporal stability in glottic opening localization remains challenging due to the complementary weaknesses of single-frame detectors and foundation-model trackers: the former lacks temporal context, while the latter suffers from memory drift. Specifically, in video laryngoscopy, rapid tissue deformation, occlusions, and visual ambiguities in emergency settings require a robust, temporally aware solution that can prevent progressive tracking errors. We propose Closed-Loop Memory Correction (CL-MC), a detector-in-the-loop framework that supervises Segment Anything Model 2(SAM2) through confidence-aligned state decisions and active memory rectification. High-confidence detections trigger semantic resets that overwrite corrupted tracker memory, effectively mitigating drift accumulation with a training-free foundation tracker in complex endoscopic scenes. On emergency intubation videos, CL-MC achieves state-of-the-art performance, significantly reducing drift and missing rate compared with the SAM2 variants and open loop based methods. Our results establish memory correction as a crucial component for reliable clinical video tracking. Our code will be available in https://github.com/huayuww/CL-MR.

</details>


### [133] [CLCR: Cross-Level Semantic Collaborative Representation for Multimodal Learning](https://arxiv.org/abs/2602.19605)
*Chunlei Meng,Guanhong Huang,Rong Fu,Runmin Jian,Zhongxue Gan,Chun Ouyang*

Main category: cs.CV

TL;DR: CLCR通过多级语义层次和层级约束优化多模态学习，提升表示质量并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法将所有模态投射到单一潜在空间进行融合，忽视了多模态数据的异步、多级语义结构，导致语义错位和错误传播，降低了表示质量。

Method: CLCR采用语义层次编码器对齐多模态的浅层、中层和深层特征，并通过IntraCED和InterCAD分别处理层级内和层级间的特征交互，确保共享和私有特征的分离。

Result: 在六个基准测试（包括情感识别、事件定位、情感分析和动作识别）中，CLCR表现出色且具有良好泛化能力。

Conclusion: CLCR通过明确组织多模态数据的语义层次并引入层级间约束，显著提升了多模态学习的表现和泛化能力。

Abstract: Multimodal learning aims to capture both shared and private information from multiple modalities. However, existing methods that project all modalities into a single latent space for fusion often overlook the asynchronous, multi-level semantic structure of multimodal data. This oversight induces semantic misalignment and error propagation, thereby degrading representation quality. To address this issue, we propose Cross-Level Co-Representation (CLCR), which explicitly organizes each modality's features into a three-level semantic hierarchy and specifies level-wise constraints for cross-modal interactions. First, a semantic hierarchy encoder aligns shallow, mid, and deep features across modalities, establishing a common basis for interaction. And then, at each level, an Intra-Level Co-Exchange Domain (IntraCED) factorizes features into shared and private subspaces and restricts cross-modal attention to the shared subspace via a learnable token budget. This design ensures that only shared semantics are exchanged and prevents leakage from private channels. To integrate information across levels, the Inter-Level Co-Aggregation Domain (InterCAD) synchronizes semantic scales using learned anchors, selectively fuses the shared representations, and gates private cues to form a compact task representation. We further introduce regularization terms to enforce separation of shared and private features and to minimize cross-level interference. Experiments on six benchmarks spanning emotion recognition, event localization, sentiment analysis, and action recognition show that CLCR achieves strong performance and generalizes well across tasks.

</details>


### [134] [Adaptive Data Augmentation with Multi-armed Bandit: Sample-Efficient Embedding Calibration for Implicit Pattern Recognition](https://arxiv.org/abs/2602.19385)
*Minxue Tang,Yangyang Yu,Aolin Ding,Maziyar Baran Pouyan,Taha Belkhouja Yujia Bao*

Main category: cs.CV

TL;DR: ADAMAB是一种高效的嵌入校准框架，通过轻量级校准器和自适应数据增强，显著提升少样本模式识别的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前预训练基础模型（如LLMs和VLMs）在长尾模式识别任务中表现不佳，且微调通常因缺乏训练数据和高计算开销而不可行。

Method: ADAMAB通过在固定嵌入模型上训练嵌入无关的轻量级校准器，并采用基于多臂老虎机（MAB）机制的自适应数据增强策略，减少计算开销和数据需求。

Result: ADAMAB在少样本训练中表现出色，尤其在每类初始样本少于5个的情况下，准确率提升高达40%。

Conclusion: ADAMAB框架通过嵌入无关的轻量级校准器和自适应数据增强策略，显著提升了少样本模式识别的性能，最高可达40%的准确率提升。

Abstract: Recognizing implicit visual and textual patterns is essential in many real-world applications of modern AI. However, tackling long-tail pattern recognition tasks remains challenging for current pre-trained foundation models such as LLMs and VLMs. While finetuning pre-trained models can improve accuracy in recognizing implicit patterns, it is usually infeasible due to a lack of training data and high computational overhead. In this paper, we propose ADAMAB, an efficient embedding calibration framework for few-shot pattern recognition. To maximally reduce the computational costs, ADAMAB trains embedder-agnostic light-weight calibrators on top of fixed embedding models without accessing their parameters. To mitigate the need for large-scale training data, we introduce an adaptive data augmentation strategy based on the Multi-Armed Bandit (MAB) mechanism. With a modified upper confidence bound algorithm, ADAMAB diminishes the gradient shifting and offers theoretically guaranteed convergence in few-shot training. Our multi-modal experiments justify the superior performance of ADAMAB, with up to 40% accuracy improvement when training with less than 5 initial data samples of each class.

</details>


### [135] [Satellite-Based Detection of Looted Archaeological Sites Using Machine Learning](https://arxiv.org/abs/2602.19608)
*Girmaw Abebe Tadesse,Titien Bartette,Andrew Hassanali,Allen Kim,Jonathan Chemla,Andrew Zolli,Yves Ubelmann,Caleb Robinson,Inbal Becker-Reshef,Juan Lavista Ferres*

Main category: cs.CV

TL;DR: 卫星遥感结合CNN能高效检测考古遗址掠夺，效果远超传统方法。


<details>
  <summary>Details</summary>
Motivation: 考古遗址掠夺对文化遗产构成严重威胁，但远程监控数千个遗址在操作上具有挑战性。研究旨在开发一种可扩展的卫星遥感方法来检测掠夺行为。

Method: 使用PlanetScope月度拼接图像（4.7米/像素）和1,943个阿富汗考古遗址的标注数据集（898个被掠夺，1,045个保存完好），比较了端到端CNN分类器和传统机器学习方法。CNN基于ImageNet预训练和空间掩码，传统ML则基于手工特征和遥感基础模型嵌入。

Result: ImageNet预训练的CNN结合空间掩码达到F1分数0.926，显著优于传统ML的最佳配置（F1分数0.710）。

Conclusion: 卫星遥感结合深度学习的端到端CNN分类器在检测考古遗址掠夺方面表现优异，明显优于传统机器学习方法，尤其是在结合空间掩码和ImageNet预训练的情况下。

Abstract: Looting at archaeological sites poses a severe risk to cultural heritage, yet monitoring thousands of remote locations remains operationally difficult. We present a scalable and satellite-based pipeline to detect looted archaeological sites, using PlanetScope monthly mosaics (4.7m/pixel) and a curated dataset of 1,943 archaeological sites in Afghanistan (898 looted, 1,045 preserved) with multi-year imagery (2016--2023) and site-footprint masks. We compare (i) end-to-end CNN classifiers trained on raw RGB patches and (ii) traditional machine learning (ML) trained on handcrafted spectral/texture features and embeddings from recent remote-sensing foundation models. Results indicate that ImageNet-pretrained CNNs combined with spatial masking reach an F1 score of 0.926, clearly surpassing the strongest traditional ML setup, which attains an F1 score of 0.710 using SatCLIP-V+RF+Mean, i.e., location and vision embeddings fed into a Random Forest with mean-based temporal aggregation. Ablation studies demonstrate that ImageNet pretraining (even in the presence of domain shift) and spatial masking enhance performance. In contrast, geospatial foundation model embeddings perform competitively with handcrafted features, suggesting that looting signatures are extremely localized. The repository is available at https://github.com/microsoft/looted_site_detection.

</details>


### [136] [PedaCo-Gen: Scaffolding Pedagogical Agency in Human-AI Collaborative Video Authoring](https://arxiv.org/abs/2602.19623)
*Injun Baek,Yearim Kim,Nojun Kwak*

Main category: cs.CV

TL;DR: PedaCo-Gen是一个教学导向的人机协作视频生成系统，通过互动优化视频蓝图，显著提升教学视频质量，并增强教育者的教学设计能力。


<details>
  <summary>Details</summary>
Motivation: 当前文本到视频（T2V）生成AI模型通常侧重于视觉保真度而非教学效果，本研究旨在开发一个教学导向的人机协作视频生成系统。

Method: 研究引入了PedaCo-Gen系统，基于Mayer的多媒体学习认知理论，通过中间表示（IR）阶段，让教育工作者与AI评审互动审查和优化视频蓝图。

Result: 与基线相比，PedaCo-Gen显著提升了视频质量，参与者认为AI驱动的指导不仅是操作指南，更是增强教学设计专业知识的元认知支架。

Conclusion: 研究发现，通过原则性共创可以重新获得教学主导权，为未来结合生成能力与人类专业知识的AI创作工具奠定了基础。

Abstract: While advancements in Text-to-Video (T2V) generative AI offer a promising path toward democratizing content creation, current models are often optimized for visual fidelity rather than instructional efficacy. This study introduces PedaCo-Gen, a pedagogically-informed human-AI collaborative video generating system for authoring instructional videos based on Mayer's Cognitive Theory of Multimedia Learning (CTML). Moving away from traditional "one-shot" generation, PedaCo-Gen introduces an Intermediate Representation (IR) phase, enabling educators to interactively review and refine video blueprints-comprising scripts and visual descriptions-with an AI reviewer. Our study with 23 education experts demonstrates that PedaCo-Gen significantly enhances video quality across various topics and CTML principles compared to baselines. Participants perceived the AI-driven guidance not merely as a set of instructions but as a metacognitive scaffold that augmented their instructional design expertise, reporting high production efficiency (M=4.26) and guide validity (M=4.04). These findings highlight the importance of reclaiming pedagogical agency through principled co-creation, providing a foundation for future AI authoring tools that harmonize generative power with human professional expertise.

</details>


### [137] [PA-Attack: Guiding Gray-Box Attacks on LVLM Vision Encoders with Prototypes and Attention](https://arxiv.org/abs/2602.19418)
*Hefei Mei,Zirui Wang,Chang Xu,Jianyuan Guo,Minjing Dong*

Main category: cs.CV

TL;DR: PA-Attack通过原型锚定和注意力增强机制，显著提升对抗攻击效果和任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对现有对抗攻击方法在任务泛化和效率上的不足，利用视觉编码器的稳定性作为灰盒攻击的切入点。

Method: PA-Attack采用原型锚定引导和两阶段注意力增强机制，包括关键视觉令牌的扰动集中和注意力权重的自适应调整。

Result: 在多种下游任务和LVLM架构上，PA-Attack平均实现了75.1%的得分降低率（SRR）。

Conclusion: PA-Attack通过原型锚定和注意力增强机制，显著提升了对抗攻击的效果和任务泛化能力，在多种LVLM架构上表现出色。

Abstract: Large Vision-Language Models (LVLMs) are foundational to modern multimodal applications, yet their susceptibility to adversarial attacks remains a critical concern. Prior white-box attacks rarely generalize across tasks, and black-box methods depend on expensive transfer, which limits efficiency. The vision encoder, standardized and often shared across LVLMs, provides a stable gray-box pivot with strong cross-model transfer. Building on this premise, we introduce PA-Attack (Prototype-Anchored Attentive Attack). PA-Attack begins with a prototype-anchored guidance that provides a stable attack direction towards a general and dissimilar prototype, tackling the attribute-restricted issue and limited task generalization of vanilla attacks. Building on this, we propose a two-stage attention enhancement mechanism: (i) leverage token-level attention scores to concentrate perturbations on critical visual tokens, and (ii) adaptively recalibrate attention weights to track the evolving attention during the adversarial process. Extensive experiments across diverse downstream tasks and LVLM architectures show that PA-Attack achieves an average 75.1% score reduction rate (SRR), demonstrating strong attack effectiveness, efficiency, and task generalization in LVLMs. Code is available at https://github.com/hefeimei06/PA-Attack.

</details>


### [138] [Localized Concept Erasure in Text-to-Image Diffusion Models via High-Level Representation Misdirection](https://arxiv.org/abs/2602.19631)
*Uichan Lee,Jeonghyeon Kim,Sangheum Hwang*

Main category: cs.CV

TL;DR: HiRM是一种通过误导高层次语义表示实现精确概念擦除的方法，对非目标概念影响小，且保持生成实用性。


<details>
  <summary>Details</summary>
Motivation: 针对文本到图像扩散模型可能被滥用于合成有害、隐私或受版权保护内容的担忧，研究概念擦除技术以降低风险。

Method: 提出了High-Level Representation Misdirection (HiRM)方法，通过将目标概念的高层次语义表示误导至指定向量（如随机方向或语义定义方向），同时仅更新包含视觉属性因果状态的早期层。

Result: 在UnlearnCanvas和NSFW基准测试中，HiRM对多样化目标（如对象、风格、裸露）表现出强大的概念擦除效果，同时保持生成质量。

Conclusion: HiRM方法通过在高层次语义表示上进行误导，实现了精确的概念擦除，同时对非目标概念的影响最小化，且在低训练成本下保持了生成实用性。该方法还能迁移至最新架构，并与基于去噪器的概念擦除方法产生协同效应。

Abstract: Recent advances in text-to-image (T2I) diffusion models have seen rapid and widespread adoption. However, their powerful generative capabilities raise concerns about potential misuse for synthesizing harmful, private, or copyrighted content. To mitigate such risks, concept erasure techniques have emerged as a promising solution. Prior works have primarily focused on fine-tuning the denoising component (e.g., the U-Net backbone). However, recent causal tracing studies suggest that visual attribute information is localized in the early self-attention layers of the text encoder, indicating a potential alternative for concept erasing. Building on this insight, we conduct preliminary experiments and find that directly fine-tuning early layers can suppress target concepts but often degrades the generation quality of non-target concepts. To overcome this limitation, we propose High-Level Representation Misdirection (HiRM), which misdirects high-level semantic representations of target concepts in the text encoder toward designated vectors such as random directions or semantically defined directions (e.g., supercategories), while updating only early layers that contain causal states of visual attributes. Our decoupling strategy enables precise concept removal with minimal impact on unrelated concepts, as demonstrated by strong results on UnlearnCanvas and NSFW benchmarks across diverse targets (e.g., objects, styles, nudity). HiRM also preserves generative utility at low training cost, transfers to state-of-the-art architectures such as Flux without additional training, and shows synergistic effects with denoiser-based concept erasing methods.

</details>


### [139] [Prefer-DAS: Learning from Local Preferences and Sparse Prompts for Domain Adaptive Segmentation of Electron Microscopy](https://arxiv.org/abs/2602.19423)
*Jiabao Chen,Shan Xiong,Jialin Peng*

Main category: cs.CV

TL;DR: Prefer-DAS通过稀疏提示学习和局部偏好对齐，显著提升了域自适应分割的性能和灵活性，接近监督模型效果。


<details>
  <summary>Details</summary>
Motivation: 解决无监督域适应（UDA）策略在实际应用中的性能限制和偏差问题，探索稀疏点和局部人类偏好作为目标域的弱标签，以实现更高效且现实的标注设置。

Method: 开发了Prefer-DAS，一种可提示的多任务模型，集成了自训练和提示引导的对比学习，并引入了局部直接偏好优化（LPO）、稀疏LPO（SLPO）和无监督偏好优化（UPO）。

Result: 在四个具有挑战性的DAS任务上的综合实验表明，Prefer-DAS在性能和灵活性上均优于现有方法。

Conclusion: Prefer-DAS模型在自动和交互式分割模式下均优于SAM类方法以及无监督和弱监督的DAS方法，表现出强大的泛化能力和灵活性，其性能接近甚至超过监督模型。

Abstract: Domain adaptive segmentation (DAS) is a promising paradigm for delineating intracellular structures from various large-scale electron microscopy (EM) without incurring extensive annotated data in each domain. However, the prevalent unsupervised domain adaptation (UDA) strategies often demonstrate limited and biased performance, which hinders their practical applications. In this study, we explore sparse points and local human preferences as weak labels in the target domain, thereby presenting a more realistic yet annotation-efficient setting. Specifically, we develop Prefer-DAS, which pioneers sparse promptable learning and local preference alignment. The Prefer-DAS is a promptable multitask model that integrates self-training and prompt-guided contrastive learning. Unlike SAM-like methods, the Prefer-DAS allows for the use of full, partial, and even no point prompts during both training and inference stages and thus enables interactive segmentation. Instead of using image-level human preference alignment for segmentation, we introduce Local direct Preference Optimization (LPO) and sparse LPO (SLPO), plug-and-play solutions for alignment with spatially varying human feedback or sparse feedback. To address potential missing feedback, we also introduce Unsupervised Preference Optimization (UPO), which leverages self-learned preferences. As a result, the Prefer-DAS model can effectively perform both weakly-supervised and unsupervised DAS, depending on the availability of points and human preferences. Comprehensive experiments on four challenging DAS tasks demonstrate that our model outperforms SAM-like methods as well as unsupervised and weakly-supervised DAS methods in both automatic and interactive segmentation modes, highlighting strong generalizability and flexibility. Additionally, the performance of our model is very close to or even exceeds that of supervised models.

</details>


### [140] [Hepato-LLaVA: An Expert MLLM with Sparse Topo-Pack Attention for Hepatocellular Pathology Analysis on Whole Slide Images](https://arxiv.org/abs/2602.19424)
*Yuxuan Yang,Zhonghao Yan,Yi Zhang,Bo Yun,Muxi Diao,Guowei Zhao,Kongming Liang,Wenbin Li,Zhanyu Ma*

Main category: cs.CV

TL;DR: Hepato-LLaVA是一种多模态大语言模型，通过稀疏拓扑注意力机制改进肝细胞癌病理分析，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 当前肝细胞癌诊断的计算方法受限于固定分辨率处理机制和低效特征聚合，导致信息丢失或特征冗余，亟需改进。

Method: 提出Hepato-LLaVA模型，采用稀疏拓扑注意力机制（Sparse Topo-Pack Attention）显式建模2D组织拓扑结构，有效聚合局部诊断证据并保留全局上下文。

Result: 实验表明，Hepato-LLaVA在HCC诊断和描述任务中达到最先进性能，显著优于现有方法。

Conclusion: Hepato-LLaVA通过创新的稀疏拓扑注意力机制和多模态大语言模型，显著提升了肝细胞癌诊断和描述的准确性和效率，为病理分析提供了新的解决方案。

Abstract: Hepatocellular Carcinoma diagnosis relies heavily on the interpretation of gigapixel Whole Slide Images. However, current computational approaches are constrained by fixed-resolution processing mechanisms and inefficient feature aggregation, which inevitably lead to either severe information loss or high feature redundancy. To address these challenges, we propose Hepato-LLaVA, a specialized Multi-modal Large Language Model designed for fine-grained hepatocellular pathology analysis. We introduce a novel Sparse Topo-Pack Attention mechanism that explicitly models 2D tissue topology. This mechanism effectively aggregates local diagnostic evidence into semantic summary tokens while preserving global context. Furthermore, to overcome the lack of multi-scale data, we present HepatoPathoVQA, a clinically grounded dataset comprising 33K hierarchically structured question-answer pairs validated by expert pathologists. Our experiments demonstrate that Hepato-LLaVA achieves state-of-the-art performance on HCC diagnosis and captioning tasks, significantly outperforming existing methods. Our code and implementation details are available at https://pris-cv.github.io/Hepto-LLaVA/.

</details>


### [141] [TeHOR: Text-Guided 3D Human and Object Reconstruction with Textures](https://arxiv.org/abs/2602.19679)
*Hyeongjin Nam,Daniel Sungho Jung,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: TeHOR通过文本和外观线索改进3D人-物重建，解决现有方法的局限性，实现更准确和语义一致的输出。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖物理接触信息，无法捕捉非接触交互，且忽视全局外观信息。TeHOR旨在解决这些局限性。

Method: TeHOR框架利用文本描述和外观线索，通过语义对齐和全局上下文捕捉，改进3D重建过程。

Result: TeHOR在3D重建中表现出色，能够处理更广泛的交互类型，并生成视觉上合理的结果。

Conclusion: TeHOR框架通过结合文本描述和外观线索，实现了更准确且语义一致的3D重建，达到了最先进的性能。

Abstract: Joint reconstruction of 3D human and object from a single image is an active research area, with pivotal applications in robotics and digital content creation. Despite recent advances, existing approaches suffer from two fundamental limitations. First, their reconstructions rely heavily on physical contact information, which inherently cannot capture non-contact human-object interactions, such as gazing at or pointing toward an object. Second, the reconstruction process is primarily driven by local geometric proximity, neglecting the human and object appearances that provide global context crucial for understanding holistic interactions. To address these issues, we introduce TeHOR, a framework built upon two core designs. First, beyond contact information, our framework leverages text descriptions of human-object interactions to enforce semantic alignment between the 3D reconstruction and its textual cues, enabling reasoning over a wider spectrum of interactions, including non-contact cases. Second, we incorporate appearance cues of the 3D human and object into the alignment process to capture holistic contextual information, thereby ensuring visually plausible reconstructions. As a result, our framework produces accurate and semantically coherent reconstructions, achieving state-of-the-art performance.

</details>


### [142] [TherA: Thermal-Aware Visual-Language Prompting for Controllable RGB-to-Thermal Infrared Translation](https://arxiv.org/abs/2602.19430)
*Dong-Guw Lee,Tai Hyoung Rhee,Hyunsoo Jang,Young-Sik Shin,Ukcheol Shin,Ayoung Kim*

Main category: cs.CV

TL;DR: TherA是一个可控的RGB-to-TIR转换框架，通过热感知嵌入和扩散模型生成物理合理的TIR图像，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 热红外(TIR)成像虽具优势，但大规模数据收集与标注仍是瓶颈。现有RGB-to-TIR方法依赖RGB先验，忽略热物理，导致热分布不合理。

Method: TherA耦合了TherA-VLM与基于潜在扩散的翻译器，通过用户提示的条件对和RGB图像生成热感知嵌入，进而控制扩散模型实现精细化的TIR合成。

Result: TherA在零样本翻译性能上平均提升33%，达到最先进的转换性能。

Conclusion: TherA框架通过结合TherA-VLM和潜在扩散模型，实现了在场景和对象级别生成多样且热物理合理的TIR图像，显著提升了RGB-to-TIR转换的性能。

Abstract: Despite the inherent advantages of thermal infrared(TIR) imaging, large-scale data collection and annotation remain a major bottleneck for TIR-based perception. A practical alternative is to synthesize pseudo TIR data via image translation; however, most RGB-to-TIR approaches heavily rely on RGB-centric priors that overlook thermal physics, yielding implausible heat distributions. In this paper, we introduce TherA, a controllable RGB-to-TIR translation framework that produces diverse and thermally plausible images at both scene and object level. TherA couples TherA-VLM with a latent-diffusion-based translator. Given a single RGB image and a user-prompted condition pair, TherA-VLM yields a thermal-aware embedding that encodes scene, object, material, and heat-emission context reflecting the input scene-condition pair. Conditioning the diffusion model on this embedding enables realistic TIR synthesis and fine-grained control across time of day, weather, and object state. Compared to other baselines, TherA achieves state-of-the-art translation performance, demonstrating improved zero-shot translation performance up to 33% increase averaged across all metrics.

</details>


### [143] [CountEx: Fine-Grained Counting via Exemplars and Exclusion](https://arxiv.org/abs/2602.19432)
*Yifeng Huang,Gia Khanh Nguyen,Minh Hoai*

Main category: cs.CV

TL;DR: CountEx是一种新型视觉计数框架，通过引入排他性提示和判别性查询优化，显著提升了复杂场景中的计数准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的计数方法无法明确排除视觉相似的干扰物，导致在杂乱场景中出现歧义和过度计数的问题。

Method: 提出了一种名为CountEx的视觉计数框架，包含判别性查询优化模块，该模块通过联合推理包含和排除提示，识别共享视觉特征并隔离排除特定模式，最终应用选择性抑制来优化计数查询。

Result: 实验表明，CountEx在已知和新类别对象的计数任务中均优于现有最先进方法。

Conclusion: CountEx通过引入排他性提示和判别性查询优化模块，显著提升了在复杂场景中的计数准确性，尤其在存在视觉相似干扰物的情况下。

Abstract: This paper presents CountEx, a discriminative visual counting framework designed to address a key limitation of existing prompt-based methods: the inability to explicitly exclude visually similar distractors. While current approaches allow users to specify what to count via inclusion prompts, they often struggle in cluttered scenes with confusable object categories, leading to ambiguity and overcounting. CountEx enables users to express both inclusion and exclusion intent, specifying what to count and what to ignore, through multimodal prompts including natural language descriptions and optional visual exemplars. At the core of CountEx is a novel Discriminative Query Refinement module, which jointly reasons over inclusion and exclusion cues by first identifying shared visual features, then isolating exclusion-specific patterns, and finally applying selective suppression to refine the counting query. To support systematic evaluation of fine-grained counting methods, we introduce CoCount, a benchmark comprising 1,780 videos and 10,086 annotated frames across 97 category pairs. Experiments show that CountEx achieves substantial improvements over state-of-the-art methods for counting objects from both known and novel categories. The data and code are available at https://github.com/bbvisual/CountEx.

</details>


### [144] [Efficient endometrial carcinoma screening via cross-modal synthesis and gradient distillation](https://arxiv.org/abs/2602.19822)
*Dongjing Shan,Yamei Luo,Jiqing Xuan,Lu Huang,Jin Li,Mengchu Yang,Zeyu Chen,Fajin Lv,Yong Tang,Chunxiang Zhang*

Main category: cs.CV

TL;DR: 提出两阶段深度学习框架，通过跨模态合成和轻量级网络提升子宫内膜癌筛查的准确性和效率，显著优于专家诊断。


<details>
  <summary>Details</summary>
Motivation: 早期检测子宫内膜癌的肌层浸润对分期和挽救生命的管理至关重要，但现有方法在资源受限的初级医疗机构中面临诊断可靠性低的问题。

Method: 提出了一种自动化的两阶段深度学习框架，包括结构引导的跨模态生成网络和轻量级筛查网络，利用梯度蒸馏技术。

Result: 在7,951名参与者的多中心队列中，模型达到了99.5%的灵敏度、97.2%的特异性和0.987的AUC，计算成本极低（0.289 GFLOPs）。

Conclusion: 结合跨模态合成增强与知识驱动的高效建模，可以为资源受限的初级医疗机构提供专家级的实时癌症筛查。

Abstract: Early detection of myometrial invasion is critical for the staging and life-saving management of endometrial carcinoma (EC), a prevalent global malignancy. Transvaginal ultrasound serves as the primary, accessible screening modality in resource-constrained primary care settings; however, its diagnostic reliability is severely hindered by low tissue contrast, high operator dependence, and a pronounced scarcity of positive pathological samples. Existing artificial intelligence solutions struggle to overcome this severe class imbalance and the subtle imaging features of invasion, particularly under the strict computational limits of primary care clinics. Here we present an automated, highly efficient two-stage deep learning framework that resolves both data and computational bottlenecks in EC screening. To mitigate pathological data scarcity, we develop a structure-guided cross-modal generation network that synthesizes diverse, high-fidelity ultrasound images from unpaired magnetic resonance imaging (MRI) data, strictly preserving clinically essential anatomical junctions. Furthermore, we introduce a lightweight screening network utilizing gradient distillation, which transfers discriminative knowledge from a high-capacity teacher model to dynamically guide sparse attention towards task-critical regions. Evaluated on a large, multicenter cohort of 7,951 participants, our model achieves a sensitivity of 99.5\%, a specificity of 97.2\%, and an area under the curve of 0.987 at a minimal computational cost (0.289 GFLOPs), substantially outperforming the average diagnostic accuracy of expert sonographers. Our approach demonstrates that combining cross-modal synthetic augmentation with knowledge-driven efficient modeling can democratize expert-level, real-time cancer screening for resource-constrained primary care settings.

</details>


### [145] [UrbanAlign: Post-hoc Semantic Calibration for VLM-Human Preference Alignment](https://arxiv.org/abs/2602.19442)
*Yecheng Zhang,Rong Zhao,Zhizhou Sha,Yong Li,Lei Wang,Ce Hou,Wen Ji,Hao Huang,Yunshan Wan,Jian Yu,Junhao Xia,Yuru Zhang,Chunlei Shi*

Main category: cs.CV

TL;DR: 无需训练的后处理流程UrbanAlign通过概念挖掘、多智能体评分和几何校准，显著提升了视觉语言模型在领域特定任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 针对领域特定任务中视觉语言模型输出与人类偏好的对齐问题，传统方法需要微调或强化学习，成本高昂。本文旨在证明无需模型训练即可实现这一目标。

Method: 提出了一种无训练的后处理概念瓶颈流程，包括概念挖掘、多智能体结构化评分和几何校准三个阶段，通过端到端的维度优化循环统一。

Result: 在Place Pulse 2.0数据集上，UrbanAlign框架在六个类别中达到了72.2%的准确率（κ=0.45），优于最佳监督基线15.1个百分点和无校准VLM评分16.3个百分点。

Conclusion: UrbanAlign框架通过无训练的后处理概念瓶颈流程，在特定领域任务中成功对齐了视觉语言模型输出与人类偏好，显著提升了性能并保持了完全的可解释性。

Abstract: Aligning vision-language model (VLM) outputs with human preferences in domain-specific tasks typically requires fine-tuning or reinforcement learning, both of which demand labelled data and GPU compute. We show that for subjective perception tasks, this alignment can be achieved without any model training: VLMs are already strong concept extractors but poor decision calibrators, and the gap can be closed externally. We propose a training-free post-hoc concept-bottleneck pipeline consisting of three tightly coupled stages: concept mining, multi-agent structured scoring, and geometric calibration, unified by an end-to-end dimension optimization loop. Interpretable evaluation dimensions are mined from a handful of human annotations; an Observer-Debater-Judge chain extracts robust continuous concept scores from a frozen VLM; and locally-weighted ridge regression on a hybrid visual-semantic manifold calibrates these scores against human ratings. Applied to urban perception as UrbanAlign, the framework achieves 72.2% accuracy ($κ=0.45$) on Place Pulse 2.0 across six categories, outperforming the best supervised baseline by +15.1 pp and uncalibrated VLM scoring by +16.3 pp, with full dimension-level interpretability and zero model-weight modification.

</details>


### [146] [GOAL: Geometrically Optimal Alignment for Continual Generalized Category Discovery](https://arxiv.org/abs/2602.19872)
*Jizhou Han,Chenhao Ding,SongLin Dong,Yuhang He,Shaokun Wang,Qiang Wang,Yihong Gong*

Main category: cs.CV

TL;DR: GOAL框架通过固定ETF分类器和一致性几何结构，显著减少遗忘并提升新类别发现能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态更新分类器权重时会导致遗忘和特征对齐不一致的问题，需要一种更稳定的框架来持续发现新类别。

Method: GOAL采用固定的Equiangular Tight Frame (ETF)分类器，通过监督对齐和置信度引导对齐，稳定整合新类别而不干扰旧类别。

Result: 在四个基准测试中，GOAL比现有方法Happy减少了16.1%的遗忘，并提升了3.2%的新类别发现能力。

Conclusion: GOAL框架通过引入固定的ETF分类器和一致性几何结构，显著减少了遗忘问题并提升了新类别的发现能力，为长期持续学习提供了强有力的解决方案。

Abstract: Continual Generalized Category Discovery (C-GCD) requires identifying novel classes from unlabeled data while retaining knowledge of known classes over time. Existing methods typically update classifier weights dynamically, resulting in forgetting and inconsistent feature alignment. We propose GOAL, a unified framework that introduces a fixed Equiangular Tight Frame (ETF) classifier to impose a consistent geometric structure throughout learning. GOAL conducts supervised alignment for labeled samples and confidence-guided alignment for novel samples, enabling stable integration of new classes without disrupting old ones. Experiments on four benchmarks show that GOAL outperforms the prior method Happy, reducing forgetting by 16.1% and boosting novel class discovery by 3.2%, establishing a strong solution for long-horizon continual discovery.

</details>


### [147] [Decoupling Vision and Language: Codebook Anchored Visual Adaptation](https://arxiv.org/abs/2602.19449)
*Jason Wu,Tianchen Zhao,Chang Liu,Jiarui Cai,Zheng Zhang,Zhuowei Li,Aaditya Singh,Xiang Xu,Mani Srivastava,Jonathan Wu*

Main category: cs.CV

TL;DR: CRAFT是一种轻量级方法，通过离散码本微调视觉编码器，提升LVLMs在特定领域的性能，同时保持语言模型能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过连续特征接口调整编码器和语言模型，导致两者耦合且需重新对齐，限制了灵活性和性能。

Method: CRAFT利用离散码本对视觉编码器进行微调，将视觉表示锚定到稳定的标记空间。

Result: CRAFT在10个领域特定基准（如VQARAD和PlantVillage）上平均提升13.51%，优于基于连续标记的同类方法。

Conclusion: CRAFT通过离散码本稳定视觉表示，实现了领域适应且不修改模型其他部分，显著提升了LVLMs在特定领域的性能。

Abstract: Large Vision-Language Models (LVLMs) use their vision encoders to translate images into representations for downstream reasoning, but the encoders often underperform in domain-specific visual tasks such as medical image diagnosis or fine-grained classification, where representation errors can cascade through the language model, leading to incorrect responses. Existing adaptation methods modify the continuous feature interface between encoder and language model through projector tuning or other parameter-efficient updates, which still couples the two components and requires re-alignment whenever the encoder changes. We introduce CRAFT (Codebook RegulAted Fine-Tuning), a lightweight method that fine-tunes the encoder using a discrete codebook that anchors visual representations to a stable token space, achieving domain adaptation without modifying other parts of the model. This decoupled design allows the adapted encoder to seamlessly boost the performance of LVLMs with different language architectures, as long as they share the same codebook. Empirically, CRAFT achieves an average gain of 13.51% across 10 domain-specific benchmarks such as VQARAD and PlantVillage, while preserving the LLM's linguistic capabilities and outperforming peer methods that operate on continuous tokens.

</details>


### [148] [Make Some Noise: Unsupervised Remote Sensing Change Detection Using Latent Space Perturbations](https://arxiv.org/abs/2602.19881)
*Blaž Rolih,Matic Fučka,Filip Wolf,Luka Čehovin Zajc*

Main category: cs.CV

TL;DR: MaSoN是一种无监督变化检测框架，通过在潜在特征空间中合成多样化变化，显著提升了性能并实现了最先进的成果。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督变化检测方法依赖于预定义的假设，无法泛化到少数变化类型之外，限制了其在真实世界中的应用。MaSoN旨在通过直接在潜在特征空间中合成多样化的变化来解决这一问题。

Method: MaSoN是一个端到端的无监督变化检测框架，通过在训练期间直接在潜在特征空间中合成多样化的变化，利用目标数据的特征统计动态估计变化，从而生成与目标域对齐的多样化变化。

Result: MaSoN在五个基准测试中实现了最先进的性能，平均F1分数提高了14.1个百分点，并能轻松扩展到新的模态（如SAR）。

Conclusion: MaSoN框架通过直接在潜在特征空间中合成多样化的变化，显著提升了无监督变化检测的性能，并在五个基准测试中实现了最先进的性能，平均F1分数提高了14.1个百分点。

Abstract: Unsupervised change detection (UCD) in remote sensing aims to localise semantic changes between two images of the same region without relying on labelled data during training. Most recent approaches rely either on frozen foundation models in a training-free manner or on training with synthetic changes generated in pixel space. Both strategies inherently rely on predefined assumptions about change types, typically introduced through handcrafted rules, external datasets, or auxiliary generative models. Due to these assumptions, such methods fail to generalise beyond a few change types, limiting their real-world usage, especially in rare or complex scenarios. To address this, we propose MaSoN (Make Some Noise), an end-to-end UCD framework that synthesises diverse changes directly in the latent feature space during training. It generates changes that are dynamically estimated using feature statistics of target data, enabling diverse yet data-driven variation aligned with the target domain. It also easily extends to new modalities, such as SAR. MaSoN generalises strongly across diverse change types and achieves state-of-the-art performance on five benchmarks, improving the average F1 score by 14.1 percentage points. Project page: https://blaz-r.github.io/mason_ucd

</details>


### [149] [HD-TTA: Hypothesis-Driven Test-Time Adaptation for Safer Brain Tumor Segmentation](https://arxiv.org/abs/2602.19454)
*Kartik Jhawar,Lipo Wang*

Main category: cs.CV

TL;DR: HD-TTA是一种假设驱动的测试时适应框架，通过动态选择几何假设提升医学分割的安全性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标准TTA方法在医学分割中缺乏选择性，可能导致肿瘤掩模溢出到健康组织或破坏原本正确的预测，因此需要更安全的适应策略。

Method: 提出了假设驱动的TTA框架，通过生成竞争的几何假设（压缩与膨胀）和基于纹理一致性的选择器，动态决定最优适应策略。

Result: 在跨域脑肿瘤分割任务中，HD-TTA显著改善了安全性指标（HD95减少约6.4毫米，精确度提高4%以上），同时保持相当的Dice分数。

Conclusion: HD-TTA通过明确的假设选择解决了安全性与适应性的权衡问题，为安全的临床模型部署提供了一条可行且稳健的路径。

Abstract: Standard Test-Time Adaptation (TTA) methods typically treat inference as a blind optimization task, applying generic objectives to all or filtered test samples. In safety-critical medical segmentation, this lack of selectivity often causes the tumor mask to spill into healthy brain tissue or degrades predictions that were already correct. We propose Hypothesis-Driven TTA, a novel framework that reformulates adaptation as a dynamic decision process. Rather than forcing a single optimization trajectory, our method generates intuitive competing geometric hypotheses: compaction (is the prediction noisy? trim artifacts) versus inflation (is the valid tumor under-segmented? safely inflate to recover). It then employs a representation-guided selector to autonomously identify the safest outcome based on intrinsic texture consistency. Additionally, a pre-screening Gatekeeper prevents negative transfer by skipping adaptation on confident cases. We validate this proof-of-concept on a cross-domain binary brain tumor segmentation task, applying a source model trained on adult BraTS gliomas to unseen pediatric and more challenging meningioma target domains. HD-TTA improves safety-oriented outcomes (Hausdorff Distance (HD95) and Precision) over several state-of-the-art representative baselines in the challenging safety regime, reducing the HD95 by approximately 6.4 mm and improving Precision by over 4%, while maintaining comparable Dice scores. These results demonstrate that resolving the safety-adaptation trade-off via explicit hypothesis selection is a viable, robust path for safe clinical model deployment. Code will be made publicly available upon acceptance.

</details>


### [150] [When Pretty Isn't Useful: Investigating Why Modern Text-to-Image Models Fail as Reliable Training Data Generators](https://arxiv.org/abs/2602.19946)
*Krzysztof Adamkiewicz,Brian Moser,Stanislav Frolov,Tobias Christian Nauen,Federico Raue,Andreas Dengel*

Main category: cs.CV

TL;DR: 研究发现，尽管文本到图像模型在视觉质量和提示跟随上进步，但其生成的合成数据作为训练集时，分类器在真实数据上的性能反而下降，揭示模型生成的数据缺乏多样性和标签对齐性。


<details>
  <summary>Details</summary>
Motivation: 探讨文本到图像扩散模型作为合成视觉数据生成器的表现，验证其是否能够替代真实训练数据。

Method: 利用2022至2025年间发布的先进文本到图像模型生成大规模合成数据集，仅用这些数据训练标准分类器，并在真实测试数据上评估性能。

Result: 尽管视觉保真度和提示跟随能力提升，但使用更新的文本到图像模型生成的合成数据训练的模型在真实测试数据上的分类准确率持续下降。分析显示，这些模型倾向于生成审美集中但多样性和标签-图像对齐性不足的数据。

Conclusion: 研究挑战了生成模型在视觉研究中作为可靠训练数据生成器的假设，指出需要重新思考现代文本到图像模型的真实数据生成能力。

Abstract: Recent text-to-image (T2I) diffusion models produce visually stunning images and demonstrate excellent prompt following. But do they perform well as synthetic vision data generators? In this work, we revisit the promise of synthetic data as a scalable substitute for real training sets and uncover a surprising performance regression. We generate large-scale synthetic datasets using state-of-the-art T2I models released between 2022 and 2025, train standard classifiers solely on this synthetic data, and evaluate them on real test data. Despite observable advances in visual fidelity and prompt adherence, classification accuracy on real test data consistently declines with newer T2I models as training data generators. Our analysis reveals a hidden trend: These models collapse to a narrow, aesthetic-centric distribution that undermines diversity and label-image alignment. Overall, our findings challenge a growing assumption in vision research, namely that progress in generative realism implies progress in data realism. We thus highlight an urgent need to rethink the capabilities of modern T2I models as reliable training data generators.

</details>


### [151] [Laplacian Multi-scale Flow Matching for Generative Modeling](https://arxiv.org/abs/2602.19461)
*Zelin Zhao,Petr Molodyk,Haotian Xue,Yongxin Chen*

Main category: cs.CV

TL;DR: LapFlow通过多尺度并行处理提升图像生成质量和效率，适用于高分辨率任务。


<details>
  <summary>Details</summary>
Motivation: 解决传统级联方法需要显式去噪的问题，提升生成质量和加速采样过程。

Method: 采用Laplacian金字塔残差分解和多尺度并行处理，结合混合变换器（MoT）架构和因果注意力机制。

Result: 在CelebA-HQ和ImageNet上表现出色，生成质量优于单尺度和多尺度基线，计算效率更高。

Conclusion: LapFlow框架通过并行处理多尺度表示，显著提升了图像生成质量，同时降低了计算开销，适用于高分辨率生成任务。

Abstract: In this paper, we present Laplacian multiscale flow matching (LapFlow), a novel framework that enhances flow matching by leveraging multi-scale representations for image generative modeling. Our approach decomposes images into Laplacian pyramid residuals and processes different scales in parallel through a mixture-of-transformers (MoT) architecture with causal attention mechanisms. Unlike previous cascaded approaches that require explicit renoising between scales, our model generates multi-scale representations in parallel, eliminating the need for bridging processes. The proposed multi-scale architecture not only improves generation quality but also accelerates the sampling process and promotes scaling flow matching methods. Through extensive experimentation on CelebA-HQ and ImageNet, we demonstrate that our method achieves superior sample quality with fewer GFLOPs and faster inference compared to single-scale and multi-scale flow matching baselines. The proposed model scales effectively to high-resolution generation (up to 1024$\times$1024) while maintaining lower computational overhead.

</details>


### [152] [Physics-informed Active Polarimetric 3D Imaging for Specular Surfaces](https://arxiv.org/abs/2602.19470)
*Jiazhang Wang,Hyelim Yang,Tianyi Wang,Florian Willomitzer*

Main category: cs.CV

TL;DR: 提出一种单次3D成像方法，结合偏振与结构光，通过深度学习框架实现复杂镜面表面的快速准确测量。


<details>
  <summary>Details</summary>
Motivation: 解决现有技术在动态环境中测量复杂几何形状时的局限性，如多帧采集的不适用性或单次傅里叶方法在高空间频率结构或大曲率表面性能下降的问题。

Method: 采用双编码器架构与互特征调制，结合偏振线索和结构光照明的几何信息，直接推断表面法线。

Result: 所提方法在单次拍摄中实现了准确且鲁棒的法线估计，具有快速推理能力。

Conclusion: 本文提出了一种基于物理信息的深度学习框架，用于复杂镜面表面的单次3D成像，实现了准确且鲁棒的法线估计，适用于实际应用。

Abstract: 3D imaging of specular surfaces remains challenging in real-world scenarios, such as in-line inspection or hand-held scanning, requiring fast and accurate measurement of complex geometries. Optical metrology techniques such as deflectometry achieve high accuracy but typically rely on multi-shot acquisition, making them unsuitable for dynamic environments. Fourier-based single-shot approaches alleviate this constraint, yet their performance deteriorates when measuring surfaces with high spatial frequency structure or large curvature. Alternatively, polarimetric 3D imaging in computer vision operates in a single-shot fashion and exhibits robustness to geometric complexity. However, its accuracy is fundamentally limited by the orthographic imaging assumption. In this paper, we propose a physics-informed deep learning framework for single-shot 3D imaging of complex specular surfaces. Polarization cues provide orientation priors that assist in interpreting geometric information encoded by structured illumination. These complementary cues are processed through a dual-encoder architecture with mutual feature modulation, allowing the network to resolve their nonlinear coupling and directly infer surface normals. The proposed method achieves accurate and robust normal estimation in single-shot with fast inference, enabling practical 3D imaging of complex specular surfaces.

</details>


### [153] [Descriptor: Dataset of Parasitoid Wasps and Associated Hymenoptera (DAPWH)](https://arxiv.org/abs/2602.20028)
*Joao Manoel Herrera Pinheiro,Gabriela Do Nascimento Herrera,Luciana Bueno Dos Reis Fernandes,Alvaro Doria Dos Santos,Ricardo V. Godoy,Eduardo A. B. Almeida,Helena Carolina Onody,Marcelo Andrade Da Costa Vieira,Angelica Maria Penteado-Dias,Marcelo Becker*

Main category: cs.CV

TL;DR: 该论文发布了一个包含3,556张高分辨率图像的精选数据集，旨在通过计算机视觉模型解决Ichneumonoidea超科的分类学鉴定难题。


<details>
  <summary>Details</summary>
Motivation: 由于Ichneumonoidea超科（包括Ichneumonidae和Braconidae）的形态隐蔽性和大量未描述物种，其分类学鉴定极具挑战性，而现有的数字资源匮乏。

Method: 研究团队创建了一个包含3,556张高分辨率图像的精选数据集，其中1,739张图像以COCO格式标注，包含多类边界框（如昆虫全身、翅脉和比例尺）。

Result: 数据集不仅聚焦于新热带区的Ichneumonidae和Braconidae，还包含其他补充科（如Andrenidae、Apidae等），以提高模型的鲁棒性。

Conclusion: 该论文提供了一个高质量的图像数据集，旨在推动自动识别系统的发展，特别是在解决Ichneumonoidea超科分类学挑战方面。

Abstract: Accurate taxonomic identification is the cornerstone of biodiversity monitoring and agricultural management, particularly for the hyper-diverse superfamily Ichneumonoidea. Comprising the families Ichneumonidae and Braconidae, these parasitoid wasps are ecologically critical for regulating insect populations, yet they remain one of the most taxonomically challenging groups due to their cryptic morphology and vast number of undescribed species. To address the scarcity of robust digital resources for these key groups, we present a curated image dataset designed to advance automated identification systems. The dataset contains 3,556 high-resolution images, primarily focused on Neotropical Ichneumonidae and Braconidae, while also including supplementary families such as Andrenidae, Apidae, Bethylidae, Chrysididae, Colletidae, Halictidae, Megachilidae, Pompilidae, and Vespidae to improve model robustness. Crucially, a subset of 1,739 images is annotated in COCO format, featuring multi-class bounding boxes for the full insect body, wing venation, and scale bars. This resource provides a foundation for developing computer vision models capable of identifying these families.

</details>


### [154] [Forgetting-Resistant and Lesion-Aware Source-Free Domain Adaptive Fundus Image Analysis with Vision-Language Model](https://arxiv.org/abs/2602.19471)
*Zheang Huai,Hui Tang,Hualiang Wang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出FRLA方法解决SFDA中目标模型预测遗忘和视觉语言模型细粒度知识利用不足的问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有利用视觉语言模型进行SFDA的方法存在两个问题：（i）目标模型的某些优越预测被遗忘；（ii）忽视了视觉语言模型中丰富的细粒度知识。

Method: 通过遗忘抵抗适应模块显式保留目标模型的置信预测，以及病变感知适应模块利用视觉语言模型的细粒度知识生成补丁级预测，帮助目标模型识别病变区域。

Result: 大量实验表明，该方法不仅显著优于视觉语言模型，而且在性能上持续超越现有最先进方法。

Conclusion: 本文提出了一种新颖的遗忘抵抗和病变感知（FRLA）方法，用于基于视觉语言模型的眼底图像诊断的无源域适应（SFDA），该方法在性能上显著优于现有技术。

Abstract: Source-free domain adaptation (SFDA) aims to adapt a model trained in the source domain to perform well in the target domain, with only unlabeled target domain data and the source model. Taking into account that conventional SFDA methods are inevitably error-prone under domain shift, recently greater attention has been directed to SFDA assisted with off-the-shelf foundation models, e.g., vision-language (ViL) models. However, existing works of leveraging ViL models for SFDA confront two issues: (i) Although mutual information is exploited to consider the joint distribution between the predictions of ViL model and the target model, we argue that the forgetting of some superior predictions of the target model still occurs, as indicated by the decline of the accuracies of certain classes during adaptation; (ii) Prior research disregards the rich, fine-grained knowledge embedded in the ViL model, which offers detailed grounding for fundus image diagnosis. In this paper, we introduce a novel forgetting-resistant and lesion-aware (FRLA) method for SFDA of fundus image diagnosis with ViL model. Specifically, a forgetting-resistant adaptation module explicitly preserves the confident predictions of the target model, and a lesion-aware adaptation module yields patch-wise predictions from ViL model and employs them to help the target model be aware of the lesion areas and leverage the ViL model's fine-grained knowledge. Extensive experiments show that our method not only significantly outperforms the vision-language model, but also achieves consistent improvements over the state-of-the-art methods. Our code will be released.

</details>


### [155] [SEAL-pose: Enhancing 3D Human Pose Estimation via a Learned Loss for Structural Consistency](https://arxiv.org/abs/2602.20051)
*Yeonsung Kim,Junggeun Do,Seunguk Do,Sangmin Kim,Jaesik Park,Jay-Yoon Lee*

Main category: cs.CV

TL;DR: SEAL-pose通过可学习的loss-net直接学习结构依赖，提升3D姿态估计性能，无需手工先验。


<details>
  <summary>Details</summary>
Motivation: 传统监督损失无法捕捉关节间的复杂依赖，手工设计的先验或规则约束通常需要手动指定且不可微分。

Method: 提出SEAL-pose框架，包含可学习的loss-net和pose-net，通过基于关节图的设计直接从数据中学习结构依赖。

Result: 在三个3D HPE基准测试中，SEAL-pose显著降低了关节误差并提升了姿态合理性，且优于显式结构约束的模型。

Conclusion: SEAL-pose 通过数据驱动的方式学习结构依赖，显著提升了3D人体姿态估计的准确性和合理性，且无需依赖手工设计的先验。

Abstract: 3D human pose estimation (HPE) is characterized by intricate local and global dependencies among joints. Conventional supervised losses are limited in capturing these correlations because they treat each joint independently. Previous studies have attempted to promote structural consistency through manually designed priors or rule-based constraints; however, these approaches typically require manual specification and are often non-differentiable, limiting their use as end-to-end training objectives. We propose SEAL-pose, a data-driven framework in which a learnable loss-net trains a pose-net by evaluating structural plausibility. Rather than relying on hand-crafted priors, our joint-graph-based design enables the loss-net to learn complex structural dependencies directly from data. Extensive experiments on three 3D HPE benchmarks with eight backbones show that SEAL-pose reduces per-joint errors and improves pose plausibility compared with the corresponding backbones across all settings. Beyond improving each backbone, SEAL-pose also outperforms models with explicit structural constraints, despite not enforcing any such constraints. Finally, we analyze the relationship between the loss-net and structural consistency, and evaluate SEAL-pose in cross-dataset and in-the-wild settings.

</details>


### [156] [Exploiting Label-Independent Regularization from Spatial Dependencies for Whole Slide Image Analysis](https://arxiv.org/abs/2602.19487)
*Weiyi Wu,Xinwen Xu,Chongyang Gao,Xingjian Diao,Siting Li,Jiang Gui*

Main category: cs.CV

TL;DR: 针对全切片图像分析中的挑战，提出空间正则化MIL框架，通过结合空间重建和分类目标提升性能，实验结果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决全切片图像分析中数据量大、标注稀缺及现有MIL方法因稀疏监督导致的优化不稳定和性能不佳问题。

Method: 提出了一种空间正则化MIL框架，利用补丁特征间的空间关系作为标签无关的正则化信号，联合优化空间重建和分类目标。

Result: 在多个公共数据集上的实验结果表明，该方法显著优于现有最先进方法。

Conclusion: 提出的空间正则化MIL框架通过结合特征诱导的空间重建和标签引导的分类目标，显著提升了现有方法的性能，为高分辨率图像分析提供了新方向。

Abstract: Whole slide images, with their gigapixel-scale panoramas of tissue samples, are pivotal for precise disease diagnosis. However, their analysis is hindered by immense data size and scarce annotations. Existing MIL methods face challenges due to the fundamental imbalance where a single bag-level label must guide the learning of numerous patch-level features. This sparse supervision makes it difficult to reliably identify discriminative patches during training, leading to unstable optimization and suboptimal solutions. We propose a spatially regularized MIL framework that leverages inherent spatial relationships among patch features as label-independent regularization signals. Our approach learns a shared representation space by jointly optimizing feature-induced spatial reconstruction and label-guided classification objectives, enforcing consistency between intrinsic structural patterns and supervisory signals. Experimental results on multiple public datasets demonstrate significant improvements over state-of-the-art methods, offering a promising direction.

</details>


### [157] [MICON-Bench: Benchmarking and Enhancing Multi-Image Context Image Generation in Unified Multimodal Models](https://arxiv.org/abs/2602.19497)
*Mingrui Wu,Hang Liu,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: 提出了 MICON-Bench 基准和 DAR 机制，用于评估和提升多图像任务的生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有基准多关注单图像任务，缺乏多图像上下文生成的评估挑战。

Method: 提出了 MICON-Bench 基准和 MLLM 驱动的评估框架，以及训练无关的动态注意力再平衡（DAR）机制。

Result: 实验证明 MICON-Bench 能有效暴露多图像推理挑战，DAR 显著提升生成质量。

Conclusion: MICON-Bench 和 DAR 机制在多图像推理任务中展现出显著效果，提升了生成质量和跨图像连贯性。

Abstract: Recent advancements in Unified Multimodal Models (UMMs) have enabled remarkable image understanding and generation capabilities. However, while models like Gemini-2.5-Flash-Image show emerging abilities to reason over multiple related images, existing benchmarks rarely address the challenges of multi-image context generation, focusing mainly on text-to-image or single-image editing tasks. In this work, we introduce \textbf{MICON-Bench}, a comprehensive benchmark covering six tasks that evaluate cross-image composition, contextual reasoning, and identity preservation. We further propose an MLLM-driven Evaluation-by-Checkpoint framework for automatic verification of semantic and visual consistency, where multimodal large language model (MLLM) serves as a verifier. Additionally, we present \textbf{Dynamic Attention Rebalancing (DAR)}, a training-free, plug-and-play mechanism that dynamically adjusts attention during inference to enhance coherence and reduce hallucinations. Extensive experiments on various state-of-the-art open-source models demonstrate both the rigor of MICON-Bench in exposing multi-image reasoning challenges and the efficacy of DAR in improving generation quality and cross-image coherence. Github: https://github.com/Angusliuuu/MICON-Bench.

</details>


### [158] [A Text-Guided Vision Model for Enhanced Recognition of Small Instances](https://arxiv.org/abs/2602.19503)
*Hyun-Ki Jung*

Main category: cs.CV

TL;DR: 改进版YOLO-World模型通过优化主干网络和并行处理，提升了无人机目标检测的准确性和轻量化性能，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机目标检测技术的发展，需求从单纯检测物体转向用户能准确识别特定目标，因此需要开发高效的文本引导目标检测模型以增强小物体检测能力。

Method: 改进YOLOv8主干网络中的C2f层为C3k2层，以更精确地表示局部特征，特别是小物体或边界清晰的物体；通过并行处理优化提升处理速度和效率，同时实现更轻量化的模型设计。

Result: 在VisDrone数据集上的对比实验显示，改进模型的精确度从40.6%提升至41.6%，召回率从30.8%增至31%，F1分数从35%升至35.5%，mAP@0.5从30.4%增至30.7%；参数数量从400万降至380万，FLOPs从157亿降至152亿。

Conclusion: 该研究提出的改进版YOLO-World模型在无人机目标检测中表现出更高的准确性和轻量化性能，为精确目标检测提供了实用有效的解决方案。

Abstract: As drone-based object detection technology continues to evolve, the demand is shifting from merely detecting objects to enabling users to accurately identify specific targets. For example, users can input particular targets as prompts to precisely detect desired objects. To address this need, an efficient text-guided object detection model has been developed to enhance the detection of small objects. Specifically, an improved version of the existing YOLO-World model is introduced. The proposed method replaces the C2f layer in the YOLOv8 backbone with a C3k2 layer, enabling more precise representation of local features, particularly for small objects or those with clearly defined boundaries. Additionally, the proposed architecture improves processing speed and efficiency through parallel processing optimization, while also contributing to a more lightweight model design. Comparative experiments on the VisDrone dataset show that the proposed model outperforms the original YOLO-World model, with precision increasing from 40.6% to 41.6%, recall from 30.8% to 31%, F1 score from 35% to 35.5%, and mAP@0.5 from 30.4% to 30.7%, confirming its enhanced accuracy. Furthermore, the model demonstrates superior lightweight performance, with the parameter count reduced from 4 million to 3.8 million and FLOPs decreasing from 15.7 billion to 15.2 billion. These results indicate that the proposed approach provides a practical and effective solution for precise object detection in drone-based applications.

</details>


### [159] [HeatPrompt: Zero-Shot Vision-Language Modeling of Urban Heat Demand from Satellite Images](https://arxiv.org/abs/2602.20066)
*Kundan Thota,Xuanhao Mu,Thorsten Schlachter,Veit Hagenmeyer*

Main category: cs.CV

TL;DR: HeatPrompt利用卫星图像和视觉语言模型，显著提升了热需求预测的准确性，适用于数据稀缺地区。


<details>
  <summary>Details</summary>
Motivation: 大多数城市缺乏建筑级别的详细数据来生成准确的热需求地图，而这对空间供暖的脱碳至关重要。

Method: 使用预训练的视觉语言模型（VLMs）提取卫星图像中的语义特征（如屋顶年龄、建筑密度等），并结合基础GIS数据，通过多层感知机（MLP）回归器预测年度热需求。

Result: HeatPrompt的R²提升了93.7%，平均绝对误差（MAE）降低了30%，且高影响词符与高需求区域对齐。

Conclusion: HeatPrompt通过结合视觉语言模型和基础GIS数据，显著提升了热需求预测的准确性，为数据稀缺地区提供了轻量化的热规划支持。

Abstract: Accurate heat-demand maps play a crucial role in decarbonizing space heating, yet most municipalities lack detailed building-level data needed to calculate them. We introduce HeatPrompt, a zero-shot vision-language energy modeling framework that estimates annual heat demand using semantic features extracted from satellite images, basic Geographic Information System (GIS), and building-level features. We feed pretrained Large Vision Language Models (VLMs) with a domain-specific prompt to act as an energy planner and extract the visual attributes such as roof age, building density, etc, from the RGB satellite image that correspond to the thermal load. A Multi-Layer Perceptron (MLP) regressor trained on these captions shows an $R^2$ uplift of 93.7% and shrinks the mean absolute error (MAE) by 30% compared to the baseline model. Qualitative analysis shows that high-impact tokens align with high-demand zones, offering lightweight support for heat planning in data-scarce regions.

</details>


### [160] [Test-Time Computing for Referring Multimodal Large Language Models](https://arxiv.org/abs/2602.19505)
*Mingrui Wu,Hao Chen,Jiayi Ji,Xiaoshuai Sun,Zhiyuan Liu,Liujuan Cao,Ming-Ming Cheng,Rongrong Ji*

Main category: cs.CV

TL;DR: ControlMLLM++ 是一种测试时自适应框架，通过可学习的视觉提示和优化的能量函数，实现了细粒度的区域视觉推理，无需重新训练或微调。


<details>
  <summary>Details</summary>
Motivation: 旨在无需重新训练或微调的情况下，实现细粒度的区域视觉推理，并解决语言提示偏见问题。

Method: 通过注入可学习的视觉提示到冻结的多模态大语言模型中，利用跨模态注意力图优化潜在视觉标记修改器，并结合改进的优化策略（Optim++）和提示去偏机制（PromptDebias）。

Result: 支持多种视觉提示类型（如边界框、掩码、涂鸦和点），展示了强大的跨领域泛化能力和可解释性。

Conclusion: ControlMLLM++ 是一种无需重新训练或微调的测试时自适应框架，通过可学习的视觉提示和优化的能量函数，实现了细粒度的区域视觉推理，展示了强大的跨领域泛化能力和可解释性。

Abstract: We propose ControlMLLM++, a novel test-time adaptation framework that injects learnable visual prompts into frozen multimodal large language models (MLLMs) to enable fine-grained region-based visual reasoning without any model retraining or fine-tuning. Leveraging the insight that cross-modal attention maps intrinsically encode semantic correspondences between textual tokens and visual regions, ControlMLLM++ optimizes a latent visual token modifier during inference via a task-specific energy function to steer model attention towards user-specified areas. To enhance optimization stability and mitigate language prompt biases, ControlMLLM++ incorporates an improved optimization strategy (Optim++) and a prompt debiasing mechanism (PromptDebias). Supporting diverse visual prompt types including bounding boxes, masks, scribbles, and points, our method demonstrates strong out-of-domain generalization and interpretability. The code is available at https://github.com/mrwu-mac/ControlMLLM.

</details>


### [161] [StructXLIP: Enhancing Vision-language Models with Multimodal Structural Cues](https://arxiv.org/abs/2602.20089)
*Zanxi Ruan,Qiuyu Kong,Songqun Gao,Yiming Wang,Marco Cristani*

Main category: cs.CV

TL;DR: StructXLIP通过结构对齐增强视觉语言模型，提升跨模态检索性能。


<details>
  <summary>Details</summary>
Motivation: 基于边缘的表示是视觉理解的基础，本研究将其扩展到视觉语言对齐，以提升长且细节丰富的字幕的跨模态检索性能。

Method: StructXLIP通过提取边缘图（如Canny）作为视觉结构代理，并过滤对应字幕以强调结构线索，引入三种结构中心损失进行微调。

Result: StructXLIP在通用和专用领域的跨模态检索中均优于当前竞争者，并展示了更强的语义稳定性。

Conclusion: StructXLIP通过增强视觉语言对齐的结构性表示，显著提升了跨模态检索性能，并可作为通用增强方法灵活集成到未来方法中。

Abstract: Edge-based representations are fundamental cues for visual understanding, a principle rooted in early vision research and still central today. We extend this principle to vision-language alignment, showing that isolating and aligning structural cues across modalities can greatly benefit fine-tuning on long, detail-rich captions, with a specific focus on improving cross-modal retrieval. We introduce StructXLIP, a fine-tuning alignment paradigm that extracts edge maps (e.g., Canny), treating them as proxies for the visual structure of an image, and filters the corresponding captions to emphasize structural cues, making them "structure-centric". Fine-tuning augments the standard alignment loss with three structure-centric losses: (i) aligning edge maps with structural text, (ii) matching local edge regions to textual chunks, and (iii) connecting edge maps to color images to prevent representation drift. From a theoretical standpoint, while standard CLIP maximizes the mutual information between visual and textual embeddings, StructXLIP additionally maximizes the mutual information between multimodal structural representations. This auxiliary optimization is intrinsically harder, guiding the model toward more robust and semantically stable minima, enhancing vision-language alignment. Beyond outperforming current competitors on cross-modal retrieval in both general and specialized domains, our method serves as a general boosting recipe that can be integrated into future approaches in a plug-and-play manner. Code and pretrained models are publicly available at: https://github.com/intelligolabs/StructXLIP.

</details>


### [162] [Relational Feature Caching for Accelerating Diffusion Transformers](https://arxiv.org/abs/2602.19506)
*Byunggwan Son,Jeimin Jeon,Jeongwoo Choi,Bumsub Ham*

Main category: cs.CV

TL;DR: RFC通过输入-输出关系提升特征预测准确性，优于现有缓存方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于时间外推的缓存方法因输出特征变化幅度的不规则性导致预测误差较大，性能下降。研究发现输入特征与输出特征强相关，因此提出利用这种关系提高预测准确性。

Method: 提出了关系特征缓存（RFC）框架，包括关系特征估计（RFE）和关系缓存调度（RCS）。RFE通过输入特征估计输出特征的变化幅度，RCS则利用输入特征预测误差并仅在误差较大时执行完整计算。

Result: 在各种DiT模型上的广泛实验表明，RFC显著优于现有方法。

Conclusion: RFC框架通过利用输入-输出关系显著提高了特征预测的准确性，并在各种DiT模型中表现优于现有方法。

Abstract: Feature caching approaches accelerate diffusion transformers (DiTs) by storing the output features of computationally expensive modules at certain timesteps, and exploiting them for subsequent steps to reduce redundant computations. Recent forecasting-based caching approaches employ temporal extrapolation techniques to approximate the output features with cached ones. Although effective, relying exclusively on temporal extrapolation still suffers from significant prediction errors, leading to performance degradation. Through a detailed analysis, we find that 1) these errors stem from the irregular magnitude of changes in the output features, and 2) an input feature of a module is strongly correlated with the corresponding output. Based on this, we propose relational feature caching (RFC), a novel framework that leverages the input-output relationship to enhance the accuracy of the feature prediction. Specifically, we introduce relational feature estimation (RFE) to estimate the magnitude of changes in the output features from the inputs, enabling more accurate feature predictions. We also present relational cache scheduling (RCS), which estimates the prediction errors using the input features and performs full computations only when the errors are expected to be substantial. Extensive experiments across various DiT models demonstrate that RFC consistently outperforms prior approaches significantly. Project page is available at https://cvlab.yonsei.ac.kr/projects/RFC

</details>


### [163] [Transcending the Annotation Bottleneck: AI-Powered Discovery in Biology and Medicine](https://arxiv.org/abs/2602.20100)
*Soumick Chatterjee*

Main category: cs.CV

TL;DR: 无监督和自监督学习在生物医学中减少对专家标注的依赖，通过数据固有结构学习，实现新表型发现、基因表达预测和高效病理检测。


<details>
  <summary>Details</summary>
Motivation: 依赖专家标注一直是人工智能在生物医学应用中主要的限制因素，而无监督和自监督学习能够解锁生物银行规模数据集的潜在价值，减少人工偏见。

Method: 通过直接从数据的固有结构（如MRI中的像素、体积扫描中的体素或基因组序列中的标记）学习，无监督和自监督学习框架被用于发现新表型、预测空间基因表达及检测异常。

Result: 这些方法成功推导出可遗传的心脏特征、预测组织学中的空间基因表达，并在病理检测中达到或超越监督学习的性能。

Conclusion: 无监督和自监督学习（SSL）方法在生物医学领域展现出巨大潜力，能够在不依赖专家标注的情况下，从生物银行规模的数据集中发现新表型、连接形态与遗传学，并以媲美或超越监督学习的性能检测病理。

Abstract: The dependence on expert annotation has long constituted the primary rate-limiting step in the application of artificial intelligence to biomedicine. While supervised learning drove the initial wave of clinical algorithms, a paradigm shift towards unsupervised and self-supervised learning (SSL) is currently unlocking the latent potential of biobank-scale datasets. By learning directly from the intrinsic structure of data - whether pixels in a magnetic resonance image (MRI), voxels in a volumetric scan, or tokens in a genomic sequence - these methods facilitate the discovery of novel phenotypes, the linkage of morphology to genetics, and the detection of anomalies without human bias. This article synthesises seminal and recent advances in "learning without labels," highlighting how unsupervised frameworks can derive heritable cardiac traits, predict spatial gene expression in histology, and detect pathologies with performance that rivals or exceeds supervised counterparts.

</details>


### [164] [OSInsert: Towards High-authenticity and High-fidelity Image Composition](https://arxiv.org/abs/2602.19523)
*Jingyuan Wang,Li Niu*

Main category: cs.CV

TL;DR: 提出两阶段策略，兼顾生成图像合成的高真实性和高保真度，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时实现高真实性和高保真度，因此提出两阶段策略以兼顾两者。

Method: 采用两阶段策略：第一阶段使用高真实性方法生成合理的前景形状，第二阶段以此作为高保真方法的条件。

Result: 在MureCOM数据集上的实验验证了两阶段策略的有效性。

Conclusion: 本文提出的两阶段策略在生成图像合成中同时实现了高真实性和高保真度，实验验证了其有效性。

Abstract: Generative image composition aims to regenerate the given foreground object in the background image to produce a realistic composite image. Some high-authenticity methods can adjust foreground pose/view to be compatible with background, while some high-fidelity methods can preserve the foreground details accurately. However, existing methods can hardly achieve both goals at the same time. In this work, we propose a two-stage strategy to achieve both goals. In the first stage, we use high-authenticity method to generate reasonable foreground shape, serving as the condition of high-fidelity method in the second stage. The experiments on MureCOM dataset verify the effectiveness of our two-stage strategy. The code and model have been released at https://github.com/bcmi/OSInsert-Image-Composition.

</details>


### [165] [Benchmarking Unlearning for Vision Transformers](https://arxiv.org/abs/2602.20114)
*Kairan Zhao,Iurie Luca,Peter Triantafillou*

Main category: cs.CV

TL;DR: 首次针对视觉Transformer（VT）的机器遗忘（MU）性能进行基准测试，评估了不同算法、数据集和遗忘协议，为未来研究提供了参考基线。


<details>
  <summary>Details</summary>
Motivation: 尽管机器遗忘研究在构建安全公平的AI中至关重要，且视觉Transformer在计算机视觉任务中表现优异，但现有的MU研究主要集中在CNN上，缺乏对VT的基准测试。

Method: 研究采用了多种数据集、不同的MU算法以及单次和持续遗忘协议，重点评估了利用训练数据记忆的MU算法，并通过统一的评价指标来衡量遗忘质量和模型性能。

Result: 研究揭示了VT与CNN在训练数据记忆上的差异，评估了不同记忆代理对性能的影响，并为VT上的MU算法性能提供了首个参考基线。

Conclusion: 本研究首次为视觉Transformer（VT）建立了机器遗忘（MU）的基准测试，提供了可重复、公平且全面的比较框架，并为现有及未来MU算法在VT上的性能设定了参考基线。

Abstract: Research in machine unlearning (MU) has gained strong momentum: MU is now widely regarded as a critical capability for building safe and fair AI. In parallel, research into transformer architectures for computer vision tasks has been highly successful: Increasingly, Vision Transformers (VTs) emerge as strong alternatives to CNNs. Yet, MU research for vision tasks has largely centered on CNNs, not VTs. While benchmarking MU efforts have addressed LLMs, diffusion models, and CNNs, none exist for VTs. This work is the first to attempt this, benchmarking MU algorithm performance in different VT families (ViT and Swin-T) and at different capacities. The work employs (i) different datasets, selected to assess the impacts of dataset scale and complexity; (ii) different MU algorithms, selected to represent fundamentally different approaches for MU; and (iii) both single-shot and continual unlearning protocols. Additionally, it focuses on benchmarking MU algorithms that leverage training data memorization, since leveraging memorization has been recently discovered to significantly improve the performance of previously SOTA algorithms. En route, the work characterizes how VTs memorize training data relative to CNNs, and assesses the impact of different memorization proxies on performance. The benchmark uses unified evaluation metrics that capture two complementary notions of forget quality along with accuracy on unseen (test) data and on retained data. Overall, this work offers a benchmarking basis, enabling reproducible, fair, and comprehensive comparisons of existing (and future) MU algorithms on VTs. And, for the first time, it sheds light on how well existing algorithms work in VT settings, establishing a promising reference performance baseline.

</details>


### [166] [ORION: ORthonormal Text Encoding for Universal VLM AdaptatION](https://arxiv.org/abs/2602.19530)
*Omprakash Chakraborty,Jose Dolz,Ismail Ben Ayed*

Main category: cs.CV

TL;DR: ORION通过优化文本嵌入的几何结构，提升了视觉语言模型的性能，适用于多种任务和预测设置。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本分类器因文本原型的质量和几何结构限制，导致嵌入相关性高或分离度低，影响了任务特异性判别能力。

Method: ORION采用低秩适应方法，通过结合类间正交性和初始原型偏差惩罚的损失函数，对预训练的视觉语言模型进行微调。

Result: 在11个基准测试和三种大型VLM骨干上的实验表明，ORION能显著提升性能，适用于零样本、少样本和测试时适应等多种预测设置。

Conclusion: ORION框架通过优化文本嵌入，显著提升了视觉语言模型在多种任务中的性能，证明了其作为即插即用模块的有效性和普适性。

Abstract: Vision language models (VLMs) have demonstrated remarkable generalization across diverse tasks, yet their performance remains constrained by the quality and geometry of the textual prototypes used to represent classes. Standard zero shot classifiers, derived from frozen text encoders and handcrafted prompts, may yield correlated or weakly separated embeddings that limit task specific discriminability. We introduce ORION, a text encoder fine tuning framework that improves pretrained VLMs using only class names. Our method optimizes, via low rank adaptation, a novel loss integrating two terms, one promoting pairwise orthogonality between the textual representations of the classes of a given task and the other penalizing deviations from the initial class prototypes. Furthermore, we provide a probabilistic interpretation of our orthogonality penalty, connecting it to the general maximum likelihood estimation (MLE) principle via Huygens theorem. We report extensive experiments on 11 benchmarks and three large VLM backbones, showing that the refined textual embeddings yield powerful replacements for the standard CLIP prototypes. Added as plug and play module on top of various state of the art methods, and across different prediction settings (zero shot, few shot and test time adaptation), ORION improves the performance consistently and significantly.

</details>


### [167] [Can a Teenager Fool an AI? Evaluating Low-Cost Cosmetic Attacks on Age Estimation Systems](https://arxiv.org/abs/2602.19539)
*Xingyu Shen,Tommy Duong,Xiaodong An,Zengqi Zhao,Zebang Hu,Haoyu Hu,Ziyou Wang,Finn Guo,Simiao Ren*

Main category: cs.CV

TL;DR: 研究发现简单的化妆修改（如胡须、灰发）能显著欺骗AI年龄估计系统，导致未成年人被误判为成年人，呼吁将对抗鲁棒性纳入模型评估标准。


<details>
  <summary>Details</summary>
Motivation: 年龄估计系统作为年龄限制在线内容的守门人日益普及，但其对化妆修改的鲁棒性尚未得到系统评估。研究旨在评估这些系统是否容易被简单的家庭可实现的化妆修改所欺骗。

Method: 研究通过在329张10至21岁个体的面部图像上模拟物理攻击（使用VLM图像编辑器Gemini 2.5 Flash Image），评估了八种模型的性能。引入了攻击转化率（ACR）作为评估指标。

Result: 研究发现，合成胡须单独使用可在所有八种模型上实现28%至69%的ACR；结合所有四种攻击时，预测年龄平均增加7.7岁，ACR最高可达83%。视觉语言模型在完整攻击下的ACR（59%至71%）低于专用模型（63%至83%）。

Conclusion: 研究发现，当前的年龄估计系统在对抗简单的家庭可实现的化妆修改（如胡须、灰发、化妆和模拟皱纹）时表现出显著的脆弱性，这可能导致未成年人被错误分类为成年人。这强调了在模型选择中必须将对抗鲁棒性评估作为强制性标准。

Abstract: Age estimation systems are increasingly deployed as gatekeepers for age-restricted online content, yet their robustness to cosmetic modifications has not been systematically evaluated. We investigate whether simple, household-accessible cosmetic changes, including beards, grey hair, makeup, and simulated wrinkles, can cause AI age estimators to classify minors as adults. To study this threat at scale without ethical concerns, we simulate these physical attacks on 329 facial images of individuals aged 10 to 21 using a VLM image editor (Gemini 2.5 Flash Image). We then evaluate eight models from our prior benchmark: five specialized architectures (MiVOLO, Custom-Best, Herosan, MiViaLab, DEX) and three vision-language models (Gemini 3 Flash, Gemini 2.5 Flash, GPT-5-Nano). We introduce the Attack Conversion Rate (ACR), defined as the fraction of images predicted as minor at baseline that flip to adult after attack, a population-agnostic metric that does not depend on the ratio of minors to adults in the test set. Our results reveal that a synthetic beard alone achieves 28 to 69 percent ACR across all eight models; combining all four attacks shifts predicted age by +7.7 years on average across all 329 subjects and reaches up to 83 percent ACR; and vision-language models exhibit lower ACR (59 to 71 percent) than specialized models (63 to 83 percent) under the full attack, although the ACR ranges overlap and the difference is not statistically tested. These findings highlight a critical vulnerability in deployed age-verification pipelines and call for adversarial robustness evaluation as a mandatory criterion for model selection.

</details>


### [168] [Vinedresser3D: Agentic Text-guided 3D Editing](https://arxiv.org/abs/2602.19542)
*Yankuan Chi,Xiang Li,Zixuan Huang,James M. Rehg*

Main category: cs.CV

TL;DR: Vinedresser3D 是一个代理框架，通过多模态大语言模型和图像编辑模型实现高质量的文本引导3D编辑，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法在联合理解复杂提示、自动定位3D编辑区域和保留未编辑内容方面存在困难。

Method: Vinedresser3D 是一个基于代理的框架，直接在原生3D生成模型的潜在空间中操作。它使用多模态大语言模型推断原始资产的丰富描述，识别编辑区域和类型，并生成分解的结构和外观级文本指导。随后，代理选择信息视图并应用图像编辑模型获取视觉指导，最后通过基于反转的修正流修复流程进行3D潜在空间中的编辑。

Result: Vinedresser3D 在多样化的3D编辑实验中表现出色，优于现有基线。

Conclusion: Vinedresser3D 在自动指标和人类偏好研究中均优于现有基线，实现了精确、连贯且无需掩模的3D编辑。

Abstract: Text-guided 3D editing aims to modify existing 3D assets using natural-language instructions. Current methods struggle to jointly understand complex prompts, automatically localize edits in 3D, and preserve unedited content. We introduce Vinedresser3D, an agentic framework for high-quality text-guided 3D editing that operates directly in the latent space of a native 3D generative model. Given a 3D asset and an editing prompt, Vinedresser3D uses a multimodal large language model to infer rich descriptions of the original asset, identify the edit region and edit type (addition, modification, deletion), and generate decomposed structural and appearance-level text guidance. The agent then selects an informative view and applies an image editing model to obtain visual guidance. Finally, an inversion-based rectified-flow inpainting pipeline with an interleaved sampling module performs editing in the 3D latent space, enforcing prompt alignment while maintaining 3D coherence and unedited regions. Experiments on diverse 3D edits demonstrate that Vinedresser3D outperforms prior baselines in both automatic metrics and human preference studies, while enabling precise, coherent, and mask-free 3D editing.

</details>


### [169] [VALD: Multi-Stage Vision Attack Detection for Efficient LVLM Defense](https://arxiv.org/abs/2602.19570)
*Nadav Kadvil,Ayellet Tal*

Main category: cs.CV

TL;DR: 论文提出一种无需训练的高效防御方法，通过两阶段检测和代理数据整合，有效对抗对抗性图像攻击，保持模型准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）容易受到对抗性图像的干扰，导致输出偏向看似合理但错误的回答，因此需要一种通用、高效且无需训练的防御方法。

Method: 采用两阶段检测机制，首先通过内容保留的图像转换快速过滤大部分干净输入，然后在文本嵌入空间中检查差异，必要时调用强大的LLM来解决攻击引起的分歧。

Result: 该方法在大多数干净图像上跳过昂贵处理，即使在存在大量对抗样本的情况下，开销也保持最小，同时实现了最先进的准确率。

Conclusion: 该论文提出的防御方法结合图像转换和代理数据整合，能有效恢复大型视觉语言模型的正确行为，且在保持高效的同时实现了最先进的准确率。

Abstract: Large Vision-Language Models (LVLMs) can be vulnerable to adversarial images that subtly bias their outputs toward plausible yet incorrect responses. We introduce a general, efficient, and training-free defense that combines image transformations with agentic data consolidation to recover correct model behavior. A key component of our approach is a two-stage detection mechanism that quickly filters out the majority of clean inputs. We first assess image consistency under content-preserving transformations at negligible computational cost. For more challenging cases, we examine discrepancies in a text-embedding space. Only when necessary do we invoke a powerful LLM to resolve attack-induced divergences. A key idea is to consolidate multiple responses, leveraging both their similarities and their differences. We show that our method achieves state-of-the-art accuracy while maintaining notable efficiency: most clean images skip costly processing, and even in the presence of numerous adversarial examples, the overhead remains minimal.

</details>


### [170] [HOCA-Bench: Beyond Semantic Perception to Predictive World Modeling via Hegelian Ontological-Causal Anomalies](https://arxiv.org/abs/2602.19571)
*Chang Liu,Yunfan Ye,Qingyang Zhou,Xichen Tan,Mengxuan Luo,Zhenyu Qiu,Wei Peng,Zhiping Cai*

Main category: cs.CV

TL;DR: HOCA-Bench基准测试显示，视频-LLMs在因果机制理解上存在显著不足，系统-2思维模式虽能提升推理能力，但无法完全弥补差距。


<details>
  <summary>Details</summary>
Motivation: 提升视频-LLMs在预测世界建模方面的能力，弥补其在物理基础智能上的不足。

Method: 通过HOCA-Bench基准测试，将物理异常分为本体异常和因果异常两类，利用生成视频模型构建测试集（1,439个视频，3,470个QA对），评估了17个视频-LLMs的表现。

Result: 模型在静态本体异常（如形状突变）识别上表现较好，但在因果机制（如重力或摩擦力）任务上性能下降超过20%。

Conclusion: 当前的视频-LLMs在静态本体异常识别上表现较好，但在因果机制理解上存在明显不足，系统-2思维模式虽能提升推理能力，但无法完全弥补这一差距。

Abstract: Video-LLMs have improved steadily on semantic perception, but they still fall short on predictive world modeling, which is central to physically grounded intelligence. We introduce HOCA-Bench, a benchmark that frames physical anomalies through a Hegelian lens. HOCA-Bench separates anomalies into two types: ontological anomalies, where an entity violates its own definition or persistence, and causal anomalies, where interactions violate physical relations. Using state-of-the-art generative video models as adversarial simulators, we build a testbed of 1,439 videos (3,470 QA pairs). Evaluations on 17 Video-LLMs show a clear cognitive lag: models often identify static ontological violations (e.g., shape mutations) but struggle with causal mechanisms (e.g., gravity or friction), with performance dropping by more than 20% on causal tasks. System-2 "Thinking" modes improve reasoning, but they do not close the gap, suggesting that current architectures recognize visual patterns more readily than they apply basic physical laws.

</details>


### [171] [ConceptPrism: Concept Disentanglement in Personalized Diffusion Models via Residual Token Optimization](https://arxiv.org/abs/2602.19575)
*Minseo Kim,Minchan Kwon,Dongyeun Lee,Yunho Jeon,Junmo Kim*

Main category: cs.CV

TL;DR: ConceptPrism自动解耦共享概念与图像残差，无需人工指导，显著提升文本到图像生成的保真度与对齐。


<details>
  <summary>Details</summary>
Motivation: 解决个性化文本到图像生成中的概念纠缠问题，避免现有方法依赖人工指导（如语言提示或分割掩码）的局限性。

Method: 提出ConceptPrism框架，通过比较图像集中的图像，联合优化目标token和图像特定残差token，采用重建损失和新颖的排除损失目标，无需直接监督即可捕捉纯净概念。

Result: 实验表明，ConceptPrism有效解决概念纠缠，显著改善了保真度与对齐的权衡。

Conclusion: ConceptPrism通过自动解耦共享视觉概念与图像特定残差，有效解决了概念纠缠问题，显著提升了生成图像的概念保真度与文本对齐的平衡。

Abstract: Personalized text-to-image generation suffers from concept entanglement, where irrelevant residual information from reference images is captured, leading to a trade-off between concept fidelity and text alignment. Recent disentanglement approaches attempt to solve this utilizing manual guidance, such as linguistic cues or segmentation masks, which limits their applicability and fails to fully articulate the target concept. In this paper, we propose ConceptPrism, a novel framework that automatically disentangles the shared visual concept from image-specific residuals by comparing images within a set. Our method jointly optimizes a target token and image-wise residual tokens using two complementary objectives: a reconstruction loss to ensure fidelity, and a novel exclusion loss that compels residual tokens to discard the shared concept. This process allows the target token to capture the pure concept without direct supervision. Extensive experiments demonstrate that ConceptPrism effectively resolves concept entanglement, achieving a significantly improved trade-off between fidelity and alignment.

</details>


### [172] [Learning Mutual View Information Graph for Adaptive Adversarial Collaborative Perception](https://arxiv.org/abs/2602.19596)
*Yihang Tao,Senkang Hu,Haonan An,Zhengru Fang,Hangcheng Cao,Yuguang Fang*

Main category: cs.CV

TL;DR: MVIG攻击是一种自适应对抗协作感知框架，通过MVIG表示和时间图学习优化攻击策略，显著降低现有防御系统的效果。


<details>
  <summary>Details</summary>
Motivation: 当前协作感知防御系统存在两个关键弱点：（i）对具有系统时间和目标区域优化的攻击缺乏鲁棒性；（ii）通过共享协作数据中的隐含置信度信息无意泄露漏洞知识。

Method: 提出MVIG攻击框架，利用MVIG表示和时间图学习生成动态伪造风险图，并通过熵感知漏洞搜索优化攻击位置、时间和持续性。

Result: 在OPV2V和Adv-OPV2V数据集上的评估显示，MVIG攻击将防御成功率降低了62%，并在29.9 FPS下实现47%的持续性攻击检测率降低。

Conclusion: MVIG攻击通过统一的相互视图信息图（MVIG）表示，结合时间图学习和熵感知漏洞搜索，成功降低了现有防御系统的成功率，暴露了协作感知系统的关键安全漏洞。

Abstract: Collaborative perception (CP) enables data sharing among connected and autonomous vehicles (CAVs) to enhance driving safety. However, CP systems are vulnerable to adversarial attacks where malicious agents forge false objects via feature-level perturbations. Current defensive systems use threshold-based consensus verification by comparing collaborative and ego detection results. Yet, these defenses remain vulnerable to more sophisticated attack strategies that could exploit two critical weaknesses: (i) lack of robustness against attacks with systematic timing and target region optimization, and (ii) inadvertent disclosure of vulnerability knowledge through implicit confidence information in shared collaboration data. In this paper, we propose MVIG attack, a novel adaptive adversarial CP framework learning to capture vulnerability knowledge disclosed by different defensive CP systems from a unified mutual view information graph (MVIG) representation. Our approach combines MVIG representation with temporal graph learning to generate evolving fabrication risk maps and employs entropy-aware vulnerability search to optimize attack location, timing and persistence, enabling adaptive attacks with generalizability across various defensive configurations. Extensive evaluations on OPV2V and Adv-OPV2V datasets demonstrate that MVIG attack reduces defense success rates by up to 62\% against state-of-the-art defenses while achieving 47\% lower detection for persistent attacks at 29.9 FPS, exposing critical security gaps in CP systems. Code will be released at https://github.com/yihangtao/MVIG.git

</details>


### [173] [RAID: Retrieval-Augmented Anomaly Detection](https://arxiv.org/abs/2602.19611)
*Mingxiu Cai,Zhe Zhang,Gaochang Wu,Tianyou Chai,Xiatian Zhu*

Main category: cs.CV

TL;DR: RAID是一种检索增强的无监督异常检测框架，通过噪声抑制机制在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有无监督异常检测方法因类内变化、不完美匹配和模板有限而引入噪声，RAID通过检索增强生成技术解决这一问题。

Method: RAID采用分层向量数据库检索类、语义和实例级表示，构建粗到细的流程，并通过匹配成本量和引导的Mixture-of-Experts网络抑制噪声。

Result: RAID在MVTec、VisA、MPDD和BTAD基准测试中，在全样本、少样本和多数据集设置下均达到最优性能。

Conclusion: RAID框架通过检索增强的噪声抑制机制，在无监督异常检测任务中实现了最先进的性能，适用于多种数据集和设置。

Abstract: Unsupervised Anomaly Detection (UAD) aims to identify abnormal regions by establishing correspondences between test images and normal templates. Existing methods primarily rely on image reconstruction or template retrieval but face a fundamental challenge: matching between test images and normal templates inevitably introduces noise due to intra-class variations, imperfect correspondences, and limited templates. Observing that Retrieval-Augmented Generation (RAG) leverages retrieved samples directly in the generation process, we reinterpret UAD through this lens and introduce \textbf{RAID}, a retrieval-augmented UAD framework designed for noise-resilient anomaly detection and localization. Unlike standard RAG that enriches context or knowledge, we focus on using retrieved normal samples to guide noise suppression in anomaly map generation. RAID retrieves class-, semantic-, and instance-level representations from a hierarchical vector database, forming a coarse-to-fine pipeline. A matching cost volume correlates the input with retrieved exemplars, followed by a guided Mixture-of-Experts (MoE) network that leverages the retrieved samples to adaptively suppress matching noise and produce fine-grained anomaly maps. RAID achieves state-of-the-art performance across full-shot, few-shot, and multi-dataset settings on MVTec, VisA, MPDD, and BTAD benchmarks. \href{https://github.com/Mingxiu-Cai/RAID}{https://github.com/Mingxiu-Cai/RAID}.

</details>


### [174] [Seeing Clearly, Reasoning Confidently: Plug-and-Play Remedies for Vision Language Model Blindness](https://arxiv.org/abs/2602.19615)
*Xin Hu,Haomiao Ni,Yunbei Zhang,Jihun Hamm,Zechen Li,Zhengming Ding*

Main category: cs.CV

TL;DR: 本文提出一种无需微调VLMs的高效模块，通过多模态类别嵌入和文本提示增强，显著提升稀有物体推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在稀有物体上推理能力不足的问题，由于预训练数据中稀有物体实例稀缺，现有方法计算成本高且未充分利用原始训练数据。

Method: 提出了一种轻量级的基于注意力的增强模块，利用视觉基础模型和同义词增强的文本描述学习多模态类别嵌入，以优化视觉令牌。同时，将学习到的嵌入作为物体感知检测器生成提示信息，注入文本提示中以引导VLM关注相关图像区域。

Result: 在两个基准测试中，预训练的VLMs在稀有物体识别和推理任务上取得了显著且一致的性能提升。

Conclusion: 本文提出的高效即插即用模块显著提升了视觉语言模型（VLMs）在稀有物体上的推理能力，无需微调VLMs。通过多模态类别嵌入和文本提示增强，实验证明该方法在稀有物体识别和推理任务上取得了显著提升。

Abstract: Vision language models (VLMs) have achieved remarkable success in broad visual understanding, yet they remain challenged by object-centric reasoning on rare objects due to the scarcity of such instances in pretraining data. While prior efforts alleviate this issue by retrieving additional data or introducing stronger vision encoders, these methods are still computationally intensive during finetuning VLMs and don't fully exploit the original training data. In this paper, we introduce an efficient plug-and-play module that substantially improves VLMs' reasoning over rare objects by refining visual tokens and enriching input text prompts, without VLMs finetuning. Specifically, we propose to learn multi-modal class embeddings for rare objects by leveraging prior knowledge from vision foundation models and synonym-augmented text descriptions, compensating for limited training examples. These embeddings refine the visual tokens in VLMs through a lightweight attention-based enhancement module that improves fine-grained object details. In addition, we use the learned embeddings as object-aware detectors to generate informative hints, which are injected into the text prompts to help guide the VLM's attention toward relevant image regions. Experiments on two benchmarks show consistent and substantial gains for pretrained VLMs in rare object recognition and reasoning. Further analysis reveals how our method strengthens the VLM's ability to focus on and reason about rare objects.

</details>


### [175] [Accurate Planar Tracking With Robust Re-Detection](https://arxiv.org/abs/2602.19624)
*Jonas Serych,Jiri Matas*

Main category: cs.CV

TL;DR: SAM-H和WOFTSAM是新型平面跟踪器，结合SAM 2的分割跟踪和单应性估计，显著提升了跟踪性能，并在基准测试中创下新纪录。


<details>
  <summary>Details</summary>
Motivation: 结合SAM 2提供的鲁棒长期分割跟踪和8自由度单应性姿态估计，以提升平面跟踪的鲁棒性和性能。

Method: SAM-H通过分割掩模轮廓估计单应性，对目标外观变化具有高度鲁棒性；WOFTSAM利用SAM-H提供的丢失目标重新检测功能，显著改进了现有的WOFT跟踪器。

Result: 在PlanarTrack基准测试中，SAM-H和WOFTSAM分别以+12.4和+15.2pp的优势大幅超越第二名，并在p@15和p@5指标上表现出色。

Conclusion: SAM-H和WOFTSAM在POT-210和PlanarTrack基准测试中表现优异，显著提升了当前最先进的平面跟踪性能，并提供了改进的地面真实注释以支持更精确的基准测试。

Abstract: We present SAM-H and WOFTSAM, novel planar trackers that combine robust long-term segmentation tracking provided by SAM 2 with 8 degrees-of-freedom homography pose estimation. SAM-H estimates homographies from segmentation mask contours and is thus highly robust to target appearance changes. WOFTSAM significantly improves the current state-of-the-art planar tracker WOFT by exploiting lost target re-detection provided by SAM-H. The proposed methods are evaluated on POT-210 and PlanarTrack tracking benchmarks, setting the new state-of-the-art performance on both. On the latter, they outperform the second best by a large margin, +12.4 and +15.2pp on the p@15 metric. We also present improved ground-truth annotations of initial PlanarTrack poses, enabling more accurate benchmarking in the high-precision p@5 metric. The code and the re-annotations are available at https://github.com/serycjon/WOFTSAM

</details>


### [176] [Personalized Longitudinal Medical Report Generation via Temporally-Aware Federated Adaptation](https://arxiv.org/abs/2602.19668)
*He Zhu,Ren Togo,Takahiro Ogawa,Kenji Hirata,Minghui Tang,Takaaki Yoshimura,Hiroyuki Sugimori,Noriko Nishioka,Yukie Shimizu,Kohsuke Kudo,Miki Haseyama*

Main category: cs.CV

TL;DR: FedTAR 是一种联邦学习框架，通过时间感知聚合和个性化适配器，解决了纵向医疗报告生成中的隐私和动态性问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 纵向医疗报告生成在临床中非常重要，但由于严格的隐私约束和疾病进展的动态性，现有联邦学习方法忽略了纵向动态，假设客户端分布是静态的，无法建模跨访问的时间变化或患者特异性异质性。

Method: FedTAR 框架通过从人口统计嵌入生成轻量级 LoRA 适配器，并执行时间残差聚合，其中不同访问的更新由通过一阶 MAML 优化的元学习时间策略加权。

Result: 在 J-MID（1M 次检查）和 MIMIC-CXR 上的实验显示，FedTAR 在语言准确性、时间连贯性和跨站点泛化方面均取得了持续改进。

Conclusion: FedTAR 通过结合人口统计驱动的个性化和时间感知的全局聚合，为联邦纵向建模提供了一个稳健且隐私保护的范式，显著提升了语言准确性、时间连贯性和跨站点泛化能力。

Abstract: Longitudinal medical report generation is clinically important yet remains challenging due to strict privacy constraints and the evolving nature of disease progression. Although federated learning (FL) enables collaborative training without data sharing, existing FL methods largely overlook longitudinal dynamics by assuming stationary client distributions, making them unable to model temporal shifts across visits or patient-specific heterogeneity-ultimately leading to unstable optimization and suboptimal report generation.
  We introduce Federated Temporal Adaptation (FTA), a federated setting that explicitly accounts for the temporal evolution of client data. Building upon this setting, we propose FedTAR, a framework that integrates demographic-driven personalization with time-aware global aggregation. FedTAR generates lightweight LoRA adapters from demographic embeddings and performs temporal residual aggregation, where updates from different visits are weighted by a meta-learned temporal policy optimized via first-order MAML.
  Experiments on J-MID (1M exams) and MIMIC-CXR demonstrate consistent improvements in linguistic accuracy, temporal coherence, and cross-site generalization, establishing FedTAR as a robust and privacy-preserving paradigm for federated longitudinal modeling.

</details>


### [177] [HDR Reconstruction Boosting with Training-Free and Exposure-Consistent Diffusion](https://arxiv.org/abs/2602.19706)
*Yo-Tin Lin,Su-Kai Chen,Hou-Ning Hu,Yen-Yu Lin,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 无需训练的扩散修复方法，结合文本引导和SDEdit，显著提升HDR重建效果，尤其在过曝区域。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在过曝区域因信息完全丢失而失效的问题，提升HDR重建的质量和效率。

Method: 提出了一种基于扩散修复的无训练方法，结合文本引导的扩散模型和SDEdit细化，通过迭代补偿机制确保多曝光LDR图像的亮度一致性。

Result: 在标准HDR数据集和实际拍摄中，该方法在感知质量和定量指标上均显著提升，成功恢复了自然细节。

Conclusion: 该方法通过结合文本引导的扩散模型和SDEdit细化，有效提升了现有HDR重建技术，特别是在过曝区域的细节恢复上表现出色，且无需额外训练。

Abstract: Single LDR to HDR reconstruction remains challenging for over-exposed regions where traditional methods often fail due to complete information loss. We present a training-free approach that enhances existing indirect and direct HDR reconstruction methods through diffusion-based inpainting. Our method combines text-guided diffusion models with SDEdit refinement to generate plausible content in over-exposed areas while maintaining consistency across multi-exposure LDR images. Unlike previous approaches requiring extensive training, our method seamlessly integrates with existing HDR reconstruction techniques through an iterative compensation mechanism that ensures luminance coherence across multiple exposures. We demonstrate significant improvements in both perceptual quality and quantitative metrics on standard HDR datasets and in-the-wild captures. Results show that our method effectively recovers natural details in challenging scenarios while preserving the advantages of existing HDR reconstruction pipelines. Project page: https://github.com/EusdenLin/HDR-Reconstruction-Boosting

</details>


### [178] [ChimeraLoRA: Multi-Head LoRA-Guided Synthetic Datasets](https://arxiv.org/abs/2602.19708)
*Hoyoung Kim,Minwoo Jang,Jabin Koo,Sangdoo Yun,Jungseul Ok*

Main category: cs.CV

TL;DR: 结合类共享和每图像LoRA，通过语义增强生成多样且细节丰富的图像，提升少样本分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决在数据稀缺（尤其是尾部类别）情况下，如何通过扩散模型补充真实数据不足的问题，同时平衡多样性和细节捕获的需求。

Method: 将适配器分为类共享LoRA（A）和每图像LoRAs（B），并通过语义增强技术（如保留类别边界框）在共享LoRA中暴露一致的类语义。生成时，使用Dirichlet分布抽取系数组合A和B。

Result: 合成的图像既多样又细节丰富，与少样本真实分布紧密对齐，显著提升了下游分类任务的准确性。

Conclusion: 通过结合类共享LoRA和每图像LoRA，并引入语义增强技术，该方法在保持多样性的同时捕获了精细细节，显著提升了少样本分类任务的性能。

Abstract: Beyond general recognition tasks, specialized domains including privacy-constrained medical applications and fine-grained settings often encounter data scarcity, especially for tail classes. To obtain less biased and more reliable models under such scarcity, practitioners leverage diffusion models to supplement underrepresented regions of real data. Specifically, recent studies fine-tune pretrained diffusion models with LoRA on few-shot real sets to synthesize additional images. While an image-wise LoRA trained on a single image captures fine-grained details yet offers limited diversity, a class-wise LoRA trained over all shots produces diverse images as it encodes class priors yet tends to overlook fine details. To combine both benefits, we separate the adapter into a class-shared LoRA~$A$ for class priors and per-image LoRAs~$\mathcal{B}$ for image-specific characteristics. To expose coherent class semantics in the shared LoRA~$A$, we propose a semantic boosting by preserving class bounding boxes during training. For generation, we compose $A$ with a mixture of $\mathcal{B}$ using coefficients drawn from a Dirichlet distribution. Across diverse datasets, our synthesized images are both diverse and detail-rich while closely aligning with the few-shot real distribution, yielding robust gains in downstream classification accuracy.

</details>


### [179] [Pixels Don't Lie (But Your Detector Might): Bootstrapping MLLM-as-a-Judge for Trustworthy Deepfake Detection and Reasoning Supervision](https://arxiv.org/abs/2602.19715)
*Kartik Kuckreja,Parul Gupta,Muhammad Haris Khan,Abhinav Dhall*

Main category: cs.CV

TL;DR: DeepfakeJudge通过可扩展的推理监督框架，显著提升深度伪造检测的推理忠实度，准确性和人类评价一致性优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测模型的自然语言解释常缺乏视觉证据支持，限制了其可靠性，且现有评估忽视推理忠实度。

Method: 提出了DeepfakeJudge框架，包括一个分布外基准、人类标注的视觉推理标签子集和一套评估模型，通过自举生成器-评估器过程优化推理监督。

Result: 在提出的元评估基准上，推理自举模型准确率达96.2%，优于30倍大的基线模型；推理评估器与人类评分高度相关，配对一致性达98.9%。用户研究表明，70%的参与者更偏好该框架生成的解释。

Conclusion: DeepfakeJudge框架通过可扩展的推理监督和评估，显著提升了深度伪造检测的推理忠实度，并在准确性和人类评价一致性方面优于现有方法。

Abstract: Deepfake detection models often generate natural-language explanations, yet their reasoning is frequently ungrounded in visual evidence, limiting reliability. Existing evaluations measure classification accuracy but overlook reasoning fidelity. We propose DeepfakeJudge, a framework for scalable reasoning supervision and evaluation, that integrates an out-of-distribution benchmark containing recent generative and editing forgeries, a human-annotated subset with visual reasoning labels, and a suite of evaluation models, that specialize in evaluating reasoning rationales without the need for explicit ground truth reasoning rationales. The Judge is optimized through a bootstrapped generator-evaluator process that scales human feedback into structured reasoning supervision and supports both pointwise and pairwise evaluation. On the proposed meta-evaluation benchmark, our reasoning-bootstrapped model achieves an accuracy of 96.2\%, outperforming \texttt{30x} larger baselines. The reasoning judge attains very high correlation with human ratings and 98.9\% percent pairwise agreement on the human-annotated meta-evaluation subset. These results establish reasoning fidelity as a quantifiable dimension of deepfake detection and demonstrate scalable supervision for interpretable deepfake reasoning. Our user study shows that participants preferred the reasonings generated by our framework 70\% of the time, in terms of faithfulness, groundedness, and usefulness, compared to those produced by other models and datasets. All of our datasets, models, and codebase are \href{https://github.com/KjAeRsTuIsK/DeepfakeJudge}{open-sourced}.

</details>


### [180] [Generative 6D Pose Estimation via Conditional Flow Matching](https://arxiv.org/abs/2602.19719)
*Amir Hamza,Davide Boscaini,Weihang Li,Benjamin Busam,Fabio Poiesi*

Main category: cs.CV

TL;DR: Flose是一种基于条件流匹配的6D姿态估计方法，整合几何和语义特征，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在物体对称性或缺乏局部特征时表现不佳，Flose旨在通过生成式方法和语义特征整合解决这些问题。

Method: Flose通过条件流匹配问题在ℝ³中进行6D姿态估计，结合了基于几何和外观的语义特征，并采用RANSAC-based注册处理异常值。

Result: Flose在BOP基准测试中平均召回率提高了+4.5%，显著优于现有方法。

Conclusion: Flose在BOP基准测试的五个数据集上表现优异，平均召回率提高了+4.5%，证明了其在6D姿态估计任务中的有效性。

Abstract: Existing methods for instance-level 6D pose estimation typically rely on neural networks that either directly regress the pose in $\mathrm{SE}(3)$ or estimate it indirectly via local feature matching. The former struggle with object symmetries, while the latter fail in the absence of distinctive local features. To overcome these limitations, we propose a novel formulation of 6D pose estimation as a conditional flow matching problem in $\mathbb{R}^3$. We introduce Flose, a generative method that infers object poses via a denoising process conditioned on local features. While prior approaches based on conditional flow matching perform denoising solely based on geometric guidance, Flose integrates appearance-based semantic features to mitigate ambiguities caused by object symmetries. We further incorporate RANSAC-based registration to handle outliers. We validate Flose on five datasets from the established BOP benchmark. Flose outperforms prior methods with an average improvement of +4.5 Average Recall. Project Website : https://tev-fbk.github.io/Flose/

</details>


### [181] [Towards Personalized Multi-Modal MRI Synthesis across Heterogeneous Datasets](https://arxiv.org/abs/2602.19723)
*Yue Zhang,Zhizheng Zhuo,Siyao Xu,Shan Lv,Zhaoxi Liu,Jun Qiu,Qiuli Wang,Yaou Liu,S. Kevin Zhou*

Main category: cs.CV

TL;DR: PMM-Synth是一个支持跨数据集泛化的多模态MRI合成框架，通过三个创新模块在多个临床数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有统一合成模型在单一数据集上训练和评估的局限性，提升多模态MRI合成模型的临床适用性。

Method: PMM-Synth通过个性化特征调制模块、模态一致批量调度器和选择性监督损失三个核心创新实现跨数据集泛化。

Result: 在四个临床多模态MRI数据集上，PMM-Synth在PSNR和SSIM指标上均优于现有方法，且能更好地保留解剖结构和病理细节。

Conclusion: PMM-Synth在多种多模态MRI数据集上表现优异，不仅在合成任务中超越了现有方法，还能有效支持真实世界中的诊断任务。

Abstract: Synthesizing missing modalities in multi-modal magnetic resonance imaging (MRI) is vital for ensuring diagnostic completeness, particularly when full acquisitions are infeasible due to time constraints, motion artifacts, and patient tolerance. Recent unified synthesis models have enabled flexible synthesis tasks by accommodating various input-output configurations. However, their training and evaluation are typically restricted to a single dataset, limiting their generalizability across diverse clinical datasets and impeding practical deployment. To address this limitation, we propose PMM-Synth, a personalized MRI synthesis framework that not only supports various synthesis tasks but also generalizes effectively across heterogeneous datasets. PMM-Synth is jointly trained on multiple multi-modal MRI datasets that differ in modality coverage, disease types, and intensity distributions. It achieves cross-dataset generalization through three core innovations: a Personalized Feature Modulation module that dynamically adapts feature representations based on dataset identifier to mitigate the impact of distributional shifts; a Modality-Consistent Batch Scheduler that facilitates stable and efficient batch training under inconsistent modality conditions; and a selective supervision loss to ensure effective learning when ground truth modalities are partially missing. Evaluated on four clinical multi-modal MRI datasets, PMM-Synth consistently outperforms state-of-the-art methods in both one-to-one and many-to-one synthesis tasks, achieving superior PSNR and SSIM scores. Qualitative results further demonstrate improved preservation of anatomical structures and pathological details. Additionally, downstream tumor segmentation and radiological reporting studies suggest that PMM-Synth holds potential for supporting reliable diagnosis under real-world modality-missing scenarios.

</details>


### [182] [VGGT-MPR: VGGT-Enhanced Multimodal Place Recognition in Autonomous Driving Environments](https://arxiv.org/abs/2602.19735)
*Jingyi Xu,Zhangshuo Qi,Zhongmiao Yan,Xuyu Gao,Qianyun Jiao,Songpengcheng Xia,Xieyuanli Chen,Ling Pei*

Main category: cs.CV

TL;DR: VGGT-MPR是一种多模态地点识别框架，利用VGGT几何引擎和无需训练的重排序机制，显著提升了自动驾驶中的地点识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态地点识别方法依赖手工融合策略和参数化主干网络、需要昂贵重新训练的问题。

Method: 采用Visual Geometry Grounded Transformer (VGGT)作为统一的几何引擎，结合深度感知和点图监督提取几何丰富的视觉嵌入，并通过预测深度图增强稀疏LiDAR点云的结构表示。此外，设计了无需训练的重排序机制，利用VGGT的跨视图关键点跟踪能力优化检索结果。

Result: 在大规模自动驾驶基准测试和自收集数据上的实验表明，VGGT-MPR实现了最先进的性能，对环境变化、视角偏移和遮挡表现出强鲁棒性。

Conclusion: VGGT-MPR框架通过结合几何引擎和训练无关的重排序机制，在自动驾驶领域实现了最先进的性能，展现出对环境变化、视角偏移和遮挡的强鲁棒性。

Abstract: In autonomous driving, robust place recognition is critical for global localization and loop closure detection. While inter-modality fusion of camera and LiDAR data in multimodal place recognition (MPR) has shown promise in overcoming the limitations of unimodal counterparts, existing MPR methods basically attend to hand-crafted fusion strategies and heavily parameterized backbones that require costly retraining. To address this, we propose VGGT-MPR, a multimodal place recognition framework that adopts the Visual Geometry Grounded Transformer (VGGT) as a unified geometric engine for both global retrieval and re-ranking. In the global retrieval stage, VGGT extracts geometrically-rich visual embeddings through prior depth-aware and point map supervision, and densifies sparse LiDAR point clouds with predicted depth maps to improve structural representation. This enhances the discriminative ability of fused multimodal features and produces global descriptors for fast retrieval. Beyond global retrieval, we design a training-free re-ranking mechanism that exploits VGGT's cross-view keypoint-tracking capability. By combining mask-guided keypoint extraction with confidence-aware correspondence scoring, our proposed re-ranking mechanism effectively refines retrieval results without additional parameter optimization. Extensive experiments on large-scale autonomous driving benchmarks and our self-collected data demonstrate that VGGT-MPR achieves state-of-the-art performance, exhibiting strong robustness to severe environmental changes, viewpoint shifts, and occlusions. Our code and data will be made publicly available.

</details>


### [183] [InfScene-SR: Spatially Continuous Inference for Arbitrary-Size Image Super-Resolution](https://arxiv.org/abs/2602.19736)
*Shoukun Sun,Zhe Wang,Xiang Que,Jiyin Zhang,Xiaogang Ma*

Main category: cs.CV

TL;DR: InfScene-SR是一种新型超分辨率框架，通过创新的融合机制解决大尺寸图像处理中的边界问题，无需重新训练即可生成高质量结果。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于扩散模型的超分辨率方法在处理大尺寸图像时因内存限制导致的边界不一致和纹理不连续问题。

Method: 提出了InfScene-SR框架，采用引导和方差校正的融合机制，适应扩散模型的迭代细化过程，支持大尺度任意场景的超分辨率处理。

Result: 在遥感数据集上验证了InfScene-SR能够重建高感知质量的细节并消除边界伪影，提升了如语义分割等下游任务的性能。

Conclusion: InfScene-SR框架通过创新的引导和方差校正融合机制，实现了大尺度高分辨率图像的无缝生成，无需重新训练，显著提升了超分辨率任务的性能。

Abstract: Image Super-Resolution (SR) aims to recover high-resolution (HR) details from low-resolution (LR) inputs, a task where Denoising Diffusion Probabilistic Models (DDPMs) have recently shown superior performance compared to Generative Adversarial Networks (GANs) based approaches. However, standard diffusion-based SR models, such as SR3, are typically trained on fixed-size patches and struggle to scale to arbitrary-sized images due to memory constraints. Applying these models via independent patch processing leads to visible seams and inconsistent textures across boundaries. In this paper, we propose InfScene-SR, a framework enabling spatially continuous super-resolution for large, arbitrary scenes. We adapt the iterative refinement process of diffusion models with a novel guided and variance-corrected fusion mechanism, allowing for the seamless generation of large-scale high-resolution imagery without retraining. We validate our approach on remote sensing datasets, demonstrating that InfScene-SR not only reconstructs fine details with high perceptual quality but also eliminates boundary artifacts, benefiting downstream tasks such as semantic segmentation.

</details>


### [184] [Multimodal Dataset Distillation Made Simple by Prototype-Guided Data Synthesis](https://arxiv.org/abs/2602.19756)
*Junhyeok Choi,Sangwoo Mo,Minwoo Chae*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的多模态数据集蒸馏框架，利用CLIP和unCLIP实现高效跨架构泛化，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态学习在视觉-语言任务中取得了显著成功，但其依赖大规模图像-文本数据集，导致训练成本高且效率低。现有数据集过滤和剪枝方法仍需较大子集以保持性能，且在极小子集下表现不佳。数据集蒸馏虽具潜力，但现有方法需全数据集训练和联合优化图像像素与文本特征，限制了跨架构泛化。

Method: 该方法使用CLIP提取对齐的图像-文本嵌入，获取原型，并利用unCLIP解码器合成图像，实现高效且可扩展的多模态数据集蒸馏。

Result: 实验表明，该方法在跨架构泛化上优于基于优化的数据集蒸馏和子集选择方法，实现了最先进的性能。

Conclusion: 本文提出的无学习数据集蒸馏框架通过利用CLIP提取对齐的图像-文本嵌入，获取原型，并使用unCLIP解码器合成图像，显著提升了跨架构的泛化能力，优于现有的基于优化的数据集蒸馏和子集选择方法。

Abstract: Recent advances in multimodal learning have achieved remarkable success across diverse vision-language tasks. However, such progress heavily relies on large-scale image-text datasets, making training costly and inefficient. Prior efforts in dataset filtering and pruning attempt to mitigate this issue, but still require relatively large subsets to maintain performance and fail under very small subsets. Dataset distillation offers a promising alternative, yet existing multimodal dataset distillation methods require full-dataset training and joint optimization of image pixels and text features, making them architecture-dependent and limiting cross-architecture generalization. To overcome this, we propose a learning-free dataset distillation framework that eliminates the need for large-scale training and optimization while enhancing generalization across architectures. Our method uses CLIP to extract aligned image-text embeddings, obtains prototypes, and employs an unCLIP decoder to synthesize images, enabling efficient and scalable multimodal dataset distillation. Extensive experiments demonstrate that our approach consistently outperforms optimization-based dataset distillation and subset selection methods, achieving state-of-the-art cross-architecture generalization.

</details>


### [185] [Training Deep Stereo Matching Networks on Tree Branch Imagery: A Benchmark Study for Real-Time UAV Forestry Applications](https://arxiv.org/abs/2602.19763)
*Yida Lin,Bing Xue,Mengjie Zhang,Sam Schofield,Richard Green*

Main category: cs.CV

TL;DR: 研究评估了十种深度立体匹配网络在树木修剪场景中的表现，发现BANet-3D质量最佳，RAFT-Stereo场景理解最强，AnyNet接近实时处理，BANet-2D平衡质量与速度。


<details>
  <summary>Details</summary>
Motivation: 自主无人机树木修剪需要从立体相机中获取准确、实时的深度估计，而即使小的视差误差也会在工作距离上引起明显的深度错误。

Method: 训练和测试了十种深度立体匹配网络，包括逐步细化、3D卷积、边缘感知注意力和轻量级设计等方法，使用Canterbury Tree Branches数据集（5,313对立体图像）和DEFOM生成的视差图作为训练目标。

Result: BANet-3D在感知指标（SSIM、LPIPS、ViTScore）和结构指标（SIFT/ORB特征匹配）上表现最佳。AnyNet在1080P分辨率下达到6.99 FPS，是唯一接近实时处理的选项。

Conclusion: BANet-3D在整体质量上表现最佳（SSIM = 0.883，LPIPS = 0.157），而RAFT-Stereo在场景理解上得分最高（ViTScore = 0.799）。AnyNet在1080P分辨率下达到6.99 FPS，是唯一接近实时处理的选项，而BANet-2D在1.21 FPS下提供了最佳的质量-速度平衡。

Abstract: Autonomous drone-based tree pruning needs accurate, real-time depth estimation from stereo cameras. Depth is computed from disparity maps using $Z = f B/d$, so even small disparity errors cause noticeable depth mistakes at working distances. Building on our earlier work that identified DEFOM-Stereo as the best reference disparity generator for vegetation scenes, we present the first study to train and test ten deep stereo matching networks on real tree branch images. We use the Canterbury Tree Branches dataset -- 5,313 stereo pairs from a ZED Mini camera at 1080P and 720P -- with DEFOM-generated disparity maps as training targets. The ten methods cover step-by-step refinement, 3D convolution, edge-aware attention, and lightweight designs. Using perceptual metrics (SSIM, LPIPS, ViTScore) and structural metrics (SIFT/ORB feature matching), we find that BANet-3D produces the best overall quality (SSIM = 0.883, LPIPS = 0.157), while RAFT-Stereo scores highest on scene-level understanding (ViTScore = 0.799). Testing on an NVIDIA Jetson Orin Super (16 GB, independently powered) mounted on our drone shows that AnyNet reaches 6.99 FPS at 1080P -- the only near-real-time option -- while BANet-2D gives the best quality-speed balance at 1.21 FPS. We also compare 720P and 1080P processing times to guide resolution choices for forestry drone systems.

</details>


### [186] [One2Scene: Geometric Consistent Explorable 3D Scene Generation from a Single Image](https://arxiv.org/abs/2602.19766)
*Pengfei Wang,Liyi Chen,Zhiyuan Ma,Yanjun Guo,Guowen Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: One2Scene通过分解单图像生成3D场景为三个子任务，显著提升几何一致性和探索稳定性，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在自由探索时存在几何失真和噪声问题，One2Scene旨在通过分解问题为可处理的子任务来解决这一挑战。

Method: 框架包括全景图生成、2D锚点提升为3D几何支架，以及基于支架的新视角生成。采用多视角立体匹配和双向特征融合模块增强几何一致性。

Result: One2Scene在深度估计、360°重建和可探索3D场景生成中表现优异，支持大范围相机运动的稳定探索。

Conclusion: One2Scene通过分解问题为三个子任务，显著提升了单图像生成可探索3D场景的性能，并在实验中超越了现有方法。

Abstract: Generating explorable 3D scenes from a single image is a highly challenging problem in 3D vision. Existing methods struggle to support free exploration, often producing severe geometric distortions and noisy artifacts when the viewpoint moves far from the original perspective. We introduce \textbf{One2Scene}, an effective framework that decomposes this ill-posed problem into three tractable sub-tasks to enable immersive explorable scene generation. We first use a panorama generator to produce anchor views from a single input image as initialization. Then, we lift these 2D anchors into an explicit 3D geometric scaffold via a generalizable, feed-forward Gaussian Splatting network. Instead of treating the panorama as a single image for reconstruction, we project it into multiple sparse anchor views and reformulate the reconstruction task as multi-view stereo matching, which allows us to leverage robust geometric priors learned from large-scale multi-view datasets. A bidirectional feature fusion module is used to enforce cross-view consistency, yielding an efficient and geometrically reliable scaffold. Finally, the scaffold serves as a strong prior for a novel view generator to produce photorealistic and geometrically accurate views at arbitrary cameras. By explicitly conditioning on a 3D-consistent scaffold to perform reconstruction, One2Scene works stably under large camera motions, supporting immersive scene exploration. Extensive experiments show that One2Scene substantially outperforms state-of-the-art methods in panorama depth estimation, feed-forward 360° reconstruction, and explorable 3D scene generation. Code and models will be released.

</details>


### [187] [TraceVision: Trajectory-Aware Vision-Language Model for Human-Like Spatial Understanding](https://arxiv.org/abs/2602.19768)
*Fan Yang,Shurong Zheng,Hongyin Zhao,Yufei Zhan,Xin Li,Yousong Zhu,Chaoyang Zhao Ming Tang,Jinqiao Wang*

Main category: cs.CV

TL;DR: TraceVision是一个整合轨迹感知的视觉-语言模型，通过TVP模块和三阶段训练，在多项任务中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 当前的大视觉-语言模型主要关注全局图像理解，难以模拟人类视觉注意力轨迹和解释描述与特定区域的关联。

Method: 提出了TraceVision模型，结合轨迹感知视觉感知（TVP）模块，采用几何简化提取语义关键点，并设计了三阶段训练流程。

Result: 在轨迹引导的标题生成、文本引导的轨迹预测、理解和分割等任务中，TraceVision表现出色。

Conclusion: TraceVision通过整合轨迹感知的空间理解，在视觉-语言任务中实现了最先进的性能，为直观的空间交互和可解释的视觉理解奠定了基础。

Abstract: Recent Large Vision-Language Models (LVLMs) demonstrate remarkable capabilities in image understanding and natural language generation. However, current approaches focus predominantly on global image understanding, struggling to simulate human visual attention trajectories and explain associations between descriptions and specific regions. We propose TraceVision, a unified vision-language model integrating trajectory-aware spatial understanding in an end-to-end framework. TraceVision employs a Trajectory-aware Visual Perception (TVP) module for bidirectional fusion of visual features and trajectory information. We design geometric simplification to extract semantic keypoints from raw trajectories and propose a three-stage training pipeline where trajectories guide description generation and region localization. We extend TraceVision to trajectory-guided segmentation and video scene understanding, enabling cross-frame tracking and temporal attention analysis. We construct the Reasoning-based Interactive Localized Narratives (RILN) dataset to enhance logical reasoning and interpretability. Extensive experiments on trajectory-guided captioning, text-guided trajectory prediction, understanding, and segmentation demonstrate that TraceVision achieves state-of-the-art performance, establishing a foundation for intuitive spatial interaction and interpretable visual understanding.

</details>


### [188] [Open-vocabulary 3D scene perception in industrial environments](https://arxiv.org/abs/2602.19823)
*Keno Moenck,Adrian Philip Florea,Julian Koch,Thorsten Schüppstuhl*

Main category: cs.CV

TL;DR: 提出无需训练的开放词汇3D感知流程，通过超点合并语义特征生成掩码，结合'IndustrialCLIP'实现工业对象分割，解决了现有方法泛化不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的开放词汇方法依赖在非工业数据集上预训练的类无关分割模型，导致在工业对象上表现不佳，因此需要一种更适应工业场景的解决方案。

Method: 提出了一种基于预计算超点合并语义特征的掩码生成方法，替代了传统的预训练模型生成实例提案的方式，并结合领域适应的VLFM 'IndustrialCLIP'进行开放词汇查询。

Result: 定性实验结果表明，该方法能够成功分割工业场景中的对象。

Conclusion: 本研究提出了一种无需训练的开放词汇3D感知流程，成功解决了现有2D视觉语言基础模型在工业场景中泛化能力不足的问题，并通过实验验证了其在工业对象分割上的有效性。

Abstract: Autonomous vision applications in production, intralogistics, or manufacturing environments require perception capabilities beyond a small, fixed set of classes. Recent open-vocabulary methods, leveraging 2D Vision-Language Foundation Models (VLFMs), target this task but often rely on class-agnostic segmentation models pre-trained on non-industrial datasets (e.g., household scenes). In this work, we first demonstrate that such models fail to generalize, performing poorly on common industrial objects. Therefore, we propose a training-free, open-vocabulary 3D perception pipeline that overcomes this limitation. Instead of using a pre-trained model to generate instance proposals, our method simply generates masks by merging pre-computed superpoints based on their semantic features. Following, we evaluate the domain-adapted VLFM "IndustrialCLIP" on a representative 3D industrial workshop scene for open-vocabulary querying. Our qualitative results demonstrate successful segmentation of industrial objects.

</details>


### [189] [TextShield-R1: Reinforced Reasoning for Tampered Text Detection](https://arxiv.org/abs/2602.19828)
*Chenfan Qu,Yiwu Zhong,Jian Liu,Xuekang Zhu,Bohan Yu,Lianwen Jin*

Main category: cs.CV

TL;DR: TextShield-R1是首个基于强化学习的MLLM解决方案，通过创新预训练和微调策略提升篡改文本检测和推理能力，并引入TFR基准进行严格评估。


<details>
  <summary>Details</summary>
Motivation: 篡改图像的普遍存在带来安全威胁，现有MLLMs在微观伪影识别、篡改文本区域定位准确性低且依赖昂贵标注。

Method: 引入Forensic Continual Pre-training进行预训练，采用Group Relative Policy Optimization进行微调，并通过OCR Rectification提升定位精度。

Result: TextShield-R1在跨风格、跨方法和跨语言条件下表现优异，显著优于现有技术。

Conclusion: TextShield-R1显著提升了可解释篡改文本检测的技术水平，通过强化学习框架和创新的奖励函数设计，减少了标注依赖并提升了推理能力。

Abstract: The growing prevalence of tampered images poses serious security threats, highlighting the urgent need for reliable detection methods. Multimodal large language models (MLLMs) demonstrate strong potential in analyzing tampered images and generating interpretations. However, they still struggle with identifying micro-level artifacts, exhibit low accuracy in localizing tampered text regions, and heavily rely on expensive annotations for forgery interpretation. To this end, we introduce TextShield-R1, the first reinforcement learning based MLLM solution for tampered text detection and reasoning. Specifically, our approach introduces Forensic Continual Pre-training, an easy-to-hard curriculum that well prepares the MLLM for tampered text detection by harnessing the large-scale cheap data from natural image forensic and OCR tasks. During fine-tuning, we perform Group Relative Policy Optimization with novel reward functions to reduce annotation dependency and improve reasoning capabilities. At inference time, we enhance localization accuracy via OCR Rectification, a method that leverages the MLLM's strong text recognition abilities to refine its predictions. Furthermore, to support rigorous evaluation, we introduce the Text Forensics Reasoning (TFR) benchmark, comprising over 45k real and tampered images across 16 languages, 10 tampering techniques, and diverse domains. Rich reasoning-style annotations are included, allowing for comprehensive assessment. Our TFR benchmark simultaneously addresses seven major limitations of existing benchmarks and enables robust evaluation under cross-style, cross-method, and cross-language conditions. Extensive experiments demonstrate that TextShield-R1 significantly advances the state of the art in interpretable tampered text detection.

</details>


### [190] [M3S-Net: Multimodal Feature Fusion Network Based on Multi-scale Data for Ultra-short-term PV Power Forecasting](https://arxiv.org/abs/2602.19832)
*Penghui Niu,Taotao Cai,Suqi Zhang,Junhua Gu,Ping Zhang,Qiqi Liu,Jianxin Li*

Main category: cs.CV

TL;DR: M3S-Net通过多模态特征融合网络提升光伏功率预测精度，误差降低6.2%。


<details>
  <summary>Details</summary>
Motivation: 解决现有光伏功率预测方法在捕捉云的精细光学特征和复杂时空耦合方面的不足。

Method: 提出M3S-Net，结合多尺度部分通道选择网络、多尺度序列到图像分析网络和跨模态Mamba交互模块，实现视觉与时间模态的深度结构耦合。

Result: 在10分钟预测中，M3S-Net的平均绝对误差比现有最佳基线降低了6.2%。

Conclusion: M3S-Net通过创新的多模态特征融合网络，显著提升了超短期光伏功率预测的准确性，特别是在捕捉云的光学精细特征和气象数据的复杂时空耦合方面表现突出。

Abstract: The inherent intermittency and high-frequency variability of solar irradiance, particularly during rapid cloud advection, present significant stability challenges to high-penetration photovoltaic grids. Although multimodal forecasting has emerged as a viable mitigation strategy, existing architectures predominantly rely on shallow feature concatenation and binary cloud segmentation, thereby failing to capture the fine-grained optical features of clouds and the complex spatiotemporal coupling between visual and meteorological modalities. To bridge this gap, this paper proposes M3S-Net, a novel multimodal feature fusion network based on multi-scale data for ultra-short-term PV power forecasting. First, a multi-scale partial channel selection network leverages partial convolutions to explicitly isolate the boundary features of optically thin clouds, effectively transcending the precision limitations of coarse-grained binary masking. Second, a multi-scale sequence to image analysis network employs Fast Fourier Transform (FFT)-based time-frequency representation to disentangle the complex periodicity of meteorological data across varying time horizons. Crucially, the model incorporates a cross-modal Mamba interaction module featuring a novel dynamic C-matrix swapping mechanism. By exchanging state-space parameters between visual and temporal streams, this design conditions the state evolution of one modality on the context of the other, enabling deep structural coupling with linear computational complexity, thus overcoming the limitations of shallow concatenation. Experimental validation on the newly constructed fine-grained PV power dataset demonstrates that M3S-Net achieves a mean absolute error reduction of 6.2% in 10-minute forecasts compared to state-of-the-art baselines. The dataset and source code will be available at https://github.com/she1110/FGPD.

</details>


### [191] [DerMAE: Improving skin lesion classification through conditioned latent diffusion and MAE distillation](https://arxiv.org/abs/2602.19848)
*Francisco Filho,Kelvin Cunha,Fábio Papais,Emanoel dos Santos,Rodrigo Mota,Thales Bezerra,Erico Medeiros,Paulo Borba,Tsang Ing Ren*

Main category: cs.CV

TL;DR: 针对皮肤病变数据集的类别不平衡问题，采用扩散模型生成合成图像，结合MAE预训练和知识蒸馏，提升分类性能并实现移动端高效推理。


<details>
  <summary>Details</summary>
Motivation: 皮肤病变分类数据集中类别不平衡问题严重，尤其是恶性病例样本不足，导致深度学习训练时决策边界有偏。

Method: 使用类别条件扩散模型生成合成皮肤病变图像，随后通过自监督MAE预训练让大型ViT模型学习鲁棒的领域相关特征，最后通过知识蒸馏将表征迁移至适合移动设备的小型ViT学生模型。

Result: 实验结果表明，在合成数据上进行MAE预训练并结合蒸馏，能够提升分类性能，同时实现高效的设备端推理。

Conclusion: 结合MAE预训练和知识蒸馏的方法，不仅提高了皮肤病变分类的性能，还实现了适合移动设备的高效推理，具有临床实用价值。

Abstract: Skin lesion classification datasets often suffer from severe class imbalance, with malignant cases significantly underrepresented, leading to biased decision boundaries during deep learning training. We address this challenge using class-conditioned diffusion models to generate synthetic dermatological images, followed by self-supervised MAE pretraining to enable huge ViT models to learn robust, domain-relevant features. To support deployment in practical clinical settings, where lightweight models are required, we apply knowledge distillation to transfer these representations to a smaller ViT student suitable for mobile devices. Our results show that MAE pretraining on synthetic data, combined with distillation, improves classification performance while enabling efficient on-device inference for practical clinical use.

</details>


### [192] [Contrastive meta-domain adaptation for robust skin lesion classification across clinical and acquisition conditions](https://arxiv.org/abs/2602.19857)
*Rodrigo Mota,Kelvin Cunha,Emanoel dos Santos,Fábio Papais,Francisco Filho,Thales Bezerra,Erico Medeiros,Paulo Borba,Tsang Ing Ren*

Main category: cs.CV

TL;DR: 该论文提出了一种视觉元域适应策略，通过迁移学习提升皮肤病变分类在临床图像上的泛化能力，实验证明其有效性和重要性。


<details>
  <summary>Details</summary>
Motivation: 深度学习方法在皮肤科图像分析中对采集变异性和领域特定视觉特征的敏感性，导致在临床环境中部署时性能下降。

Method: 提出了一种基于视觉元域概念的适应策略，将大型皮肤镜数据集中的视觉表示迁移到临床图像领域。

Result: 在多个皮肤科数据集上的实验显示，分类性能有持续提升，并缩小了皮肤镜与临床图像之间的性能差距。

Conclusion: 研究强调了领域感知训练对于可部署系统的重要性，通过视觉元域策略有效提升了皮肤病变分类的泛化鲁棒性。

Abstract: Deep learning models for dermatological image analysis remain sensitive to acquisition variability and domain-specific visual characteristics, leading to performance degradation when deployed in clinical settings. We investigate how visual artifacts and domain shifts affect deep learning-based skin lesion classification. We propose an adaptation strategy, grounded in the idea of visual meta-domains, that transfers visual representations from larger dermoscopic datasets into clinical image domains, thereby improving generalization robustness. Experiments across multiple dermatology datasets show consistent gains in classification performance and reduced gaps between dermoscopic and clinical images. These results emphasize the importance of domain-aware training for deployable systems.

</details>


### [193] [Brewing Stronger Features: Dual-Teacher Distillation for Multispectral Earth Observation](https://arxiv.org/abs/2602.19863)
*Filip Wolf,Blaž Rolih,Luka Čehovin Zajc*

Main category: cs.CV

TL;DR: 双教师对比蒸馏框架提升多光谱和光学数据的表示学习性能，实现跨模态知识转移。


<details>
  <summary>Details</summary>
Motivation: 地球观测（EO）传感器的多样性和模态使得单一通用模型不现实，需要高效的知识跨模态转移。

Method: 提出了一个双教师对比蒸馏框架，结合多光谱教师和光学视觉基础模型（VFM）教师，实现跨模态表示学习。

Result: 在多种光学和多光谱基准测试中，模型在多光谱数据上表现出色，同时在纯光学输入上不妥协性能，语义分割平均提升3.64个百分点，变化检测提升1.2，分类任务提升1.31。

Conclusion: 对比蒸馏为异构地球观测数据源的可扩展表示学习提供了一种原则性和高效的方法。

Abstract: Foundation models are transforming Earth Observation (EO), yet the diversity of EO sensors and modalities makes a single universal model unrealistic. Multiple specialized EO foundation models (EOFMs) will likely coexist, making efficient knowledge transfer across modalities essential. Most existing EO pretraining relies on masked image modeling, which emphasizes local reconstruction but provides limited control over global semantic structure. To address this, we propose a dual-teacher contrastive distillation framework for multispectral imagery that aligns the student's pretraining objective with the contrastive self-distillation paradigm of modern optical vision foundation models (VFMs). Our approach combines a multispectral teacher with an optical VFM teacher, enabling coherent cross-modal representation learning. Experiments across diverse optical and multispectral benchmarks show that our model adapts to multispectral data without compromising performance on optical-only inputs, achieving state-of-the-art results in both settings, with an average improvement of 3.64 percentage points in semantic segmentation, 1.2 in change detection, and 1.31 in classification tasks. This demonstrates that contrastive distillation provides a principled and efficient approach to scalable representation learning across heterogeneous EO data sources. Code: Coming soon.

</details>


### [194] [ApET: Approximation-Error Guided Token Compression for Efficient VLMs](https://arxiv.org/abs/2602.19870)
*Qiankun Ma,Ziyao Zhang,Haofei Wang,Jie Chen,Zhen Song,Hairong Zheng*

Main category: cs.CV

TL;DR: ApET是一种基于信息论的视觉令牌压缩框架，无需依赖注意力机制，显著提升效率并与FlashAttention兼容。


<details>
  <summary>Details</summary>
Motivation: 现有视觉令牌压缩方法依赖注意力机制，存在位置偏见且与高效注意力内核不兼容，限制了实际应用。

Method: ApET采用线性近似重构原始视觉令牌，并通过近似误差识别和丢弃信息量最低的令牌。

Result: ApET在图像理解任务中保留95.2%的原始性能，视频理解任务中达到100.4%，同时令牌预算压缩88.9%和87.5%。

Conclusion: ApET框架通过信息论视角的视觉令牌压缩，显著提升了视觉语言模型的推理效率，且与FlashAttention无缝集成，具有实际部署价值。

Abstract: Recent Vision-Language Models (VLMs) have demonstrated remarkable multimodal understanding capabilities, yet the redundant visual tokens incur prohibitive computational overhead and degrade inference efficiency. Prior studies typically relies on [CLS] attention or text-vision cross-attention to identify and discard redundant visual tokens. Despite promising results, such solutions are prone to introduce positional bias and, more critically, are incompatible with efficient attention kernels such as FlashAttention, limiting their practical deployment for VLM acceleration. In this paper, we step away from attention dependencies and revisit visual token compression from an information-theoretic perspective, aiming to maximally preserve visual information without any attention involvement. We present ApET, an Approximation-Error guided Token compression framework. ApET first reconstructs the original visual tokens with a small set of basis tokens via linear approximation, then leverages the approximation error to identify and drop the least informative tokens. Extensive experiments across multiple VLMs and benchmarks demonstrate that ApET retains 95.2% of the original performance on image-understanding tasks and even attains 100.4% on video-understanding tasks, while compressing the token budgets by 88.9% and 87.5%, respectively. Thanks to its attention-free design, ApET seamlessly integrates with FlashAttention, enabling further inference acceleration and making VLM deployment more practical. Code is available at https://github.com/MaQianKun0/ApET.

</details>


### [195] [BigMaQ: A Big Macaque Motion and Animation Dataset Bridging Image and 3D Pose Representations](https://arxiv.org/abs/2602.19874)
*Lucas Martini,Alexander Lappe,Anna Bognár,Rufin Vogels,Martin A. Giese*

Main category: cs.CV

TL;DR: BigMaQ是一个大规模猕猴3D运动数据集，通过个体化虚拟形象提升姿态跟踪精度，并显著改善行为识别性能。


<details>
  <summary>Details</summary>
Motivation: 解决非人类灵长类动物3D姿态与形状重建未整合到行为识别中的问题，弥补稀疏关键点无法完整捕捉动作动态的不足。

Method: 通过构建特定个体的纹理化虚拟形象，并采用高质量猕猴模板网格，提供比现有表面跟踪方法更准确的姿态描述。从原始数据集中提取BigMaQ500作为行为识别基准。

Result: 结合姿态描述符后，平均精度（mAP）显著提升。

Conclusion: BigMaQ数据集首次将动态3D姿态-形状表示整合到动物行为识别的学习任务中，为非人类灵长类动物的视觉外观、姿势和社会互动研究提供了丰富资源。

Abstract: The recognition of dynamic and social behavior in animals is fundamental for advancing ethology, ecology, medicine and neuroscience. Recent progress in deep learning has enabled automated behavior recognition from video, yet an accurate reconstruction of the three-dimensional (3D) pose and shape has not been integrated into this process. Especially for non-human primates, mesh-based tracking efforts lag behind those for other species, leaving pose descriptions restricted to sparse keypoints that are unable to fully capture the richness of action dynamics. To address this gap, we introduce the $\textbf{Big Ma}$ca$\textbf{Q}$ue 3D Motion and Animation Dataset ($\texttt{BigMaQ}$), a large-scale dataset comprising more than 750 scenes of interacting rhesus macaques with detailed 3D pose descriptions. Extending previous surface-based animal tracking methods, we construct subject-specific textured avatars by adapting a high-quality macaque template mesh to individual monkeys. This allows us to provide pose descriptions that are more accurate than previous state-of-the-art surface-based animal tracking methods. From the original dataset, we derive BigMaQ500, an action recognition benchmark that links surface-based pose vectors to single frames across multiple individual monkeys. By pairing features extracted from established image and video encoders with and without our pose descriptors, we demonstrate substantial improvements in mean average precision (mAP) when pose information is included. With these contributions, $\texttt{BigMaQ}$ establishes the first dataset that both integrates dynamic 3D pose-shape representations into the learning task of animal action recognition and provides a rich resource to advance the study of visual appearance, posture, and social interaction in non-human primates. The code and data are publicly available at https://martinivis.github.io/BigMaQ/ .

</details>


### [196] [Monocular Mesh Recovery and Body Measurement of Female Saanen Goats](https://arxiv.org/abs/2602.19896)
*Bo Jin,Shichao Zhao,Jin Lyu,Bin Zhang,Tao Yu,Liang An,Yebin Liu,Meili Wang*

Main category: cs.CV

TL;DR: 研究建立了FemaleSaanenGoat数据集和SaanenGoat模型，实现了对Saanen奶山羊的高精度3D重建和自动身体测量，提升了精准畜牧业的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 由于现有重建方法缺乏针对山羊的真实3D数据，无法准确评估其产奶潜力，因此需要建立山羊专用的3D数据集和模型。

Method: 研究采用多视角DynamicFusion技术，将嘈杂的非刚性点云序列融合为高保真3D扫描，并基于这些扫描开发了专为雌性Saanen山羊设计的参数化3D形状模型SaanenGoat。

Result: 实验结果表明，该方法在3D重建和身体测量方面具有卓越的准确性。

Conclusion: 该研究通过建立FemaleSaanenGoat数据集和开发SaanenGoat参数化3D形状模型，成功实现了对Saanen奶山羊的高精度3D重建和关键身体尺寸的自动测量，为精准畜牧业中的大规模3D视觉应用提供了新范例。

Abstract: The lactation performance of Saanen dairy goats, renowned for their high milk yield, is intrinsically linked to their body size, making accurate 3D body measurement essential for assessing milk production potential, yet existing reconstruction methods lack goat-specific authentic 3D data. To address this limitation, we establish the FemaleSaanenGoat dataset containing synchronized eight-view RGBD videos of 55 female Saanen goats (6-18 months). Using multi-view DynamicFusion, we fuse noisy, non-rigid point cloud sequences into high-fidelity 3D scans, overcoming challenges from irregular surfaces and rapid movement. Based on these scans, we develop SaanenGoat, a parametric 3D shape model specifically designed for female Saanen goats. This model features a refined template with 41 skeletal joints and enhanced udder representation, registered with our scan data. A comprehensive shape space constructed from 48 goats enables precise representation of diverse individual variations. With the help of SaanenGoat model, we get high-precision 3D reconstruction from single-view RGBD input, and achieve automated measurement of six critical body dimensions: body length, height, chest width, chest girth, hip width, and hip height. Experimental results demonstrate the superior accuracy of our method in both 3D reconstruction and body measurement, presenting a novel paradigm for large-scale 3D vision applications in precision livestock farming.

</details>


### [197] [Gradient based Severity Labeling for Biomarker Classification in OCT](https://arxiv.org/abs/2602.19907)
*Kiran Kokilepersaud,Mohit Prabhushankar,Ghassan AlRegib,Stephanie Trejo Corona,Charles Wykoff*

Main category: cs.CV

TL;DR: 提出基于疾病严重程度的对比学习策略，用于医学图像，通过生成疾病标签提升分类准确率6%。


<details>
  <summary>Details</summary>
Motivation: 医学图像中任意增强可能扭曲包含生物标志物的小局部区域，而基于疾病严重程度选择样本更可能保留与疾病进展相关的相似结构。

Method: 引入了一种基于异常检测算法梯度响应的方法，为未标记的OCT扫描生成疾病严重程度标签，并用于监督对比学习。

Result: 该方法在关键糖尿病视网膜病变指标上比自监督基线提高了6%的分类准确率。

Conclusion: 论文提出了一种针对医学图像的对比学习新策略，通过疾病严重程度标签选择正负样本，显著提高了糖尿病视网膜病变关键指标的生物标志物分类准确率。

Abstract: In this paper, we propose a novel selection strategy for contrastive learning for medical images. On natural images, contrastive learning uses augmentations to select positive and negative pairs for the contrastive loss. However, in the medical domain, arbitrary augmentations have the potential to distort small localized regions that contain the biomarkers we are interested in detecting. A more intuitive approach is to select samples with similar disease severity characteristics, since these samples are more likely to have similar structures related to the progression of a disease. To enable this, we introduce a method that generates disease severity labels for unlabeled OCT scans on the basis of gradient responses from an anomaly detection algorithm. These labels are used to train a supervised contrastive learning setup to improve biomarker classification accuracy by as much as 6% above self-supervised baselines for key indicators of Diabetic Retinopathy.

</details>


### [198] [Multi-Modal Representation Learning via Semi-Supervised Rate Reduction for Generalized Category Discovery](https://arxiv.org/abs/2602.19910)
*Wei He,Xianghan Meng,Zhiyuan Huang,Xianbiao Qi,Rong Xiao,Chun-Guang Li*

Main category: cs.CV

TL;DR: SSR$^2$-GCD通过模态内对齐和跨模态表示学习，提升了广义类别发现的性能。


<details>
  <summary>Details</summary>
Motivation: 当前广义类别发现任务的多模态表示学习方法过于依赖模态间对齐，忽视了模态内对齐对表示分布底层结构的重要性。

Method: 提出了一种基于半监督率减少的多模态表示学习框架SSR$^2$-GCD，强调模态内关系的对齐，并利用视觉语言模型的跨模态对齐能力集成提示候选。

Result: 在通用和细粒度基准数据集上的广泛实验表明，SSR$^2$-GCD方法表现出卓越的性能。

Conclusion: SSR$^2$-GCD框架通过半监督率减少和跨模态表示学习，显著提升了广义类别发现任务的性能，特别是在已知和未知类别的识别上。

Abstract: Generalized Category Discovery (GCD) aims to identify both known and unknown categories, with only partial labels given for the known categories, posing a challenging open-set recognition problem. State-of-the-art approaches for GCD task are usually built on multi-modality representation learning, which is heavily dependent upon inter-modality alignment. However, few of them cast a proper intra-modality alignment to generate a desired underlying structure of representation distributions. In this paper, we propose a novel and effective multi-modal representation learning framework for GCD via Semi-Supervised Rate Reduction, called SSR$^2$-GCD, to learn cross-modality representations with desired structural properties based on emphasizing to properly align intra-modality relationships. Moreover, to boost knowledge transfer, we integrate prompt candidates by leveraging the inter-modal alignment offered by Vision Language Models. We conduct extensive experiments on generic and fine-grained benchmark datasets demonstrating superior performance of our approach.

</details>


### [199] [Learning Positive-Incentive Point Sampling in Neural Implicit Fields for Object Pose Estimation](https://arxiv.org/abs/2602.19937)
*Yifei Shi,Boyan Wan,Xin Xu,Kai Xu*

Main category: cs.CV

TL;DR: 提出SO(3)-等变网络与PIPS策略，提升隐式场在姿态估计中的性能，尤其在挑战性场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 神经隐式场在未观测相机空间区域预测规范坐标时缺乏直接观测信号，导致高度不确定性，需要依赖模型的泛化能力。

Method: 采用SO(3)-等变卷积隐式网络和PIPS策略，动态确定采样位置以提高网络准确性和训练效率。

Result: 该方法在三个姿态估计数据集上优于现有技术，尤其在未见过姿态、高遮挡、新几何形状和严重噪声等挑战性场景中表现显著提升。

Conclusion: 本文提出了一种结合SO(3)-等变卷积隐式网络和正向激励点采样（PIPS）策略的方法，显著提升了在挑战性场景下的物体姿态估计性能。

Abstract: Learning neural implicit fields of 3D shapes is a rapidly emerging field that enables shape representation at arbitrary resolutions. Due to the flexibility, neural implicit fields have succeeded in many research areas, including shape reconstruction, novel view image synthesis, and more recently, object pose estimation. Neural implicit fields enable learning dense correspondences between the camera space and the object's canonical space-including unobserved regions in camera space-significantly boosting object pose estimation performance in challenging scenarios like highly occluded objects and novel shapes. Despite progress, predicting canonical coordinates for unobserved camera-space regions remains challenging due to the lack of direct observational signals. This necessitates heavy reliance on the model's generalization ability, resulting in high uncertainty. Consequently, densely sampling points across the entire camera space may yield inaccurate estimations that hinder the learning process and compromise performance. To alleviate this problem, we propose a method combining an SO(3)-equivariant convolutional implicit network and a positive-incentive point sampling (PIPS) strategy. The SO(3)-equivariant convolutional implicit network estimates point-level attributes with SO(3)-equivariance at arbitrary query locations, demonstrating superior performance compared to most existing baselines. The PIPS strategy dynamically determines sampling locations based on the input, thereby boosting the network's accuracy and training efficiency. Our method outperforms the state-of-the-art on three pose estimation datasets. Notably, it demonstrates significant improvements in challenging scenarios, such as objects captured with unseen pose, high occlusion, novel geometry, and severe noise.

</details>


### [200] [Discover, Segment, and Select: A Progressive Mechanism for Zero-shot Camouflaged Object Segmentation](https://arxiv.org/abs/2602.19944)
*Yilong Yang,Jianxin Tian,Shengchuan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: DSS是一种无需训练的逐步优化框架，通过特征一致发现、分割和语义驱动选择，显著提升零样本伪装物体分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决当前零样本伪装物体分割方法依赖MLLMs导致的定位不准确、误检和漏检问题。

Method: 提出了一种逐步优化的发现-分割-选择（DSS）框架，包含特征一致物体发现（FOD）模块、分割模块和语义驱动掩码选择（SMS）模块。

Result: 在多个COS基准测试中，尤其是在多实例场景下，DSS实现了最先进的性能。

Conclusion: DSS机制通过逐步优化的方式显著提升了零样本伪装物体分割的准确性和鲁棒性，无需任何训练或监督即可在多个COS基准测试中达到最先进的性能。

Abstract: Current zero-shot Camouflaged Object Segmentation methods typically employ a two-stage pipeline (discover-then-segment): using MLLMs to obtain visual prompts, followed by SAM segmentation. However, relying solely on MLLMs for camouflaged object discovery often leads to inaccurate localization, false positives, and missed detections. To address these issues, we propose the \textbf{D}iscover-\textbf{S}egment-\textbf{S}elect (\textbf{DSS}) mechanism, a progressive framework designed to refine segmentation step by step. The proposed method contains a Feature-coherent Object Discovery (FOD) module that leverages visual features to generate diverse object proposals, a segmentation module that refines these proposals through SAM segmentation, and a Semantic-driven Mask Selection (SMS) module that employs MLLMs to evaluate and select the optimal segmentation mask from multiple candidates. Without requiring any training or supervision, DSS achieves state-of-the-art performance on multiple COS benchmarks, especially in multiple-instance scenes.

</details>


### [201] [RL-RIG: A Generative Spatial Reasoner via Intrinsic Reflection](https://arxiv.org/abs/2602.19974)
*Tianyu Wang,Zhiyuan Ma,Qian Wang,Xinyi Zhang,Xinwei Long,Bowen Zhou*

Main category: cs.CV

TL;DR: RL-RIG通过强化学习框架提升图像生成的空间推理能力，实验显示其空间准确性优于现有模型11%。


<details>
  <summary>Details</summary>
Motivation: 现有图像生成模型在捕捉细粒度空间关系和保持结构完整性方面表现不足。

Method: 提出RL-RIG框架，包含Diffuser、Checker、Actor和Inverse Diffuser四个组件，采用Generate-Reflect-Edit范式，并开发Reflection-GRPO训练方法。

Result: RL-RIG在LAION-SG数据集上比现有开源模型在可控和精确空间推理方面提升高达11%。

Conclusion: RL-RIG通过强化学习框架显著提升了图像生成中的空间推理能力，实验证明其在空间准确性上优于现有开源模型。

Abstract: Recent advancements in image generation have achieved impressive results in producing high-quality images. However, existing image generation models still generally struggle with a spatial reasoning dilemma, lacking the ability to accurately capture fine-grained spatial relationships from the prompt and correctly generate scenes with structural integrity. To mitigate this dilemma, we propose RL-RIG, a Reinforcement Learning framework for Reflection-based Image Generation. Our architecture comprises four primary components: Diffuser, Checker, Actor, and Inverse Diffuser, following a Generate-Reflect-Edit paradigm to spark the Chain of Thought reasoning ability in image generation for addressing the dilemma. To equip the model with better intuition over generation trajectories, we further develop Reflection-GRPO to train the VLM Actor for edit prompts and the Image Editor for better image quality under a given prompt, respectively. Unlike traditional approaches that solely produce visually stunning yet structurally unreasonable content, our evaluation metrics prioritize spatial accuracy, utilizing Scene Graph IoU and employing a VLM-as-a-Judge strategy to assess the spatial consistency of generated images on LAION-SG dataset. Experimental results show that RL-RIG outperforms existing state-of-the-art open-source models by up to 11% in terms of controllable and precise spatial reasoning in image generation.

</details>


### [202] [RADE-Net: Robust Attention Network for Radar-Only Object Detection in Adverse Weather](https://arxiv.org/abs/2602.19994)
*Christof Leitgeb,Thomas Puchleitner,Max Peter Ronecker,Daniel Watzenig*

Main category: cs.CV

TL;DR: RADE-Net通过3D投影和轻量级模型设计，显著提升了雷达在恶劣天气下的感知性能，性能超越现有雷达和部分激光雷达方法。


<details>
  <summary>Details</summary>
Motivation: 光学传感器在恶劣天气条件下性能受限，而现有雷达方法因数据稀疏或2D投影导致信息丢失。深度学习有望从低层雷达数据中提取更丰富的特征。

Method: 提出了一种基于快速傅里叶变换的4D RADE张量的3D投影方法，并设计了轻量级模型RADE-Net，利用空间和通道注意力机制提取雷达张量的低层和高层特征。

Result: 在K-Radar数据集上，RADE-Net比基线模型性能提升16.7%，比现有雷达模型提升6.5%，并在恶劣天气下超越部分激光雷达方法。

Conclusion: 提出的RADE-Net方法在恶劣天气条件下显著提升了雷达感知性能，并在K-Radar数据集上实现了16.7%的性能提升，超越了现有雷达和部分激光雷达方法。

Abstract: Automotive perception systems are obligated to meet high requirements. While optical sensors such as Camera and Lidar struggle in adverse weather conditions, Radar provides a more robust perception performance, effectively penetrating fog, rain, and snow. Since full Radar tensors have large data sizes and very few datasets provide them, most Radar-based approaches work with sparse point clouds or 2D projections, which can result in information loss. Additionally, deep learning methods show potential to extract richer and more dense features from low level Radar data and therefore significantly increase the perception performance. Therefore, we propose a 3D projection method for fast-Fourier-transformed 4D Range-Azimuth-Doppler-Elevation (RADE) tensors. Our method preserves rich Doppler and Elevation features while reducing the required data size for a single frame by 91.9% compared to a full tensor, thus achieving higher training and inference speed as well as lower model complexity. We introduce RADE-Net, a lightweight model tailored to 3D projections of the RADE tensor. The backbone enables exploitation of low-level and high-level cues of Radar tensors with spatial and channel-attention. The decoupled detection heads predict object center-points directly in the Range-Azimuth domain and regress rotated 3D bounding boxes from rich feature maps in the cartesian scene. We evaluate the model on scenes with multiple different road users and under various weather conditions on the large-scale K-Radar dataset and achieve a 16.7% improvement compared to their baseline, as well as 6.5% improvement over current Radar-only models. Additionally, we outperform several Lidar approaches in scenarios with adverse weather conditions. The code is available under https://github.com/chr-is-tof/RADE-Net.

</details>


### [203] [Token-UNet: A New Case for Transformers Integration in Efficient and Interpretable 3D UNets for Brain Imaging Segmentation](https://arxiv.org/abs/2602.20008)
*Louis Fabrice Tshimanga,Andrea Zanola,Federico Del Pup,Manfredo Atzori*

Main category: cs.CV

TL;DR: Token-UNet通过优化token提取和注意力机制，在计算资源受限下实现高效3D医学图像分割，性能优于SwinUNETR。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于Transformer的医学图像分割模型因计算复杂度高而难以在普通硬件上部署的问题。

Method: 采用TokenLearner模块从3D特征图中提取预设数量的token，结合卷积编码器和Transformer的注意力机制，构建Token-UNet模型家族。

Result: Token-UNet在内存占用、推理时间和参数量上显著优于SwinUNETR（分别减少至33%、10%和35%），且平均性能更优（Dice分数87.21%±0.35% vs 86.75%±0.19%）。

Conclusion: Token-UNet通过结合TokenLearner和TokenFuser模块，在计算资源受限的环境中实现了高效的3D医学图像分割，为研究社区提供了更优化的模型训练、微调和迁移学习方案。

Abstract: We present Token-UNet, adopting the TokenLearner and TokenFuser modules to encase Transformers into UNets.
  While Transformers have enabled global interactions among input elements in medical imaging, current computational challenges hinder their deployment on common hardware. Models like (Swin)UNETR adapt the UNet architecture by incorporating (Swin)Transformer encoders, which process tokens that each represent small subvolumes ($8^3$ voxels) of the input.
  The Transformer attention mechanism scales quadratically with the number of tokens, which is tied to the cubic scaling of 3D input resolution.
  This work reconsiders the role of convolution and attention, introducing Token-UNets, a family of 3D segmentation models that can operate in constrained computational environments and time frames.
  To mitigate computational demands, our approach maintains the convolutional encoder of UNet-like models, and applies TokenLearner to 3D feature maps. This module pools a preset number of tokens from local and global structures.
  Our results show this tokenization effectively encodes task-relevant information, yielding naturally interpretable attention maps. The memory footprint, computation times at inference, and parameter counts of our heaviest model are reduced to 33\%, 10\%, and 35\% of the SwinUNETR values, with better average performance (86.75\% $\pm 0.19\%$ Dice score for SwinUNETR vs our 87.21\% $\pm 0.35\%$).
  This work opens the way to more efficient trainings in contexts with limited computational resources, such as 3D medical imaging. Easing model optimization, fine-tuning, and transfer-learning in limited hardware settings can accelerate and diversify the development of approaches, for the benefit of the research community.

</details>


### [204] [Closing the gap in multimodal medical representation alignment](https://arxiv.org/abs/2602.20046)
*Eleonora Grassucci,Giordano Cicchetti,Danilo Comminiello*

Main category: cs.CV

TL;DR: 本文研究医学领域的模态间隙问题，提出模态无关框架，提升图像与文本对齐效果。


<details>
  <summary>Details</summary>
Motivation: CLIP在多模态学习中虽广泛应用，但其对比损失在复杂多模态场景（如医学领域）中可能导致稀疏和碎片化的潜在空间，即模态间隙问题。本文旨在解决这一问题。

Method: 通过研究医学领域的模态间隙现象，作者提出了一个模态无关的框架，旨在确保语义相关的表示在不同模态间更加对齐。

Result: 提出的方法显著提升了放射学图像与临床文本的对齐效果，改善了跨模态检索和图像描述任务。

Conclusion: 本文提出了一种模态无关的框架，有效缩小了医学领域中的模态间隙，提升了放射学图像与临床文本的对齐效果，从而改善了跨模态检索和图像描述任务。

Abstract: In multimodal learning, CLIP has emerged as the de-facto approach for mapping different modalities into a shared latent space by bringing semantically similar representations closer while pushing apart dissimilar ones. However, CLIP-based contrastive losses exhibit unintended behaviors that negatively impact true semantic alignment, leading to sparse and fragmented latent spaces. This phenomenon, known as the modality gap, has been partially mitigated for standard text and image pairs but remains unknown and unresolved in more complex multimodal settings, such as the medical domain. In this work, we study this phenomenon in the latter case, revealing that the modality gap is present also in medical alignment, and we propose a modality-agnostic framework that closes this gap, ensuring that semantically related representations are more aligned, regardless of their source modality. Our method enhances alignment between radiology images and clinical text, improving cross-modal retrieval and image captioning.

</details>


### [205] [Decoupling Defense Strategies for Robust Image Watermarking](https://arxiv.org/abs/2602.20053)
*Jiahui Chen,Zehang Deng,Zeyu Zhang,Chaoyang Li,Lianchen Jia,Lifeng Sun*

Main category: cs.CV

TL;DR: AdvMark通过两阶段微调框架提升深度学习图像水印的鲁棒性，显著改善对抗攻击下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法在联合优化编码器和解码器时面临清洁准确度下降和鲁棒性有限的问题，AdvMark旨在克服这些挑战。

Method: AdvMark采用两阶段微调框架：第一阶段通过定制化的对抗训练范式主要微调编码器，第二阶段通过直接图像优化处理失真和再生攻击。

Result: 实验表明AdvMark在图像质量和鲁棒性上表现最佳，对抗失真、再生和对抗攻击的准确度分别提升了29%、33%和46%。

Conclusion: AdvMark通过两阶段微调框架有效解决了深度学习图像水印在对抗和再生攻击中的脆弱性问题，显著提升了图像质量和鲁棒性。

Abstract: Deep learning-based image watermarking, while robust against conventional distortions, remains vulnerable to advanced adversarial and regeneration attacks. Conventional countermeasures, which jointly optimize the encoder and decoder via a noise layer, face 2 inevitable challenges: (1) decrease of clean accuracy due to decoder adversarial training and (2) limited robustness due to simultaneous training of all three advanced attacks. To overcome these issues, we propose AdvMark, a novel two-stage fine-tuning framework that decouples the defense strategies. In stage 1, we address adversarial vulnerability via a tailored adversarial training paradigm that primarily fine-tunes the encoder while only conditionally updating the decoder. This approach learns to move the image into a non-attackable region, rather than modifying the decision boundary, thus preserving clean accuracy. In stage 2, we tackle distortion and regeneration attacks via direct image optimization. To preserve the adversarial robustness gained in stage 1, we formulate a principled, constrained image loss with theoretical guarantees, which balances the deviation from cover and previous encoded images. We also propose a quality-aware early-stop to further guarantee the lower bound of visual quality. Extensive experiments demonstrate AdvMark outperforms with the highest image quality and comprehensive robustness, i.e. up to 29\%, 33\% and 46\% accuracy improvement for distortion, regeneration and adversarial attacks, respectively.

</details>


### [206] [The Invisible Gorilla Effect in Out-of-distribution Detection](https://arxiv.org/abs/2602.20068)
*Harry Anthony,Ziyun Liang,Hermione Warr,Konstantinos Kamnitsas*

Main category: cs.CV

TL;DR: 论文发现OOD检测中存在‘隐形大猩猩效应’，即伪影与模型ROI的视觉相似性显著影响检测性能，并提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 探索OOD检测性能差异的潜在原因，特别是在难以检测的伪影（近OOD）中，检测性能与伪影视觉相似性之间的关系。

Method: 通过注释11,355张图像中的伪影颜色并生成颜色交换的反事实，排除了数据集偏差，评估了40种OOD方法在7个基准测试中的表现。

Result: 研究发现，当伪影与模型的ROI视觉相似时（如颜色），检测性能提高；反之则下降。例如，在皮肤病变分类器中，红色墨水（与ROI相似）的AUROC比黑色墨水（不相似）高31.5%。

Conclusion: 论文揭示了OOD检测中一个未被报告的偏差，即‘隐形大猩猩效应’，并提供了构建更鲁棒检测器的指导。

Abstract: Deep Neural Networks achieve high performance in vision tasks by learning features from regions of interest (ROI) within images, but their performance degrades when deployed on out-of-distribution (OOD) data that differs from training data. This challenge has led to OOD detection methods that aim to identify and reject unreliable predictions. Although prior work shows that OOD detection performance varies by artefact type, the underlying causes remain underexplored. To this end, we identify a previously unreported bias in OOD detection: for hard-to-detect artefacts (near-OOD), detection performance typically improves when the artefact shares visual similarity (e.g. colour) with the model's ROI and drops when it does not - a phenomenon we term the Invisible Gorilla Effect. For example, in a skin lesion classifier with red lesion ROI, we show the method Mahalanobis Score achieves a 31.5% higher AUROC when detecting OOD red ink (similar to ROI) compared to black ink (dissimilar) annotations. We annotated artefacts by colour in 11,355 images from three public datasets (e.g. ISIC) and generated colour-swapped counterfactuals to rule out dataset bias. We then evaluated 40 OOD methods across 7 benchmarks and found significant performance drops for most methods when artefacts differed from the ROI. Our findings highlight an overlooked failure mode in OOD detection and provide guidance for more robust detectors. Code and annotations are available at: https://github.com/HarryAnthony/Invisible_Gorilla_Effect.

</details>


### [207] [SemanticNVS: Improving Semantic Scene Understanding in Generative Novel View Synthesis](https://arxiv.org/abs/2602.20079)
*Xinya Chen,Christopher Wewer,Jiahao Xie,Xinting Hu,Jan Eric Lenssen*

Main category: cs.CV

TL;DR: SemanticNVS利用预训练语义特征提升新视角合成的生成质量，尤其在长距离视角下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有NVS方法在输入视角附近表现良好，但在长距离相机运动下容易生成语义不合理和扭曲的图像，推测原因是当前模型未能充分理解其条件或中间生成的场景内容。

Method: 提出了两种策略：(1) 扭曲语义特征和 (2) 在每一步去噪中交替进行理解和生成。

Result: 在多个数据集上的实验结果表明，该方法在定性和定量（FID提升4.69%-15.26%）上均优于现有技术。

Conclusion: SemanticNVS通过集成预训练的语义特征提取器，显著提升了新视角合成（NVS）的生成质量和一致性，尤其是在长距离相机运动下。

Abstract: We present SemanticNVS, a camera-conditioned multi-view diffusion model for novel view synthesis (NVS), which improves generation quality and consistency by integrating pre-trained semantic feature extractors. Existing NVS methods perform well for views near the input view, however, they tend to generate semantically implausible and distorted images under long-range camera motion, revealing severe degradation. We speculate that this degradation is due to current models failing to fully understand their conditioning or intermediate generated scene content. Here, we propose to integrate pre-trained semantic feature extractors to incorporate stronger scene semantics as conditioning to achieve high-quality generation even at distant viewpoints. We investigate two different strategies, (1) warped semantic features and (2) an alternating scheme of understanding and generation at each denoising step. Experimental results on multiple datasets demonstrate the clear qualitative and quantitative (4.69%-15.26% in FID) improvement over state-of-the-art alternatives.

</details>


### [208] [Do Large Language Models Understand Data Visualization Principles?](https://arxiv.org/abs/2602.20084)
*Martin Sinnona,Valentin Bonas,Viviana Siless,Emmanuel Iarussi*

Main category: cs.CV

TL;DR: 评估了LLMs和VLMs在推理可视化原则方面的能力，发现它们在纠正违规方面表现优于检测，但仍与符号求解器存在差距。


<details>
  <summary>Details</summary>
Motivation: 利用LLMs和VLMs作为原则检查器，直接推理视觉设计，绕过符号规则规范的需求。

Method: 编译了一组以自然语言陈述的可视化原则，并生成了一个包含约2,000个带有明确原则违规的Vega-Lite规范的数据集，辅以300多个真实世界的Vega-Lite图表。

Result: 前沿模型在纠正违规方面比可靠检测违规更有效。

Conclusion: 大型（视觉）语言模型作为可视化设计的灵活验证器和编辑器具有潜力，但在视觉感知的细微方面仍与符号求解器存在差距。

Abstract: Data visualization principles, derived from decades of research in design and perception, ensure proper visual communication. While prior work has shown that large language models (LLMs) can generate charts or flag misleading figures, it remains unclear whether they and their vision-language counterparts (VLMs) can reason about and enforce visualization principles directly. Constraint based systems encode these principles as logical rules for precise automated checks, but translating them into formal specifications demands expert knowledge. This motivates leveraging LLMs and VLMs as principle checkers that can reason about visual design directly, bypassing the need for symbolic rule specification. In this paper, we present the first systematic evaluation of both LLMs and VLMs on their ability to reason about visualization principles, using hard verification ground truth derived from Answer Set Programming (ASP). We compiled a set of visualization principles expressed as natural-language statements and generated a controlled dataset of approximately 2,000 Vega-Lite specifications annotated with explicit principle violations, complemented by over 300 real-world Vega-Lite charts. We evaluated both checking and fixing tasks, assessing how well models detect principle violations and correct flawed chart specifications. Our work highlights both the promise of large (vision-)language models as flexible validators and editors of visualization designs and the persistent gap with symbolic solvers on more nuanced aspects of visual perception. They also reveal an interesting asymmetry: frontier models tend to be more effective at correcting violations than at detecting them reliably.

</details>


### [209] [Do Large Language Models Understand Data Visualization Rules?](https://arxiv.org/abs/2602.20137)
*Martin Sinnona,Valentin Bonas,Emmanuel Iarussi,Viviana Siless*

Main category: cs.CV

TL;DR: LLMs在可视化规则验证上表现良好，尤其在自然语言处理上，但在技术性和细微规则上仍有局限。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否能够直接推理和执行可视化规则，以替代需要专家维护的符号编码系统。

Method: 通过将Draco的约束子集翻译为自然语言陈述，并生成一个包含2000个Vega-Lite规范的受控数据集，标注明确的规则违反情况，评估LLMs在检测违反和提示遵循方面的准确性。

Result: 前沿模型在常见违反检测上表现良好（F1最高达0.82），但在细微感知规则和技术性ASP表述上表现下降（某些类别F1<0.15）。自然语言翻译显著提升了小模型的性能（最高提升150%）。

Conclusion: LLMs具有作为灵活、语言驱动的验证器的潜力，但在当前阶段仍存在局限性，尤其是在处理细微的感知规则和技术性ASP表述时。

Abstract: Data visualization rules-derived from decades of research in design and perception-ensure trustworthy chart communication. While prior work has shown that large language models (LLMs) can generate charts or flag misleading figures, it remains unclear whether they can reason about and enforce visualization rules directly. Constraint-based systems such as Draco encode these rules as logical constraints for precise automated checks, but maintaining symbolic encodings requires expert effort, motivating the use of LLMs as flexible rule validators. In this paper, we present the first systematic evaluation of LLMs against visualization rules using hard-verification ground truth derived from Answer Set Programming (ASP). We translated a subset of Draco's constraints into natural-language statements and generated a controlled dataset of 2,000 Vega-Lite specifications annotated with explicit rule violations. LLMs were evaluated on both accuracy in detecting violations and prompt adherence, which measures whether outputs follow the required structured format. Results show that frontier models achieve high adherence (Gemma 3 4B / 27B: 100%, GPT-oss 20B: 98%) and reliably detect common violations (F1 up to 0.82),yet performance drops for subtler perceptual rules (F1 < 0.15 for some categories) and for outputs generated from technical ASP formulations.Translating constraints into natural language improved performance by up to 150% for smaller models. These findings demonstrate the potential of LLMs as flexible, language-driven validators while highlighting their current limitations compared to symbolic solvers.

</details>


### [210] [Flow3r: Factored Flow Prediction for Scalable Visual Geometry Learning](https://arxiv.org/abs/2602.20157)
*Zhongxiao Cong,Qitao Zhao,Minsik Jeon,Shubham Tulsiani*

Main category: cs.CV

TL;DR: Flow3r通过分解流预测模块，利用无标注视频数据提升3D/4D重建性能，尤其在动态场景中效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有的3D/4D重建系统依赖密集几何和姿态标注数据，这些数据获取成本高且动态场景中尤为稀缺。Flow3r旨在通过无监督学习解决这一问题。

Method: Flow3r框架利用密集2D对应关系（流）作为监督信号，将流预测模块分解为基于几何潜在变量和姿态潜在变量的两部分，直接指导场景几何和相机运动的学习。

Result: Flow3r在8个基准测试中（包括静态和动态场景）取得了最先进的结果，尤其是在标注数据稀缺的动态视频中表现最佳。

Conclusion: Flow3r通过引入分解的流预测模块，显著提升了在无标注单目视频数据上的3D/4D重建性能，尤其在动态场景中表现突出。

Abstract: Current feed-forward 3D/4D reconstruction systems rely on dense geometry and pose supervision -- expensive to obtain at scale and particularly scarce for dynamic real-world scenes. We present Flow3r, a framework that augments visual geometry learning with dense 2D correspondences (`flow') as supervision, enabling scalable training from unlabeled monocular videos. Our key insight is that the flow prediction module should be factored: predicting flow between two images using geometry latents from one and pose latents from the other. This factorization directly guides the learning of both scene geometry and camera motion, and naturally extends to dynamic scenes. In controlled experiments, we show that factored flow prediction outperforms alternative designs and that performance scales consistently with unlabeled data. Integrating factored flow into existing visual geometry architectures and training with ${\sim}800$K unlabeled videos, Flow3r achieves state-of-the-art results across eight benchmarks spanning static and dynamic scenes, with its largest gains on in-the-wild dynamic videos where labeled data is most scarce.

</details>


### [211] [tttLRM: Test-Time Training for Long Context and Autoregressive 3D Reconstruction](https://arxiv.org/abs/2602.20160)
*Chen Wang,Hao Tan,Wang Yifan,Zhiqin Chen,Yuheng Liu,Kalyan Sunkavalli,Sai Bi,Lingjie Liu,Yiwei Hu*

Main category: cs.CV

TL;DR: tttLRM是一种新型3D重建模型，通过测试时训练层实现高效长上下文重建，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D重建中长上下文和计算复杂度的问题，同时支持流式观测的渐进式重建与优化。

Method: 提出了一种利用测试时训练（TTT）层的新型大规模3D重建模型tttLRM，能够将多幅图像观测高效压缩到TTT层的快速权重中，形成隐式3D表示，并可解码为高斯泼溅（GS）等显式格式。

Result: 实验表明，tttLRM在3D高斯重建任务中表现优于现有方法，且通过预训练在新视角合成任务上有效提升了重建质量和收敛速度。

Conclusion: tttLRM通过测试时训练层实现了长上下文自回归3D重建，具有线性计算复杂度，并在多个实验中展示了优于现有方法的性能。

Abstract: We propose tttLRM, a novel large 3D reconstruction model that leverages a Test-Time Training (TTT) layer to enable long-context, autoregressive 3D reconstruction with linear computational complexity, further scaling the model's capability. Our framework efficiently compresses multiple image observations into the fast weights of the TTT layer, forming an implicit 3D representation in the latent space that can be decoded into various explicit formats, such as Gaussian Splats (GS) for downstream applications. The online learning variant of our model supports progressive 3D reconstruction and refinement from streaming observations. We demonstrate that pretraining on novel view synthesis tasks effectively transfers to explicit 3D modeling, resulting in improved reconstruction quality and faster convergence. Extensive experiments show that our method achieves superior performance in feedforward 3D Gaussian reconstruction compared to state-of-the-art approaches on both objects and scenes.

</details>


### [212] [Mobile-O: Unified Multimodal Understanding and Generation on Mobile Device](https://arxiv.org/abs/2602.20161)
*Abdelrahman Shaker,Ahmed Heakl,Jaseel Muhammad,Ritesh Thawkar,Omkar Thawakar,Senmao Li,Hisham Cholakkal,Ian Reid,Eric P. Xing,Salman Khan,Fahad Shahbaz Khan*

Main category: cs.CV

TL;DR: Mobile-O 是一种轻量级多模态模型，通过高效设计在边缘设备上实现实时理解和生成，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的统一多模态模型数据需求大且难以部署在边缘设备上，Mobile-O 旨在解决这一问题。

Method: Mobile-O 的核心模块 Mobile Conditioning Projector (MCP) 通过深度可分离卷积和层级对齐融合视觉语言特征与扩散生成器，实现了高效的跨模态条件处理。

Result: Mobile-O 在 GenEval 上达到 74%，比 Show-O 和 JanusFlow 分别高出 5% 和 11%，运行速度快 6 倍和 11 倍；在视觉理解任务中，平均超越它们 15.3% 和 5.1%。

Conclusion: Mobile-O 是首个在边缘设备上实现实时统一多模态理解和生成的实用框架，为完全依赖设备运行的多模态智能研究铺平了道路。

Abstract: Unified multimodal models can both understand and generate visual content within a single architecture. Existing models, however, remain data-hungry and too heavy for deployment on edge devices. We present Mobile-O, a compact vision-language-diffusion model that brings unified multimodal intelligence to a mobile device. Its core module, the Mobile Conditioning Projector (MCP), fuses vision-language features with a diffusion generator using depthwise-separable convolutions and layerwise alignment. This design enables efficient cross-modal conditioning with minimal computational cost. Trained on only a few million samples and post-trained in a novel quadruplet format (generation prompt, image, question, answer), Mobile-O jointly enhances both visual understanding and generation capabilities. Despite its efficiency, Mobile-O attains competitive or superior performance compared to other unified models, achieving 74% on GenEval and outperforming Show-O and JanusFlow by 5% and 11%, while running 6x and 11x faster, respectively. For visual understanding, Mobile-O surpasses them by 15.3% and 5.1% averaged across seven benchmarks. Running in only ~3s per 512x512 image on an iPhone, Mobile-O establishes the first practical framework for real-time unified multimodal understanding and generation on edge devices. We hope Mobile-O will ease future research in real-time unified multimodal intelligence running entirely on-device with no cloud dependency. Our code, models, datasets, and mobile application are publicly available at https://amshaker.github.io/Mobile-O/

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [213] [Compact Hadamard Latent Codes for Efficient Spectral Rendering](https://arxiv.org/abs/2602.18741)
*Jiaqi Yu,Dar'ya Guarnera,Giuseppe Claudio Guarnera*

Main category: cs.GR

TL;DR: 提出Hadamard光谱编码，通过少量RGB渲染通道实现高效光谱渲染，降低计算成本并保持颜色准确性。


<details>
  <summary>Details</summary>
Motivation: 传统光谱渲染计算成本高，需大量波长样本和光谱纹理，限制了其应用。

Method: 提出Hadamard光谱编码，使用非负线性编码器和解码器架构，保持缩放和加法操作，同时近似乘法操作。通过k=6或k=9的RGB渲染通道实现高效光谱渲染。

Result: 实验表明，k=6显著减少颜色误差且比传统光谱渲染更快，k=9提供更高质量结果。轻量级神经上采样网络支持RGB内容无缝集成。

Conclusion: Hadamard光谱编码提供了一种紧凑的潜在表示方法，通过标准RGB渲染操作实现光谱渲染，显著降低了计算成本，同时保持了颜色准确性。

Abstract: Spectral rendering accurately reproduces wavelength-dependent appearance but is computationally expensive, as shading must be evaluated at many wavelength samples and scales roughly linearly with the number of samples. It also requires spectral textures and lights throughout the rendering pipeline. We propose Hadamard spectral codes, a compact latent representation that enables spectral rendering using standard RGB rendering operations. Spectral images are approximated with a small number of RGB rendering passes, followed by a decoding step. Our key requirement is latent linearity: scaling and addition in spectral space correspond to scaling and addition of codes, and the element-wise product of spectra (for example reflectance times illumination) is approximated by the element-wise product of their latent codes. We show that an exact low-dimensional algebra-preserving representation cannot exist for arbitrary spectra when the latent dimension k is smaller than the number of spectral samples n. We therefore introduce a learned non-negative linear encoder and decoder architecture that preserves scaling and addition exactly while encouraging approximate multiplicativity under the Hadamard product. With k = 6, we render k/3 = 2 RGB images per frame using an unmodified RGB renderer, reconstruct the latent image, and decode to high-resolution spectra or XYZ or RGB. Experiments on 3D scenes demonstrate that k = 6 significantly reduces color error compared to RGB baselines while being substantially faster than naive n-sample spectral rendering. Using k = 9 provides higher-quality reference results. We further introduce a lightweight neural upsampling network that maps RGB assets directly to latent codes, enabling integration of legacy RGB content into the spectral pipeline while maintaining perceptually accurate colors in rendered images.

</details>


### [214] [HistCAD: Geometrically Constrained Parametric History-based CAD Dataset](https://arxiv.org/abs/2602.19171)
*Xintong Dong,Chuanyang Li,Chuqi Han,Peng Zheng,Jiaxin Jing,Yanzhi Song,Zhouwang Yang*

Main category: cs.GR

TL;DR: HistCAD是一个大规模数据集，通过约束感知的建模序列和多模态对齐，提升了CAD生成的可编辑性和语义丰富性。


<details>
  <summary>Details</summary>
Motivation: 现有的CAD数据集通常缺乏明确的几何约束和细粒度的功能语义，限制了可编辑且符合约束的生成。

Method: 开发了AM_HistCAD注释模块，从建模序列中提取几何和空间特征，并利用大型语言模型生成建模过程、几何结构和功能类型的补充注释。

Result: HistCAD的显式约束、扁平化序列格式和多类型注释提高了文本驱动CAD生成的鲁棒性、参数可编辑性和准确性。

Conclusion: HistCAD提供了一个统一的基准，推动了可编辑、约束感知且语义丰富的生成式CAD建模的发展。

Abstract: Parametric computer-aided design (CAD) modeling is fundamental to industrial design, but existing datasets often lack explicit geometric constraints and fine-grained functional semantics, limiting editable, constraint-compliant generation. We present HistCAD, a large-scale dataset featuring constraint-aware modeling sequences that compactly represent procedural operations while ensuring compatibility with native CAD software, encompassing five aligned modalities: modeling sequences, multi-view renderings, STEP-format B-reps, native parametric files, and textual annotations. We develop AM\(_\text{HistCAD}\), an annotation module that extracts geometric and spatial features from modeling sequences and uses a large language model to generate complementary annotations of the modeling process, geometric structure, and functional type. Extensive evaluations demonstrate that HistCAD's explicit constraints, flattened sequence format, and multi-type annotations improve robustness, parametric editability, and accuracy in text-driven CAD generation, while industrial parts included in HistCAD further support complex real-world design scenarios. HistCAD thus provides a unified benchmark for advancing editable, constraint-aware, and semantically enriched generative CAD modeling.

</details>


### [215] [Thin Plate Spline Surface Reconstruction via the Method of Matched Sections](https://arxiv.org/abs/2602.19182)
*Igor Orynyak,Kirill Danylenko,Danylo Tavrov*

Main category: cs.GR

TL;DR: 本文发展了匹配截面法（MMS），用于解决偏微分方程边界值问题，特别适用于表面建模。该方法通过1D组件匹配实现高阶导数连续性，展示了在高保真表面重建中的优越性能。


<details>
  <summary>Details</summary>
Motivation: MMS方法源于力学领域，旨在解决等几何分析和计算机图形学中的关键挑战，弥合物理精度与几何连续性之间的差距。

Method: 该方法通过将域分解为一组1D方向性组件，并在其整个边界上进行匹配，固有地强制执行所有变分参数的连续性，包括二阶（曲率）和三阶（剪切）导数。

Result: 研究表明，该方法在高保真表面重建和混合中展现出先进能力，能够从复杂的边界条件或稀疏内部点一致生成能量最优、公平的表面。

Conclusion: 本研究通过进一步发展匹配截面法（MMS），将其确立为一个强大的、物理信息驱动的几何工具，满足了严格数值分析和美学计算机辅助设计的双重需求。

Abstract: This paper further develops the Method of Matched Sections (MMS), a robust numerical framework for the solution of boundary value problems governed by partial differential equations, specifically for surface modeling. While originating in mechanics, the method addresses critical challenges in isogeometric analysis and computer graphics by bridging the gap between physical accuracy and geometric continuity. By decomposing the domain into an assembly of 1D directional components matched along their entire boundaries, the method inherently enforces the continuity of all variational parameters, including second-order (curvature) and third-order (shear) derivatives. We demonstrate the method's advanced capabilities in high-fidelity surface reconstruction and blending, showing that it consistently generates energetically optimal, fair surfaces even from complex boundary conditions or sparse internal points. By advancing the application of MMS, this research establishes it as a powerful, physics-informed geometric tool that satisfies the dual demands of rigorous numerical analysis and aesthetic computer-aided design.

</details>


### [216] [Spherical Hermite Maps](https://arxiv.org/abs/2602.20063)
*Mohamed Abouagour,Eleftherios Garyfallidis*

Main category: cs.GR

TL;DR: Spherical Hermite Maps 通过导数增强的 LUT 表示，以四个纹理样本实现高质量球形函数评估，显著提升性能与质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在球形函数评估中存在质量与性能的权衡，如双线性 LUT 采样速度快但会产生面化，而双三次滤波需要 16 个纹理样本。

Method: 采用导数增强的 LUT 表示（Spherical Hermite Maps），通过存储函数值和缩放偏导数，实现仅需四个纹理样本的 bicubic-Hermite 重建。

Result: 实验表明，Spherical Hermite Maps 在 PSNR 上比双线性插值提高了 8-41 dB，且以四分之一的成本匹配 16 次采样的双三次滤波质量。

Conclusion: Spherical Hermite Maps 提供了一种高效且高质量的球形函数评估方法，通过结合导数增强的 LUT 表示，显著提升了性能与质量，适用于多种图形学应用。

Abstract: Spherical functions appear throughout computer graphics, from spherical harmonic lighting and precomputed radiance transfer to neural radiance fields and procedural planet rendering. Efficient evaluation is critical for real-time applications, yet existing approaches face a quality-performance trade-off: bilinear LUT sampling is fast but produces faceting, while bicubic filtering requires 16 texture samples. Most implementations use finite differences for normals, requiring extra samples and introducing noise. This paper presents Spherical Hermite Maps, a derivative-augmented LUT representation that resolves this trade-off. By storing function values alongside scaled partial derivatives at each texel of a padded cubemap, bicubic-Hermite reconstruction is enabled from only four texture samples (a 2x2 footprint) while providing continuous gradients from the same samples. The key insight is that Hermite interpolation reconstructs smooth derivatives as a byproduct of value reconstruction, making surface normals effectively free. In controlled experiments, Spherical Hermite Maps improve PSNR by 8-41 dB over bilinear interpolation and match 16-tap bicubic quality at one-quarter the cost. Analytic normals reduce mean angular error by 9-13% on complex surfaces while yielding stable specular highlights. Three applications demonstrate versatility: spherical harmonic glyph visualization, radial depth-map impostors for mesh level-of-detail, and procedural planet/asteroid rendering with spherical heightfields.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [217] [On the Inherent Resilience of Task-Oriented V2X Networks to Content-Selection Errors](https://arxiv.org/abs/2602.18620)
*Luca Lusvarghi,Javier Gozalvez*

Main category: cs.NI

TL;DR: 任务导向型V2X网络在动态车辆场景中对内容选择错误具有弹性，确保相关信息传递。


<details>
  <summary>Details</summary>
Motivation: 在高度动态和复杂的车辆场景中，相关性估计错误可能导致内容选择错误，从而影响接收者的情境感知。

Method: 分析了内容选择错误对任务导向型V2X网络的影响，并揭示了其固有弹性的基本条件。

Result: 任务导向型V2X网络即使在高度相关性估计错误条件下，也能保证相关信息的持续传递。

Conclusion: 任务导向型V2X网络对内容选择错误具有固有弹性，即使在高度动态和复杂的车辆场景中也能保证相关信息的持续传递。

Abstract: Task-oriented Vehicle-to-Everything (V2X) networks have recently been proposed to scalably support the large-scale deployment of connected vehicles within the Internet of Vehicles (IoV) vision. In task-oriented V2X networks, vehicles select the content of the transmitted messages based on its relevance to the intended receivers. However, relevance estimation can be quite challenging, especially in highly dynamic and complex vehicular scenarios. Relevance estimation errors can cause a vehicle to omit relevant information from its transmitted message, leading to a content-selection error. Content-selection errors reduce the amount of relevant information available at the receivers and can potentially impair their situational awareness. This work analyses the impact of content-selection errors on task-oriented V2X networks. Our analysis reveals that task-oriented V2X networks feature an inherent resilience to content-selection errors that guarantees a consistent delivery of relevant information even under high relevance estimation error conditions. Moreover, we identify the fundamental conditions underpinning such inherent resilience. These conditions can be encountered in other task-oriented networks where multiple transmitters select the content of their messages based on the task-related requirements of a common set of intended receivers.

</details>


### [218] [Federated Learning-Assisted Optimization of Mobile Transmission with Digital Twins](https://arxiv.org/abs/2602.18627)
*Mohammad Heydari,Terence D. Todd,Dongmei Zhao,George Karakostas*

Main category: cs.NI

TL;DR: 通过数字孪生和联邦优化，实现隐私保护的实时信道调度，实验验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 在线调度器通常需要移动设备的隐私信息（如移动轨迹、位置、信道条件）进行任务分配，但此类信息需保持隐私。论文旨在解决在能量约束下的三个传输调度问题，同时保护隐私。

Method: 采用实时联邦优化框架，调度器仅与数字孪生迭代交互生成全局分数解，再通过依赖舍入将分数解转换为物理系统的信道传输调度方案。

Result: 实验表明，该方法能持续减少总传输时间，且在典型边缘服务器硬件上实现毫秒级运行时间，几乎无带宽/能量违规。

Conclusion: 该论文提出了首个在不暴露隐私数据的情况下，通过数字孪生（DT）实现信道共享的实时联邦优化框架，实验证明其在典型边缘服务器硬件上能实现毫秒级端到端运行时间，且几乎无带宽/能量违规。

Abstract: A Digital Twin (DT) may protect information that is considered private to its associated physical system. For a mobile device, this may include its mobility profile, recent location(s), and experienced channel conditions. Online schedulers, however, typically use this type of information to perform tasks such as shared bandwidth and channel time slot assignments. In this paper, we consider three transmission scheduling problems with energy constraints, where such information is needed, and yet must remain private: minimizing total transmission time when (i) fixed-power or (ii) fixed-rate time slotting with power control is used, and (iii) maximizing the amount of data uploaded in a fixed time period. Using a real-time federated optimization framework, we show how the scheduler can iteratively interact only with the DTs to produce global fractional solutions to these problems, without the latter revealing their private information. Then dependent rounding is used to round the fractional solution into a channel transmission schedule for the physical systems. Experiments show consistent makespan reductions with near-zero bandwidth/energy violations and millisecond-order end-to-end runtime for typical edge server hardware. To the best of our knowledge, this is the first framework that enables channel sharing across DTs using operations that do not expose private data.

</details>


### [219] [MetaBlue: A Metasurface-Assisted Acoustic Underwater Localization System](https://arxiv.org/abs/2602.19252)
*Junling Wang,Yi Guo,Bojun Yang,Yazhou Yuan,Zhenlin An*

Main category: cs.NI

TL;DR: 低成本声学超表面MetaBlue实现单水听器高精度水下定位，AoA误差8.7度，3D误差0.37米。


<details>
  <summary>Details</summary>
Motivation: 现有水下定位技术受限于快速衰减或有限能见度，传统声学系统硬件成本高且部署复杂。

Method: 采用方向依赖的光谱模式嵌入发射波形以实现角度估计（AoA），并提出EM-声学混合到达时间（ToA）方法进行测距。

Result: 实验表明，系统在超过10米距离下平均AoA误差为8.7度，3D定位误差为0.37米，单锚点下精度为0.73米。

Conclusion: 论文提出了一种低成本被动声学超表面MetaBlue，能够将普通超声波发射器转变为定向“超级发射器”，并通过单水听器实现高精度的水下定位。

Abstract: Underwater localization is essential for marine exploration and autonomous underwater operations, yet existing radio frequency and optical approaches are limited by rapid attenuation or limited visibility. Acoustic sensing remains the most practical choice, but conventional acoustic systems typically rely on large arrays or multiple synchronized anchors, resulting in high hardware costs and complex deployment. This paper introduces a novel low-cost passive acoustic metasurface, MetaBlue , explicitly designed for underwater localization, which, when attached to an ordinary ultrasonic transmitter, transforms it into a directional "super-transmitter." The metasurface embeds direction-dependent spectral patterns into the transmitted waveform, enabling accurate angle-of-arrival (AoA) estimation using only a single hydrophone. For ranging, we present a new EM-acoustic mixed time-of-arrival (ToA) method that leverages the acoustic transducer's inherent low-frequency EM leakage as a timing reference, enabling precise ranging without shared clocks. This allows complete 3D localization with a single low-cost anchor. We evaluate the system across diverse real-world underwater settings, including pools, tanks, and outdoor environments. Experiments show that our design achieves an average AoA error of 8.7 degree and 3D localization error of 0.37 m at distances over 10 m. Even with a single anchor, the system maintains 0.73 m precision.

</details>


### [220] [EMS-FL: Federated Tuning of Mixture-of-Experts in Satellite-Terrestrial Networks via Expert-Driven Model Splitting](https://arxiv.org/abs/2602.19485)
*Angzi Xu,Zezhong Zhang,Zhi Liu,Shuguang Cui*

Main category: cs.NI

TL;DR: EMS-FL结合专家模型分割和联邦学习，解决数据短缺和计算限制，提升训练效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 大型AI模型对数据和计算资源需求高，联邦学习在边缘设备上因网络覆盖有限和计算资源受限面临挑战。

Method: 提出EMS-FL，一种专家驱动的模型分割和联邦学习方法，通过非重叠专家分配和异步本地学习，减少训练开销。

Result: EMS-FL在公共数据集和大模型上的实验表明，其训练开销更低，收敛更快，准确性更高。

Conclusion: EMS-FL通过非重叠专家分配和异步本地学习，有效降低了训练开销，实现了比传统联邦学习更快的收敛速度和更高的准确性。严格的收敛分析和全面的实验验证了其优越性。

Abstract: The rapid advancement of large AI models imposes stringent demands on data volume and computational resources. Federated learning, though designed to exploit distributed data and computational resources, faces data shortage from limited network coverage and computational constraints from edge devices. To address these issues, both the mixture-of-experts (MoE) and satellite-terrestrial network (STN) provide promising solutions, offering lightweight computation overhead and broad coverage, respectively. However, the satellite-ground relative motion results in intermittent connectivity, hindering conventional federated learning that relies on model synchronization across devices. To leverage the coverage of STN while preserving training efficiency, we propose EMS-FL, an expert-driven model splitting and federated learning method. EMS-FL assigns each device cluster only the experts highly correlated to their local data. Through non-overlapping expert assignments, asynchronous local learning is further proposed, where each device cluster trains its assigned experts consecutively and only uploads local parameters to the satellite during connected phases for aggregation and model updates. Consequently, EMS-FL effectively reduces the training overhead and achieves both faster convergence and higher accuracy compared with conventional federated learning. Rigorous convergence analysis is provided to theoretically characterize the learning performance. Furthermore, comprehensive experiments are conducted using public datasets and large models, validating the superiority of EMS-FL.

</details>


### [221] [Spritz: Path-Aware Load Balancing in Low-Diameter Networks](https://arxiv.org/abs/2602.19567)
*Tommaso Bonato,Ales Kubicek,Abdul Kabbani,Ahmad Ghalayini,Maciej Besta,Torsten Hoefler*

Main category: cs.NI

TL;DR: Spritz 是一种灵活的发送端负载均衡框架，利用标准以太网功能在低直径拓扑中实现高效路由和负载均衡，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有负载均衡技术要么依赖专有网络机制，要么未能充分利用低直径拓扑的路径多样性。

Method: 提出了两种算法：Spritz-Scout 和 Spritz-Spray，分别利用 ECN、数据包修剪和超时反馈来探索和缓存高效路径。

Result: 在 Dragonfly 和 Slim Fly 拓扑中，Spritz 在流完成时间上比 ECMP、UGAL-L 和其他发送端方法提升高达 1.8 倍，并在链路故障时提供高达 25.4 倍的性能改进。

Conclusion: Spritz 通过仅使用标准以太网功能，实现了高效的负载均衡和路由，为超以太网时代提供了统一的解决方案。

Abstract: Low-diameter topologies such as Dragonfly and Slim Fly are increasingly adopted in HPC and datacenter networks, yet existing load balancing techniques either rely on proprietary in-network mechanisms or fail to utilize the full path diversity of these topologies. We introduce Spritz, a flexible sender-based load balancing framework that shifts adaptive topology-aware routing to the endpoints using only standard Ethernet features. We propose two algorithms, Spritz-Scout and Spritz-Spray that, respectively, explore and adaptively cache efficient paths using ECN, packet trimming, and timeout feedback. Through simulation on Dragonfly and Slim Fly topologies with over 1000 endpoints, Spritz outperforms ECMP, UGAL-L, and prior sender-based approaches by up to 1.8x in flow completion time under AI training and datacenter workloads, while offering robust failover with performance improvements of up to 25.4x under link failures, all without additional hardware support. Spritz enables datacenter-scale, commodity Ethernet networks to efficiently leverage low-diameter topologies, offering unified routing and load balancing for the Ultra Ethernet era.

</details>


### [222] [Traffic-Aware Configuration of OPC UA PubSub in Industrial Automation Networks](https://arxiv.org/abs/2602.19603)
*Kasra Ekrad,Bjarne Johansson,Inés Alvarez Vadillo,Saad Mubeen,Mohammad Ashjaei*

Main category: cs.NI

TL;DR: 本文提出了一套工业流量类型映射到OPC UA PubSub配置的指南，解决了因配置不当导致的网络性能问题，并通过用例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 工业自动化系统中缺乏将多样化的工业流量类型映射到适当PubSub配置的明确指南，导致网络性能下降和实时性要求无法满足。

Method: 通过分析工业流量的时序和服务质量要求，提出了一套将工业流量类型映射到OPC UA PubSub配置的指南。

Result: 通过工业用例评估，展示了错误配置对延迟和吞吐量的影响，验证了流量感知的PubSub配置对实现互操作性的重要性。

Conclusion: 本文提出的工业流量类型映射指南能够显著提升OPC UA PubSub配置的准确性，从而确保工业网络的实时性能和互操作性。

Abstract: Interoperability across industrial automation systems is a cornerstone of Industry 4.0. To address this need, the OPC Unified Architecture (OPC UA) Publish-Subscribe (PubSub) model offers a promising mechanism for enabling efficient communication among heterogeneous devices. PubSub facilitates resource sharing and communication configuration between devices, but it lacks clear guidelines for mapping diverse industrial traffic types to appropriate PubSub configurations. This gap can lead to misconfigurations that degrade network performance and compromise real-time requirements. This paper proposes a set of guidelines for mapping industrial traffic types, based on their timing and quality-of-service specifications, to OPC UA PubSub configurations. The goal is to ensure predictable communication and support real-time performance in industrial networks. The proposed guidelines are evaluated through an industrial use case that demonstrates the impact of incorrect configuration on latency and throughput. The results underline the importance of traffic-aware PubSub configuration for achieving interoperability in Industry 4.0 systems.

</details>


### [223] [AI-Powered Conflict Management in Open RAN: Detection, Classification, and Mitigation](https://arxiv.org/abs/2602.19758)
*Abdul Wadud,Nima Afraz,Fatemeh Golpayegani*

Main category: cs.NI

TL;DR: 论文提出AI框架解决Open RAN中的冲突管理问题，实验证明其高效且准确。


<details>
  <summary>Details</summary>
Motivation: Open RAN中AI驱动的xApps和rApps的独立调整可能导致冲突，传统规则方法难以应对复杂性，因此需要AI驱动的实时冲突管理解决方案。

Method: 论文提出了GenC合成冲突生成框架，利用GNNs、Bi-LSTM和SMOTE增强的GNNs进行分类，并通过合成数据集和ns3-oran仿真进行实验验证。

Result: 实验显示，AI方法比规则方法快3.2倍，且保持近乎完美的准确性，成功解决了ES/MRO冲突场景。

Conclusion: 该论文提出的AI驱动框架成功解决了Open RAN中的冲突管理问题，为6G网络的弹性、超低延迟和能源效率奠定了基础。

Abstract: Open Radio Access Network (RAN) was designed with native Artificial Intelligence (AI) as a core pillar, enabling AI- driven xApps and rApps to dynamically optimize network performance. However, the independent ICP adjustments made by these applications can inadvertently create conflicts- direct, indirect, and implicit, which lead to network instability and KPI degradation. Traditional rule-based conflict management becomes increasingly impractical as Open RAN scales in terms of xApps, associated ICPs, and relevant KPIs, struggling to handle the complexity of multi-xApp interactions. This highlights the necessity for AI-driven solutions that can efficiently detect, classify, and mitigate conflicts in real-time. This paper proposes an AI-powered framework for conflict detection, classification, and mitigation in Open RAN. We introduce GenC, a synthetic conflict generation framework for large-scale labeled datasets with controlled parameter sharing and realistic class imbalance, enabling robust training and evaluation of AI models. Our classification pipeline leverages GNNs, Bi-LSTM, and SMOTE-enhanced GNNs, with results demonstrating SMOTE-GNN's superior robustness in handling imbalanced data. Experimental validation using both synthetic datasets (5-50 xApps) and realistic ns3-oran simulations with OpenCellID-derived Dublin topology shows that AI-based methods achieve 3.2x faster classification than rule-based approaches while maintaining near-perfect accuracy. Our framework successfully addresses Energy Saving (ES)/Mobility Robustness Optimization (MRO) conflict scenarios using realistic ns3-oran and scales efficiently to large-scale xApp environments. By embedding this workflow into Open RAN's AI-driven architecture, our solution ensures autonomous and self-optimizing conflict management, paving the way for resilient, ultra-low-latency, and energy-efficient 6G networks.

</details>


### [224] [BeamVLM for Low-altitude Economy: Generative Beam Prediction via Vision-language Models](https://arxiv.org/abs/2602.19929)
*Chenran Kou,Changsheng You,Mingjiang Wu,Dingzhu Wen,Zezhong Zhang,Chengwen Xing*

Main category: cs.NI

TL;DR: BeamVLM利用视觉语言模型（VLM）实现高精度波束预测，解决了现有方法泛化能力差和缺乏环境感知的问题，实验证明其优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法缺乏对动态环境的高级语义理解，泛化能力差；而基于大语言模型（LLM）的方法缺乏丰富的环境感知，无法捕捉精细的空间语义。

Method: 提出了一种名为BeamVLM的端到端生成框架，将波束预测视为视觉问答任务，利用现有的视觉语言模型（VLM），通过设计指令提示联合推理无人机轨迹和环境上下文。

Result: 在真实数据集上的实验表明，BeamVLM在预测精度上优于现有方法，并在其他场景（如车对基础设施V2I波束预测）中表现出优越的泛化能力。

Conclusion: BeamVLM框架通过结合视觉语言模型（VLM）在低空经济（LAE）中实现了高精度和泛化能力的波束预测，优于现有方法。

Abstract: For low-altitude economy (LAE), fast and accurate beam prediction between high-mobility unmanned aerial vehicles (UAVs) and ground base stations is of paramount importance, which ensures seamless coverage and reliable communications. However, existing deep learning-based beam prediction methods lack high-level semantic understanding of dynamic environments, resulting in poor generalization. On the other hand, the emerging large language model (LLM) based approaches show promise in enhancing generalization, but they typically lack rich environmental perception, thereby failing to capture fine-grained spatial semantics essential for precise beam alignment. To tackle these limitations, we propose in this correspondence a novel end-to-end generative framework for beam prediction, called BeamVLM, which treats beam prediction as a vision question answering task capitalizing on powerful existing vision-language models (VLMs). By projecting raw visual patches directly into the language domain and judiciously designing an instructional prompt, the proposed BeamVLM enables the VLM to jointly reason over UAV trajectories and environmental context. Last, experimental results on real-world datasets demonstrate that the proposed BeamVLM outperforms state-of-the-art methods in prediction accuracy and also exhibits superior generalization for other scenarios such as vehicle-to-infrastructure (V2I) beam prediction.

</details>


### [225] [Adaptive Underwater Acoustic Communications with Limited Feedback: An AoI-Aware Hierarchical Bandit Approach](https://arxiv.org/abs/2602.20105)
*Fabio Busacca,Andrea Panebianco,Yin Sun*

Main category: cs.NI

TL;DR: 双层MAB框架优化水下声学网络性能，吞吐量提升20.61%，节能36.60%。


<details>
  <summary>Details</summary>
Motivation: 水下声学网络因带宽有限、传播延迟高和信道动态性强，导致实时通信受限和系统性能下降，亟需高效解决方案。

Method: 采用双层MAB框架：内层为上下文延迟MAB（CD-MAB），联合优化自适应调制和传输功率；外层为反馈调度MAB，动态调整信道状态反馈间隔。

Result: 仿真结果显示，相比现有DRL基线，吞吐量提升20.61%，节能36.60%。

Conclusion: 本文提出的双层MAB框架在资源受限的水下声学网络中显著提升了吞吐量和能效，相比现有DRL基线方法，吞吐量提升达20.61%，节能达36.60%。

Abstract: Underwater Acoustic (UWA) networks are vital for remote sensing and ocean exploration but face inherent challenges such as limited bandwidth, long propagation delays, and highly dynamic channels. These constraints hinder real-time communication and degrade overall system performance. To address these challenges, this paper proposes a bilevel Multi-Armed Bandit (MAB) framework. At the fast inner level, a Contextual Delayed MAB (CD-MAB) jointly optimizes adaptive modulation and transmission power based on both channel state feedback and its Age of Information (AoI), thereby maximizing throughput. At the slower outer level, a Feedback Scheduling MAB dynamically adjusts the channel-state feedback interval according to throughput dynamics: stable throughput allows longer update intervals, while throughput drops trigger more frequent updates. This adaptive mechanism reduces feedback overhead and enhances responsiveness to varying network conditions. The proposed bilevel framework is computationally efficient and well-suited to resource-constrained UWA networks. Simulation results using the DESERT Underwater Network Simulator demonstrate throughput gains of up to 20.61% and energy savings of up to 36.60% compared with Deep Reinforcement Learning (DRL) baselines reported in the existing literature.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [226] [Exact Algorithms for Resource Reallocation Under Budgetary Constraints](https://arxiv.org/abs/2602.18438)
*Arun Kumar Das,Sandip Das,Sweta Das,Foivos Fioravantes,Nikolaos Melissinos*

Main category: cs.DS

TL;DR: 本文针对预算约束下的客户端重新分配问题，提出了三种高效的精确算法，适用于特定网络拓扑，具有实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 多党供应链网络中资源（重新）分配的高效性是优化生产力和可持续性的关键挑战。本文旨在解决服务提供商在预算约束下如何最小化客户端重新分配以减少所需服务器数量的问题。

Method: 通过系统性算法研究，提出了三种固定参数可处理（FPT）的精确算法，适用于具有特定拓扑结构的网络，如乡村道路网络、现代交通系统或具有有限团宽度的网络。

Result: 提出的算法在特定网络拓扑中表现高效，尤其是那些模拟乡村道路网络、现代交通系统或具有有限团宽度的网络。

Conclusion: 本文提出了三种精确算法，用于解决在预算约束下最小化客户端重新分配的问题，这些算法在处理特定拓扑结构时表现出色，具有实际应用潜力。

Abstract: Efficient resource (re-)allocation is a critical challenge in optimizing productivity and sustainability within multi-party supply networks. In this work, we introduce the \textsc{Red-Blue Reinforcement} (R-BR) problem, where a service provider under budgetary constraints must minimize client reallocations to reduce the required number of servers they should maintain by a specified amount. We conduct a systematic algorithmic study, providing three exact algorithms that scale well as the input grows (FPT), which could prove useful in practice. Our algorithms are efficient for topologies that model rural road networks (bounded distance to cluster), modern transportation systems (bounded modular-width), or have bounded clique-width, a parameter that is of great theoretical importance.

</details>


### [227] [Strengths and Limitations of Greedy in Cup Games](https://arxiv.org/abs/2602.18610)
*Kalina Jasińska,John Kuszmaul,Gyudong Lee*

Main category: cs.DS

TL;DR: 本文推翻了贪婪算法在竹子修剪问题中积压为2的猜想，证明其下界为2.076。提出新算法在多个设置中表现优异，并引入半遗忘杯游戏模型，分析了贪婪算法在不同模型中的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于验证贪婪算法在竹子修剪问题中的最优性猜想，并探索在不同杯游戏模型中算法的性能表现。同时，引入新的模型以扩展对杯游戏的理解。

Method: 本文通过理论分析和构造性证明，研究了贪婪算法在不同杯游戏模型中的性能。提出了混合贪婪/Deadline-Driven算法，并分析了其在多个设置中的表现。此外，引入了半遗忘杯游戏模型，并对其进行了详细的上下界分析。

Result: 本文证明了贪婪算法在竹子修剪问题中的下界为2.076，推翻了之前的猜想。新算法在通用杯游戏中实现了O(log n)的积压，并在竹子修剪问题和固定速率杯游戏中保持最优。在半遗忘杯游戏中，贪婪算法的积压为Θ(n^(c-1)/c)，并在加法误差设置中实现了Θ(log n)的积压。

Conclusion: 本文证明了贪婪算法在竹子修剪问题中的下界为2.076，推翻了之前的猜想。同时，提出了一种新的混合贪婪/Deadline-Driven算法，在通用杯游戏中实现了O(log n)的积压，并在竹子修剪问题和固定速率杯游戏中保持最优。此外，引入了一个新的半遗忘杯游戏模型，分析了贪婪算法在该模型中的表现，并证明了匹配的上界和下界。

Abstract: In the cup game, an adversary distributes 1 unit of water among $n$ cups every time step. The player then selects a single cup from which to remove 1 unit of water. In the bamboo trimming problem, the adversary must choose fixed rates for the cups, and the player is additionally allowed to empty the chosen cup entirely. Past work has shown that the optimal backlog in these two settings is $Θ(\log n)$ and 2 respectively.
  The greedy algorithm has been shown in previous work to be exactly optimal in the general cup game and asymptotically optimal in the bamboo setting. The greedy algorithm has been conjectured [16] to achieve the exactly optimal backlog of 2 in the bamboo setting as well. In this paper, we prove a lower bound of $2.076$ for the backlog of the greedy algorithm, disproving the conjecture of [16]. We also introduce a new algorithm, a hybrid greedy/Deadline-Driven, which achieves backlog $O(\log n)$ in the general cup game, and remains exactly optimal for the bamboo trimming problem and the fixed-rate cup game -- this constitutes the first algorithm that achieves asymptotically optimal performance across all three settings.
  Additionally, we introduce a new model, the semi-oblivious cup game, in which the player is uncertain of the exact heights of each cup. We analyze the performance of the greedy algorithm in this setting, which can be viewed as selecting an arbitrary cup within a constant multiplicative factor of the fullest cup. We prove matching upper and lower bounds showing that the greedy algorithm achieves a backlog of $Θ(n^{\frac{c-1}{c}})$ in the semi-oblivious cup game. We also establish matching upper and lower bounds of $2^{Θ(\sqrt{\log n})}$ in the semi-oblivious cup flushing game. Finally, we show that in an additive error setting, greedy is actually able to achieve backlog $Θ(\log n)$, via matching upper and lower bounds.

</details>


### [228] [Dynamic data structures for twin-ordered matrices](https://arxiv.org/abs/2602.18770)
*Bartłomiej Bosek,Jadwiga Czyżewska,Evangelos Kipouridis,Wojciech Nadara,Michał Pilipczuk,Karol Węgrzycki,Anna Zych-Pawlewicz*

Main category: cs.DS

TL;DR: 论文提出了一种动态数据结构，用于高效处理$d$-twin-ordered二元矩阵的查询和更新，内存使用优化且操作快速。


<details>
  <summary>Details</summary>
Motivation: 解决$d$-twin-ordered二元矩阵的高效查询和更新问题，以优化计算资源的使用。

Method: 采用动态数据结构设计，支持在$\Oh(\log \log n)$的预期最坏情况下进行单元格查询和单单元格更新。

Result: 实现了$\Oh_d(n)$的内存使用效率，同时保持查询和更新的高效性。

Conclusion: 该论文提出了一种动态数据结构，用于高效处理$d$-twin-ordered的二元矩阵查询和更新操作。

Abstract: We present a dynamic data structure for representing binary $n\times n$ matrices that are $d$-twin-ordered, for a~fixed parameter $d$. Our structure supports cell queries and single-cell updates both in $\Oh(\log \log n)$ expected worst case time, while using $\Oh_d(n)$ memory; here, the $\Oh_d(\cdot)$ notation

</details>


### [229] [EdgeSketch: Efficient Analysis of Massive Graph Streams](https://arxiv.org/abs/2602.18957)
*Jakub Lemiesz,Dingqi Yang,Philippe Cudré-Mauroux*

Main category: cs.DS

TL;DR: EdgeSketch是一种高效的紧凑图表示方法，适用于大规模图流分析，显著节省内存并提升运行效率。


<details>
  <summary>Details</summary>
Motivation: 为了高效分析大规模图流，需要一种紧凑的图表示方法，能够提供关键图属性的无偏估计，并支持可控方差。

Method: EdgeSketch是一种完全流式构建的紧凑图表示，仅需单次遍历边流，支持直接在存储的摘要上实现图算法。

Result: 实验表明，EdgeSketch在社区检测和图重建等应用中，实现了显著的内存节省和运行时改进。

Conclusion: EdgeSketch作为一种紧凑的图表示方法，在保持可靠准确性的同时，显著节省了内存并提高了运行效率，优于无损表示和先前的草图方法。

Abstract: We introduce EdgeSketch, a compact graph representation for efficient analysis of massive graph streams. EdgeSketch provides unbiased estimators for key graph properties with controllable variance and supports implementing graph algorithms on the stored summary directly. It is constructed in a fully streaming manner, requiring a single pass over the edge stream, while offline analysis relies solely on the sketch. We evaluate the proposed approach on two representative applications: community detection via the Louvain method and graph reconstruction through node similarity estimation. Experiments demonstrate substantial memory savings and runtime improvements over both lossless representations and prior sketching approaches, while maintaining reliable accuracy.

</details>


### [230] [One Color Makes All the Difference in the Tractability of Partial Coloring in Semi-Streaming](https://arxiv.org/abs/2602.18987)
*Avinandan Das*

Main category: cs.DS

TL;DR: 本文研究了k-部分着色的半流复杂度，发现k-部分(k+1)-着色可单次随机半流解决，而k-部分k-着色则不可，展示了流式模型中的“一色二分法”。


<details>
  <summary>Details</summary>
Motivation: 探讨经典着色问题（如(Δ+1)-proper着色和Δ-proper着色）的效率提升是否能扩展到其部分着色泛化问题。

Method: 本文研究了k-部分着色的半流复杂度，通过随机化半流算法分析了k-部分(k+1)-着色和k-部分k-着色的可解性。

Result: 发现k-部分(k+1)-着色允许单次随机半流算法，而k-部分k-着色则不具备半流可解性。

Conclusion: 本文揭示了k-部分着色问题在流式计算模型中的计算阈值：k-部分(k+1)-着色允许单次随机半流算法，而k-部分k-着色则不具备半流可解性，展示了流式模型中的“一色二分法”。

Abstract: This paper investigates the semi-streaming complexity of \textit{$k$-partial coloring}, a generalization of proper graph coloring. For $k \geq 1$, a $k$-partial coloring requires that each vertex $v$ in an $n$-node graph is assigned a color such that at least $\min\{k, °(v)\}$ of its neighbors are assigned colors different from its own. This framework naturally extends classical coloring problems: specifically, $k$-partial $(k+1)$-coloring and $k$-partial $k$-coloring generalize $(Δ+1)$-proper coloring and $Δ$-proper coloring, respectively.
  Prior works of Assadi, Chen, and Khanna [SODA~2019] and Assadi, Kumar, and Mittal [TheoretiCS~2023] show that both $(Δ+1)$-proper coloring and $Δ$-proper coloring admit one-pass randomized semi-streaming algorithms. We explore whether these efficiency gains extend to their partial coloring generalizations and reveal a sharp computational threshold : while $k$-partial $(k+1)$-coloring admits a one-pass randomized semi-streaming algorithm, the $k$-partial $k$-coloring remains semi-streaming intractable, effectively demonstrating a ``dichotomy of one color'' in the streaming model.

</details>


### [231] [An efficient recursive decomposition algorithm for undirected graphs](https://arxiv.org/abs/2602.19189)
*Pei Heng,Yi Sun,Jianhua Guo*

Main category: cs.DS

TL;DR: 论文提出基于MCS排序的递归算法，将无向图分解为原子，避免最小三角化和团最小分隔符识别，实验显示效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于简化复杂无向图问题的分解过程，通过原子分解和MCS排序的结合，避免传统方法中的最小三角化和团最小分隔符识别，从而提高效率。

Method: 论文提出了一种基于最大基数搜索（MCS）排序的递归算法，用于将无向图分解为其原子。该方法通过凸扩展和避免最小三角化及团最小分隔符的识别，简化了分解过程。

Result: 实验结果表明，所提出的分解算法与两种现有凸扩展方法结合后，在效率上显著优于现有算法。

Conclusion: 该论文证明了在最大基数搜索（MCS）排序中对节点1及其邻域应用凸扩展可以得到图的原子，并基于MCS排序提出了一种递归算法，用于将无向图分解为其原子。这种方法避免了最小三角化和识别团最小分隔符的需求，实验结果表明，所提出的分解算法与两种现有凸扩展方法结合后，在效率上显著优于现有算法。

Abstract: The decomposition of undirected graphs simplifies complex problems by breaking them into solvable subgraphs, following the philosophy of divide and conquer. This paper investigates the relationship between atom decomposition and the maximum cardinality search (MCS) ordering in general undirected graphs. Specifically, we prove that applying a convex extension to the node numbered $1$ and its neighborhood in an MCS ordering yields an atom in the graph. Furthermore, based on the MCS ordering, we introduce a recursive algorithm for decomposing an undirected graph into its atoms. This approach closely aligns with the results of chordal graph decomposition. As a result, minimal triangulation of the graph is no longer required, and the identification of clique minimal separators is avoided. In the experimental section, we combine the proposed decomposition algorithm with two existing convex expansion methods. The results show that both combinations significantly outperform the existing algorithms in terms of efficiency.

</details>


### [232] [On Identifying Critical Network Edges via Analyzing Changes in Shapes (Curvatures)](https://arxiv.org/abs/2602.19328)
*Bhaskar DasGupta,Katie Kruzan*

Main category: cs.DS

TL;DR: 本文提出一个形式化框架，研究基于Ollivier-Ricci曲率检测无向图中关键边的算法和计算复杂性，展示了与二分图完美匹配问题的联系。


<details>
  <summary>Details</summary>
Motivation: 近年来，流形Ricci曲率的离散扩展在多个研究领域有广泛应用，但算法和计算复杂性领域的研究相对较少。本文旨在推动跨学科互动，将网络Ricci曲率相关问题引入计算复杂性研究。

Method: 通过Ollivier-Ricci曲率构建了一个形式化框架，并提供了该框架下的算法和不可近似性结果。

Result: 提出了一个形式化框架，并展示了二分图中精确完美匹配与完美匹配阻塞问题之间的有趣联系。

Conclusion: 本文提出了一个形式化框架，用于研究基于Ollivier-Ricci曲率检测无向图中关键边的算法和计算复杂性，并展示了二分图中精确完美匹配与完美匹配阻塞问题之间的有趣联系。

Abstract: In recent years extensions of manifold Ricci curvature to discrete combinatorial objects such as graphs and hypergraphs (popularly called as "network shapes"), have found a plethora of applications in a wide spectrum of research areas ranging over metabolic systems, transcriptional regulatory networks, protein-protein-interaction networks, social networks and brain networks to deep learning models and quantum computing but, in contrast, they have been looked at by relatively fewer researchers in the algorithms and computational complexity community. As an attempt to bring these network Ricci-curvature related problems under the lens of computational complexity and foster further inter-disciplinary interactions, we provide a formal framework for studying algorithmic and computational complexity issues for detecting critical edges in an undirected graph using Ollivier-Ricci curvatures and provide several algorithmic and inapproximability results for problems in this framework. Our results show some interesting connections between the exact perfect matching and perfect matching blocker problems for bipartite graphs and our problems.

</details>


### [233] [Variations on the Problem of Identifying Spectrum-Preserving String Sets](https://arxiv.org/abs/2602.19408)
*Sankardeep Chakraborty,Roberto Grossi,Ren Kimura,Giulia Punzi,Kunihiko Sadakane,Wiktor Zuba*

Main category: cs.DS

TL;DR: 论文提出项链覆盖方法，通过贪婪算法优化k-mer存储，实验显示其压缩效果优于Eulertigs，与Masked Superstrings相当。


<details>
  <summary>Details</summary>
Motivation: 计算基因组学中，许多分析依赖于k-mer的高效存储和遍历，现有方法（如Unitigs、Eulertigs和Matchtigs）将其建模为deBruijn图上的路径覆盖问题，但缺乏对分支结构的考虑。

Method: 提出了一种贪婪算法，用于构建项链覆盖（结合环和树状附件），并在特定条件下保证最终表示的累积大小最优。

Result: 在真实基因组数据集上的实验表明，最小项链覆盖的表示大小优于Eulertigs，且与Masked Superstrings方法压缩效果相当。

Conclusion: 最小项链覆盖在保持k-mer谱精确性的同时，相比Eulertigs实现了更小的表示，并与Masked Superstrings方法的压缩效果相当。

Abstract: In computational genomics, many analyses rely on efficient storage and traversal of $k$-mers, motivating compact representations such as spectrum-preserving string sets (SPSS), which store strings whose $k$-mer spectrum matches that of the input. Existing approaches, including Unitigs, Eulertigs and Matchtigs, model this task as a path cover problem on the deBruijn graph. We extend this framework from paths to branching structures by introducing necklace covers, which combine cycles and tree-like attachments (pendants). We present a greedy algorithm that constructs a necklace cover while guaranteeing, under certain conditions, optimality in the cumulative size of the final representation.
  Experiments on real genomic datasets indicate that the minimum necklace cover achieves smaller representations than Eulertigs and comparable compression to the Masked Superstrings approach, while maintaining exactness of the $k$-mer spectrum.

</details>


### [234] [Covering a Polyomino-Shaped Stain with Non-Overlapping Identical Stickers](https://arxiv.org/abs/2602.19525)
*Keigo Oka,Naoki Inaba,Akira Iino*

Main category: cs.DS

TL;DR: 本文分类了polyomino约束下可被单一形状贴纸非重叠覆盖的污渍形状，证明了覆盖问题的NP完全性，并展示了复杂实例。


<details>
  <summary>Details</summary>
Motivation: 探讨在单一形状贴纸（允许旋转和反射）非重叠覆盖污渍时，是否存在无法覆盖的污渍形状，特别是在polyomino约束下。

Method: 通过构造具体反例和证明最大可覆盖polyomino，完成分类。同时，针对特定hexomino污渍，搜索最小贴纸尺寸以避免覆盖。

Result: 分类了always-coverable polyominoes，证明了判断覆盖问题的NP完全性，并通过具体例子展示了问题的复杂性。

Conclusion: 本文完成了在polyomino约束下对‘always-coverable’污渍形状的分类，并提供了最大可覆盖polyomino的证明及最小不可覆盖polyomino的反例。此外，还提出了一个算法用于判断任意给定污渍的可覆盖性，并证明了判断给定贴纸是否能覆盖给定污渍的问题是NP完全的。

Abstract: You find a stain on the wall and decide to cover it with non-overlapping stickers of a single identical shape (rotation and reflection are allowed). Is it possible to find a sticker shape that fails to cover the stain? In this paper, we consider this problem under polyomino constraints and complete the classification of always-coverable stain shapes (polyominoes). We provide proofs for the maximal always-coverable polyominoes and construct concrete counterexamples for the minimal not always-coverable ones, demonstrating that such cases exist even among hole-free polyominoes. This classification consequently yields an algorithm to determine the always-coverability of any given stain. We also show that the problem of determining whether a given sticker can cover a given stain is $\NP$-complete, even though exact cover is not demanded. This result extends to the 1D case where the connectivity requirement is removed. As an illustration of the problem complexity, for a specific hexomino (6-cell) stain, the smallest sticker found in our search that avoids covering it has, although not proven minimum, a bounding box of $325 \times 325$.

</details>


### [235] [Minimizing Total Travel Time for Collaborative Package Delivery with Heterogeneous Drones](https://arxiv.org/abs/2602.19535)
*Thomas Erlebach,Kelin Luo,Wen Zhang*

Main category: cs.DS

TL;DR: 本文提出了一种近似算法，用于计算无人机协作配送的最佳非抢占式调度，实验证明其高效且可扩展。


<details>
  <summary>Details</summary>
Motivation: 研究无人机协作配送问题，旨在最小化所有无人机的总旅行时间，探讨非抢占式调度与抢占式调度的性能差距。

Method: 算法将问题简化为树组合问题，并使用原始-对偶方法求解。针对实际效率优化的版本在合成和真实数据的大规模实例上进行了实验。

Result: 实验结果表明，优化后的算法在大规模实例上具有可扩展性，并能生成高质量的调度方案。

Conclusion: 本文通过将问题简化为树组合问题并采用原始-对偶方法求解，提出了一种计算最佳非抢占式调度的常数因子近似算法。实验证明该算法具有可扩展性且能生成高质量调度方案。

Abstract: Given a fleet of drones with different speeds and a set of package delivery requests, the collaborative delivery problem asks for a schedule for the drones to collaboratively carry out all package deliveries, with the objective of minimizing the total travel time of all drones. We show that the best non-preemptive schedule (where a package that is picked up at its source is immediately delivered to its destination by one drone) is within a factor of three of the best preemptive schedule (where several drones can participate in the delivery of a single package). Then, we present a constant-factor approximation algorithm for the problem of computing the best non-preemptive schedule. The algorithm reduces the problem to a tree combination problem and uses a primal-dual approach to solve the latter. We have implemented a version of the algorithm optimized for practical efficiency and report the results of experiments on large-scale instances with synthetic and real-world data, demonstrating that our algorithm is scalable and delivers schedules of excellent quality.

</details>


### [236] [Analyzing and Leveraging the $k$-Sensitivity of LZ77](https://arxiv.org/abs/2602.19649)
*Gabriel Bathie,Paul Huber,Guillaume Lagarde,Akka Zemmari*

Main category: cs.DS

TL;DR: 论文研究了LZ77压缩算法对编辑操作的敏感性，证明了k次编辑下的压缩上界，并提出了基于可压缩性的三分法。最后，设计了一种优化压缩效果的ε-近似算法。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对Lempel-Ziv压缩算法对编辑操作敏感性的探索。特别是，LZ78的“单比特灾难”现象表明，单次编辑可能显著降低压缩效果。因此，研究LZ77在编辑操作下的表现，有助于理解其鲁棒性，并为实际应用中的压缩优化提供理论支持。

Method: 研究采用理论分析和算法设计相结合的方法。首先，通过理论推导确定了LZ77在k次编辑下的压缩效果上界。然后，根据字符串的可压缩性提出了三分法，并证明了不同条件下的压缩上界。最后，设计了一种ε-近似算法，用于优化压缩效果。

Result: 研究结果表明，LZ77在k次编辑下的压缩效果上界为3倍原始压缩大小加4k。此外，根据字符串的可压缩性，压缩效果的上界可分为三种情况：压缩大小最多增加约3倍、2倍或1倍。最后，提出的ε-近似算法在某些情况下可将总压缩大小减少至多3倍。

Conclusion: 论文通过研究Lempel-Ziv 77（LZ77）压缩算法对编辑操作的敏感性，揭示了编辑字符串对压缩效果的影响。研究发现，LZ77在面对k次编辑时，压缩效果的上界为3倍原始压缩大小加4k，这与LZ78的“单比特灾难”形成鲜明对比。此外，研究还根据字符串的可压缩性提出了三分法，并展示了在不同条件下压缩效果的上界。最后，论文提出了一种ε-近似算法，用于在给定编辑预算的情况下优化压缩效果。

Abstract: We study the sensitivity of the Lempel-Ziv 77 compression algorithm to edits, showing how modifying a string $w$ can deteriorate or improve its compression. Our first result is a tight upper bound for $k$ edits: $\forall w' \in B(w,k)$, we have $C_{\mathrm{LZ77}}(w') \leq 3 \cdot C_{\mathrm{LZ77}}(w) + 4k$. This result contrasts with Lempel-Ziv 78, where a single edit can significantly deteriorate compressibility, a phenomenon known as a *one-bit catastrophe*.
  We further refine this bound, focusing on the coefficient $3$ in front of $C_{\mathrm{LZ77}}(w)$, and establish a surprising trichotomy based on the compressibility of $w$. More precisely we prove the following bounds:
  - if $C_{\mathrm{LZ77}}(w) \lesssim k^{3/2}\sqrt{n}$, the compression may increase by up to a factor of $\approx 3$,
  - if $k^{3/2}\sqrt{n} \lesssim C_{\mathrm{LZ77}}(w) \lesssim k^{1/3}n^{2/3}$, this factor is at most $\approx 2$,
  - if $C_{\mathrm{LZ77}}(w) \gtrsim k^{1/3}n^{2/3}$, the factor is at most $\approx 1$.
  Finally, we present an $\varepsilon$-approximation algorithm to pre-edit a word $w$ with a budget of $k$ modifications to improve its compression. In favorable scenarios, this approach yields a total compressed size reduction by up to a factor of~$3$, accounting for both the LZ77 compression of the modified word and the cost of storing the edits, $C_{\mathrm{LZ77}}(w') + k \log |w|$.

</details>


### [237] [Exploration of Always $S$-Connected Temporal Graphs](https://arxiv.org/abs/2602.19657)
*Duncan Adamson,Paul G Spirakis*

Main category: cs.DS

TL;DR: 本文研究了时间图的探索问题，提出了在特定条件下高效探索的方法，并改进了现有结果。


<details>
  <summary>Details</summary>
Motivation: 研究时间图的探索问题，特别是在代理数量有限的情况下，如何高效地探索图的顶点。

Method: 通过引入并研究总是S-连通的时间图，利用(r,b)-分割的概念，将顶点集分割为多个S-连通的组件。

Result: 证明了在总是S-连通的时间图中，m个代理可以在O(n^1.5 m^3 Δ^1.5 log^1.5(n))快照内完成探索；对于树宽不超过k的总是连通时间图，单个代理可在O(n^4/3 k^5.5 log^2.5(n))快照内完成探索。

Conclusion: 本文展示了在特定条件下，使用多个代理或单个代理可以有效探索时间图，并提供了具体的性能界限。

Abstract: \emph{Temporal graphs} are a generalisation of (static) graphs, defined by a sequence of \emph{snapshots}, each a static graph defined over a common set of vertices. \emph{Exploration} problems are one of the most fundamental and most heavily studied problems on temporal graphs, asking if a set of $m$ agents can visit every vertex in the graph, with each agent only allowed to traverse a single edge per snapshot. In this paper, we introduce and study \emph{always $S$-connected} temporal graphs, a generalisation of always connected temporal graphs where, rather than forming a single connected component in each snapshot, we have at most $\vert S \vert$ components, each defined by the connection to a single vertex in the set $S$. We use this formulation as a tool for exploring graphs admitting an \emph{$(r,b)$-division}, a partitioning of the vertex set into disconnected components, each of which is $S$-connected, where $\vert S \vert \leq b$.
  We show that an always $S$-connected temporal graph with $m = \vert S \vert$ and an average degree of $Δ$ can be explored by $m$ agents in $O(n^{1.5} m^3 Δ^{1.5}\log^{1.5}(n))$ snapshots. Using this as a subroutine, we show that any always-connected temporal graph with treewidth at most $k$ can be explored by a single agent in $O\left(n^{4/3} k^{5.5}\log^{2.5}(n)\right)$ snapshots, improving on the current state-of-the-art for small values of $k$. Further, we show that interval graph with only a small number of large cliques can be explored by a single agent in $O\left(n^{4/3} \log^{2.5}(n)\right)$ snapshots.

</details>


### [238] [Servicing Matched Client Pairs with Facilities](https://arxiv.org/abs/2602.19680)
*Fateme Abbasi,Martin Böhm,Jarosław Byrka,Matin Mohammadi,Yongho Shin*

Main category: cs.DS

TL;DR: 本文研究设施位置与匹配问题，提出基于LP松弛的3.868-近似算法，特殊情况下提升至2.218，适用于匹配服务场景。


<details>
  <summary>Details</summary>
Motivation: 该问题源于视频游戏或社交应用中的匹配服务需求，结合了无容量设施位置和最小成本最大匹配两个经典组合优化问题，并推广了Kim等人研究的偶数约束设施位置问题。

Method: 通过线性规划（LP）松弛和双因子近似算法（Byrka和Aardal，2012）的结合，设计了一个重新路由子程序，将分数解重新路由到固定的最大匹配上，以较小的额外成本实现近似解。

Result: 提出的3.868-近似算法在一般情况下有效，特殊情况下（所有客户均匹配）近似比提升至2.218。

Conclusion: 本文提出了设施位置与匹配问题的线性规划松弛解法，并开发了3.868-近似算法。对于所有客户均匹配的特殊情况，算法近似比提升至2.218。这些结果也为线性规划松弛的完整性间隙提供了上限。

Abstract: We study Facility Location with Matching, a Facility Location problem where, given additional information about which pair of clients is compatible to be matched, we need to match as many clients as possible and assign each matched client pair to a same open facility at minimum total cost. The problem is motivated by match-making services relevant in, for example, video games or social apps. It naturally generalizes two prominent combinatorial optimization problems -- Uncapacitated Facility Location and Minimum-cost Maximum Matching. Facility Location with Matching also generalizes the Even-constrained Facility Location problem studied by Kim, Shin, and An (Algorithmica 2023).
  We propose a linear programming (LP) relaxation for this problem, and present a 3.868-approximation algorithm. Our algorithm leverages the work on bifactor-approximation algorithms (Byrka and Aardal, SICOMP 2012); our main technical contribution is a rerouting subroutine that reroutes a fractional solution to be supported on a fixed maximum matching with only small additional cost. For a special case where all clients are matched, we provide a refined algorithm achieving an approximation ratio of 2.218. As our algorithms are based on rounding an optimal solution to the LP relaxation, these approximation results also give the same upper bounds on the integrality gap of the relaxation.

</details>


### [239] [Placing Green Bridges Optimally for Robust Habitat Reconnection](https://arxiv.org/abs/2602.19834)
*Gero Ellmies,Till Fluschnik*

Main category: cs.DS

TL;DR: 本文研究了在预算限制下通过绿色桥梁重新连接栖息地的问题，证明了在特定条件下的NP难解性，并提出了多项式时间算法。


<details>
  <summary>Details</summary>
Motivation: 栖息地因人类活动而碎片化，导致生物多样性下降。通过绿色桥梁重新连接栖息地可以缓解这一问题，但如何在预算限制下高效实现这一目标是一个关键问题。

Method: 本文使用图论方法，将栖息地重新连接问题建模为无向图中的2-顶点连通性和2-边连通性问题。通过分析最大栖息地大小和最大顶点度数为常数时的计算复杂性，证明了在特定条件下的NP难解性，并提出了多项式时间算法。

Result: 研究证明，当最大栖息地大小至少为四且顶点度数有界时，问题为NP难解。同时，提出了在栖息地大小和度数有界时的多项式时间算法，部分解决了这一边界问题。

Conclusion: 本文研究了在预算限制下，通过放置绿色桥梁以最小总成本重新连接栖息地的问题。通过分析计算复杂性，确定了在栖息地大小和顶点度数有界时的NP难解性和多项式时间可解性的边界。

Abstract: We study the problem of robustly reconnecting habitats via the placement of green bridges at minimum total cost. Habitats are fragmented into patches and we seek to reconnect each habitat such that it remains connected even if any of its patches becomes unavailable. Formally, we are given an undirected graph with edge costs, a set of fixed green bridges represented as a subset of the graph's edges, a set of habitats represented as vertex subsets, and some budget. We decide whether there exists a subset of the graph's edges containing all fixed green bridges such that, for each habitat, the induced subgraph on the solution edges is 2-vertex-connected, and the total cost does not exceed the budget. We also study the 2-edge-connectivity variant, modeling the case where any single reconnecting green bridge may fail. We analyze the computational complexity of these problems, focusing on the boundary between NP-hardness and polynomial-time solvability when the maximum habitat size and maximum vertex degree are bounded by constants. We prove that for each constant maximum habitat size of at least four there exists a small constant maximum degree for which the problems are NP-hard, and complement this with polynomial-time algorithms yielding partial dichotomies for bounded habitat size and degree.

</details>


### [240] [The Bidirected Cut Relaxation for Steiner Tree: Better Integrality Gap Bounds and the Limits of Moat Growing](https://arxiv.org/abs/2602.19879)
*Paul Paschmanns,Vera Traub*

Main category: cs.DS

TL;DR: 本文显著改进了BCR整数性间隙的上界至1.898，特定情况下为12/7，并扩展了对偶增长算法类别。


<details>
  <summary>Details</summary>
Motivation: 解决Steiner树问题中Bidirected Cut Relaxation（BCR）整数性间隙的长期开放性问题，改进现有界限。

Method: 通过将Byrka等人的对偶增长过程推广到更广泛的moat-growing算法类别，并分析这些算法的性能。

Result: 证明了BCR的整数性间隙最多为1.898，并在特定情况下为12/7。同时发现与Hypergraphic Relaxation的联系。

Conclusion: 本文证明了BCR的整数性间隙最多为1.898，显著改进了之前的1.9988界限。在终端最小生成树是最优Steiner树的重要特例中，整数性间隙最多为12/7。此外，研究还发现与超图松弛的有趣联系。

Abstract: The Steiner Tree problem asks for the cheapest way of connecting a given subset of the vertices in an undirected graph. One of the most prominent linear programming relaxations for Steiner Tree is the Bidirected Cut Relaxation (BCR). Determining the integrality gap of this relaxation is a long-standing open question. For several decades, the best known upper bound was 2, which is achievable by standard techniques. Only very recently, Byrka, Grandoni, and Traub [FOCS 2024] showed that the integrality gap of BCR is strictly below 2.
  We prove that the integrality gap of BCR is at most 1.898, improving significantly on the previous bound of 1.9988. For the important special case where a terminal minimum spanning tree is an optimal Steiner tree, we show that the integrality gap is at most 12/7, by providing a tight analysis of the dual-growth procedure by Byrka et al. To obtain the general bound of 1.898 on the integrality gap, we generalize their dual growth procedure to a broad class of moat-growing algorithms. Moreover, we prove that no such moat-growing algorithm yields dual solutions certifying an integrality gap below 12/7.
  Finally, we observe an interesting connection to the Hypergraphic Relaxation.

</details>


### [241] [Fast and simple multiplication of bounded twin-width matrices](https://arxiv.org/abs/2602.20023)
*László Kozma,Michal Opler*

Main category: cs.DS

TL;DR: 该论文提出了一种预处理方法，使得具有有限twin-width的二进制矩阵能高效计算矩阵-向量乘法，无需特定顺序或已知twin-width，算法更简单快速。


<details>
  <summary>Details</summary>
Motivation: 解决在不知道twin-width或特定行列顺序的情况下，高效计算矩阵-向量乘法的开放性问题。

Method: 通过预处理技术，使得矩阵-向量乘法的时间复杂度降低，无需预先知道twin-width或特定的行列顺序。若存在规范顺序，预处理和乘法时间可进一步优化。

Result: 实现了矩阵-向量乘法在预处理后的高效计算，并扩展到矩阵乘法和对抗性损坏的情况，算法比先前方法更快且更简单。

Conclusion: 该论文展示了如何预处理具有有限twin-width的二进制矩阵，以实现高效的矩阵-向量乘法，并进一步扩展到矩阵乘法和对抗性损坏的情况。

Abstract: Matrix multiplication is a fundamental task in almost all computational fields, including machine learning and optimization, computer graphics, signal processing, and graph algorithms (static and dynamic). Twin-width is a natural complexity measure of matrices (and more general structures) that has recently emerged as a unifying concept with important algorithmic applications. While the twin-width of a matrix is invariant to re-ordering rows and columns, most of its algorithmic applications to date assume that the input is given in a certain canonical ordering that yields a bounded twin-width contraction sequence. In general, efficiently finding such a sequence -- even for an approximate twin-width value -- remains a central and elusive open question.
  In this paper we show that a binary $n \times n$ matrix of twin-width $d$ can be preprocessed in $\widetilde{\mathcal{O}}_d(n^2)$ time, so that its product with any vector can be computed in $\widetilde{\mathcal{O}}_d(n)$ time. Notably, the twin-width of the input matrix need not be known and no particular ordering of its rows and columns is assumed. If a canonical ordering is available, i.e., if the input matrix is $d$-twin-ordered, then the runtime of preprocessing and matrix-vector products can be further reduced to $\mathcal{O}(n^2+dn)$ and $\mathcal{O}(dn)$.
  Consequently, we can multiply two $n \times n$ matrices in $\widetilde{\mathcal{O}}(n^2)$ time, when at least one of the matrices consists of 0/1 entries and has bounded twin-width. The results also extend to the case of bounded twin-width matrices with adversarial corruption. Our algorithms are significantly faster and simpler than earlier methods that involved first-order model checking and required both input matrices to be $d$-twin-ordered.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [242] [Design and Biomechanical Evaluation of a Lightweight Low-Complexity Soft Bilateral Ankle Exoskeleton](https://arxiv.org/abs/2602.18569)
*Josée Mallah,Zakii Javed,Zafer Azak,Thomas Stone,Luigi G. Occhipinti*

Main category: cs.RO

TL;DR: 开发了一种轻量、低复杂度的软性踝关节外骨骼，实验证明其不干扰步态，舒适且有望提供有效辅助。控制系统已开发，更多测试进行中。


<details>
  <summary>Details</summary>
Motivation: 外骨骼辅助步态在医疗和非医疗领域有广泛应用潜力，但传统外骨骼因质量和结构问题需要补偿。本研究旨在开发一种轻量、低复杂度的解决方案，减少对步态的干扰。

Method: 研究设计了一种轻量、低复杂度的软性双侧踝关节外骨骼，采用鞋附件设计，可适配任何鞋子。通过实验测试，比较了穿戴外骨骼（零扭矩模式）与不穿戴时的下肢运动学和动力学差异。

Result: 实验结果显示，穿戴外骨骼（零扭矩模式）与不穿戴时，下肢运动学和动力学无显著差异，表明该设备不会阻碍健康步态，且具有顺应性和舒适性。

Conclusion: 该研究开发了一种轻量、低复杂度的软性双侧踝关节外骨骼，用于跖屈辅助，其鞋附件设计可适配任何鞋子。实验表明，该设备不会阻碍健康步态，具有顺应性和舒适性，有望提供有效辅助。目前控制系统已开发，正在进行更多测试。

Abstract: Many people could benefit from exoskeleton assistance during gait, for either medical or nonmedical purposes. But exoskeletons bring added mass and structure, which in turn require compensating for. In this work, we present a lightweight, low-complexity, soft bilateral ankle exoskeleton for plantarflexion assistance, with a shoe attachment design that can be mounted on top of any pair of shoes. Experimental tests show no significant difference in lower limb kinematics and kinetics when wearing the exoskeleton in zero-torque mode relative to not wearing an exoskeleton, showing that our device does not obstruct healthy gait, and proving it as a compliant and comfortable device, promising to provide effective assistance. Hence, a control system was developed, and additional tests are underway.

</details>


### [243] [Enhancing Goal Inference via Correction Timing](https://arxiv.org/abs/2602.18603)
*Anjiabei Wang,Shuangge Wang,Tesca Fitzgerald*

Main category: cs.RO

TL;DR: 研究发现纠正时机是机器人学习的重要信号，尤其在识别纠正触发因素和快速推断纠正目标方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将纠正视为新的演示或偏好，但忽略了人类决定干预机器人行为的时机这一关键因素。本研究旨在探索纠正时机是否能作为推断任务相关影响的信号。

Method: 通过分析人类纠正行为的时机和初始方向，研究了三种潜在应用：识别可能引发纠正的机器人动作特征、快速推断纠正的最终目标以及学习更精确的任务约束。

Result: 结果表明，纠正时机在前两种应用中显著提升了学习效果。

Conclusion: 该研究揭示了纠正时机作为机器人学习信号的价值，特别是在识别引发人类纠正的机器人动作特征、快速推断纠正目标以及学习更精确的任务约束方面。

Abstract: Corrections offer a natural modality for people to provide feedback to a robot, by (i) intervening in the robot's behavior when they believe the robot is failing (or will fail) the task objectives and (ii) modifying the robot's behavior to successfully fulfill the task. Each correction offers information on what the robot should and should not do, where the corrected behavior is more aligned with task objectives than the original behavior. Most prior work on learning from corrections involves interpreting a correction as a new demonstration (consisting of the modified robot behavior), or a preference (for the modified trajectory compared to the robot's original behavior). However, this overlooks one essential element of the correction feedback, which is the human's decision to intervene in the robot's behavior in the first place. This decision can be influenced by multiple factors including the robot's task progress, alignment with human expectations, dynamics, motion legibility, and optimality. In this work, we investigate whether the timing of this decision can offer a useful signal for inferring these task-relevant influences. In particular, we investigate three potential applications for this learning signal: (1) identifying features of a robot's motion that may prompt people to correct it, (2) quickly inferring the final goal of a human's correction based on the timing and initial direction of their correction motion, and (3) learning more precise constraints for task objectives. Our results indicate that correction timing results in improved learning for the first two of these applications. Overall, our work provides new insights on the value of correction timing as a signal for robot learning.

</details>


### [244] [OVerSeeC: Open-Vocabulary Costmap Generation from Satellite Images and Natural Language](https://arxiv.org/abs/2602.18606)
*Rwik Rana,Jesse Quattrociocchi,Dongmyeong Lee,Christian Ellis,Amanda Adkins,Adam Uccello,Garrett Warnell,Joydeep Biswas*

Main category: cs.RO

TL;DR: OVerSeeC是一个零样本模块化框架，通过分解任务为语言解释、实体定位和成本合成，实现了基于卫星图像和自然语言提示的全局成本图生成，适用于多样化的任务需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于固定本体和静态成本映射，无法适应任务需求的多样性和用户提示中的组合遍历逻辑。基础模型在语言解释和开放词汇感知方面表现出色，但没有单一模型能同时解析复杂的任务指令、定位大规模图像中的任意实体并将其合成为规划器可执行的成本函数。

Method: OVerSeeC框架将问题分解为Interpret-Locate-Synthesize三个步骤：(i) 使用LLM提取实体和排名偏好，(ii) 通过开放词汇分割流程从高分辨率图像中识别这些实体，(iii) 利用用户的自然语言偏好和掩码生成可执行的成本图代码。

Result: 实证研究表明，OVerSeeC能够处理新实体、尊重排名和组合偏好，并在不同区域生成与人类绘制轨迹一致的路由，表现出对分布变化的鲁棒性。

Conclusion: OVerSeeC通过模块化组合基础模型，实现了开放词汇、偏好对齐的成本图生成，为可扩展、任务自适应的全局规划提供了解决方案。

Abstract: Aerial imagery provides essential global context for autonomous navigation, enabling route planning at scales inaccessible to onboard sensing. We address the problem of generating global costmaps for long-range planning directly from satellite imagery when entities and mission-specific traversal rules are expressed in natural language at test time. This setting is challenging since mission requirements vary, terrain entities may be unknown at deployment, and user prompts often encode compositional traversal logic. Existing approaches relying on fixed ontologies and static cost mappings cannot accommodate such flexibility. While foundation models excel at language interpretation and open-vocabulary perception, no single model can simultaneously parse nuanced mission directives, locate arbitrary entities in large-scale imagery, and synthesize them into an executable cost function for planners. We therefore propose OVerSeeC, a zero-shot modular framework that decomposes the problem into Interpret-Locate-Synthesize: (i) an LLM extracts entities and ranked preferences, (ii) an open-vocabulary segmentation pipeline identifies these entities from high-resolution imagery, and (iii) the LLM uses the user's natural language preferences and masks to synthesize executable costmap code. Empirically, OVerSeeC handles novel entities, respects ranked and compositional preferences, and produces routes consistent with human-drawn trajectories across diverse regions, demonstrating robustness to distribution shifts. This shows that modular composition of foundation models enables open-vocabulary, preference-aligned costmap generation for scalable, mission-adaptive global planning.

</details>


### [245] [FORMICA: Decision-Focused Learning for Communication-Free Multi-Robot Task Allocation](https://arxiv.org/abs/2602.18622)
*Antonio Lopez,Jack Muirhead,Carlo Pinciroli*

Main category: cs.RO

TL;DR: FORMICA 是一种无需通信的学习框架，通过预测投标分布优化任务分配，显著提升性能并快速适应新环境。


<details>
  <summary>Details</summary>
Motivation: 解决在通信受限或对抗性干扰环境下，现有多机器人任务分配方法性能急剧下降的问题。

Method: 采用基于学习的方法，通过预测队友的投标分布来隐式协调，并利用均值场近似将复杂度从O(NT)降低到O(T)。

Result: 在16机器人和64任务的场景中，系统奖励提升17%；在256机器人和4096任务的更大场景中，性能提升7%。

Conclusion: FORMICA 框架在无机器人间通信的情况下实现了高质量的任务分配，显著优于传统方法，并能快速适应新环境。

Abstract: Most multi-robot task allocation methods rely on communication to resolve conflicts and reach consistent assignments. In environments with limited bandwidth, degraded infrastructure, or adversarial interference, existing approaches degrade sharply. We introduce a learning-based framework that achieves high-quality task allocation without any robot-to-robot communication. The key idea is that robots coordinate implicitly by predicting teammates' bids: if each robot can anticipate competition for a task, it can adjust its choices accordingly. Our method predicts bid distributions to correct systematic errors in analytical mean-field approximations. While analytical predictions assume idealized conditions (uniform distributions, known bid functions), our learned approach adapts to task clustering and spatial heterogeneity. Inspired by Smart Predict-then-Optimize (SPO), we train predictors end-to-end to minimize Task Allocation Regret rather than prediction error. To scale to large swarms, we develop a mean-field approximation where each robot predicts the distribution of competing bids rather than individual bids, reducing complexity from $O(NT)$ to $O(T)$. We call our approach FORMICA: Field-Oriented Regret-Minimizing Implicit Coordination Algorithm. Experiments show FORMICA substantially outperforms a natural analytical baseline. In scenarios with 16 robots and 64 tasks, our approach improves system reward by 17% and approaches the optimal MILP solution. When deployed on larger scenarios (256 robots, 4096 tasks), the same model improves performance by 7%, demonstrating strong generalization. Training requires only 21 seconds on a laptop, enabling rapid adaptation to new environments.

</details>


### [246] [Soft Surfaced Vision-Based Tactile Sensing for Bipedal Robot Applications](https://arxiv.org/abs/2602.18638)
*Jaeeun Kim,Junhee Lim,Yu She*

Main category: cs.RO

TL;DR: 开发了一种软表面触觉足部传感器，通过光学捕捉足部与地面的交互，显著提升了机器人的平衡和地形感知能力。


<details>
  <summary>Details</summary>
Motivation: 腿式运动受益于具身感知，其中感知源于身体与环境的物理交互。通过开发一种新型触觉足部传感器，旨在提升机器人的平衡控制和地形感知能力。

Method: 我们提出了一种基于视觉的软表面触觉足部传感器，通过光学捕捉足部与地面的接触变形，将交互转化为丰富的触觉信号。该方法从接触图像流中估计接触姿态（位置和方向）、可视化剪切力、计算压力中心（CoP）、分类地形并检测接触块的几何特征。

Result: 在倾斜平台和视觉受限条件下的验证表明，足部触觉反馈显著提升了平衡控制和地形感知能力，超越了仅依赖本体感知的效果。

Conclusion: 将触觉感知集成到腿式机器人脚部可以提升稳定性、适应性和环境感知能力，为更柔顺和智能的运动系统提供了有前景的方向。

Abstract: Legged locomotion benefits from embodied sensing, where perception emerges from the physical interaction between body and environment. We present a soft-surfaced, vision-based tactile foot sensor that endows a bipedal robot with a skin-like deformable layer that captures contact deformations optically, turning foot-ground interactions into rich haptic signals. From a contact image stream, our method estimates contact pose (position and orientation), visualizes shear, computes center of pressure (CoP), classifies terrain, and detects geometric features of the contact patch. We validate these capabilities on a tilting platform and in visually obscured conditions, showing that foot-borne tactile feedback improves balance control and terrain awareness beyond proprioception alone. These findings suggest that integrating tactile perception into legged robot feet improves stability, adaptability, and environmental awareness, offering a promising direction toward more compliant and intelligent locomotion systems. For the supplementary video, please visit: https://youtu.be/ceJiy9q_2Aw

</details>


### [247] [Infinite-Dimensional Closed-Loop Inverse Kinematics for Soft Robots via Neural Operators](https://arxiv.org/abs/2602.18655)
*Carina Veil,Moritz Flaschel,Ellen Kuhl,Cosimo Della Santina*

Main category: cs.RO

TL;DR: 该论文提出了一种无限维闭环逆运动学（CLIK）方法，利用神经算子网络学习驱动到形状的映射，实现了软机器人的微分控制。


<details>
  <summary>Details</summary>
Motivation: 解决欠驱动软机器人因无限自由度而难以进行运动学逆解的问题。

Method: 通过组合驱动到形状的映射与形状到任务的映射，利用无限维链式法则推导微分端到端运动学，从而获得基于雅可比矩阵的CLIK算法。

Result: 在恒定曲率段进行了分析研究，并将神经版本算法应用于三纤维软机器人臂，验证了方法的有效性。

Conclusion: 该研究通过将CLIK扩展到无限维领域，利用神经算子网络学习从驱动到形状的映射，为软机器人的微分控制提供了新的可能性。

Abstract: While kinematic inversion is a purely geometric problem for fully actuated rigid robots, it becomes extremely challenging for underactuated soft robots with infinitely many degrees of freedom. Closed-loop inverse kinematics (CLIK) schemes address this by introducing end-to-end mappings from actuation to task space for the controller to operate on, but typically assume finite dimensions of the underlying virtual configuration space. In this work, we extend CLIK to the infinite-dimensional domain to reason about the entire soft robot shape while solving tasks. We do this by composing an actuation-to-shape map with a shape-to-task map, deriving the differential end-to-end kinematics via an infinite-dimensional chain rule, and thereby obtaining a Jacobian-based CLIK algorithm. Since the actuation-to-shape mapping is rarely available in closed form, we propose to learn it from simulation data using neural operator networks, which are differentiable. We first present an analytical study on a constant-curvature segment, and then apply the neural version of the algorithm to a three-fiber soft robotic arm whose underlying model relies on morphoelasticity and active filament theory. This opens new possibilities for differentiable control of soft robots by exploiting full-body shape information in a continuous, infinite-dimensional framework.

</details>


### [248] [Robotic Fruits with Tunable Stiffness and Sensing: Towards a Methodology for Developing Realistic Physical Twins of Fruits](https://arxiv.org/abs/2602.18661)
*Saitarun Nadipineni,Keshav Pandiyan,Kaspar Althoefer,Shinichi Hirai,Thilina Dulantha Lalitharatne*

Main category: cs.RO

TL;DR: 开发可调谐软物理孪生体模拟水果刚度，为机器人夹持器训练提供高效、可持续平台。


<details>
  <summary>Details</summary>
Motivation: 解决农业劳动力短缺、高消费者需求和供应链中断导致的未收获农产品损失问题，同时克服现有测试方法依赖大量真实水果的低效、高成本和浪费问题。

Method: 开发了一种可调谐的软物理孪生体，模拟不同成熟度猕猴桃的刚度特性，并通过纤维增强气动设计实现。

Result: 实验结果显示，物理孪生体的刚度可精确调谐（97.35 - 99.43%准确度），夹持任务中传感器反馈能反映施加的夹持力，50次循环应力测试显示刚度保持稳定（0.56 - 1.10%误差）。

Conclusion: 该研究展示了可调谐软物理孪生体在模拟不同成熟度水果刚度特性方面的潜力，为机器人夹持器的基准测试和训练提供了一个可持续、可控的平台。

Abstract: The global agri-food sector faces increasing challenges from labour shortages, high consumer demand, and supply-chain disruptions, resulting in substantial losses of unharvested produce. Robotic harvesting has emerged as a promising alternative; however, evaluating and training soft grippers for delicate fruits remains difficult due to the highly variable mechanical properties of natural produce. This makes it difficult to establish reliable benchmarks or data-driven control strategies. Existing testing practices rely on large quantities of real fruit to capture this variability, leading to inefficiency, higher costs, and waste. The methodology presented in this work aims to address these limitations by developing tunable soft physical twins that emulate the stiffness characteristics of real fruits at different ripeness levels. A fiber-reinforced pneumatic physical twin of a kiwi fruit was designed and fabricated to replicate the stiffness at different ripeness levels. Experimental results show that the stiffness of the physical twin can be tuned accurately over multiple trials (97.35 - 99.43% accuracy). Gripping tasks with a commercial robotic gripper showed that sensor feedback from the physical twin can reflect the applied gripping forces. Finally, a stress test was performed over 50 cycles showed reliable maintenance of desired stiffness (0.56 - 1.10% error). This work shows promise that robotic physical twins could adjust their stiffness to resemble that of real fruits. This can provide a sustainable, controllable platform for benchmarking and training robotic grippers.

</details>


### [249] [Toward AI Autonomous Navigation for Mechanical Thrombectomy using Hierarchical Modular Multi-agent Reinforcement Learning (HM-MARL)](https://arxiv.org/abs/2602.18663)
*Harry Robertshaw,Nikola Fischer,Lennart Karstensen,Benjamin Jackson,Xingyu Chen,S. M. Hadi Sadati,Christos Bergeles,Alejandro Granados,Thomas C Booth*

Main category: cs.RO

TL;DR: HM-MARL框架通过模块化多智能体方法实现自主双设备导航，体外实验验证了其可行性，但仿真到现实的过渡仍需优化。


<details>
  <summary>Details</summary>
Motivation: 机械取栓（MT）是急性缺血性卒中大血管闭塞的优选治疗方法，但地理和物流障碍限制了其可及性。强化学习（RL）在自主血管内导航中显示出潜力，但在'长'导航任务中的泛化仍具挑战性。

Method: 提出了一种分层模块化多智能体强化学习（HM-MARL）框架，用于体外自主双设备导航。采用模块化多智能体方法将复杂导航任务分解为专门子任务，每个子任务使用Soft Actor-Critic RL进行训练。

Result: 在仿真中，单血管模型在个体解剖结构上达到92-100%的成功率，多血管模型在多个患者解剖结构上达到56-80%。体外实验中，HM-MARL模型成功导航100%的试验从股动脉到右颈总动脉，80%到右颈内动脉，但在左侧血管的超人挑战中失败。

Conclusion: 本研究首次展示了机械取栓血管内的体外自主导航，虽然HM-MARL实现了跨解剖结构的泛化，但仿真到现实的过渡带来了挑战。未来工作将利用世界模型优化RL策略，并在未见的体外数据上验证性能，推动自主机械取栓向临床转化。

Abstract: Mechanical thrombectomy (MT) is typically the optimal treatment for acute ischemic stroke involving large vessel occlusions, but access is limited due to geographic and logistical barriers. Reinforcement learning (RL) shows promise in autonomous endovascular navigation, but generalization across 'long' navigation tasks remains challenging. We propose a Hierarchical Modular Multi-Agent Reinforcement Learning (HM-MARL) framework for autonomous two-device navigation in vitro, enabling efficient and generalizable navigation. HM-MARL was developed to autonomously navigate a guide catheter and guidewire from the femoral artery to the internal carotid artery (ICA). A modular multi-agent approach was used to decompose the complex navigation task into specialized subtasks, each trained using Soft Actor-Critic RL. The framework was validated in both in silico and in vitro testbeds to assess generalization and real-world feasibility. In silico, a single-vasculature model achieved 92-100% success rates on individual anatomies, while a multi-vasculature model achieved 56-80% across multiple patient anatomies. In vitro, both HM-MARL models successfully navigated 100% of trials from the femoral artery to the right common carotid artery and 80% to the right ICA but failed on the left-side vessel superhuman challenge due to the anatomy and catheter type used in navigation. This study presents the first demonstration of in vitro autonomous navigation in MT vasculature. While HM-MARL enables generalization across anatomies, the simulation-to-real transition introduces challenges. Future work will refine RL strategies using world models and validate performance on unseen in vitro data, advancing autonomous MT towards clinical translation.

</details>


### [250] [Systematic Analysis of Coupling Effects on Closed-Loop and Open-Loop Performance in Aerial Continuum Manipulators](https://arxiv.org/abs/2602.18684)
*Niloufar Amiri,Shayan Sepahvand,Iraj Mantegh,Farrokh Janabi-Sharifi*

Main category: cs.RO

TL;DR: The paper compares decoupled and coupled models for ACMs, finding the decoupled model achieves similar closed-loop accuracy with lower computational cost.


<details>
  <summary>Details</summary>
Motivation: The primary objective is to determine when the decoupled model can match the accuracy of the coupled model while reducing computational costs under identical numerical conditions.

Method: The paper uses the Euler-Lagrange method under the PCC assumption to derive system dynamics, develops a decoupled model by neglecting coupling terms, and implements a DPD-SM-IBVS controller for closed-loop analysis.

Result: Open-loop simulations show significant discrepancies between the two models, but closed-loop experiments demonstrate the decoupled model's comparable accuracy (subpixel error) and lower computational cost.

Conclusion: The decoupled model achieves comparable tracking accuracy to the coupled model with lower computational cost in closed-loop scenarios, making it a viable alternative for practical applications.

Abstract: This paper investigates two distinct approaches to the dynamic modeling of aerial continuum manipulators (ACMs): the decoupled and the coupled formulations. Both open-loop and closed-loop behaviors of a representative ACM are analyzed. The primary objective is to determine the conditions under which the decoupled model attains accuracy comparable to the coupled model while offering reduced computational cost under identical numerical conditions. The system dynamics are first derived using the Euler--Lagrange method under the piecewise constant curvature (PCC) assumption, with explicit treatment of the near-zero curvature singularity. A decoupled model is then obtained by neglecting the coupling terms in the ACM dynamics, enabling systematic evaluation of open-loop responses under diverse actuation profiles and external wrenches. To extend the analysis to closed-loop performance, a novel dynamics-based proportional-derivative sliding mode image-based visual servoing (DPD-SM-IBVS) controller is developed for regulating image feature errors in the presence of a moving target. The controller is implemented with both coupled and decoupled models, allowing a direct comparison of their effectiveness. The open-loop simulations reveal pronounced discrepancies between the two modeling approaches, particularly under varying torque inputs and continuum arm parameters. Conversely, the closed-loop experiments demonstrate that the decoupled model achieves tracking accuracy on par with the coupled model (within subpixel error) while incurring lower computational cost.

</details>


### [251] [Scout-Rover cooperation: online terrain strength mapping and traversal risk estimation for planetary-analog explorations](https://arxiv.org/abs/2602.18688)
*Shipeng Liu,J. Diego Caporale,Yifeng Zhang,Xingjue Liao,William Hoganson,Wilson Hu,Shivangi Misra,Neha Peddinti,Rachel Holladay,Ethan Fulcher,Akshay Ram Panyam,Andrik Puentes,Jordan M. Bretzfelder,Michael Zanetti,Uland Wong,Daniel E. Koditschek,Mark Yim,Douglas Jerolmack,Cynthia Sung,Feifei Qian*

Main category: cs.RO

TL;DR: 该论文提出了一种腿式和轮式机器人协作框架，通过腿部机器人的地形感知构建地图，指导漫游车安全穿越松软行星表面，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 许多科学上有价值的区域（如火星沙丘和月球陨石坑）由于松软、可变形的地表而危险，机器人辅助的行星表面探索对于理解地质过程至关重要。

Method: 提出了一种侦察车-漫游车协作框架，利用腿式和轮式机器人的混合团队，通过腿部机器人的本体感知腿-地形交互来估计地形强度并构建空间分辨地形图，这些地图与漫游车运动模型结合以估计穿越风险并指导路径规划。

Result: 实验证明，腿部机器人可以在线生成地形强度图，并能可靠地捕捉空间变异性并预测移动故障模式，从而实现风险感知的路径规划，避免危险区域。

Conclusion: 通过结合腿部机器人的地形感知与异构机器人协作，该框架提高了在可变形行星环境中的操作鲁棒性，并扩大了可到达的科学工作空间。

Abstract: Robot-aided exploration of planetary surfaces is essential for understanding geologic processes, yet many scientifically valuable regions, such as Martian dunes and lunar craters, remain hazardous due to loose, deformable regolith. We present a scout-rover cooperation framework that expands safe access to such terrain using a hybrid team of legged and wheeled robots. In our approach, a high-mobility legged robot serves as a mobile scout, using proprioceptive leg-terrain interactions to estimate regolith strength during locomotion and construct spatially resolved terrain maps. These maps are integrated with rover locomotion models to estimate traversal risk and inform path planning.
  We validate the framework through analogue missions at the NASA Ames Lunar Simulant Testbed and the White Sands Dune Field. Experiments demonstrate (1) online terrain strength mapping from legged locomotion and (2) rover-specific traversal-risk estimation enabling safe navigation to scientific targets. Results show that scout-generated terrain maps reliably capture spatial variability and predict mobility failure modes, allowing risk-aware path planning that avoids hazardous regions. By combining embodied terrain sensing with heterogeneous rover cooperation, this framework enhances operational robustness and expands the reachable science workspace in deformable planetary environments.

</details>


### [252] [CLASH: Collision Learning via Augmented Sim-to-real Hybridization to Bridge the Reality Gap](https://arxiv.org/abs/2602.18707)
*Haotian He,Ning Guo,Siqi Shi,Qipeng Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: CLASH通过结合仿真与少量真实数据，构建高保真混合仿真器，显著提升策略在真实世界中的转移性能。


<details>
  <summary>Details</summary>
Motivation: 传统物理引擎在精度与计算速度间难以平衡，导致仿真训练的机器人策略难以直接应用于现实。CLASH旨在通过数据高效的方式解决这一问题。

Method: CLASH首先从MuJoCo中提取基础模型以获取物理先验，然后仅需少量真实数据（如10个样本）进行微调，以修正仿真误差，构建高保真混合仿真器。

Result: 混合仿真器不仅预测精度更高，还将碰撞计算时间减少近50%。使用该仿真器训练的强化学习策略在真实世界中的成功率翻倍，基于模型的控制任务性能也显著提升。

Conclusion: CLASH框架通过结合仿真与少量真实数据，显著提升了策略在真实世界中的转移性能，成功减少了仿真与现实的差距。

Abstract: The sim-to-real gap, particularly in the inaccurate modeling of contact-rich dynamics like collisions, remains a primary obstacle to deploying robot policies trained in simulation. Conventional physics engines often trade accuracy for computational speed, leading to discrepancies that prevent direct policy transfer. To address this, we introduce Collision Learning via Augmented Sim-to-real Hybridization (CLASH), a data-efficient framework that creates a high-fidelity hybrid simulator by learning a surrogate collision model from a minimal set of real-world data. In CLASH, a base model is first distilled from an imperfect simulator (MuJoCo) to capture general physical priors; this model is then fine-tuned with a remarkably small number of real-world interactions (as few as 10 samples) to correct for the simulator's inherent inaccuracies. The resulting hybrid simulator not only achieves higher predictive accuracy but also reduces collision computation time by nearly 50\%. We demonstrate that policies obtained with our hybrid simulator transfer more robustly to the real world, doubling the success rate in sequential pushing tasks with reinforecement learning and significantly increase the task performance with model-based control.

</details>


### [253] [Temporal Action Representation Learning for Tactical Resource Control and Subsequent Maneuver Generation](https://arxiv.org/abs/2602.18716)
*Hoseong Jung,Sungil Son,Daesol Cho,Jonghae Park,Changhyun Choi,H. Jin Kim*

Main category: cs.RO

TL;DR: TART通过对比学习捕捉资源-机动的时间依赖性，优于现有方法，适用于有限资源场景。


<details>
  <summary>Details</summary>
Motivation: 现有混合动作空间方法未能充分捕捉资源使用与机动之间的因果依赖性和多模态战术决策，这在快速变化场景中至关重要。

Method: TART采用基于互信息目标的对比学习框架，量化离散码本条目以捕捉资源-机动交互的时间依赖性，并生成多模态行为。

Result: 在迷宫导航和高保真空战模拟器中，TART均优于混合动作基线，有效利用有限资源并生成上下文感知的后续机动。

Conclusion: TART框架通过对比学习和时间依赖性捕捉，在资源控制和后续机动生成方面表现出色，优于现有混合动作基线方法。

Abstract: Autonomous robotic systems should reason about resource control and its impact on subsequent maneuvers, especially when operating with limited energy budgets or restricted sensing. Learning-based control is effective in handling complex dynamics and represents the problem as a hybrid action space unifying discrete resource usage and continuous maneuvers. However, prior works on hybrid action space have not sufficiently captured the causal dependencies between resource usage and maneuvers. They have also overlooked the multi-modal nature of tactical decisions, both of which are critical in fast-evolving scenarios. In this paper, we propose TART, a Temporal Action Representation learning framework for Tactical resource control and subsequent maneuver generation. TART leverages contrastive learning based on a mutual information objective, designed to capture inherent temporal dependencies in resource-maneuver interactions. These learned representations are quantized into discrete codebook entries that condition the policy, capturing recurring tactical patterns and enabling multi-modal and temporally coherent behaviors. We evaluate TART in two domains where resource deployment is critical: (i) a maze navigation task where a limited budget of discrete actions provides enhanced mobility, and (ii) a high-fidelity air combat simulator in which an F-16 agent operates weapons and defensive systems in coordination with flight maneuvers. Across both domains, TART consistently outperforms hybrid-action baselines, demonstrating its effectiveness in leveraging limited resources and producing context-aware subsequent maneuvers.

</details>


### [254] [RoboCurate: Harnessing Diversity with Action-Verified Neural Trajectory for Robot Learning](https://arxiv.org/abs/2602.18742)
*Seungku Kim,Suhyeok Jang,Byungjun Yoon,Dongyoung Kim,John Won,Jinwoo Shin*

Main category: cs.RO

TL;DR: RoboCurate通过模拟回放评估动作质量，结合编辑技术增强数据多样性，显著提升机器人学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频生成模型生成的合成数据动作质量不一致及视觉语言模型无法直接评估动作准确性的问题。

Method: 通过模拟回放比较生成视频与模拟动作的一致性来评估动作质量，并结合图像到图像编辑和视频到视频转换技术增强数据多样性。

Result: 相比仅使用真实数据，RoboCurate生成的数据在多个场景中显著提升成功率（如GR-1 Tabletop +70.1%）。

Conclusion: RoboCurate显著提升了合成数据在机器人学习中的效果，尤其在GR-1 Tabletop、DexMimicGen和ALLEX等场景中表现突出。

Abstract: Synthetic data generated by video generative models has shown promise for robot learning as a scalable pipeline, but it often suffers from inconsistent action quality due to imperfectly generated videos. Recently, vision-language models (VLMs) have been leveraged to validate video quality, but they have limitations in distinguishing physically accurate videos and, even then, cannot directly evaluate the generated actions themselves. To tackle this issue, we introduce RoboCurate, a novel synthetic robot data generation framework that evaluates and filters the quality of annotated actions by comparing them with simulation replay. Specifically, RoboCurate replays the predicted actions in a simulator and assesses action quality by measuring the consistency of motion between the simulator rollout and the generated video. In addition, we unlock observation diversity beyond the available dataset via image-to-image editing and apply action-preserving video-to-video transfer to further augment appearance. We observe RoboCurate's generated data yield substantial relative improvements in success rates compared to using real data only, achieving +70.1% on GR-1 Tabletop (300 demos), +16.1% on DexMimicGen in the pre-training setup, and +179.9% in the challenging real-world ALLEX humanoid dexterous manipulation setting.

</details>


### [255] [Learning to Localize Reference Trajectories in Image-Space for Visual Navigation](https://arxiv.org/abs/2602.18803)
*Finn Lukas Busch,Matti Vahs,Quantao Yang,Jesús Gerardo Ortega Peimbert,Yixi Cai,Jana Tumova,Olov Andersson*

Main category: cs.RO

TL;DR: LoTIS是一种机器人无关的视觉导航模型，通过图像空间轨迹定位实现跨平台零样本导航，显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种机器人无关的视觉导航模型，避免依赖特定机器人的行为先验或校准需求。

Method: 模型通过定位参考RGB轨迹在当前视图中的图像空间坐标，提供机器人无关的视觉引导，无需相机校准、姿态或机器人特定训练。

Result: 在传统前向导航中，成功率比现有方法高20-50个百分点，达到94-98%；在挑战性任务（如逆向遍历）中表现尤为突出。

Conclusion: LoTIS模型通过解耦感知与动作，实现了跨机器人平台的零样本视觉导航，显著提升了导航成功率，并在挑战性任务中表现优异。

Abstract: We present LoTIS, a model for visual navigation that provides robot-agnostic image-space guidance by localizing a reference RGB trajectory in the robot's current view, without requiring camera calibration, poses, or robot-specific training. Instead of predicting actions tied to specific robots, we predict the image-space coordinates of the reference trajectory as they would appear in the robot's current view. This creates robot-agnostic visual guidance that easily integrates with local planning. Consequently, our model's predictions provide guidance zero-shot across diverse embodiments. By decoupling perception from action and learning to localize trajectory points rather than imitate behavioral priors, we enable a cross-trajectory training strategy for robustness to viewpoint and camera changes. We outperform state-of-the-art methods by 20-50 percentage points in success rate on conventional forward navigation, achieving 94-98% success rate across diverse sim and real environments. Furthermore, we achieve over 5x improvements on challenging tasks where baselines fail, such as backward traversal. The system is straightforward to use: we show how even a video from a phone camera directly enables different robots to navigate to any point on the trajectory. Videos, demo, and code are available at https://finnbusch.com/lotis.

</details>


### [256] [Habilis-$β$: A Fast-Motion and Long-Lasting On-Device Vision-Language-Action Model](https://arxiv.org/abs/2602.18813)
*Tommoro Robotics,:,Jesoon Kang,Taegeon Park,Jisu An,Soo Min Kimm,Jaejoon Kim,Jinu Pahk,Byungju Kim,Junseok Lee,Namheon Baek,Sungwan Ha,Hojun Baek,Eduardo Ayerve Cruz,Wontae Kim,Junghyeon Choi,Yousuk Lee,Joonmo Han,Sunghyun Cho,Sunghyun Kwon,Soyoung Lee,Jun Ki Lee,Seung-Joon Yi,Byoung-Tak Zhang,Theo Taeyeong Kim*

Main category: cs.RO

TL;DR: Habilis-$β$是一种高速持久的VLA模型，通过PRP评估其在连续运行中的表现，整合多项技术实现高性能，在模拟和现实任务中均优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言-动作（VLA）模型的评估局限于单次试验成功率，无法捕捉实际操作所需的高速和持久能力，因此提出了生产力-可靠性平面（PRP）作为新评估标准。

Method: 整合了无语言预训练和循环任务演示后训练，采用ESPADA进行相位自适应运动整形，利用整流流蒸馏实现高频控制，并结合无分类器指导（CFG）动态平衡指令遵循和交互先验。

Result: 在1小时连续运行评估中，Habilis-$β$在模拟环境中达到572.6 TPH和39.2秒MTBI，现实物流工作流中达到124 TPH和137.4秒MTBI，均显著优于$π_{0.5}$。

Conclusion: Habilis-$β$在模拟和现实环境中均表现出色，尤其在连续运行评估中显著优于$π_{0.5}$，验证了其在复杂操作场景中的有效性。

Abstract: We introduce Habilis-$β$, a fast-motion and long-lasting on-device vision-language-action (VLA) model designed for real-world deployment. Current VLA evaluation remains largely confined to single-trial success rates under curated resets, which fails to capture the fast-motion and long-lasting capabilities essential for practical operation. To address this, we introduce the Productivity-Reliability Plane (PRP), which evaluates performance through Tasks per Hour (TPH) and Mean Time Between Intervention (MTBI) under a continuous-run protocol that demands both high-speed execution and sustained robustness. Habilis-$β$ achieves high performance by integrating language-free pre-training on large-scale play data for robust interaction priors with post-training on cyclic task demonstrations that capture state drift across consecutive task iterations. The system further employs ESPADA for phase-adaptive motion shaping to accelerate free-space transit, utilizes rectified-flow distillation to enable high-frequency control on edge devices, and incorporates classifier-free guidance (CFG) as a deployment-time knob to dynamically balance instruction adherence and learned interaction priors. In 1-hour continuous-run evaluations, Habilis-$β$ achieves strong performance under the PRP metrics, compared to $π_{0.5}$ in both simulation and real-world environments. In simulation, Habilis-$β$ achieves 572.6 TPH and 39.2 s MTBI (vs. 120.5 TPH and 30.5 s for $π_{0.5}$), while in a real-world humanoid logistics workflow it achieves 124 TPH and 137.4 s MTBI (vs. 19 TPH and 46.1 s for $π_{0.5}$). Finally, Habilis-$β$ achieves the highest reported performance on the standard RoboTwin 2.0 leaderboard across representative tasks, validating its effectiveness in complex manipulation scenarios.

</details>


### [257] [RotorSuite: A MATLAB/Simulink Toolbox for Tilt Multi-Rotor UAV Modeling](https://arxiv.org/abs/2602.18814)
*Nicola Cigarini,Giulia Michieletto,Angelo Cenedese*

Main category: cs.RO

TL;DR: 提出RotorSuite工具箱，通过解析与物理方法结合，高效建模多旋翼平台动态，适用于教育、研究和工业。


<details>
  <summary>Details</summary>
Motivation: 传统多旋翼平台建模方法耗时、依赖用户且易出错，需一种更高效准确的工具。

Method: 结合解析和基于物理的方法，开发了MATLAB/Simulink工具箱RotorSuite，支持广泛的多旋翼平台动态建模与仿真。

Result: RotorSuite工具箱具备全面文档和示例用例，验证了其在多旋翼平台动态分析中的实用性。

Conclusion: RotorSuite工具箱为多旋翼平台的建模与仿真提供了高效、准确的解决方案，适用于教育、研究和工业开发。

Abstract: In recent years, aerial platforms have evolved from passive flying sensors into versatile, contact-aware robotic systems, leading to rapid advances in platform design. Standard coplanar and collinear quadrotors have been complemented by modern tilted and tilting multi-rotor platforms with enhanced maneuverability. To properly analyze, control, and validate the performance of these emerging platforms, an accurate modeling step is required; however, this can be time-consuming, user-dependent and error-prone. To address this issue, we propose a MATLAB/Simulink toolbox for modeling and simulating the dynamics of a broad class of multi-rotor platforms through both an analytical and physics-based approaches. The toolbox, named RotorSuite, is provided with comprehensive documentation and example use cases, representing a valuable tool for didactic, research, and industrial development purposes.

</details>


### [258] [GRAB: A Systematic Real-World Grasping Benchmark for Robotic Food Waste Sorting](https://arxiv.org/abs/2602.18835)
*Moniesha Thilakarathna,Xing Wang,Min Wang,David Hinwood,Shuangzhe Liu,Damith Herath*

Main category: cs.RO

TL;DR: GRAB框架通过大规模实验评估食品废弃物抓取性能，揭示物体质量是关键因素，并强调多模态夹具技术的必要性。


<details>
  <summary>Details</summary>
Motivation: 食品废弃物管理对可持续发展至关重要，但无机污染物阻碍了回收潜力。机器人自动化虽能加速分拣过程，但污染物的多样性和不可预测性为抓取带来挑战。现有基准框架依赖有限模拟数据集且忽视关键抓取前条件。

Method: GRAB框架整合了多样化可变形物体、先进的抓取姿态估计视觉技术及抓取前条件，通过1,750次抓取实验在四个高保真场景中系统比较工业抓取模式。

Result: 实验结果表明，物体质量是杂乱环境中抓取性能的主导因素，视觉质量和杂乱程度影响中等。这些发现为夹具设计提供了关键考量。

Conclusion: GRAB框架通过综合评估抓取性能，揭示了不同夹具在食品废弃物分类中的优势和限制，强调了多模态夹具技术开发的重要性。

Abstract: Food waste management is critical for sustainability, yet inorganic contaminants hinder recycling potential. Robotic automation presents a compelling approach to this challenge by accelerating the sorting process through automated contaminant removal. Still, the diverse and unpredictable nature of contaminants creates major challenges for robotic grasping. Benchmarking frameworks are critical for evaluating challenges from various perspectives. However, existing protocols rely on limited simulation datasets, prioritise simple metrics such as success rate, and overlook key object and environment-related pre-grasp conditions. This paper introduces GRAB, a comprehensive Grasping Real-World Article Benchmarking framework that addresses this gap by integrating diverse deformable objects, advanced grasp-pose-estimation vision, and, importantly, pre-grasp conditions, establishing a set of critical graspability metrics. It systematically compares industrial grasping modalities through an in-depth experimental evaluation involving 1,750 food contaminant grasp attempts across four high-fidelity scenes. This large-scale evaluation provides an extensive assessment of grasp performance for food waste sorting, offering a level of depth that has rarely been explored in previous studies. The results reveal distinct gripper strengths and limitations, with object quality emerging as the dominant performance factor in cluttered environments, while vision quality and clutter levels play moderate roles. These findings highlight essential design considerations and reinforce the necessity of developing multimodal gripper technologies capable of robust cross-category performance for effective robotic food waste sorting.

</details>


### [259] [When the Inference Meets the Explicitness or Why Multimodality Can Make Us Forget About the Perfect Predictor](https://arxiv.org/abs/2602.18850)
*J. E. Domínguez-Vidal,Alberto Sanfeliu*

Main category: cs.RO

TL;DR: 研究比较了四种人机协作通信系统，发现人类偏好自然系统，最佳方案是预测与显式通信的结合。


<details>
  <summary>Details</summary>
Motivation: 由于人类行为的随机性导致预测模型的不确定性，作者提倡使用显式通信系统来明确获取人类意图，以提高人机协作效率。

Method: 研究使用了四种不同的通信系统：两种意图预测器（基于力预测和增强速度预测算法）和两种显式通信方法（按钮界面和语音命令识别系统）。这些系统集成到IVO移动社交机器人中，通过力传感器和LiDAR进行实验。75名志愿者完成了255次实验，分为三组分别测试推理系统、通信系统及组合策略。

Result: 结果显示：1）技术改进达到一定水平后，人类对其不再敏感但仍给予正面评价；2）人类更倾向于自然系统，即使其失败率较高；3）最佳方案是预测系统与显式通信系统的结合。

Conclusion: 研究表明，当技术改进达到一定水平后，人类对其不再敏感，但仍会给予正面评价；人类更倾向于使用更自然的系统，即使其失败率较高；最佳方案是预测系统与显式通信系统的结合。

Abstract: Although in the literature it is common to find predictors and inference systems that try to predict human intentions, the uncertainty of these models due to the randomness of human behavior has led some authors to start advocating the use of communication systems that explicitly elicit human intention. In this work, it is analyzed the use of four different communication systems with a human-robot collaborative object transportation task as experimental testbed: two intention predictors (one based on force prediction and another with an enhanced velocity prediction algorithm) and two explicit communication methods (a button interface and a voice-command recognition system). These systems were integrated into IVO, a custom mobile social robot equipped with force sensor to detect the force exchange between both agents and LiDAR to detect the environment. The collaborative task required transporting an object over a 5-7 meter distance with obstacles in the middle, demanding rapid decisions and precise physical coordination. 75 volunteers perform a total of 255 executions divided into three groups, testing inference systems in the first round, communication systems in the second, and the combined strategies in the third. The results show that, 1) once sufficient performance is achieved, the human no longer notices and positively assesses technical improvements; 2) the human prefers systems that are more natural to them even though they have higher failure rates; and 3) the preferred option is the right combination of both systems.

</details>


### [260] [Gait Asymmetry from Unilateral Weakness and Improvement With Ankle Assistance: a Reinforcement Learning based Simulation Study](https://arxiv.org/abs/2602.18862)
*Yifei Yuan,Ghaith Androwis,Xianlian Zhou*

Main category: cs.RO

TL;DR: 该研究通过RL模拟框架量化单侧肌肉无力对步态对称性的影响，并评估踝关节外骨骼辅助的改善效果，为未来实验提供基础。


<details>
  <summary>Details</summary>
Motivation: 单侧肌肉无力常导致不对称步态，破坏肢体间协调和站立时间。研究目标是建立一个基于模拟和学习的流程，以支持在患者实验之前进行早期控制器开发。

Method: 本研究提出了一个基于强化学习（RL）的肌肉骨骼模拟框架，通过逐步减少右腿肌肉力量（至基线水平的75%、50%和25%）来诱导不对称步态，并使用脚趾离地时间、峰值接触力和关节对称性指标量化步态不对称性。

Result: 随着肌肉无力的加剧，时间和运动学不对称性逐渐增大，尤其在踝关节最为明显。在50%力量时，踝关节外骨骼辅助改善了运动学对称性，减少了踝关节对称性指数的幅度，并提高了相关性，尽管峰值负荷仍偏向未受损侧。

Conclusion: 该框架支持对损伤严重程度和辅助策略的受控评估，并为未来在人体实验中的验证提供了基础。

Abstract: Unilateral muscle weakness often leads to asymmetric gait, disrupting interlimb coordination and stance timing. This study presents a reinforcement learning (RL) based musculoskeletal simulation framework to (1) quantify how progressive unilateral muscle weakness affects gait symmetry and (2) evaluate whether ankle exoskeleton assistance can improve gait symmetry under impaired conditions. The overarching goal is to establish a simulation- and learning-based workflow that supports early controller development prior to patient experiments. Asymmetric gait was induced by reducing right-leg muscle strength to 75%, 50%, and 25% of baseline. Gait asymmetry was quantified using toe-off timing, peak contact forces, and joint-level symmetry metrics. Increasing weakness produced progressively larger temporal and kinematic asymmetry, most pronounced at the ankle. Ankle range of motion symmetry degraded from near-symmetric behavior at 100% strength (symmetry index, SI = +6.4%; correlation r=0.974) to severe asymmetry at 25% strength (SI = -47.1%, r=0.889), accompanied by a load shift toward the unimpaired limb. At 50% strength, ankle exoskeleton assistance improved kinematic symmetry relative to the unassisted impaired condition, reducing the magnitude of ankle SI from 25.8% to 18.5% and increasing ankle correlation from r=0.948 to 0.966, although peak loading remained biased toward the unimpaired side. Overall, this framework supports controlled evaluation of impairment severity and assistive strategies, and provides a basis for future validation in human experiments.

</details>


### [261] [Equivalence and Divergence of Bayesian Log-Odds and Dempster's Combination Rule for 2D Occupancy Grids](https://arxiv.org/abs/2602.18872)
*Tatiana Berlenko,Kirill Krinkin*

Main category: cs.RO

TL;DR: 论文提出了一种公平比较贝叶斯和Dempster规则的方法，结果显示贝叶斯在BetP匹配下更优，但结果依赖于匹配准则。


<details>
  <summary>Details</summary>
Motivation: 为了公平比较贝叶斯对数赔率和Dempster组合规则在占据栅格地图中的表现，并隔离传感器参数化的影响。

Method: 采用pignistic变换方法，通过匹配每观测决策概率，将融合规则与传感器参数化隔离，并在仿真、真实激光雷达数据集及下游路径规划中进行验证。

Result: 在BetP匹配下，贝叶斯融合表现一致优于Dempster组合规则（15/15方向一致性，p = 3.1e-5），绝对差异较小（0.001-0.022）。而在归一化似然匹配下，结果反转，表明结果依赖于匹配准则。

Conclusion: 该论文提出了一种基于pignistic变换的方法论，用于公平比较贝叶斯对数赔率和Dempster组合规则在占据栅格地图中的表现，并证明该方法可重复用于未来任何贝叶斯/信念函数的比较。

Abstract: We introduce a pignistic-transform-based methodology for fair comparison of Bayesian log-odds and Dempster's combination rule in occupancy grid mapping, matching per-observation decision probabilities to isolate the fusion rule from sensor parameterization. Under BetP matching across simulation, two real lidar datasets, and downstream path planning, Bayesian fusion is consistently favored (15/15 directional consistency, p = 3.1e-5) with small absolute differences (0.001-0.022). Under normalized plausibility matching, the direction reverses, confirming the result is matching-criterion-specific. The methodology is reusable for any future Bayesian/belief function comparison.

</details>


### [262] [Temporal-Logic-Aware Frontier-Based Exploration](https://arxiv.org/abs/2602.18951)
*Azizollah Taheri,Derya Aksaray*

Main category: cs.RO

TL;DR: 本文提出了一种利用commit states的前沿探索算法，帮助机器人在未知环境中有效完成时间逻辑任务。


<details>
  <summary>Details</summary>
Motivation: 解决自主机器人在未知环境中执行时间逻辑任务时，由于目标位置未知而面临的规划挑战。

Method: 提出了一种新型自动机状态（commit states），并基于此设计了一个前沿探索算法，用于指导机器人在未知环境中完成任务。

Result: 仿真验证了所提方法的有效性，能够确保机器人在满足任务的同时保留所有可能的完成路径。

Conclusion: 通过引入commit states和前沿探索算法，本文提出了一种在未知环境中实现时间逻辑运动规划的完整且可靠的方法，并通过仿真验证了其有效性。

Abstract: This paper addresses the problem of temporal logic motion planning for an autonomous robot operating in an unknown environment. The objective is to enable the robot to satisfy a syntactically co-safe Linear Temporal Logic (scLTL) specification when the exact locations of the desired labels are not known a priori. We introduce a new type of automaton state, referred to as commit states. These states capture intermediate task progress resulting from actions whose consequences are irreversible. In other words, certain future paths to satisfaction become not feasible after taking those actions that lead to the commit states. By leveraging commit states, we propose a sound and complete frontier-based exploration algorithm that strategically guides the robot to make progress toward the task while preserving all possible ways of satisfying it. The efficacy of the proposed method is validated through simulations.

</details>


### [263] [TactEx: An Explainable Multimodal Robotic Interaction Framework for Human-Like Touch and Hardness Estimation](https://arxiv.org/abs/2602.18967)
*Felix Verstraete,Lan Wei,Wen Fan,Dandan Zhang*

Main category: cs.RO

TL;DR: TactEx是一个可解释的多模态机器人交互框架，结合视觉、触觉和语言进行类人硬度估计与交互指导，在水果成熟度评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 准确感知物体硬度对于安全且灵巧的接触密集型机器人操作至关重要。

Method: TactEx通过融合GelSight-Mini触觉数据流、RGB观察和语言提示，采用ResNet50+LSTM模型从序列触觉数据估计硬度，并通过跨模态对齐模块结合视觉线索与大型语言模型（LLM）的指导。

Result: TactEx在水果成熟度评估任务中实现了显著的类别区分（所有水果对的p值<0.01），并在端到端评估中达到90%的任务成功率，且能泛化至新任务而无需大规模调整。

Conclusion: TactEx展示了结合预训练的视觉、触觉模型与语言基础的潜力，推动了机器人领域可解释、类人触觉感知与决策的发展。

Abstract: Accurate perception of object hardness is essential for safe and dexterous contact-rich robotic manipulation. Here, we present TactEx, an explainable multimodal robotic interaction framework that unifies vision, touch, and language for human-like hardness estimation and interactive guidance. We evaluate TactEx on fruit-ripeness assessment, a representative task that requires both tactile sensing and contextual understanding. The system fuses GelSight-Mini tactile streams with RGB observations and language prompts. A ResNet50+LSTM model estimates hardness from sequential tactile data, while a cross-modal alignment module combines visual cues with guidance from a large language model (LLM). This explainable multimodal interface allows users to distinguish ripeness levels with statistically significant class separation (p < 0.01 for all fruit pairs). For touch placement, we compare YOLO with Grounded-SAM (GSAM) and find GSAM to be more robust for fine-grained segmentation and contact-site selection. A lightweight LLM parses user instructions and produces grounded natural-language explanations linked to the tactile outputs. In end-to-end evaluations, TactEx attains 90% task success on simple user queries and generalises to novel tasks without large-scale tuning. These results highlight the promise of combining pretrained visual and tactile models with language grounding to advance explainable, human-like touch perception and decision-making in robotics.

</details>


### [264] [Bumper Drone: Elastic Morphology Design for Aerial Physical Interaction](https://arxiv.org/abs/2602.18976)
*Pongporn Supa,Alex Dunnett,Feng Xiao,Rui Wu,Mirko Kovac,Basaran Bahadir Kocer*

Main category: cs.RO

TL;DR: 无人机通过弹性触角实现被动环境交互，减少俯仰振荡并提升稳定性，无需主动避障控制。


<details>
  <summary>Details</summary>
Motivation: 无人机从避障转向利用环境交互进行导航、探索和操作时，面临不确定接触力的挑战，需解决传感与控制的精度问题。

Method: 研究采用弹性触角设计，通过自调节的‘触碰即走’机动，利用无人机与障碍物系统的被动动态响应（类似质量-弹簧-阻尼系统）实现稳定。实验对比了弹性与刚性触角的效果。

Result: 弹性触角可吸收冲击能量并保持飞行稳定性，俯仰振荡减少38%；低位触角布置进一步减少54%。平台还能与静态物体保持稳定持续接触。

Conclusion: 该论文展示了一种配备弹性触角的无人机平台，能够通过被动动态响应实现与环境的物理交互，显著提升了飞行稳定性并减少了俯仰振荡。

Abstract: Aerial robots are evolving from avoiding obstacles to exploiting the environmental contact interactions for navigation, exploration and manipulation. A key challenge in such aerial physical interactions lies in handling uncertain contact forces on unknown targets, which typically demand accurate sensing and active control. We present a drone platform with elastic horns that enables touch-and-go manoeuvres - a self-regulated, consecutive bumping motion that allows the drone to maintain proximity to a wall without relying on active obstacle avoidance. It leverages environmental interaction as a form of embodied control, where low-level stabilisation and near-obstacle navigation emerge from the passive dynamic responses of the drone-obstacle system that resembles a mass-spring-damper system. Experiments show that the elastic horn can absorb impact energy while maintaining vehicle stability, reducing pitch oscillations by 38% compared to the rigid horn configuration. The lower horn arrangement was found to reduce pitch oscillations by approximately 54%. In addition to intermittent contact, the platform equipped with elastic horns also demonstrates stable, sustained contact with static objects, relying on a standard attitude PID controller.

</details>


### [265] [FruitTouch: A Perceptive Gripper for Gentle and Scalable Fruit Harvesting](https://arxiv.org/abs/2602.18991)
*Ruohan Zhang,Mohammad Amin Mirzaee,Wenzhen Yuan*

Main category: cs.RO

TL;DR: FruitTouch 是一种紧凑的视觉触觉夹持器，用于自动化水果采摘，能稳定抓取多种水果并提供实时反馈，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决劳动力短缺问题，开发一种能够在有限空间内稳定抓取多种水果并提供可靠反馈的传感器化夹持器。

Method: 设计了一种紧凑的夹持器 FruitTouch，采用高分辨率视觉触觉传感技术，通过嵌入式摄像头捕获触觉图像，实现实时力估计、滑动检测和软度预测。

Result: 在真实水果采摘实验中验证了 FruitTouch 的抓取稳定性和防损伤效果。

Conclusion: FruitTouch 是一种紧凑的夹持器，通过优化的光学设计集成了高分辨率的视觉触觉传感，能够稳定抓取多种水果并提供实时反馈，验证了其在真实水果采摘中的稳定性和防损伤效果。

Abstract: The automation of fruit harvesting has gained increasing significance in response to rising labor shortages. A sensorized gripper is a key component of this process, which must be compact enough for confined spaces, able to stably grasp diverse fruits, and provide reliable feedback on fruit conditions for efficient harvesting. To address this need, we propose FruitTouch, a compact gripper that integrates high-resolution, vision-based tactile sensing through an optimized optical design. This configuration accommodates a wide range of fruit sizes while maintaining low cost and mechanical simplicity. Tactile images captured by an embedded camera provide rich information for real-time force estimation, slip detection, and softness prediction. We validate the gripper in real-world fruit harvesting experiments, demonstrating robust grasp stability and effective damage prevention.

</details>


### [266] [A Checklist for Deploying Robots in Public: Articulating Tacit Knowledge in the HRI Community](https://arxiv.org/abs/2602.19038)
*Claire Liang,Franziska Babel,Hannah Pelikan,Sydney Thompson,Xiang Zhi Tan*

Main category: cs.RO

TL;DR: 该论文提供了一个公共HRI研究的检查清单，总结了部署中的关键要点，并通过社区反馈和实际应用验证了其有效性，最终以开源形式贡献给社区。


<details>
  <summary>Details</summary>
Motivation: 公共机器人部署中的许多挑战未被记录，导致常见陷阱重复出现，增加了进入门槛。为了阐明HRI社区中的隐性知识，该论文旨在提供一个指南形式的检查清单，帮助研究人员准备公共机器人部署。

Method: 研究团队基于自身在公共机器人部署中的经验，收集了公共HRI研究中需要考虑的要点，并以模块化翻转卡片的形式呈现，组织成部署阶段和重要领域的层次结构表。此外，还采访了六位跨学科研究人员，展示了社区意见如何完善检查清单。

Result: 研究展示了检查清单在实际公共研究中的应用，并通过社区反馈进一步完善了清单内容。

Conclusion: 该论文贡献了一个开源、可定制的社区资源——检查清单，旨在收集联合专业知识以持续演进，并可作为列表、卡片集和交互式网络工具使用。

Abstract: Many of the challenges encountered in in-the-wild public deployments of robots remain undocumented despite sharing many common pitfalls. This creates a high barrier of entry and results in repetition of avoidable mistakes. To articulate the tacit knowledge in the HRI community, this paper presents a guideline in the form of a checklist to support researchers in preparing for robot deployments in public. Drawing on their own experience with public robot deployments, the research team collected essential topics to consider in public HRI research. These topics are represented as modular flip cards in a hierarchical table, structured into deployment phases and important domains. We interviewed six interdisciplinary researchers with expertise in public HRI and show how including community input refines the checklist. We further show the checklist in action in context of real public studies. Finally, we contribute the checklist as an open-source, customizable community resource that both collects joint expertise for continual evolution and is usable as a list, set of cards, and an interactive web tool.

</details>


### [267] [Path planning for unmanned surface vehicle based on predictive artificial potential field. International Journal of Advanced Robotic Systems](https://arxiv.org/abs/2602.19062)
*Jia Song,Ce Hao,Jiangcheng Su*

Main category: cs.RO

TL;DR: 该论文提出了一种结合时间信息和预测势的新预测人工势场，通过角度限制、速度调整和预测势改进路径规划，有效减少航行时间和能源消耗。


<details>
  <summary>Details</summary>
Motivation: 高速无人水面艇的路径规划需要更复杂的解决方案以减少航行时间和节省能源。

Method: 研究首先分析了最先进的传统人工势场及其在全局和局部路径规划中的缺点，随后引入了三种修改：角度限制、速度调整和预测势，以增强生成路径的可行性和平坦性。

Result: 仿真结果验证了预测人工势场解决了凹形局部最小值问题，提高了特殊场景下的可达性，最终生成了更高效的路径。

Conclusion: 该研究提出的预测人工势场方法成功解决了传统方法的局限性，通过限制最大转向角、缩短航行时间和智能避障，为高速无人水面艇生成了更高效的路径，减少了航行时间和能源消耗。

Abstract: Path planning for high-speed unmanned surface vehicles requires more complex solutions to reduce sailing time and save energy. This article proposes a new predictive artificial potential field that incorporates time information and predictive potential to plan smoother paths. It explores the principles of the artificial potential field, considering vehicle dynamics and local minimum reachability. The study first analyzes the most advanced traditional artificial potential field and its drawbacks in global and local path planning. It then introduces three modifications to the predictive artificial potential field-angle limit, velocity adjustment, and predictive potential to enhance the feasibility and flatness of the generated path. A comparison between the traditional and predictive artificial potential fields demonstrates that the latter successfully restricts the maximum turning angle, shortens sailing time, and intelligently avoids obstacles. Simulation results further verify that the predictive artificial potential field addresses the concave local minimum problem and improves reachability in special scenarios, ultimately generating a more efficient path that reduces sailing time and conserves energy for unmanned surface vehicles.

</details>


### [268] [Design, Locomotion, and Control of Amphibious Robots: Recent Advances](https://arxiv.org/abs/2602.19077)
*Yi Jin,Chang Liu,Roger D. Quinn,Robert J. Wood,C. Chase Cao*

Main category: cs.RO

TL;DR: 本文综述了水陆两栖机器人在运动机制、驱动技术和控制集成方面的进展，指出了未来研究的挑战和方向。


<details>
  <summary>Details</summary>
Motivation: 水陆两栖机器人在保护、灾害响应和国防等领域的应用需求推动了相关技术的发展。

Method: 通过回顾和分析水陆两栖机器人的运动机制、驱动技术和传感器控制集成等方面的研究进展。

Result: 综述了水陆两栖机器人在运动策略、基于材料的驱动器和控制系统方面的最新进展，并提出了未来的挑战和机遇。

Conclusion: 本文总结了水陆两栖机器人的最新进展，并指出了未来研究的方向，以实现更高效、更具弹性和多功能的水陆两栖机器人。

Abstract: Amphibious robots, operating seamlessly across land and water, are advancing applications in conservation, disaster response, and defense. Their performance depends on locomotion mechanisms, actuation technologies, and sensor-control integration. This review highlights recent progress in these areas, examining movement strategies, material-based actuators, and control systems for autonomy and adaptability. Challenges and opportunities are outlined to guide future research toward more efficient, resilient, and multifunctional amphibious robots.

</details>


### [269] [A User-driven Design Framework for Robotaxi](https://arxiv.org/abs/2602.19107)
*Yue Deng,Changyang He*

Main category: cs.RO

TL;DR: 研究通过真实体验和访谈发现，无人驾驶出租车吸引用户的因素包括低成本和社会推荐，但也存在透明度和灵活性等问题，提出了用户驱动的设计框架。


<details>
  <summary>Details</summary>
Motivation: 研究填补了现有文献中对乘客在无人驾驶出租车中实际体验和评价的空白，超越了以往依赖模拟或假设场景的研究。

Method: 通过18次半结构化访谈和自民族志乘车体验，研究了真实世界中的无人驾驶出租车使用情况。

Result: 用户被无人驾驶出租车的低成本、社交推荐和好奇心吸引，但也面临灵活性不足、透明度低、管理困难、边缘案例鲁棒性问题和紧急处理担忧等挑战。体验还涉及隐私、安全、伦理和信任问题。

Conclusion: 基于研究发现，提出了一个用户驱动的设计框架，涵盖从预约到反馈的整个乘车流程，以指导无人驾驶出租车的交互和服务设计。

Abstract: Robotaxis are emerging as a promising form of urban mobility, yet research has largely emphasized technical driving performance while leaving open how passengers experience and evaluate rides without a human driver. To address the limitations of prior work that often relies on simulated or hypothetical settings, we investigate real-world robotaxi use through 18 semi-structured interviews and autoethnographic ride experiences. We found that users were drawn to robotaxis by low cost, social recommendation, and curiosity. They valued a distinctive set of benefits, such as an increased sense of agency, and consistent driving behavioral consistency and standardized ride experiences. However, they encountered persistent challenges around limited flexibility, insufficient transparency, management difficulty, robustness concerns in edge cases, and emergency handling concerns. Robotaxi experiences were shaped by privacy, safety, ethics, and trust. Users were often privacy-indifferent yet sensitive to opaque access and leakage risks; safety perceptions were polarized; and ethical considerations surfaced round issues such as accountability, feedback responsibility and absence of human-like social norms. Based on these findings, we propose a user-driven design framework spanning the end-to-end journey, such as pre-ride configuration (hailing), context-aware pickup facilitation (pick-up) in-ride explainability (traveling), and accountable post-ride feedback (drop-off) to guide robotaxi interaction and service design.

</details>


### [270] [Understanding Fire Through Thermal Radiation Fields for Mobile Robots](https://arxiv.org/abs/2602.19108)
*Anton R. Wagner,Madhan Balaji Rao,Xuesu Xiao,Sören Pirk*

Main category: cs.RO

TL;DR: 研究提出了一种通过构建实时热辐射场使机器人在火灾环境中安全导航的方法，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 火灾环境中的安全移动是自主移动机器人在灾难响应中的关键能力，本研究旨在解决这一问题。

Method: 通过注册深度和热图像获得带有温度值的3D点云，利用斯特藩-玻尔兹曼定律估算空置空间的热辐射，构建连续的热辐射场，并将热约束嵌入成本地图以计算无碰撞且热安全的路径。

Result: 在波士顿动力Spot机器人上的控制实验中，验证了机器人能够避开危险区域并达到导航目标。

Conclusion: 该研究提出了一种新颖的方法，使移动机器人能够在火灾环境中安全导航，通过构建实时热辐射场并嵌入热约束，成功验证了机器人在控制实验中的避障能力，为自主部署在火灾环境中的机器人应用铺平了道路。

Abstract: Safely moving through environments affected by fire is a critical capability for autonomous mobile robots deployed in disaster response. In this work, we present a novel approach for mobile robots to understand fire through building real-time thermal radiation fields. We register depth and thermal images to obtain a 3D point cloud annotated with temperature values. From these data, we identify fires and use the Stefan-Boltzmann law to approximate the thermal radiation in empty spaces. This enables the construction of a continuous thermal radiation field over the environment. We show that this representation can be used for robot navigation, where we embed thermal constraints into the cost map to compute collision-free and thermally safe paths. We validate our approach on a Boston Dynamics Spot robot in controlled experimental settings. Our experiments demonstrate the robot's ability to avoid hazardous regions while still reaching navigation goals. Our approach paves the way toward mobile robots that can be autonomously deployed in fire-affected environments, with potential applications in search-and-rescue, firefighting, and hazardous material response.

</details>


### [271] [Distributed and Consistent Multi-Robot Visual-Inertial-Ranging Odometry on Lie Groups](https://arxiv.org/abs/2602.19173)
*Ziwei Kang,Yizhi Zhou*

Main category: cs.RO

TL;DR: DC-VIRO框架通过融合VIO和UWB测量，提升多机器人在GPS拒止环境中的定位精度和鲁棒性，同时支持锚点自校准。


<details>
  <summary>Details</summary>
Motivation: 在GPS拒止环境中，多机器人系统需要可靠的定位。现有UWB辅助VIO方法多针对单机器人且依赖预校准锚点，限制了实际应用的鲁棒性。

Method: 提出了一种分布式协作视觉-惯性-测距里程计（DC-VIRO）框架，将VIO和UWB测量紧密融合，并利用机器人间通信共享锚点观测以提供额外几何约束。

Result: 仿真结果表明，DC-VIRO显著提高了多机器人系统的定位精度和鲁棒性，并实现了锚点自校准。

Conclusion: DC-VIRO框架通过紧密融合多机器人的VIO和UWB测量，显著提高了定位精度和鲁棒性，并在分布式设置中实现了锚点自校准。

Abstract: Reliable localization is a fundamental requirement for multi-robot systems operating in GPS-denied environments. Visual-inertial odometry (VIO) provides lightweight and accurate motion estimation but suffers from cumulative drift in the absence of global references. Ultra-wideband (UWB) ranging offers complementary global observations, yet most existing UWB-aided VIO methods are designed for single-robot scenarios and rely on pre-calibrated anchors, which limits their robustness in practice. This paper proposes a distributed collaborative visual-inertial-ranging odometry (DC-VIRO) framework that tightly fuses VIO and UWB measurements across multiple robots. Anchor positions are explicitly included in the system state to address calibration uncertainty, while shared anchor observations are exploited through inter-robot communication to provide additional geometric constraints. By leveraging a right-invariant error formulation on Lie groups, the proposed approach preserves the observability properties of standard VIO, ensuring estimator consistency. Simulation results with multiple robots demonstrate that DC-VIRO significantly improves localization accuracy and robustness, while simultaneously enabling anchor self-calibration in distributed settings.

</details>


### [272] [Distributional Stability of Tangent-Linearized Gaussian Inference on Smooth Manifolds](https://arxiv.org/abs/2602.19179)
*Junghoon Seo,Hakjin Lee,Jaehoon Sim*

Main category: cs.RO

TL;DR: 论文研究了平滑流形上的高斯推断，推导了稳定性界限，实验验证了校准转换点，并提供了切换推断方法的触发器。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决机器人学中平滑流形上的高斯推断问题，因为精确的边缘化和条件化通常是非高斯且依赖于几何的。

Method: 论文采用切线线性化的高斯推断方法，推导了投影边缘化和表面测量条件的显式非渐近W2稳定性界限。

Result: 实验结果验证了预测的校准转换点（√‖Σ‖op/R≈1/6），并表明当局部性失效时，法向不确定性是主要失效模式。

Conclusion: 该论文的结论是，基于切线线性化的高斯推断在平滑流形上具有明确的非渐近稳定性界限，实验验证了预测的校准转换点，并提供了从单图线性化切换到多图或基于样本的流形推断的实用触发器。

Abstract: Gaussian inference on smooth manifolds is central to robotics, but exact marginalization and conditioning are generally non-Gaussian and geometry-dependent. We study tangent-linearized Gaussian inference and derive explicit non-asymptotic $W_2$ stability bounds for projection marginalization and surface-measure conditioning. The bounds separate local second-order geometric distortion from nonlocal tail leakage and, for Gaussian inputs, yield closed-form diagnostics from $(μ,Σ)$ and curvature/reach surrogates. Circle and planar-pushing experiments validate the predicted calibration transition near $\sqrt{\|Σ\|_{\mathrm{op}}}/R\approx 1/6$ and indicate that normal-direction uncertainty is the dominant failure mode when locality breaks. These diagnostics provide practical triggers for switching from single-chart linearization to multi-chart or sample-based manifold inference.

</details>


### [273] [Human-to-Robot Interaction: Learning from Video Demonstration for Robot Imitation](https://arxiv.org/abs/2602.19184)
*Thanh Nguyen Canh,Thanh-Tuan Tran,Haolan Zhang,Ziyan Gao,Nak Young Chong,Xiem HoangVan*

Main category: cs.RO

TL;DR: 提出模块化模仿学习框架，显著提升视频到机器人操作的准确性和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有视频演示直接转化为机器人操作的方法存在全局特征优先和泛化能力不足的问题。

Method: 采用模块化框架，分为视频理解（结合TSM和VLM）和机器人模仿（基于TD3的深度强化学习）两阶段。

Result: 视频理解阶段动作分类准确率达89.97%，BLEU-4分数在标准和新物体上分别提升76.4%和128.4%；机器人操作平均成功率87.5%。

Conclusion: 该论文提出了一种新颖的“人机”模仿学习框架，通过模块化设计解决了视频演示直接转化为机器人操作的难题，并在仿真和实际实验中验证了其高效性。

Abstract: Learning from Demonstration (LfD) offers a promising paradigm for robot skill acquisition. Recent approaches attempt to extract manipulation commands directly from video demonstrations, yet face two critical challenges: (1) general video captioning models prioritize global scene features over task-relevant objects, producing descriptions unsuitable for precise robotic execution, and (2) end-to-end architectures coupling visual understanding with policy learning require extensive paired datasets and struggle to generalize across objects and scenarios. To address these limitations, we propose a novel ``Human-to-Robot'' imitation learning pipeline that enables robots to acquire manipulation skills directly from unstructured video demonstrations, inspired by the human ability to learn by watching and imitating. Our key innovation is a modular framework that decouples the learning process into two distinct stages: (1) Video Understanding, which combines Temporal Shift Modules (TSM) with Vision-Language Models (VLMs) to extract actions and identify interacted objects, and (2) Robot Imitation, which employs TD3-based deep reinforcement learning to execute the demonstrated manipulations. We validated our approach in PyBullet simulation environments with a UR5e manipulator and in a real-world experiment with a UF850 manipulator across four fundamental actions: reach, pick, move, and put. For video understanding, our method achieves 89.97% action classification accuracy and BLEU-4 scores of 0.351 on standard objects and 0.265 on novel objects, representing improvements of 76.4% and 128.4% over the best baseline, respectively. For robot manipulation, our framework achieves an average success rate of 87.5% across all actions, with 100% success on reaching tasks and up to 90% on complex pick-and-place operations. The project website is available at https://thanhnguyencanh.github.io/LfD4hri.

</details>


### [274] [Visual Prompt Guided Unified Pushing Policy](https://arxiv.org/abs/2602.19193)
*Hieu Bui,Ziyan Gao,Yuya Hosoda,Joo-Ho Lee*

Main category: cs.RO

TL;DR: 提出一种结合轻量级提示的统一推动策略，提升推动动作的通用性和效率，适用于多种规划任务。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖多步推动计划和预定义推动原语，应用范围有限，效率和通用性不足。

Method: 将轻量级提示机制融入流匹配策略，生成反应性、多模态的推动动作。

Result: 实验结果表明，统一推动策略性能优于现有基线，并能高效应用于不同规划问题。

Conclusion: 提出的统一推动策略不仅性能优于现有基线，还能作为低级原语在VLM引导的规划框架中高效解决桌面清洁任务。

Abstract: As one of the simplest non-prehensile manipulation skills, pushing has been widely studied as an effective means to rearrange objects. Existing approaches, however, typically rely on multi-step push plans composed of pre-defined pushing primitives with limited application scopes, which restrict their efficiency and versatility across different scenarios. In this work, we propose a unified pushing policy that incorporates a lightweight prompting mechanism into a flow matching policy to guide the generation of reactive, multimodal pushing actions. The visual prompt can be specified by a high-level planner, enabling the reuse of the pushing policy across a wide range of planning problems. Experimental results demonstrate that the proposed unified pushing policy not only outperforms existing baselines but also effectively serves as a low-level primitive within a VLM-guided planning framework to solve table-cleaning tasks efficiently.

</details>


### [275] [The Price Is Not Right: Neuro-Symbolic Methods Outperform VLAs on Structured Long-Horizon Manipulation Tasks with Significantly Lower Energy Consumption](https://arxiv.org/abs/2602.19260)
*Timothy Duggan,Pierrick Lorang,Hong Lu,Matthias Scheutz*

Main category: cs.RO

TL;DR: 神经符号架构在长时程操作任务中优于VLA模型，尤其在成功率和能源效率方面。


<details>
  <summary>Details</summary>
Motivation: 评估VLA模型在结构化、长时程操作任务中的有效性和效率。

Method: 对VLA模型π0进行微调，并与基于PDDL的符号规划和低级控制学习的神经符号架构进行对比。

Result: 神经符号模型在3块任务中成功率95%，VLA模型仅34%；4块任务中神经符号模型成功率78%，VLA模型失败。VLA微调能耗比神经符号方法高近两个数量级。

Conclusion: 神经符号架构在结构化、长时程操作任务中表现优于端到端VLA模型，尤其在可靠性、数据效率和能源效率方面。

Abstract: Vision-Language-Action (VLA) models have recently been proposed as a pathway toward generalist robotic policies capable of interpreting natural language and visual inputs to generate manipulation actions. However, their effectiveness and efficiency on structured, long-horizon manipulation tasks remain unclear. In this work, we present a head-to-head empirical comparison between a fine-tuned open-weight VLA model π0 and a neuro-symbolic architecture that combines PDDL-based symbolic planning with learned low-level control. We evaluate both approaches on structured variants of the Towers of Hanoi manipulation task in simulation while measuring both task performance and energy consumption during training and execution. On the 3-block task, the neuro-symbolic model achieves 95% success compared to 34% for the best-performing VLA. The neuro-symbolic model also generalizes to an unseen 4-block variant (78% success), whereas both VLAs fail to complete the task. During training, VLA fine-tuning consumes nearly two orders of magnitude more energy than the neuro-symbolic approach. These results highlight important trade-offs between end-to-end foundation-model approaches and structured reasoning architectures for long-horizon robotic manipulation, emphasizing the role of explicit symbolic structure in improving reliability, data efficiency, and energy efficiency. Code and models are available at https://price-is-not-right.github.io

</details>


### [276] [3D Shape Control of Extensible Multi-Section Soft Continuum Robots via Visual Servoing](https://arxiv.org/abs/2602.19273)
*Abhinav Gandhi,Shou-Shan Chiang,Cagdas D. Onal,Berk Calli*

Main category: cs.RO

TL;DR: 提出了一种基于视觉的全局稳定控制算法，用于调节多节软连续机械臂的整体形状，实验验证了其高精度和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉控制算法仅调节机械臂末端位姿，无法利用其运动冗余性，且存在局部极小值问题。本文旨在开发一种全局稳定且无需本体感受信息的控制方法。

Method: 采用基于模型的2.5D形状视觉伺服控制，无需本体感受传感器信息，仅通过外部摄像头获取机械臂整体形状图像，结合逆运动学求解器生成参考特征。

Result: 实验表明，控制器能够精确调节机械臂整体形状，稳态误差小于1毫米，并成功完成了堆叠、倾倒和拉动等概念验证任务。

Conclusion: 论文提出了一种新型的基于视觉的控制算法，能够有效调节多节软连续机械臂的整体形状，并通过实验验证了其精确性和稳定性。

Abstract: In this paper, we propose a novel vision-based control algorithm for regulating the whole body shape of extensible multisection soft continuum manipulators. Contrary to existing vision-based control algorithms in the literature that regulate the robot's end effector pose, our proposed control algorithm regulates the robot's whole body configuration, enabling us to leverage its kinematic redundancy. Additionally, our model-based 2.5D shape visual servoing provides globally stable asymptotic convergence in the robot's 3D workspace compared to the closest works in the literature that report local minima. Unlike existing visual servoing algorithms in the literature, our approach does not require information from proprioceptive sensors, making it suitable for continuum manipulators without such capabilities. Instead, robot state is estimated from images acquired by an external camera that observes the robot's whole body shape and is also utilized to close the shape control loop. Traditionally, visual servoing schemes require an image of the robot at its reference pose to generate the reference features. In this work, we utilize an inverse kinematics solver to generate reference features for the desired robot configuration and do not require images of the robot at the reference. Experiments are performed on a multisection continuum manipulator demonstrating the controller's capability to regulate the robot's whole body shape while precisely positioning the robot's end effector. Results validate our controller's ability to regulate the shape of continuum robots while demonstrating a smooth transient response and a steady-state error within 1 mm. Proof-of-concept object manipulation experiments including stacking, pouring, and pulling tasks are performed to demonstrate our controller's applicability.

</details>


### [277] [Safe and Interpretable Multimodal Path Planning for Multi-Agent Cooperation](https://arxiv.org/abs/2602.19304)
*Haojun Shi,Suyu Ye,Katherine M. Guerrerio,Jianzhi Shen,Yifan Yin,Daniel Khashabi,Chien-Ming Huang,Tianmin Shu*

Main category: cs.RO

TL;DR: CaPE是一种安全、可解释的多模态路径规划方法，通过语言通信和视觉语言模型实现路径调整，提升多代理合作的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 在分散式代理中，快速适应其他代理的行为对成功合作至关重要，尤其是在无法预测彼此意图和计划时，语言通信对确保安全性尤为关键。

Method: 提出了一种安全且可解释的多模态路径规划方法CaPE，利用视觉语言模型（VLM）合成路径编辑程序，并通过基于模型的规划器进行验证。

Result: 实验结果表明，CaPE可以作为即插即用模块集成到不同机器人系统中，显著提升机器人根据其他机器人或人类的语言通信调整计划的能力。

Conclusion: CaPE结合了基于视觉语言模型的路径编辑程序合成和基于模型规划的安全性，使机器人能够在保持安全性和可解释性的同时实现开放式合作。

Abstract: Successful cooperation among decentralized agents requires each agent to quickly adapt its plan to the behavior of other agents. In scenarios where agents cannot confidently predict one another's intentions and plans, language communication can be crucial for ensuring safety. In this work, we focus on path-level cooperation in which agents must adapt their paths to one another in order to avoid collisions or perform physical collaboration such as joint carrying. In particular, we propose a safe and interpretable multimodal path planning method, CaPE (Code as Path Editor), which generates and updates path plans for an agent based on the environment and language communication from other agents. CaPE leverages a vision-language model (VLM) to synthesize a path editing program verified by a model-based planner, grounding communication to path plan updates in a safe and interpretable way. We evaluate our approach in diverse simulated and real-world scenarios, including multi-robot and human-robot cooperation in autonomous driving, household, and joint carrying tasks. Experimental results demonstrate that CaPE can be integrated into different robotic systems as a plug-and-play module, greatly enhancing a robot's ability to align its plan to language communication from other robots or humans. We also show that the combination of the VLM-based path editing program synthesis and model-based planning safety enables robots to achieve open-ended cooperation while maintaining safety and interpretability.

</details>


### [278] [WildOS: Open-Vocabulary Object Search in the Wild](https://arxiv.org/abs/2602.19308)
*Hardik Shah,Erica Tevere,Deegan Atha,Marcel Kaufmann,Shehryar Khattak,Manthan Patel,Marco Hutter,Jonas Frey,Patrick Spieler*

Main category: cs.RO

TL;DR: WildOS结合几何与语义视觉推理，提升户外自主导航性能，实验证明其优于纯几何或视觉方法。


<details>
  <summary>Details</summary>
Motivation: 在复杂无结构的户外环境中，仅依赖几何边界进行探索往往不足，需要结合语义推理以实现稳健高效的探索。

Method: WildOS构建稀疏导航图，利用基于基础模型的视觉模块ExploRFM对图的边界节点进行评分，同时预测可穿越性、视觉边界和对象相似性。此外，引入基于粒子滤波的方法进行粗略定位。

Result: 广泛的闭环实地实验表明，WildOS在效率和自主性上显著优于纯几何和纯视觉基线。

Conclusion: WildOS结合几何探索与语义视觉推理，显著提升了复杂户外环境中的自主导航性能，展示了视觉基础模型在开放世界机器人行为中的潜力。

Abstract: Autonomous navigation in complex, unstructured outdoor environments requires robots to operate over long ranges without prior maps and limited depth sensing. In such settings, relying solely on geometric frontiers for exploration is often insufficient. In such settings, the ability to reason semantically about where to go and what is safe to traverse is crucial for robust, efficient exploration. This work presents WildOS, a unified system for long-range, open-vocabulary object search that combines safe geometric exploration with semantic visual reasoning. WildOS builds a sparse navigation graph to maintain spatial memory, while utilizing a foundation-model-based vision module, ExploRFM, to score frontier nodes of the graph. ExploRFM simultaneously predicts traversability, visual frontiers, and object similarity in image space, enabling real-time, onboard semantic navigation tasks. The resulting vision-scored graph enables the robot to explore semantically meaningful directions while ensuring geometric safety. Furthermore, we introduce a particle-filter-based method for coarse localization of the open-vocabulary target query, that estimates candidate goal positions beyond the robot's immediate depth horizon, enabling effective planning toward distant goals. Extensive closed-loop field experiments across diverse off-road and urban terrains demonstrate that WildOS enables robust navigation, significantly outperforming purely geometric and purely vision-based baselines in both efficiency and autonomy. Our results highlight the potential of vision foundation models to drive open-world robotic behaviors that are both semantically informed and geometrically grounded. Project Page: https://leggedrobotics.github.io/wildos/

</details>


### [279] [TOPReward: Token Probabilities as Hidden Zero-Shot Rewards for Robotics](https://arxiv.org/abs/2602.19313)
*Shirui Chen,Cole Harrison,Ying-Chun Lee,Angela Jin Yang,Zhongzheng Ren,Lillian J. Ratliff,Jiafei Duan,Dieter Fox,Ranjay Krishna*

Main category: cs.RO

TL;DR: TOPReward是一种新型时间价值函数，利用预训练视频视觉语言模型的内部知识估计任务进度，显著提升强化学习中的样本效率和奖励稀疏性问题。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言动作模型在强化学习中样本效率低和奖励稀疏的问题，开发能够提供细粒度反馈的通用过程奖励模型。

Method: TOPReward直接从视觉语言模型的内部令牌逻辑中提取任务进度，避免了数值误表示的问题。

Result: 在130多个不同的真实世界任务和多个机器人平台上，TOPReward在Qwen3-VL上实现了0.947的平均价值顺序相关性（VOC），显著优于现有技术。

Conclusion: TOPReward作为一种基于概率的时间价值函数，通过利用预训练视频视觉语言模型的潜在世界知识来估计机器人任务进度，显著提升了样本效率和奖励稀疏性问题，并在零样本评估中表现优异。

Abstract: While Vision-Language-Action (VLA) models have seen rapid progress in pretraining, their advancement in Reinforcement Learning (RL) remains hampered by low sample efficiency and sparse rewards in real-world settings. Developing generalizable process reward models is essential for providing the fine-grained feedback necessary to bridge this gap, yet existing temporal value functions often fail to generalize beyond their training domains. We introduce TOPReward, a novel, probabilistically grounded temporal value function that leverages the latent world knowledge of pretrained video Vision-Language Models (VLMs) to estimate robotic task progress. Unlike prior methods that prompt VLMs to directly output progress values, which are prone to numerical misrepresentation, TOPReward extracts task progress directly from the VLM's internal token logits. In zero-shot evaluations across 130+ distinct real-world tasks and multiple robot platforms (e.g., Franka, YAM, SO-100/101), TOPReward achieves 0.947 mean Value-Order Correlation (VOC) on Qwen3-VL, dramatically outperforming the state-of-the-art GVL baseline which achieves near-zero correlation on the same open-source model. We further demonstrate that TOPReward serves as a versatile tool for downstream applications, including success detection and reward-aligned behavior cloning.

</details>


### [280] [Online Navigation Planning for Long-term Autonomous Operation of Underwater Gliders](https://arxiv.org/abs/2602.19315)
*Victor-Alexandru Darvariu,Charlotte Z. Reed,Jan Stratmann,Bruno Lacerda,Benjamin Allsup,Stephen Woodward,Elizabeth Siddle,Trishna Saeharaseelan,Owain Jones,Dan Jones,Tobias Ferreira,Chloe Baker,Kevin Chaplin,James Kirk,Ashley Morris,Ryan Patmore,Jeff Polton,Charlotte Williams,Alexandra Kokkinaki,Alvaro Lorenzo Lopez,Justin J. H. Buck,Nick Hawes*

Main category: cs.RO

TL;DR: 论文提出了一种基于蒙特卡洛树搜索的滑翔机器人导航规划方法，通过物理信息模拟器和历史数据拟合，实现了高效的长期自主操作。


<details>
  <summary>Details</summary>
Motivation: 尽管水下滑翔机器人已成为海洋采样的重要工具，但缺乏适合的方法和系统来管理大规模滑翔机群，导致长期自主部署的成功案例稀少。

Method: 将滑翔机器人导航规划建模为随机最短路径马尔可夫决策过程，并开发了一种基于蒙特卡洛树搜索的样本在线规划器，结合物理信息模拟器生成样本。

Result: 在北海进行的两次实地部署中，总计约3个月和1000公里的自主操作，验证了该系统相比直线导航的效率提升。

Conclusion: 该论文提出了一种基于蒙特卡洛树搜索的样本在线规划方法，用于水下滑翔机器人的导航规划，并通过实际部署验证了其高效性和实用性。

Abstract: Underwater glider robots have become an indispensable tool for ocean sampling. Although stakeholders are calling for tools to manage increasingly large fleets of gliders, successful autonomous long-term deployments have thus far been scarce, which hints at a lack of suitable methodologies and systems. In this work, we formulate glider navigation planning as a stochastic shortest-path Markov Decision Process and propose a sample-based online planner based on Monte Carlo Tree Search. Samples are generated by a physics-informed simulator that captures uncertain execution of controls and ocean current forecasts while remaining computationally tractable. The simulator parameters are fitted using historical glider data. We integrate these methods into an autonomous command-and-control system for Slocum gliders that enables closed-loop replanning at each surfacing. The resulting system was validated in two field deployments in the North Sea totalling approximately 3 months and 1000 km of autonomous operation. Results demonstrate improved efficiency compared to straight-to-goal navigation and show the practicality of sample-based planning for long-term marine autonomy.

</details>


### [281] [Design and Control of Modular Magnetic Millirobots for Multimodal Locomotion and Shape Reconfiguration](https://arxiv.org/abs/2602.19346)
*Erik Garcia Oyono,Jialin Lin,Dandan Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种模块化磁性毫米机器人平台，通过三个功能模块和可编程磁场输入，实现了多模式行为和稳健控制，展示了在受限环境中的适应性任务执行潜力。


<details>
  <summary>Details</summary>
Motivation: 现有模块化磁性平台通常依赖工作空间碰撞进行重构，使用笨重的三维电磁系统，且缺乏稳健的单模块控制，限制了其在生物医学环境中的应用。

Method: 平台由三个立方体模块组成，每个模块嵌入永磁体并具有特定功能：自由模块（支持自组装和重构）、固定模块（实现翻转行走运动）和夹持模块（用于货物操作）。运动和重构通过可编程的二维均匀和梯度磁场输入实现。

Result: 实验展示了闭环导航、自组装、多模式转换和低场强下的拆卸功能。链到夹持器的转换成功率为90%，链到方形的转换一致性较低，凸显了模块几何形状对重构可靠性的影响。

Conclusion: 该研究展示了一个多功能模块化磁性毫米机器人平台，能够在受限环境中实现多模式行为和稳健控制，为可扩展和适应性任务执行提供了有前景的路径。

Abstract: Modular small-scale robots offer the potential for on-demand assembly and disassembly, enabling task-specific adaptation in dynamic and constrained environments. However, existing modular magnetic platforms often depend on workspace collisions for reconfiguration, employ bulky three-dimensional electromagnetic systems, and lack robust single-module control, which limits their applicability in biomedical settings. In this work, we present a modular magnetic millirobotic platform comprising three cube-shaped modules with embedded permanent magnets, each designed for a distinct functional role: a free module that supports self-assembly and reconfiguration, a fixed module that enables flip-and-walk locomotion, and a gripper module for cargo manipulation. Locomotion and reconfiguration are actuated by programmable combinations of time-varying two-dimensional uniform and gradient magnetic field inputs. Experiments demonstrate closed-loop navigation using real-time vision feedback and A* path planning, establishing robust single-module control capabilities. Beyond locomotion, the system achieves self-assembly, multimodal transformations, and disassembly at low field strengths. Chain-to-gripper transformations succeeded in 90% of trials, while chain-to-square transformations were less consistent, underscoring the role of module geometry in reconfiguration reliability. These results establish a versatile modular robotic platform capable of multimodal behavior and robust control, suggesting a promising pathway toward scalable and adaptive task execution in confined environments.

</details>


### [282] [Vid2Sid: Videos Can Help Close the Sim2Real Gap](https://arxiv.org/abs/2602.19359)
*Kevin Qiu,Yu Zhang,Marek Cygan,Josie Hughes*

Main category: cs.RO

TL;DR: Vid2Sid是一个视频驱动的系统识别管道，通过结合基础模型感知和VLM优化器，提供可解释的物理参数校准，优于黑盒优化器。


<details>
  <summary>Details</summary>
Motivation: 校准机器人模拟器的物理参数通常通过手动或黑盒优化器完成，这些方法无法解释物理差异如何驱动误差。

Method: Vid2Sid结合基础模型感知和VLM-in-the-loop优化器，分析配对的模拟-现实视频，诊断具体不匹配并提出物理参数更新。

Result: 在未参与训练的sim2real保持控制中，Vid2Sid表现最佳，平均排名最高，且在sim2sim验证中恢复地面真实参数最准确（平均相对误差低于13%）。

Conclusion: Vid2Sid在模拟到现实的保持控制中表现最佳，平均排名最高，同时提供可解释的推理。

Abstract: Calibrating a robot simulator's physics parameters (friction, damping, material stiffness) to match real hardware is often done by hand or with black-box optimizers that reduce error but cannot explain which physical discrepancies drive the error. When sensing is limited to external cameras, the problem is further compounded by perception noise and the absence of direct force or state measurements. We present Vid2Sid, a video-driven system identification pipeline that couples foundation-model perception with a VLM-in-the-loop optimizer that analyzes paired sim-real videos, diagnoses concrete mismatches, and proposes physics parameter updates with natural language rationales. We evaluate our approach on a tendon-actuated finger (rigid-body dynamics in MuJoCo) and a deformable continuum tentacle (soft-body dynamics in PyElastica). On sim2real holdout controls unseen during training, Vid2Sid achieves the best average rank across all settings, matching or exceeding black-box optimizers while uniquely providing interpretable reasoning at each iteration. Sim2sim validation confirms that Vid2Sid recovers ground-truth parameters most accurately (mean relative error under 13\% vs. 28--98\%), and ablation analysis reveals three calibration regimes. VLM-guided optimization excels when perception is clean and the simulator is expressive, while model-class limitations bound performance in more challenging settings.

</details>


### [283] [Seeing Farther and Smarter: Value-Guided Multi-Path Reflection for VLM Policy Optimization](https://arxiv.org/abs/2602.19372)
*Yanting Yang,Shenyuan Gao,Qingwen Bu,Li Chen,Dimitris N. Metaxas*

Main category: cs.RO

TL;DR: 提出新框架，通过解耦状态评估与动作生成、光束搜索和轻量级触发机制，显著提升机器人操作任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖低效且不准确的隐式状态值学习，仅评估单一贪婪未来，且推理延迟高，无法满足复杂、长视野机器人操作任务的需求。

Method: 采用测试时计算框架，显式建模动作计划的优势，使用可扩展的批评器进行估计，并通过光束搜索探索多条未来路径。

Result: 在多样化的未见多阶段机器人操作任务中，成功率提升了24.6%，推理时间减少了56.5%。

Conclusion: 本文提出的方法通过解耦状态评估与动作生成，引入光束搜索和轻量级触发机制，显著提升了机器人操作任务的成功率并降低了推理时间。

Abstract: Solving complex, long-horizon robotic manipulation tasks requires a deep understanding of physical interactions, reasoning about their long-term consequences, and precise high-level planning. Vision-Language Models (VLMs) offer a general perceive-reason-act framework for this goal. However, previous approaches using reflective planning to guide VLMs in correcting actions encounter significant limitations. These methods rely on inefficient and often inaccurate implicit learning of state-values from noisy foresight predictions, evaluate only a single greedy future, and suffer from substantial inference latency. To address these limitations, we propose a novel test-time computation framework that decouples state evaluation from action generation. This provides a more direct and fine-grained supervisory signal for robust decision-making. Our method explicitly models the advantage of an action plan, quantified by its reduction in distance to the goal, and uses a scalable critic to estimate. To address the stochastic nature of single-trajectory evaluation, we employ beam search to explore multiple future paths and aggregate them during decoding to model their expected long-term returns, leading to more robust action generation. Additionally, we introduce a lightweight, confidence-based trigger that allows for early exit when direct predictions are reliable, invoking reflection only when necessary. Extensive experiments on diverse, unseen multi-stage robotic manipulation tasks demonstrate a 24.6% improvement in success rate over state-of-the-art baselines, while significantly reducing inference time by 56.5%.

</details>


### [284] [Hilbert-Augmented Reinforcement Learning for Scalable Multi-Robot Coverage and Exploration](https://arxiv.org/abs/2602.19400)
*Tamil Selvan Gurunathan,Aryya Gangopadhyay*

Main category: cs.RO

TL;DR: 提出了一种结合Hilbert空间填充曲线的多机器人覆盖框架，显著提升了覆盖效率和收敛速度，并在实际机器人上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决稀疏奖励环境下多机器人学习的探索冗余问题，并提升覆盖效率。

Method: 通过将Hilbert空间填充先验与DQN和PPO算法结合，构建空间索引以优化探索过程，并设计了一种将Hilbert排序转化为曲率受限、时间参数化SE(2)轨迹的接口。

Result: 实验表明，该方法在覆盖效率、冗余度和收敛速度上优于DQN/PPO基线，并在Boston Dynamics Spot腿式机器人上验证了其可行性。

Conclusion: 几何先验（如Hilbert空间填充曲线）能显著提升群机器人和腿式机器人的自主性与可扩展性。

Abstract: We present a coverage framework that integrates Hilbert space-filling priors into decentralized multi-robot learning and execution. We augment DQN and PPO with Hilbert-based spatial indices to structure exploration and reduce redundancy in sparse-reward environments, and we evaluate scalability in multi-robot grid coverage. We further describe a waypoint interface that converts Hilbert orderings into curvature-bounded, time-parameterized SE(2) trajectories (planar (x, y, θ)), enabling onboard feasibility on resource-constrained robots. Experiments show improvements in coverage efficiency, redundancy, and convergence speed over DQN/PPO baselines. In addition, we validate the approach on a Boston Dynamics Spot legged robot, executing the generated trajectories in indoor environments and observing reliable coverage with low redundancy. These results indicate that geometric priors improve autonomy and scalability for swarm and legged robotics.

</details>


### [285] [Botson: An Accessible and Low-Cost Platform for Social Robotics Research](https://arxiv.org/abs/2602.19491)
*Samuel Bellaire,Abdalmalek Abu-raddaha,Natalie Kim,Nathan Morhan,William Elliott,Samir Rawashdeh*

Main category: cs.RO

TL;DR: Botson是一个由LLM驱动的低成本拟人化社交机器人，旨在通过拟人化设计增强AI在人类中心领域的信任。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏非语言社交线索，如语音助手等非实体化代理难以建立信任，这阻碍了AI在人类中心领域的有效整合。

Method: 本文介绍了Botson的架构，这是一个由大型语言模型（LLM）驱动的拟人化社交机器人。

Result: Botson作为一个研究平台，旨在通过拟人化设计解决信任问题。

Conclusion: Botson作为一种低成本、易获取的社交机器人平台，展示了通过拟人化设计增强AI在人类中心领域信任的潜力。

Abstract: Trust remains a critical barrier to the effective integration of Artificial Intelligence (AI) into human-centric domains. Disembodied agents, such as voice assistants, often fail to establish trust due to their inability to convey non-verbal social cues. This paper introduces the architecture of Botson: an anthropomorphic social robot powered by a large language model (LLM). Botson was created as a low-cost and accessible platform for social robotics research.

</details>


### [286] [Anticipate, Adapt, Act: A Hybrid Framework for Task Planning](https://arxiv.org/abs/2602.19518)
*Nabanita Dash,Ayush Kaura,Shivam Singh,Ramandeep Singh,Snehasis Banerjee,Mohan Sridharan,K. Madhava Krishna*

Main category: cs.RO

TL;DR: 论文提出了一种结合LLM和RDDL的混合框架，用于预测和适应机器人任务中的失败，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 机器人需要具备预测和适应失败的能力，以便在复杂领域中与人类有效协作。尽管现有的AI规划系统和LLM表现出色，但由于任务及其结果的不确定性，这一能力仍具挑战性。

Method: 论文提出了一种混合框架，将大型语言模型（LLM）的通用预测能力与关系动态影响图语言（RDDL）的概率序列决策能力相结合。机器人通过该框架预测任务中可能出现的失败，并执行预防或恢复行动。

Result: 在VirtualHome 3D仿真环境中的实验评估表明，该方法相比现有基线在性能上有显著提升。

Conclusion: 该论文提出的混合框架通过结合LLM的通用预测能力和RDDL的概率序列决策能力，显著提高了机器人在复杂任务中预测和适应失败的能力。

Abstract: Anticipating and adapting to failures is a key capability robots need to collaborate effectively with humans in complex domains. This continues to be a challenge despite the impressive performance of state of the art AI planning systems and Large Language Models (LLMs) because of the uncertainty associated with the tasks and their outcomes. Toward addressing this challenge, we present a hybrid framework that integrates the generic prediction capabilities of an LLM with the probabilistic sequential decision-making capability of Relational Dynamic Influence Diagram Language. For any given task, the robot reasons about the task and the capabilities of the human attempting to complete it; predicts potential failures due to lack of ability (in the human) or lack of relevant domain objects; and executes actions to prevent such failures or recover from them. Experimental evaluation in the VirtualHome 3D simulation environment demonstrates substantial improvement in performance compared with state of the art baselines.

</details>


### [287] [Bellman Value Decomposition for Task Logic in Safe Optimal Control](https://arxiv.org/abs/2602.19532)
*William Sharpless,Oswin So,Dylan Hirsch,Sylvia Herbert,Chuchu Fan*

Main category: cs.RO

TL;DR: 通过分解贝尔曼值图并嵌入神经网络，VDPPO方法自动平衡安全性和活跃性，显著提升复杂任务性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界任务涉及复杂的目标和安全规范组合，高维度下形式化自动机变得笨拙，稀疏奖励组合需要繁琐调整。

Method: 提出了VDPPO方法，将分解后的贝尔曼值图嵌入到双层神经网络中，利用隐式依赖关系进行自举。

Result: 在涉及异构团队和非线性动力学的复杂高维任务中，该方法显著优于现有基线。

Conclusion: 该方法通过分解贝尔曼值图并嵌入到双层神经网络中，显著提升了复杂高维任务中的性能，自动平衡安全性和活跃性。

Abstract: Real-world tasks involve nuanced combinations of goal and safety specifications. In high dimensions, the challenge is exacerbated: formal automata become cumbersome, and the combination of sparse rewards tends to require laborious tuning. In this work, we consider the innate structure of the Bellman Value as a means to naturally organize the problem for improved automatic performance. Namely, we prove the Bellman Value for a complex task defined in temporal logic can be decomposed into a graph of Bellman Values, connected by a set of well-known Bellman equations (BEs): the Reach-Avoid BE, the Avoid BE, and a novel type, the Reach-Avoid-Loop BE. To solve the Value and optimal policy, we propose VDPPO, which embeds the decomposed Value graph into a two-layer neural net, bootstrapping the implicit dependencies. We conduct a variety of simulated and hardware experiments to test our method on complex, high-dimensional tasks involving heterogeneous teams and nonlinear dynamics. Ultimately, we find this approach greatly improves performance over existing baselines, balancing safety and liveness automatically.

</details>


### [288] [Large Language Model-Assisted UAV Operations and Communications: A Multifaceted Survey and Tutorial](https://arxiv.org/abs/2602.19534)
*Yousef Emami,Hao Zhou,Radha Reddy,Atefeh Hajijamali Arani,Biliang Wang,Kai Li,Luis Almeida,Zhu Han*

Main category: cs.RO

TL;DR: This survey explores LLM integration into UAVs for enhanced intelligence, proposing a unified framework covering adaptation techniques, operations, and ethical considerations.


<details>
  <summary>Details</summary>
Motivation: To enhance UAV intelligence beyond conventional approaches by leveraging LLMs for advanced environmental understanding, swarm coordination, and adaptive operations.

Method: The survey systematically explores LLM integration into UAV systems, presenting a taxonomy of adaptation techniques (pretraining, fine-tuning, RAG, prompt engineering) and reasoning capabilities (CoT, ICL). It examines LLM-assisted communications, operations, and MLLMs for human-swarm interaction.

Result: A unified framework consolidating existing architectures, methodologies, and applications for LLM-assisted UAVs, including navigation, mission planning, swarm control, and network management.

Conclusion: LLM-assisted UAVs are positioned as a foundation for intelligent and adaptive aerial systems, with future research directions addressing ethical considerations like bias, transparency, and accountability.

Abstract: Uncrewed Aerial Vehicles (UAVs) are widely deployed across diverse applications due to their mobility and agility. Recent advances in Large Language Models (LLMs) offer a transformative opportunity to enhance UAV intelligence beyond conventional optimization-based and learning-based approaches. By integrating LLMs into UAV systems, advanced environmental understanding, swarm coordination, mobility optimization, and high-level task reasoning can be achieved, thereby allowing more adaptive and context-aware aerial operations. This survey systematically explores the intersection of LLMs and UAV technologies and proposes a unified framework that consolidates existing architectures, methodologies, and applications for UAVs. We first present a structured taxonomy of LLM adaptation techniques for UAVs, including pretraining, fine-tuning, Retrieval-Augmented Generation (RAG), and prompt engineering, along with key reasoning capabilities such as Chain-of-Thought (CoT) and In-Context Learning (ICL). We then examine LLM-assisted UAV communications and operations, covering navigation, mission planning, swarm control, safety, autonomy, and network management. After that, the survey further discusses Multimodal LLMs (MLLMs) for human-swarm interaction, perception-driven navigation, and collaborative control. Finally, we address ethical considerations, including bias, transparency, accountability, and Human-in-the-Loop (HITL) strategies, and outline future research directions. Overall, this work positions LLM-assisted UAVs as a foundation for intelligent and adaptive aerial systems.

</details>


### [289] [Cost-Aware Diffusion Active Search](https://arxiv.org/abs/2602.19538)
*Arundhati Banerjee,Jeff Schneider*

Main category: cs.RO

TL;DR: 本文提出一种基于扩散模型的主动搜索算法，无需构建搜索树，平衡探索与利用，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有前瞻算法依赖计算昂贵的搜索树的问题，同时优化扩散模型在主动搜索中的乐观偏差。

Method: 利用扩散模型的序列建模能力，采样前瞻动作序列，平衡探索与利用的权衡，无需构建详尽的搜索树。

Result: 算法在完全恢复率和计算效率上优于现有方法。

Conclusion: 本文提出的算法在离线强化学习中优于标准基线，在成本感知的主动决策中比树搜索更高效。

Abstract: Active search for recovering objects of interest through online, adaptive decision making with autonomous agents requires trading off exploration of unknown environments with exploitation of prior observations in the search space. Prior work has proposed information gain and Thompson sampling based myopic, greedy approaches for agents to actively decide query or search locations when the number of targets is unknown. Decision making algorithms in such partially observable environments have also shown that agents capable of lookahead over a finite horizon outperform myopic policies for active search. Unfortunately, lookahead algorithms typically rely on building a computationally expensive search tree that is simulated and updated based on the agent's observations and a model of the environment dynamics. Instead, in this work, we leverage the sequence modeling abilities of diffusion models to sample lookahead action sequences that balance the exploration-exploitation trade-off for active search without building an exhaustive search tree. We identify the optimism bias in prior diffusion based reinforcement learning approaches when applied to the active search setting and propose mitigating solutions for efficient cost-aware decision making with both single and multi-agent teams. Our proposed algorithm outperforms standard baselines in offline reinforcement learning in terms of full recovery rate and is computationally more efficient than tree search in cost-aware active decision making.

</details>


### [290] [Chasing Ghosts: A Simulation-to-Real Olfactory Navigation Stack with Optional Vision Augmentation](https://arxiv.org/abs/2602.19577)
*Kordel K. France,Ovidiu Daescu,Latifur Khan,Rohith Peddi*

Main category: cs.RO

TL;DR: 本文提出了一种开源无人机系统，用于在线气味源定位，使用最小传感器套件，结合定制硬件和学习导航策略，成功在真实环境中验证。


<details>
  <summary>Details</summary>
Motivation: 自主气味源定位对空中机器人仍具挑战性，由于湍流、稀疏和延迟的感官信号，以及严格的负载和计算限制。

Method: 系统集成了定制的嗅觉硬件、机载感知和基于学习的导航策略，该策略在仿真中训练并在真实四旋翼上部署。

Result: 通过在大规模室内环境中使用乙醇源进行真实飞行实验，验证了系统在现实气流条件下的稳定源寻找行为。

Conclusion: 本研究的主要贡献是提供了一个可复现的系统和方法框架，用于在最小化感知假设下实现基于无人机的嗅觉导航和源定位。

Abstract: Autonomous odor source localization remains a challenging problem for aerial robots due to turbulent airflow, sparse and delayed sensory signals, and strict payload and compute constraints. While prior unmanned aerial vehicle (UAV)-based olfaction systems have demonstrated gas distribution mapping or reactive plume tracing, they rely on predefined coverage patterns, external infrastructure, or extensive sensing and coordination. In this work, we present a complete, open-source UAV system for online odor source localization using a minimal sensor suite. The system integrates custom olfaction hardware, onboard sensing, and a learning-based navigation policy trained in simulation and deployed on a real quadrotor. Through our minimal framework, the UAV is able to navigate directly toward an odor source without constructing an explicit gas distribution map or relying on external positioning systems. Vision is incorporated as an optional complementary modality to accelerate navigation under certain conditions. We validate the proposed system through real-world flight experiments in a large indoor environment using an ethanol source, demonstrating consistent source-finding behavior under realistic airflow conditions. The primary contribution of this work is a reproducible system and methodological framework for UAV-based olfactory navigation and source finding under minimal sensing assumptions. We elaborate on our hardware design and open source our UAV firmware, simulation code, olfaction-vision dataset, and circuit board to the community. Code, data, and designs will be made available at https://github.com/KordelFranceTech/ChasingGhosts.

</details>


### [291] [Denoising Particle Filters: Learning State Estimation with Single-Step Objectives](https://arxiv.org/abs/2602.19651)
*Lennart Röstel,Berthold Bäuml*

Main category: cs.RO

TL;DR: 提出了一种基于粒子滤波和去噪分数匹配的新型状态估计方法，具有可解释性和训练效率，性能与端到端方法相当且更灵活。


<details>
  <summary>Details</summary>
Motivation: 基于学习的方法通常将机器人状态估计视为序列建模问题，虽然这种范式在最大化端到端性能方面有效，但模型往往难以解释且训练成本高。因此，提出了一种替代端到端训练状态估计的方法。

Method: 提出了一种新颖的粒子滤波算法，其中模型从单个状态转移中训练，充分利用机器人系统中的马尔可夫性质。测量模型通过最小化去噪分数匹配目标隐式学习。在推理时，学习的去噪器与（学习的）动态模型一起使用，近似求解每个时间步的贝叶斯滤波方程。

Result: 在模拟的挑战性机器人状态估计任务中评估了所提出的方法，展示了与调优的端到端训练基线相比的竞争性能。

Conclusion: 该方法在机器人状态估计任务中表现出与端到端训练基线相当的竞争性能，同时提供了经典滤波算法的可组合性，允许在不重新训练的情况下整合先验信息和外部传感器模型。

Abstract: Learning-based methods commonly treat state estimation in robotics as a sequence modeling problem. While this paradigm can be effective at maximizing end-to-end performance, models are often difficult to interpret and expensive to train, since training requires unrolling sequences of predictions in time. As an alternative to end-to-end trained state estimation, we propose a novel particle filtering algorithm in which models are trained from individual state transitions, fully exploiting the Markov property in robotic systems. In this framework, measurement models are learned implicitly by minimizing a denoising score matching objective. At inference, the learned denoiser is used alongside a (learned) dynamics model to approximately solve the Bayesian filtering equation at each time step, effectively guiding predicted states toward the data manifold informed by measurements. We evaluate the proposed method on challenging robotic state estimation tasks in simulation, demonstrating competitive performance compared to tuned end-to-end trained baselines. Importantly, our method offers the desirable composability of classical filtering algorithms, allowing prior information and external sensor models to be incorporated without retraining.

</details>


### [292] [Scalable Low-Density Distributed Manipulation Using an Interconnected Actuator Array](https://arxiv.org/abs/2602.19653)
*Bailey Dacre,Rodrigo Moreno,Jørn Lambertsen,Kasper Stoy,Andrés Faíña*

Main category: cs.RO

TL;DR: 该论文提出了一种模块化3自由度机器人瓷砖与柔性表面层结合的分布式操纵系统，有效降低执行器密度并保持对小物体的操控能力，实验验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 解决分布式操纵器系统中执行器密度过高的问题，通过柔性表面层降低执行器密度，同时保持对小物体的有效操控。

Method: 采用模块化3自由度机器人瓷砖和柔性表面层构建连续可控的操控表面，通过耦合工作空间分析和操控策略开发，实现了对物体的精确操控。

Result: 通过2×2原型实验验证，成功操控了不同形状和大小的物体，展示了系统的有效性。

Conclusion: 该论文通过模块化3自由度机器人瓷砖和柔性表面层的组合，成功实现了在降低执行器密度的同时保持对小物体的有效操控，验证了该系统的可行性和有效性。

Abstract: Distributed Manipulator Systems, composed of arrays of robotic actuators necessitate dense actuator arrays to effectively manipulate small objects. This paper presents a system composed of modular 3-DoF robotic tiles interconnected by a compliant surface layer, forming a continuous, controllable manipulation surface. The compliant layer permits increased actuator spacing without compromising object manipulation capabilities, significantly reducing actuator density while maintaining robust control, even for smaller objects. We characterize the coupled workspace of the array and develop a manipulation strategy capable of translating objects to arbitrary positions within an N X N array. The approach is validated experimentally using a minimal 2 X 2 prototype, demonstrating the successful manipulation of objects with varied shapes and sizes.

</details>


### [293] [CACTO-BIC: Scalable Actor-Critic Learning via Biased Sampling and GPU-Accelerated Trajectory Optimization](https://arxiv.org/abs/2602.19699)
*Elisa Alboni,Pietro Noah Crestaz,Elias Fontanari,Andrea Del Prete*

Main category: cs.RO

TL;DR: CACTO-BIC通过优化初始状态采样和GPU加速，提升了数据效率和计算速度，适用于高维实时系统。


<details>
  <summary>Details</summary>
Motivation: 解决CACTO在系统复杂性增加时计算成本上升的局限性，提升数据效率和计算速度。

Method: 结合TO和RL的优势，学习一个预热策略来引导TO求解器，同时利用GPU加速和初始状态采样的优化。

Result: 实证评估显示，相比CACTO，CACTO-BIC在样本效率和计算速度上均有提升，且能在更短时间内达到与PPO相似的解决方案。

Conclusion: CACTO-BIC通过改进初始状态采样和利用GPU加速，显著提升了数据效率和计算速度，适用于高维系统和实时应用。

Abstract: Trajectory Optimization (TO) and Reinforcement Learning (RL) offer complementary strengths for solving optimal control problems. TO efficiently computes locally optimal solutions but can struggle with non-convexity, while RL is more robust to non-convexity at the cost of significantly higher computational demands. CACTO (Continuous Actor-Critic with Trajectory Optimization) was introduced to combine these advantages by learning a warm-start policy that guides the TO solver towards low-cost trajectories. However, scalability remains a key limitation, as increasing system complexity significantly raises the computational cost of TO. This work introduces CACTO-BIC to address these challenges. CACTO-BIC improves data efficiency by biasing initial-state sampling leveraging a property of the value function associated with locally optimal policies; moreover, it reduces computation time by exploiting GPU acceleration. Empirical evaluations show improved sample efficiency and faster computation compared to CACTO. Comparisons with PPO demonstrate that our approach can achieve similar solutions in less time. Finally, experiments on the AlienGO quadruped robot demonstrate that CACTO-BIC can scale to high-dimensional systems and is suitable for real-time applications.

</details>


### [294] [Towards Dexterous Embodied Manipulation via Deep Multi-Sensory Fusion and Sparse Expert Scaling](https://arxiv.org/abs/2602.19764)
*Yirui Sun,Guangyu Zhuge,Keliang Liu,Jie Gu,Zhihao xia,Qionglin Ren,Chunxu tian,Zhongxue Ga*

Main category: cs.RO

TL;DR: DeMUSE框架通过多模态集成和稀疏专家系统，在复杂物理交互任务中实现高性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉主导的范式忽视了力和几何反馈对复杂任务的关键作用，DeMUSE旨在解决这一问题，实现异构多模态感官输入的深度整合。

Method: DeMUSE采用Diffusion Transformer整合RGB、深度和6轴力信息，利用Adaptive Modality-specific Normalization (AdaMN)平衡多感官信号分布，并通过Sparse Mixture-of-Experts (MoE)提升模型容量。

Result: DeMUSE在仿真和现实试验中分别达到83.2%和72.5%的成功率，展示了卓越性能。

Conclusion: DeMUSE框架通过深度多模态集成和高效的稀疏专家系统，在复杂物理交互任务中实现了最先进的性能，验证了深度多感官整合的必要性。

Abstract: Realizing dexterous embodied manipulation necessitates the deep integration of heterogeneous multimodal sensory inputs. However, current vision-centric paradigms often overlook the critical force and geometric feedback essential for complex tasks. This paper presents DeMUSE, a Deep Multimodal Unified Sparse Experts framework leveraging a Diffusion Transformer to integrate RGB, depth, and 6-axis force into a unified serialized stream. Adaptive Modality-specific Normalization (AdaMN) is employed to recalibrate modality-aware features, mitigating representation imbalance and harmonizing the heterogeneous distributions of multi-sensory signals. To facilitate efficient scaling, the architecture utilizes a Sparse Mixture-of-Experts (MoE) with shared experts, increasing model capacity for physical priors while maintaining the low inference latency required for real-time control. A Joint denoising objective synchronously synthesizes environmental evolution and action sequences to ensure physical consistency. Achieving success rates of 83.2% and 72.5% in simulation and real-world trials, DeMUSE demonstrates state-of-the-art performance, validating the necessity of deep multi-sensory integration for complex physical interactions.

</details>


### [295] [TactiVerse: Generalizing Multi-Point Tactile Sensing in Soft Robotics Using Single-Point Data](https://arxiv.org/abs/2602.19850)
*Junhui Lee,Hyosung Kim,Saekwang Nam*

Main category: cs.RO

TL;DR: TactiVerse框架通过U-Net架构和热图预测任务，显著提升了软传感器的单点和多点触觉感知能力，简化了开发流程。


<details>
  <summary>Details</summary>
Motivation: 实时预测高柔性软材料的变形在软机器人中是一个重大挑战，现有的学习模型对训练数据集依赖性强，难以泛化到复杂场景如多点传感。

Method: 引入了TactiVerse，一个基于U-Net的框架，将接触几何估计表述为空间热图预测任务。

Result: 即使在仅使用单点压痕的有限数据集训练时，该架构也实现了高度准确的单点传感，平均绝对误差为0.0589毫米，优于传统回归CNN基线的0.0612毫米。通过增加多点接触数据训练，传感器的多点传感能力显著提升，两点识别的平均MAE从1.214毫米降至0.383毫米。

Conclusion: 该方法显著简化了基于标记的软传感器的开发，为现实世界的触觉感知提供了高度可扩展的解决方案。

Abstract: Real-time prediction of deformation in highly compliant soft materials remains a significant challenge in soft robotics. While vision-based soft tactile sensors can track internal marker displacements, learning-based models for 3D contact estimation heavily depend on their training datasets, inherently limiting their ability to generalize to complex scenarios such as multi-point sensing. To address this limitation, we introduce TactiVerse, a U-Net-based framework that formulates contact geometry estimation as a spatial heatmap prediction task. Even when trained exclusively on a limited dataset of single-point indentations, our architecture achieves highly accurate single-point sensing, yielding a superior mean absolute error of 0.0589 mm compared to the 0.0612 mm of a conventional regression-based CNN baseline. Furthermore, we demonstrate that augmenting the training dataset with multi-point contact data substantially enhances the sensor's multi-point sensing capabilities, significantly improving the overall mean MAE for two-point discrimination from 1.214 mm to 0.383 mm. By successfully extrapolating complex contact geometries from fundamental interactions, this methodology unlocks advanced multi-point and large-area shape sensing. Ultimately, it significantly streamlines the development of marker-based soft sensors, offering a highly scalable solution for real-world tactile perception.

</details>


### [296] [Athena: An Autonomous Open-Hardware Tracked Rescue Robot Platform](https://arxiv.org/abs/2602.19898)
*Stefan Fabian,Aljoscha Schmidt,Jonas Süß,Dishant,Aum Oza,Oskar von Stryk*

Main category: cs.RO

TL;DR: Athena是一个开源救援机器人平台，具备可重构履带和机械臂，适用于复杂地形操作，旨在提升灾害响应效率。


<details>
  <summary>Details</summary>
Motivation: 灾害响应中，机器人能降低救援人员的风险，但现有机器人能力各异且难以提前预测，需要异构机器人群体覆盖多样化任务需求。

Method: 提出了Athena机器人平台的设计，包括四个独立可重构的履带（flippers）、工业PU带和齿形插入件的创新安装方案，以及最大可达1.54米的机械臂。

Result: Athena平台通过开源硬件和软件设计，提供了在复杂地形中导航和操作的能力，包括开门、操作阀门等任务。

Conclusion: Athena作为一个开源的救援地面机器人研究平台，通过可重构的履带和低成本紧急停止解决方案，展示了在复杂地形中导航和操作的潜力，为灾害响应提供了实用工具。

Abstract: In disaster response and situation assessment, robots have great potential in reducing the risks to the safety and health of first responders. As the situations encountered and the required capabilities of the robots deployed in such missions differ wildly and are often not known in advance, heterogeneous fleets of robots are needed to cover a wide range of mission requirements. While UAVs can quickly survey the mission environment, their ability to carry heavy payloads such as sensors and manipulators is limited. UGVs can carry required payloads to assess and manipulate the mission environment, but need to be able to deal with difficult and unstructured terrain such as rubble and stairs. The ability of tracked platforms with articulated arms (flippers) to reconfigure their geometry makes them particularly effective for navigating challenging terrain. In this paper, we present Athena, an open-hardware rescue ground robot research platform with four individually reconfigurable flippers and a reliable low-cost remote emergency stop (E-Stop) solution. A novel mounting solution using an industrial PU belt and tooth inserts allows the replacement and testing of different track profiles. The manipulator with a maximum reach of 1.54m can be used to operate doors, valves, and other objects of interest. Full CAD & PCB files, as well as all low-level software, are released as open-source contributions.

</details>


### [297] [Scaling Law of Neural Koopman Operators](https://arxiv.org/abs/2602.19943)
*Abulikemu Abuduweili,Yuyang Pang,Feihan Li,Changliu Liu*

Main category: cs.RO

TL;DR: 论文建立了连接样本大小、潜在空间维度和控制质量的缩放定律，引入正则化器提升模型性能，为Koopman动力学控制提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 解决数据驱动模型性能依赖于样本大小和模型维度之间权衡的问题，其缩放关系尚不明确。

Method: 通过推导和经验验证连接样本大小、潜在空间维度和下游控制质量的缩放定律，引入了两个轻量级正则化器：协方差损失和逆控制损失。

Result: 系统实验证实模型拟合误差遵循推导的缩放定律，正则化器提高了动态模型拟合的保真度，并增强了闭环控制性能。

Conclusion: 论文为学习Koopman动力学控制提供了一个简单的方法，用于在数据收集和模型容量之间分配努力。

Abstract: Data-driven neural Koopman operator theory has emerged as a powerful tool for linearizing and controlling nonlinear robotic systems. However, the performance of these data-driven models fundamentally depends on the trade-off between sample size and model dimensions, a relationship for which the scaling laws have remained unclear. This paper establishes a rigorous framework to address this challenge by deriving and empirically validating scaling laws that connect sample size, latent space dimension, and downstream control quality. We derive a theoretical upper bound on the Koopman approximation error, explicitly decomposing it into sampling error and projection error. We show that these terms decay at specific rates relative to dataset size and latent dimension, providing a rigorous basis for the scaling law. Based on the theoretical results, we introduce two lightweight regularizers for the neural Koopman operator: a covariance loss to help stabilize the learned latent features and an inverse control loss to ensure the model aligns with physical actuation. The results from systematic experiments across six robotic environments confirm that model fitting error follows the derived scaling laws, and the regularizers improve dynamic model fitting fidelity, with enhanced closed-loop control performance. Together, our results provide a simple recipe for allocating effort between data collection and model capacity when learning Koopman dynamics for control.

</details>


### [298] [Contextual Safety Reasoning and Grounding for Open-World Robots](https://arxiv.org/abs/2602.19983)
*Zachary Ravichadran,David Snyder,Alexander Robey,Hamed Hassani,Vijay Kumar,George J. Pappas*

Main category: cs.RO

TL;DR: CORE是一个通过视觉语言模型实现在线上下文推理的安全框架，显著提升机器人在开放世界中的安全性。


<details>
  <summary>Details</summary>
Motivation: 传统安全方法在开放世界的上下文变异性中表现不足，CORE旨在填补这一空白。

Method: CORE利用VLM直接从视觉观察中推理上下文相关的安全规则，并通过控制屏障函数在物理环境中实施这些规则。

Result: 实验证明CORE在未见环境中能实施上下文适当的行为，性能显著优于缺乏在线上下文推理的语义安全方法。

Conclusion: CORE框架通过结合视觉语言模型（VLM）和在线上下文推理，显著提升了机器人在开放世界环境中的安全性，且无需预先环境知识。

Abstract: Robots are increasingly operating in open-world environments where safe behavior depends on context: the same hallway may require different navigation strategies when crowded versus empty, or during an emergency versus normal operations. Traditional safety approaches enforce fixed constraints in user-specified contexts, limiting their ability to handle the open-ended contextual variability of real-world deployment. We address this gap via CORE, a safety framework that enables online contextual reasoning, grounding, and enforcement without prior knowledge of the environment (e.g., maps or safety specifications). CORE uses a vision-language model (VLM) to continuously reason about context-dependent safety rules directly from visual observations, grounds these rules in the physical environment, and enforces the resulting spatially-defined safe sets via control barrier functions. We provide probabilistic safety guarantees for CORE that account for perceptual uncertainty, and we demonstrate through simulation and real-world experiments that CORE enforces contextually appropriate behavior in unseen environments, significantly outperforming prior semantic safety methods that lack online contextual reasoning. Ablation studies validate our theoretical guarantees and underscore the importance of both VLM-based reasoning and spatial grounding for enforcing contextual safety in novel settings. We provide additional resources at https://zacravichandran.github.io/CORE.

</details>


### [299] [EEG-Driven Intention Decoding: Offline Deep Learning Benchmarking on a Robotic Rover](https://arxiv.org/abs/2602.20041)
*Ghadah Alosaimi,Maha Alsayyari,Yixin Sun,Stamos Katsigiannis,Amir Atapour-Abarghouei,Toby P. Breckon*

Main category: cs.RO

TL;DR: 本研究提出了一种脑-机器人控制框架，用于在机器人漫游车操作期间离线解码驾驶命令，通过多时间窗口EEG信号解码和深度学习模型比较，发现ShallowConvNet性能最佳。


<details>
  <summary>Details</summary>
Motivation: 脑机接口（BCIs）为移动机器人提供了一种无需手动的控制方式，但在真实世界导航中解码用户意图仍具挑战性。

Method: 使用16通道OpenBCI帽记录EEG信号，并与电机动作对齐（Delta = 0 ms）及未来预测时间窗口（Delta > 0 ms）。预处理后，对包括卷积神经网络、循环神经网络和Transformer架构在内的多种深度学习模型进行了基准测试。

Result: ShallowConvNet在动作预测和意图预测方面均表现出最高性能。

Conclusion: 本研究通过结合真实世界机器人控制与多时间窗口EEG意图解码，提出了一个可复现的基准测试，并揭示了基于预测性深度学习的BCI系统的关键设计见解。

Abstract: Brain-computer interfaces (BCIs) provide a hands-free control modality for mobile robotics, yet decoding user intent during real-world navigation remains challenging. This work presents a brain-robot control framework for offline decoding of driving commands during robotic rover operation. A 4WD Rover Pro platform was remotely operated by 12 participants who navigated a predefined route using a joystick, executing the commands forward, reverse, left, right, and stop. Electroencephalogram (EEG) signals were recorded with a 16-channel OpenBCI cap and aligned with motor actions at Delta = 0 ms and future prediction horizons (Delta > 0 ms). After preprocessing, several deep learning models were benchmarked, including convolutional neural networks, recurrent neural networks, and Transformer architectures. ShallowConvNet achieved the highest performance for both action prediction and intent prediction. By combining real-world robotic control with multi-horizon EEG intention decoding, this study introduces a reproducible benchmark and reveals key design insights for predictive deep learning-based BCI systems.

</details>


### [300] [Hydrodynamic Performance Enhancement of Unmanned Underwater Gliders with Soft Robotic Morphing Wings for Agility Improvement](https://arxiv.org/abs/2602.20054)
*A. Giordano,G. De Meurichy,V. Telazzi,C. Mucignat,I. Lunati,D. A. L. M. Louchard,M. Iovieno,S. F. Armanini,M. Kovac*

Main category: cs.RO

TL;DR: 软变形翼UUV比刚性翼效率高9.75%，适合压力无关操作场景。


<details>
  <summary>Details</summary>
Motivation: 评估软变形翼相较于刚性翼在流体动力效率上的优势，以扩展UUV的作业范围并提升任务可行性。

Method: 通过结构和计算流体动力学（CFD）模拟，对软变形翼及搭载该翼的UUV进行了分析。

Result: 搭载软变形翼的UUV比传统刚性翼UUV整体效率提高了9.75%。

Conclusion: 软变形翼在水下无人载具（UUV）中的应用显示出比传统刚性翼更高的流体动力效率，证实了软机器人技术在提升水下载具性能方面的潜力。

Abstract: This work assesses the hydrodynamic efficiency of Underwater Unmanned Vehicles (UUVs) equipped with soft morphing wings compared to conventional rigid wings. Unlike rigid wings, deformable counterparts can alter their aerodynamic properties on demand. Improvements in hydrodynamic efficiency extend a UUV's operational range and may determine mission feasibility. Structural and Computational Fluid Dynamics (CFD) simulations were conducted for both a soft morphing wing and a UUV incorporating it. The results show that a UUV employing soft wings achieves 9.75 percent higher overall efficiency than an equivalent vehicle with traditional rigid wings. These findings confirm the potential of soft robotics to enhance underwater vehicle performance, particularly in applications requiring pressure-agnostic operation.

</details>


### [301] [To Move or Not to Move: Constraint-based Planning Enables Zero-Shot Generalization for Interactive Navigation](https://arxiv.org/abs/2602.20055)
*Apoorva Vashisth,Manav Kulshrestha,Pranav Bakshi,Damon Conover,Guillaume Sartoretti,Aniket Bera*

Main category: cs.RO

TL;DR: 提出一种LLM驱动的导航框架，机器人通过移动杂物自主规划路径，在模拟和真实环境中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对现实场景中路径被杂物阻塞的问题，提出具备操作能力的移动机器人可通过移动杂物自主开辟路径。

Method: 采用LLM驱动的约束规划框架，结合主动感知和结构化场景图推理，决定移动对象、放置位置及下一步探索区域。

Result: 在ProcTHOR-10k模拟器中表现优于基线方法，并在真实硬件中验证了可行性。

Conclusion: 本文提出的LLM驱动的约束规划框架结合主动感知，在物理模拟器和真实硬件中均表现出色，优于非学习和学习基线。

Abstract: Visual navigation typically assumes the existence of at least one obstacle-free path between start and goal, which must be discovered/planned by the robot. However, in real-world scenarios, such as home environments and warehouses, clutter can block all routes. Targeted at such cases, we introduce the Lifelong Interactive Navigation problem, where a mobile robot with manipulation abilities can move clutter to forge its own path to complete sequential object- placement tasks - each involving placing an given object (eg. Alarm clock, Pillow) onto a target object (eg. Dining table, Desk, Bed). To address this lifelong setting - where effects of environment changes accumulate and have long-term effects - we propose an LLM-driven, constraint-based planning framework with active perception. Our framework allows the LLM to reason over a structured scene graph of discovered objects and obstacles, deciding which object to move, where to place it, and where to look next to discover task-relevant information. This coupling of reasoning and active perception allows the agent to explore the regions expected to contribute to task completion rather than exhaustively mapping the environment. A standard motion planner then executes the corresponding navigate-pick-place, or detour sequence, ensuring reliable low-level control. Evaluated in physics-enabled ProcTHOR-10k simulator, our approach outperforms non-learning and learning-based baselines. We further demonstrate our approach qualitatively on real-world hardware.

</details>


### [302] [AdaWorldPolicy: World-Model-Driven Diffusion Policy with Online Adaptive Learning for Robotic Manipulation](https://arxiv.org/abs/2602.20057)
*Ge Yuan,Qiyuan Qiao,Jing Zhang,Dong Xu*

Main category: cs.RO

TL;DR: AdaWorldPolicy是一个结合世界模型和在线自适应学习的机器人操作框架，通过多模块联合学习和动态模式切换，显著提升了动态环境中的适应性和性能。


<details>
  <summary>Details</summary>
Motivation: 提升机器人在动态环境中的操作能力，减少人工干预，通过世界模型提供强监督信号，结合力-扭矩反馈应对动态力变化。

Method: 提出了一个统一框架AdaWorldPolicy，结合Flow Matching Diffusion Transformers（DiT）实现世界模型、动作专家和力预测器的联合学习，并引入在线自适应学习（AdaOL）策略动态切换动作生成和未来想象模式。

Result: 在模拟和真实机器人基准测试中，AdaWorldPolicy实现了最先进的性能，并能有效适应分布外场景。

Conclusion: AdaWorldPolicy通过整合世界模型、动作专家和力预测器，结合在线自适应学习策略，在动态环境中实现了高效的机器人操作，展现了卓越的适应性和性能。

Abstract: Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. Effective robotic manipulation requires policies that can anticipate physical outcomes and adapt to real-world environments. In this work, we introduce a unified framework, World-Model-Driven Diffusion Policy with Online Adaptive Learning (AdaWorldPolicy) to enhance robotic manipulation under dynamic conditions with minimal human involvement. Our core insight is that world models provide strong supervision signals, enabling online adaptive learning in dynamic environments, which can be complemented by force-torque feedback to mitigate dynamic force shifts. Our AdaWorldPolicy integrates a world model, an action expert, and a force predictor-all implemented as interconnected Flow Matching Diffusion Transformers (DiT). They are interconnected via the multi-modal self-attention layers, enabling deep feature exchange for joint learning while preserving their distinct modularity characteristics. We further propose a novel Online Adaptive Learning (AdaOL) strategy that dynamically switches between an Action Generation mode and a Future Imagination mode to drive reactive updates across all three modules. This creates a powerful closed-loop mechanism that adapts to both visual and physical domain shifts with minimal overhead. Across a suite of simulated and real-robot benchmarks, our AdaWorldPolicy achieves state-of-the-art performance, with dynamical adaptive capacity to out-of-distribution scenarios.

</details>


### [303] [NovaPlan: Zero-Shot Long-Horizon Manipulation via Closed-Loop Video Language Planning](https://arxiv.org/abs/2602.20119)
*Jiahui Fu,Junyu Nan,Lingfeng Sun,Hongyu Li,Jianing Qian,Jennifer L. Barry,Kris Kitani,George Konidaris*

Main category: cs.RO

TL;DR: NovaPlan是一个分层框架，结合VLM和视频规划实现零样本长时程操作，无需演示或训练即可完成任务和错误恢复。


<details>
  <summary>Details</summary>
Motivation: 解决长时程任务需要机器人整合高级语义推理与低级物理交互，现有视觉语言模型和视频生成模型缺乏物理基础。

Method: NovaPlan采用分层框架，结合闭环VLM和视频规划与几何基础的机器人执行。高层VLM规划器分解任务并监控执行，低层利用视频生成的任务相关关键点和人手姿态作为运动学先验。

Result: NovaPlan在三个长时程任务和功能操作基准测试中表现优异，能够执行复杂装配任务并展示灵巧的错误恢复行为。

Conclusion: NovaPlan成功地将高级语义推理与低级物理交互结合，实现了零样本长时程操作任务，并展示了在复杂装配任务和灵巧错误恢复行为上的有效性。

Abstract: Solving long-horizon tasks requires robots to integrate high-level semantic reasoning with low-level physical interaction. While vision-language models (VLMs) and video generation models can decompose tasks and imagine outcomes, they often lack the physical grounding necessary for real-world execution. We introduce NovaPlan, a hierarchical framework that unifies closed-loop VLM and video planning with geometrically grounded robot execution for zero-shot long-horizon manipulation. At the high level, a VLM planner decomposes tasks into sub-goals and monitors robot execution in a closed loop, enabling the system to recover from single-step failures through autonomous re-planning. To compute low-level robot actions, we extract and utilize both task-relevant object keypoints and human hand poses as kinematic priors from the generated videos, and employ a switching mechanism to choose the better one as a reference for robot actions, maintaining stable execution even under heavy occlusion or depth inaccuracy. We demonstrate the effectiveness of NovaPlan on three long-horizon tasks and the Functional Manipulation Benchmark (FMB). Our results show that NovaPlan can perform complex assembly tasks and exhibit dexterous error recovery behaviors without any prior demonstrations or training. Project page: https://nova-plan.github.io/

</details>


### [304] [Simulation-Ready Cluttered Scene Estimation via Physics-aware Joint Shape and Pose Optimization](https://arxiv.org/abs/2602.20150)
*Wei-Cheng Huang,Jiaheng Han,Xiaohan Ye,Zherong Pan,Kris Hauser*

Main category: cs.RO

TL;DR: 本文提出了一种优化框架，通过形状可微接触模型和高效求解器，解决了复杂场景中多刚体对象形状和姿态估计的问题，实验验证了其鲁棒性和有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂环境中表现不佳，计算成本高且泛化能力有限，亟需一种能够同时恢复多刚体对象形状和姿态的鲁棒方法。

Method: 通过结合形状可微接触模型和结构化稀疏性的增强拉格朗日Hessian矩阵高效线性系统求解器，实现了对多刚体对象形状和姿态的联合优化。

Result: 在包含多达5个对象和22个凸包的复杂场景中，该方法能够稳健地重建物理有效且仿真就绪的对象形状和姿态。

Conclusion: 本文提出了一种基于优化的统一框架，用于从真实世界观测中估计仿真就绪场景，解决了现有方法在复杂环境中计算成本高、鲁棒性差和泛化能力受限的问题。

Abstract: Estimating simulation-ready scenes from real-world observations is crucial for downstream planning and policy learning tasks. Regretfully, existing methods struggle in cluttered environments, often exhibiting prohibitive computational cost, poor robustness, and restricted generality when scaling to multiple interacting objects. We propose a unified optimization-based formulation for real-to-sim scene estimation that jointly recovers the shapes and poses of multiple rigid objects under physical constraints. Our method is built on two key technical innovations. First, we leverage the recently introduced shape-differentiable contact model, whose global differentiability permits joint optimization over object geometry and pose while modeling inter-object contacts. Second, we exploit the structured sparsity of the augmented Lagrangian Hessian to derive an efficient linear system solver whose computational cost scales favorably with scene complexity. Building on this formulation, we develop an end-to-end real-to-sim scene estimation pipeline that integrates learning-based object initialization, physics-constrained joint shape-pose optimization, and differentiable texture refinement. Experiments on cluttered scenes with up to 5 objects and 22 convex hulls demonstrate that our approach robustly reconstructs physically valid, simulation-ready object shapes and poses.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [305] [On the Dynamics of Observation and Semantics](https://arxiv.org/abs/2602.18494)
*Xiu Li*

Main category: cs.AI

TL;DR: 论文提出智能是有界代理的属性，通过物理约束推导出符号结构的必要性，认为语言和逻辑是防止热崩溃的信息固态形式。


<details>
  <summary>Details</summary>
Motivation: 当前视觉智能的主流范式将语义视为潜在表示的静态属性，假设意义可以通过高维嵌入空间中的几何接近性来发现，作者认为这一观点在物理上是不完整的。

Method: 通过观察语义纤维束的运动结构，将原始感官观察数据（纤维）投影到低熵因果语义流形（基）上。

Result: 证明了对于任何有界代理，信息处理的热力学成本（兰道尔原理）对内部状态转换的复杂性施加了严格限制，称为语义常数B。从这些物理约束中，推导出符号结构的必要性。

Conclusion: 理解不是恢复隐藏的潜在变量，而是构建一个因果商，使世界在算法上可压缩且因果可预测。

Abstract: A dominant paradigm in visual intelligence treats semantics as a static property of latent representations, assuming that meaning can be discovered through geometric proximity in high dimensional embedding spaces. In this work, we argue that this view is physically incomplete. We propose that intelligence is not a passive mirror of reality but a property of a physically realizable agent, a system bounded by finite memory, finite compute, and finite energy interacting with a high entropy environment. We formalize this interaction through the kinematic structure of an Observation Semantics Fiber Bundle, where raw sensory observation data (the fiber) is projected onto a low entropy causal semantic manifold (the base). We prove that for any bounded agent, the thermodynamic cost of information processing (Landauer's Principle) imposes a strict limit on the complexity of internal state transitions. We term this limit the Semantic Constant B. From these physical constraints, we derive the necessity of symbolic structure. We show that to model a combinatorial world within the bound B, the semantic manifold must undergo a phase transition, it must crystallize into a discrete, compositional, and factorized form. Thus, language and logic are not cultural artifacts but ontological necessities the solid state of information required to prevent thermal collapse. We conclude that understanding is not the recovery of a hidden latent variable, but the construction of a causal quotient that renders the world algorithmically compressible and causally predictable.

</details>


### [306] [Hierarchical Reward Design from Language: Enhancing Alignment of Agent Behavior with Human Specifications](https://arxiv.org/abs/2602.18582)
*Zhiqin Qian,Ryan Diaz,Sangwon Seo,Vaibhav Unhelkar*

Main category: cs.AI

TL;DR: HRDL和L2HR通过层次化奖励设计，更好地将人类偏好编码到AI代理的行为中，提升了任务完成与规范遵循的效果。


<details>
  <summary>Details</summary>
Motivation: 在AI代理处理复杂任务时，如何使其行为与人类提供的规范对齐成为关键，现有方法难以捕捉长期任务中的细微人类偏好。

Method: 提出了Hierarchical Reward Design from Language (HRDL)问题框架，并提出了Language to Hierarchical Rewards (L2HR)作为解决方案。

Result: 实验表明，通过L2HR设计的奖励训练的AI代理不仅能有效完成任务，还能更好地遵循人类规范。

Conclusion: HRDL和L2HR共同推动了人类对齐AI代理的研究，为复杂任务中的人类偏好提供了更丰富的编码方式。

Abstract: When training artificial intelligence (AI) to perform tasks, humans often care not only about whether a task is completed but also how it is performed. As AI agents tackle increasingly complex tasks, aligning their behavior with human-provided specifications becomes critical for responsible AI deployment. Reward design provides a direct channel for such alignment by translating human expectations into reward functions that guide reinforcement learning (RL). However, existing methods are often too limited to capture nuanced human preferences that arise in long-horizon tasks. Hence, we introduce Hierarchical Reward Design from Language (HRDL): a problem formulation that extends classical reward design to encode richer behavioral specifications for hierarchical RL agents. We further propose Language to Hierarchical Rewards (L2HR) as a solution to HRDL. Experiments show that AI agents trained with rewards designed via L2HR not only complete tasks effectively but also better adhere to human specifications. Together, HRDL and L2HR advance the research on human-aligned AI agents.

</details>


### [307] [Feedback-based Automated Verification in Vibe Coding of CAS Adaptation Built on Constraint Logic](https://arxiv.org/abs/2602.18607)
*Michal Töpfer,František Plášil,Tomáš Bureš,Petr Hnětynka*

Main category: cs.AI

TL;DR: 论文提出结合FCL时间逻辑和vibe coding反馈循环，利用LLM生成CAS适应性管理代码，实验证明该方法高效可行。


<details>
  <summary>Details</summary>
Motivation: 解决CAS适应性管理中动态架构和行为变化的挑战，利用生成式LLM和vibe coding反馈循环提高生成代码的正确性。

Method: 使用新型时间逻辑FCL表达功能需求约束，结合适应性管理和vibe coding反馈循环，通过LLM生成AM代码。

Result: 在CAS领域的两个示例系统中，通过少量反馈循环迭代和详细的约束违反报告，成功生成了AM，并实现了高运行路径覆盖。

Conclusion: 通过结合适应性管理和vibe coding反馈循环，并在FCL约束下评估当前系统状态，实验证明在CAS领域中生成AM是可行的，通常只需少量反馈循环迭代即可。

Abstract: In CAS adaptation, a challenge is to define the dynamic architecture of the system and changes in its behavior. Implementation-wise, this is projected into an adaptation mechanism, typically realized as an Adaptation Manager (AM). With the advances of generative LLMs, generating AM code based on system specification and desired AM behavior (partially in natural language) is a tempting opportunity. The recent introduction of vibe coding suggests a way to target the problem of the correctness of generated code by iterative testing and vibe coding feedback loops instead of direct code inspection.
  In this paper, we show that generating an AM via vibe coding feedback loops is a viable option when the verification of the generated AM is based on a very precise formulation of the functional requirements. We specify these as constraints in a novel temporal logic FCL that allows us to express the behavior of traces with much finer granularity than classical LTL enables.
  Furthermore, we show that by combining the adaptation and vibe coding feedback loops where the FCL constraints are evaluated for the current system state, we achieved good results in the experiments with generating AMs for two example systems from the CAS domain. Typically, just a few feedback loop iterations were necessary, each feeding the LLM with reports describing detailed violations of the constraints. This AM testing was combined with high run path coverage achieved by different initial settings.

</details>


### [308] [Decoding ML Decision: An Agentic Reasoning Framework for Large-Scale Ranking System](https://arxiv.org/abs/2602.18640)
*Longfei Yun,Yihan Wu,Haoran Liu,Xiaoxuan Liu,Ziyun Xu,Yi Wang,Yang Xia,Pengfei Wang,Mingze Gao,Yunxiang Wang,Changfan Chen,Junfeng Pan*

Main category: cs.AI

TL;DR: GEARS是一个生成式代理排名框架，通过封装专家知识和验证机制，在复杂环境中实现高效且稳健的排名优化。


<details>
  <summary>Details</summary>
Motivation: 现代大规模排名系统面临工程上下文约束的瓶颈，即如何将模糊的产品意图转化为可执行且可验证的假设，而非仅依赖建模技术。

Method: GEARS框架采用生成式代理排名系统，将专家知识封装为可重用的专业代理技能，并通过可编程实验环境实现高层次的意图导向优化。

Result: 实验验证表明，GEARS能够通过结合算法信号和深度排名上下文，稳定地识别出接近帕累托最优的策略，同时保持部署的稳定性。

Conclusion: GEARS框架通过将排名优化重构为自主发现过程，结合专业代理技能和验证钩子，能够稳定地识别出高效且稳健的排名策略，从而在复杂的产品环境中实现长期可靠的性能提升。

Abstract: Modern large-scale ranking systems operate within a sophisticated landscape of competing objectives, operational constraints, and evolving product requirements. Progress in this domain is increasingly bottlenecked by the engineering context constraint: the arduous process of translating ambiguous product intent into reasonable, executable, verifiable hypotheses, rather than by modeling techniques alone. We present GEARS (Generative Engine for Agentic Ranking Systems), a framework that reframes ranking optimization as an autonomous discovery process within a programmable experimentation environment. Rather than treating optimization as static model selection, GEARS leverages Specialized Agent Skills to encapsulate ranking expert knowledge into reusable reasoning capabilities, enabling operators to steer systems via high-level intent vibe personalization. Furthermore, to ensure production reliability, the framework incorporates validation hooks to enforce statistical robustness and filter out brittle policies that overfit short-term signals. Experimental validation across diverse product surfaces demonstrates that GEARS consistently identifies superior, near-Pareto-efficient policies by synergizing algorithmic signals with deep ranking context while maintaining rigorous deployment stability.

</details>


### [309] [Spilled Energy in Large Language Models](https://arxiv.org/abs/2602.18671)
*Adrian Robert Minut,Hazem Dewidar,Iacopo Masi*

Main category: cs.AI

TL;DR: 通过能量基模型分析LLM输出，提出两种训练无关的指标检测幻觉，效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决LLM解码过程中的事实错误、偏见和失败问题，无需依赖训练好的探针分类器或激活消融。

Method: 引入两种无需训练的指标（溢出能量和边缘化能量），直接从输出logits中提取能量信息。

Result: 在多个基准测试和模型上展示了强大的幻觉检测和跨任务泛化能力。

Conclusion: 将LLM的softmax分类器重新解释为能量基模型（EBM），通过能量溢出指标有效检测幻觉和错误，无需额外训练。

Abstract: We reinterpret the final Large Language Model (LLM) softmax classifier as an Energy-Based Model (EBM), decomposing the sequence-to-sequence probability chain into multiple interacting EBMs at inference. This principled approach allows us to track "energy spills" during decoding, which we empirically show correlate with factual errors, biases, and failures. Similar to Orgad et al. (2025), our method localizes the exact answer token and subsequently tests for hallucinations. Crucially, however, we achieve this without requiring trained probe classifiers or activation ablations. Instead, we introduce two completely training-free metrics derived directly from output logits: spilled energy, which captures the discrepancy between energy values across consecutive generation steps that should theoretically match, and marginalized energy, which is measurable at a single step. Evaluated on nine benchmarks across state-of-the-art LLMs (including LLaMA, Mistral, and Gemma) and on synthetic algebraic operations (Qwen3), our approach demonstrates robust, competitive hallucination detection and cross-task generalization. Notably, these results hold for both pretrained and instruction-tuned variants without introducing any training overhead.

</details>


### [310] [Many AI Analysts, One Dataset: Navigating the Agentic Data Science Multiverse](https://arxiv.org/abs/2602.18710)
*Martin Bertran,Riccardo Fogliato,Zhiwei Steven Wu*

Main category: cs.AI

TL;DR: 研究表明，AI分析师能低成本地复制分析多样性，揭示分析决策对结果的重要影响，且这种影响可通过调整角色或LLM来引导。


<details>
  <summary>Details</summary>
Motivation: 过去的研究表明，独立团队对相同数据集和假设的分析常得出冲突结论，但此类研究需要大量协调。本研究旨在通过AI分析师低成本、大规模地复制这种结构化分析多样性。

Method: 本研究利用基于大型语言模型（LLMs）的自主AI分析师，在固定数据集上测试预设假设，通过改变底层模型和提示框架来生成多样化的分析流程。AI审计员筛选方法学上有效的运行。

Result: 在三个数据集中，AI分析师的分析结果显示效应大小、p值和假设支持与否的决策存在广泛分散，且这种分散具有结构性。分析选择在不同LLM和角色条件下系统性差异明显。

Conclusion: 实证研究的结论不仅依赖于数据，还依赖于一系列分析决策，而这些决策在已发表的结果中很少明确说明。通过展示自主AI分析师的多样性分析能力，本研究揭示了分析决策对研究结果的重要影响。

Abstract: The conclusions of empirical research depend not only on data but on a sequence of analytic decisions that published results seldom make explicit. Past ``many-analyst" studies have demonstrated this: independent teams testing the same hypothesis on the same dataset regularly reach conflicting conclusions. But such studies require months of coordination among dozens of research groups and are therefore rarely conducted. In this work, we show that fully autonomous AI analysts built on large language models (LLMs) can reproduce a similar structured analytic diversity cheaply and at scale. We task these AI analysts with testing a pre-specified hypothesis on a fixed dataset, varying the underlying model and prompt framing across replicate runs. Each AI analyst independently constructs and executes a full analysis pipeline; an AI auditor then screens each run for methodological validity. Across three datasets spanning experimental and observational designs, AI analyst-produced analyses display wide dispersion in effect sizes, $p$-values, and binary decisions on supporting the hypothesis or not, frequently reversing whether a hypothesis is judged supported. This dispersion is structured: recognizable analytic choices in preprocessing, model specification, and inference differ systematically across LLM and persona conditions. Critically, the effects are \emph{steerable}: reassigning the analyst persona or LLM shifts the distribution of outcomes even after excluding methodologically deficient runs.

</details>


### [311] [Task-Aware Exploration via a Predictive Bisimulation Metric](https://arxiv.org/abs/2602.18724)
*Dayang Liang,Ruihan Liu,Lipeng Wan,Yunlong Liu,Bo An*

Main category: cs.AI

TL;DR: TEB通过任务感知的双模拟度量改进稀疏奖励下的视觉强化学习探索，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决视觉强化学习在稀疏奖励下探索效率低的问题，现有方法通常假设低维状态或缺乏任务感知策略，导致在视觉领域表现脆弱。

Method: TEB利用预测的双模拟度量（predictive Bisimulation metric）学习任务相关表示，并通过潜在空间中的行为内在新颖性测量设计基于潜力的探索奖励。

Result: 在MetaWorld和Maze2D上的实验表明，TEB具有优越的探索能力，并显著优于现有基线方法。

Conclusion: TEB（Task-aware Exploration）通过结合任务相关表示和探索策略，在稀疏奖励的视觉强化学习任务中表现出卓越的探索能力，并在实验中优于现有基线方法。

Abstract: Accelerating exploration in visual reinforcement learning under sparse rewards remains challenging due to the substantial task-irrelevant variations. Despite advances in intrinsic exploration, many methods either assume access to low-dimensional states or lack task-aware exploration strategies, thereby rendering them fragile in visual domains. To bridge this gap, we present TEB, a Task-aware Exploration approach that tightly couples task-relevant representations with exploration through a predictive Bisimulation metric. Specifically, TEB leverages the metric not only to learn behaviorally grounded task representations but also to measure behaviorally intrinsic novelty over the learned latent space. To realize this, we first theoretically mitigate the representation collapse of degenerate bisimulation metrics under sparse rewards by internally introducing a simple but effective predicted reward differential. Building on this robust metric, we design potential-based exploration bonuses, which measure the relative novelty of adjacent observations over the latent space. Extensive experiments on MetaWorld and Maze2D show that TEB achieves superior exploration ability and outperforms recent baselines.

</details>


### [312] [Beyond Description: A Multimodal Agent Framework for Insightful Chart Summarization](https://arxiv.org/abs/2602.18731)
*Yuhang Bai,Yujuan Ding,Shanru Lin,Wenqi Fan*

Main category: cs.AI

TL;DR: 提出 Chart Insight Agent Flow 框架和 ChartSummInsights 数据集，显著提升 MLLMs 生成图表深层见解摘要的能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法（包括使用 MLLMs 的方法）主要关注低层次的数据描述，往往无法捕捉数据可视化的根本目的——深层见解。

Method: 提出了一个计划与执行的多智能体框架 Chart Insight Agent Flow，有效利用 MLLMs 的感知和推理能力，直接从图表图像中挖掘深层见解。

Result: 实验结果表明，该方法显著提升了 MLLMs 在图表摘要任务中的性能。

Conclusion: Chart Insight Agent Flow 显著提升了 MLLMs 在图表摘要任务中的表现，能够生成包含深刻且多样化见解的摘要。

Abstract: Chart summarization is crucial for enhancing data accessibility and the efficient consumption of information. However, existing methods, including those with Multimodal Large Language Models (MLLMs), primarily focus on low-level data descriptions and often fail to capture the deeper insights which are the fundamental purpose of data visualization. To address this challenge, we propose Chart Insight Agent Flow, a plan-and-execute multi-agent framework effectively leveraging the perceptual and reasoning capabilities of MLLMs to uncover profound insights directly from chart images. Furthermore, to overcome the lack of suitable benchmarks, we introduce ChartSummInsights, a new dataset featuring a diverse collection of real-world charts paired with high-quality, insightful summaries authored by human data analysis experts. Experimental results demonstrate that our method significantly improves the performance of MLLMs on the chart summarization task, producing summaries with deep and diverse insights.

</details>


### [313] [Federated Reasoning Distillation Framework with Model Learnability-Aware Data Allocation](https://arxiv.org/abs/2602.18749)
*Wei Guo,Siyuan Lu,Xiangdong Ran,Yiqi Tong,Yikun Ban,Zelong Xu,Jing Fan,Zixuan Huang,Xiao Zhang,Zhaojun Hu,Fuzhen Zhuang*

Main category: cs.AI

TL;DR: LaDa是一个联邦推理蒸馏框架，通过模型可学习性感知的数据分配和领域自适应推理蒸馏，解决了双向模型可学习性差距和领域无关推理转移的问题。


<details>
  <summary>Details</summary>
Motivation: 现有数据分配方法未能解决联邦学习中双向模型可学习性差距和领域无关推理转移的挑战，导致SLMs无法有效从LLMs中获取知识。

Method: 提出了LaDa框架，包括模型可学习性感知的数据过滤器和领域自适应推理蒸馏方法，前者自适应分配高回报样本，后者通过对比蒸馏学习对齐推理路径的联合概率。

Result: LaDa框架有效促进了双向知识转移，并帮助SLMs在本地数据分布下捕捉潜在的推理模式。

Conclusion: LaDa作为一种插件模块，通过模型可学习性感知的数据分配和领域自适应推理蒸馏，有效解决了联邦学习中双向模型可学习性差距和领域无关推理转移的挑战，提升了SLMs从LLMs中获取知识的能力。

Abstract: Data allocation plays a critical role in federated large language model (LLM) and small language models (SLMs) reasoning collaboration. Nevertheless, existing data allocation methods fail to address an under-explored challenge in collaboration: bidirectional model learnability gap, where client-side SLMs cannot identify high-reward samples matching their learnability constraints for effective knowledge transfer from LLMs, while LLMs struggle to select samples contributing novel knowledge beyond their existing data. Furthermore, these collaboration frameworks face another key challenge: domain-agnostic reasoning transfer, where existing reasoning transfer methods fail to flexibly adapt to the local domain data, preventing SLMs from effectively acquiring step-by-step reasoning abilities within from general LLM. To address these challenges, we propose LaDa, a federated reasoning distillation framework with model learnability-aware data allocation. It introduces a model learnability-aware data filter that adaptively allocates high-reward samples based on the learnability gap between each SLM and LLM pair, effectively facilitating bidirectional knowledge transfer. We further design a domain adaptive reasoning distillation method that aligns joint probabilities of reasoning paths on filtered high-reward samples through contrastive distillation learning between SLM and LLM, enabling SLM to capture underlying reasoning patterns under local data distribution. LaDa operates as a plug-in module for existing collaboration frameworks, adapting knowledge transfer based on model learnability gaps.

</details>


### [314] [The Convergence of Schema-Guided Dialogue Systems and the Model Context Protocol](https://arxiv.org/abs/2602.18764)
*Andreas Schlapbach*

Main category: cs.AI

TL;DR: 该论文通过分析SGD和MCP的共性，提出了五种模式设计原则，揭示了现有框架的不足，并提供了具体的设计模式，强调了模式驱动治理在AI系统监督中的重要性。


<details>
  <summary>Details</summary>
Motivation: To establish a unified paradigm for deterministic, auditable LLM-agent interaction by leveraging schemas to encode tool signatures, operational constraints, and reasoning guidance.

Method: Analyzing the convergence of Schema-Guided Dialogue (SGD) and Model Context Protocol (MCP) to extract five foundational principles for schema design.

Result: Five foundational principles for schema design were extracted, revealing novel insights and gaps in existing frameworks, along with concrete design patterns for each principle.

Conclusion: Schema-driven governance is a scalable mechanism for AI system oversight, central to Software 3.0, without requiring proprietary system inspection.

Abstract: This paper establishes a fundamental convergence: Schema-Guided Dialogue (SGD) and the Model Context Protocol (MCP) represent two manifestations of a unified paradigm for deterministic, auditable LLM-agent interaction. SGD, designed for dialogue-based API discovery (2019), and MCP, now the de facto standard for LLM-tool integration, share the same core insight -- that schemas can encode not just tool signatures but operational constraints and reasoning guidance. By analyzing this convergence, we extract five foundational principles for schema design: (1) Semantic Completeness over Syntactic Precision, (2) Explicit Action Boundaries, (3) Failure Mode Documentation, (4) Progressive Disclosure Compatibility, and (5) Inter-Tool Relationship Declaration. These principles reveal three novel insights: first, SGD's original design was fundamentally sound and should be inherited by MCP; second, both frameworks leave failure modes and inter-tool relationships unexploited -- gaps we identify and resolve; third, progressive disclosure emerges as a critical production-scaling insight under real-world token constraints. We provide concrete design patterns for each principle. These principles position schema-driven governance as a scalable mechanism for AI system oversight without requiring proprietary system inspection -- central to Software 3.0.

</details>


### [315] [LAMMI-Pathology: A Tool-Centric Bottom-Up LVLM-Agent Framework for Molecularly Informed Medical Intelligence in Pathology](https://arxiv.org/abs/2602.18773)
*Haoyang Su,Shaoting Zhang,Xiaosong Wang*

Main category: cs.AI

TL;DR: 提出LAMMI-Pathology框架，通过工具中心化架构和轨迹感知微调，提升病理图像分析的推理鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统文本-图像诊断方法过于粗粒度，而工具调用代理系统为病理图像分析提供了更证据驱动的范式。随着空间转录组技术的普及，分子验证的病理诊断变得更加开放和可访问。

Method: 采用工具中心化、自底向上的架构，通过领域自适应工具构建组件代理，并利用顶层规划器进行分层协调。引入基于原子执行节点（AENs）的轨迹构建机制，开发轨迹感知微调策略。

Result: LAMMI-Pathology框架在病理理解和工具集自适应使用方面表现出色，推理鲁棒性得到增强。

Conclusion: LAMMI-Pathology通过分层规划和轨迹感知微调策略，显著提升了病理图像分析的推理鲁棒性和工具集的自适应使用能力。

Abstract: The emergence of tool-calling-based agent systems introduces a more evidence-driven paradigm for pathology image analysis in contrast to the coarse-grained text-image diagnostic approaches. With the recent large-scale experimental adoption of spatial transcriptomics technologies, molecularly validated pathological diagnosis is becoming increasingly open and accessible. In this work, we propose LAMMI-Pathology (LVLM-Agent System for Molecularly Informed Medical Intelligence in Pathology), a scalable agent framework for domain-specific agent tool-calling. LAMMI-Pathology adopts a tool-centric, bottom-up architecture in which customized domain-adaptive tools serve as the foundation. These tools are clustered by domain style to form component agents, which are then coordinated through a top-level planner hierarchically, avoiding excessively long context lengths that could induce task drift. Based on that, we introduce a novel trajectory construction mechanism based on Atomic Execution Nodes (AENs), which serve as reliable and composable units for building semi-simulated reasoning trajectories that capture credible agent-tool interactions. Building on this foundation, we develop a trajectory-aware fine-tuning strategy that aligns the planner's decision-making process with these multi-step reasoning trajectories, thereby enhancing inference robustness in pathology understanding and its adaptive use of the customized toolset.

</details>


### [316] [GenPlanner: From Noise to Plans -- Emergent Reasoning in Flow Matching and Diffusion Models](https://arxiv.org/abs/2602.18812)
*Agnieszka Polowczyk,Alicja Polowczyk,Michał Wieczorek*

Main category: cs.AI

TL;DR: GenPlanner利用生成模型（扩散模型和流匹配）进行路径规划，其变体FlowPlanner在实验中表现突出，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 复杂环境中的路径规划是人工智能的关键问题，需要同时理解空间几何和问题全局结构，探索生成模型作为规划和推理机制的潜力。

Method: 提出了基于扩散模型和流匹配的GenPlanner方法，包含DiffPlanner和FlowPlanner两种变体，通过多通道条件（如障碍物地图和起点终点信息）迭代生成轨迹。

Result: 实验表明，GenPlanner方法显著优于基线CNN模型，FlowPlanner在有限生成步骤下仍表现优异。

Conclusion: GenPlanner,尤其是FlowPlanner变体，在路径规划任务中表现出色，显著优于传统CNN模型，证明了生成模型在此类问题中的潜力。

Abstract: Path planning in complex environments is one of the key problems of artificial intelligence because it requires simultaneous understanding of the geometry of space and the global structure of the problem. In this paper, we explore the potential of using generative models as planning and reasoning mechanisms. We propose GenPlanner, an approach based on diffusion models and flow matching, along with two variants: DiffPlanner and FlowPlanner. We demonstrate the application of generative models to find and generate correct paths in mazes. A multi-channel condition describing the structure of the environment, including an obstacle map and information about the starting and destination points, is used to condition trajectory generation. Unlike standard methods, our models generate trajectories iteratively, starting with random noise and gradually transforming it into a correct solution. Experiments conducted show that the proposed approach significantly outperforms the baseline CNN model. In particular, FlowPlanner demonstrates high performance even with a limited number of generation steps.

</details>


### [317] [ABD: Default Exception Abduction in Finite First Order Worlds](https://arxiv.org/abs/2602.18843)
*Serafim Batzoglou*

Main category: cs.AI

TL;DR: ABD基准测试评估LLM在默认-例外归纳任务中的表现，发现有效性高但简洁性不足，泛化失败模式因观察机制而异。


<details>
  <summary>Details</summary>
Motivation: 为了解决有限一阶世界中的默认-例外归纳问题，并评估前沿LLM在此类任务上的表现。

Method: 通过引入ABD基准测试，使用包含异常谓词的背景理论和关系结构集，模型需输出一阶公式定义例外以恢复可满足性。采用三种观察机制（封闭世界、存在补全、普遍补全）并进行精确的SMT验证。

Result: 在600个实例上评估了十种前沿LLM，最佳模型表现出高有效性，但在简洁性方面仍有差距，且在不同观察机制下展现出不同的泛化失败模式。

Conclusion: ABD基准测试揭示了前沿LLM在默认-例外归纳任务中的表现，虽然有效性高，但在简洁性方面仍有差距，且在不同观察机制下展现出不同的泛化失败模式。

Abstract: We introduce ABD, a benchmark for default-exception abduction over finite first-order worlds. Given a background theory with an abnormality predicate and a set of relational structures, a model must output a first-order formula that defines exceptions, restoring satisfiability while keeping exceptions sparse. We formalize three observation regimes (closed-world, existential completion, universal completion) with exact SMT verification. Evaluating ten frontier LLMs on 600 instances, the best models achieve high validity but parsimony gaps remain, and holdout evaluation reveals distinct generalization failure modes across regimes.

</details>


### [318] [TPRU: Advancing Temporal and Procedural Understanding in Large Multimodal Models](https://arxiv.org/abs/2602.18884)
*Zhenkun Gao,Xuhong Wang,Xin Tan,Yuan Xie*

Main category: cs.AI

TL;DR: TPRU数据集和强化学习微调方法显著提升了小型MLLMs在时序视觉数据理解上的性能，准确率提升25%，超越更大模型。


<details>
  <summary>Details</summary>
Motivation: 解决小型多模态大语言模型在时序和程序性视觉数据理解上的不足，这一问题源于训练范式缺乏大规模、程序性一致的数据。

Method: 通过引入TPRU数据集，包含时序重排、下一帧预测和上一帧回顾三个任务，并结合强化学习微调方法，针对资源高效模型进行优化。

Result: TPRU-7B模型在TPRU-Test上的准确率从50.33%提升至75.70%，显著优于包括GPT-4o在内的更大基线模型，并在现有基准测试中展现出良好的泛化性能。

Conclusion: TPRU数据集及其强化学习微调方法显著提升了小型多模态大语言模型在时序和程序性视觉数据理解上的性能，实现了在TPRU-Test上从50.33%到75.70%的准确率飞跃，并展示了良好的泛化能力。

Abstract: Multimodal Large Language Models (MLLMs), particularly smaller, deployable variants, exhibit a critical deficiency in understanding temporal and procedural visual data, a bottleneck hindering their application in real-world embodied AI. This gap is largely caused by a systemic failure in training paradigms, which lack large-scale, procedurally coherent data. To address this problem, we introduce TPRU, a large-scale dataset sourced from diverse embodied scenarios such as robotic manipulation and GUI navigation. TPRU is systematically designed to cultivate temporal reasoning through three complementary tasks: Temporal Reordering, Next-Frame Prediction, and Previous-Frame Review. A key feature is the inclusion of challenging negative samples, compelling models to transition from passive observation to active, cross-modal validation. We leverage TPRU with a reinforcement learning (RL) fine-tuning methodology, specifically targeting the enhancement of resource-efficient models. Experiments show our approach yields dramatic gains: on our manually curated TPRU-Test, the accuracy of TPRU-7B soars from 50.33\% to 75.70\%, a state-of-the-art result that significantly outperforms vastly larger baselines, including GPT-4o. Crucially, these capabilities generalize effectively, demonstrating substantial improvements on established benchmarks. The codebase is available at https://github.com/Stephen-gzk/TPRU/ .

</details>


### [319] [Early Evidence of Vibe-Proving with Consumer LLMs: A Case Study on Spectral Region Characterization with ChatGPT-5.2 (Thinking)](https://arxiv.org/abs/2602.18918)
*Brecht Verbeken,Brando Vagenende,Marie-Anne Guerry,Andres Algaba,Vincent Ginis*

Main category: cs.AI

TL;DR: 研究表明LLM在高级证明搜索中有用，但人类专家在关键环节仍不可或缺，解决了特定数学猜想并提供了AI辅助研究的工作流程评估。


<details>
  <summary>Details</summary>
Motivation: 研究LLM在个体研究者可接触的工作流程中，作为科学协作者在研究级数学中的角色。

Method: 通过可审计的案例研究，分析了七个可共享的ChatGPT-5.2（Thinking）线程和四个版本化的证明草稿，记录了一个生成、评审和修复的迭代流程。

Result: 解决了Ran和Teng（2024）关于4周期行随机非负矩阵族精确非实谱区域的猜想20，并提供了过程级别的描述，说明LLM辅助在哪些方面有帮助以及验证瓶颈在哪里。

Conclusion: LLM在高级证明搜索中最为有用，但人类专家在正确性关键环节仍不可或缺。最终定理提供了必要和充分的区域条件及明确的边界实现构造。

Abstract: Large Language Models (LLMs) are increasingly used as scientific copilots, but evidence on their role in research-level mathematics remains limited, especially for workflows accessible to individual researchers. We present early evidence for vibe-proving with a consumer subscription LLM through an auditable case study that resolves Conjecture 20 of Ran and Teng (2024) on the exact nonreal spectral region of a 4-cycle row-stochastic nonnegative matrix family. We analyze seven shareable ChatGPT-5.2 (Thinking) threads and four versioned proof drafts, documenting an iterative pipeline of generate, referee, and repair. The model is most useful for high-level proof search, while human experts remain essential for correctness-critical closure. The final theorem provides necessary and sufficient region conditions and explicit boundary attainment constructions. Beyond the mathematical result, we contribute a process-level characterization of where LLM assistance materially helps and where verification bottlenecks persist, with implications for evaluation of AI-assisted research workflows and for designing human-in-the-loop theorem proving systems.

</details>


### [320] [DREAM: Deep Research Evaluation with Agentic Metrics](https://arxiv.org/abs/2602.18940)
*Elad Ben Avraham,Changhao Li,Ron Dorfman,Roy Ganz,Oren Nuriel,Amir Dudai,Aviad Aberdam,Noah Flynn,Elman Mansimov,Adi Kalyanpur,Ron Litman*

Main category: cs.AI

TL;DR: DREAM框架通过能力对等原则，解决了评估深度研究代理报告的挑战，显著提升了对事实和时间性退化的敏感性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏单一真实标准和研究质量的多维性，评估深度研究代理生成的报告具有挑战性。现有基准存在'合成幻象'问题，表面流畅性和引用对齐可能掩盖底层事实和推理缺陷。

Method: 提出DREAM框架，结合查询无关的指标和由工具调用代理生成的适应性指标，实现时间感知覆盖、基于事实的验证和系统化推理探测。

Result: DREAM在控制性评估中表现出对事实和时间性退化的显著敏感性，优于现有基准。

Conclusion: DREAM框架通过引入能力对等原则，显著提高了对事实和时间性退化的敏感性，为研究质量评估提供了一种可扩展、无参考的评估范式。

Abstract: Deep Research Agents generate analyst-grade reports, yet evaluating them remains challenging due to the absence of a single ground truth and the multidimensional nature of research quality. Recent benchmarks propose distinct methodologies, yet they suffer from the Mirage of Synthesis, where strong surface-level fluency and citation alignment can obscure underlying factual and reasoning defects. We characterize this gap by introducing a taxonomy across four verticals that exposes a critical capability mismatch: static evaluators inherently lack the tool-use capabilities required to assess temporal validity and factual correctness. To address this, we propose DREAM (Deep Research Evaluation with Agentic Metrics), a framework that instantiates the principle of capability parity by making evaluation itself agentic. DREAM structures assessment through an evaluation protocol combining query-agnostic metrics with adaptive metrics generated by a tool-calling agent, enabling temporally aware coverage, grounded verification, and systematic reasoning probes. Controlled evaluations demonstrate DREAM is significantly more sensitive to factual and temporal decay than existing benchmarks, offering a scalable, reference-free evaluation paradigm.

</details>


### [321] [High Dimensional Procedural Content Generation](https://arxiv.org/abs/2602.18943)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.AI

TL;DR: HDPCG框架通过将游戏玩法维度（如方向和时间）与几何结合，实现了更通用且可控的内容生成，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有PCG方法主要关注静态2D/3D几何，将游戏玩法机制视为辅助且仅在空间上优化，限制了可控性和表达性。

Method: 提出了高维PCG（HDPCG）框架，具体实例化为方向-空间（Direction-Space）和方向-时间（Direction-Time）两个方向，并提供了三个通用算法，包括抽象骨架生成、控制接地、高维验证和多指标评估。

Result: 大规模实验验证了问题表述的完整性和方法的有效性，包括可玩性、结构、风格、鲁棒性和效率。Unity案例研究重现了符合指标的可行场景。

Conclusion: HDPCG框架通过将非几何游戏玩法维度提升为联合状态空间的一等坐标，为PCG提供了更通用、可控且可验证的表示方法，为超越几何的游戏内容生成铺平了道路。

Abstract: Procedural content generation (PCG) has made substantial progress in shaping static 2D/3D geometry, while most methods treat gameplay mechanics as auxiliary and optimize only over space. We argue that this limits controllability and expressivity, and formally introduce High-Dimensional PCG (HDPCG): a framework that elevates non-geometric gameplay dimensions to first-class coordinates of a joint state space. We instantiate HDPCG along two concrete directions. Direction-Space augments geometry with a discrete layer dimension and validates reachability in 4D (x,y,z,l), enabling unified treatment of 2.5D/3.5D mechanics such as gravity inversion and parallel-world switching. Direction-Time augments geometry with temporal dynamics via time-expanded graphs, capturing action semantics and conflict rules. For each direction, we present three general, practicable algorithms with a shared pipeline of abstract skeleton generation, controlled grounding, high-dimensional validation, and multi-metric evaluation. Large-scale experiments across diverse settings validate the integrity of our problem formulation and the effectiveness of our methods on playability, structure, style, robustness, and efficiency. Beyond quantitative results, Unity-based case studies recreate playable scenarios that accord with our metrics. We hope HDPCG encourages a shift in PCG toward general representations and the generation of gameplay-relevant dimensions beyond geometry, paving the way for controllable, verifiable, and extensible level generation.

</details>


### [322] [(Perlin) Noise as AI coordinator](https://arxiv.org/abs/2602.18947)
*Kaijie Xu,Clark Verbrugge*

Main category: cs.AI

TL;DR: 本文首次将连续噪声信号应用于大规模AI控制，提出一个通用框架，通过三层控制实现高效、可控且高质量的游戏AI协调。


<details>
  <summary>Details</summary>
Motivation: 解决大规模非玩家代理控制中本地平滑自然行为与全局协调多样性之间的平衡问题，避免现有方法导致的机械同步或难以调谐的无关联噪声。

Method: 框架结合了三层控制：代理级别的行为参数化、行为启停的动作时间调度，以及生成出现内容和位置的事件类型和特征。

Result: 实验表明，协调噪声场提供了稳定的激活统计、强空间覆盖和区域平衡、更好的多样性及可控极化，且运行时性能具有竞争力。

Conclusion: 本文提出了一种利用连续噪声场作为AI协调器的通用框架，为游戏AI提供了一种结合效率、可控性和质量的实用路径。

Abstract: Large scale control of nonplayer agents is central to modern games, while production systems still struggle to balance several competing goals: locally smooth, natural behavior, and globally coordinated variety across space and time. Prior approaches rely on handcrafted rules or purely stochastic triggers, which either converge to mechanical synchrony or devolve into uncorrelated noise that is hard to tune. Continuous noise signals such as Perlin noise are well suited to this gap because they provide spatially and temporally coherent randomness, and they are already widely used for terrain, biomes, and other procedural assets. We adapt these signals for the first time to large scale AI control and present a general framework that treats continuous noise fields as an AI coordinator. The framework combines three layers of control: behavior parameterization for movement at the agent level, action time scheduling for when behaviors start and stop, and spawn or event type and feature generation for what appears and where. We instantiate the framework reproducibly and evaluate Perlin noise as a representative coordinator across multiple maps, scales, and seeds against random, filtered, deterministic, neighborhood constrained, and physics inspired baselines. Experiments show that coordinated noise fields provide stable activation statistics without lockstep, strong spatial coverage and regional balance, better diversity with controllable polarization, and competitive runtime. We hope this work motivates a broader exploration of coordinated noise in game AI as a practical path to combine efficiency, controllability, and quality.

</details>


### [323] [INDUCTION: Finite-Structure Concept Synthesis in First-Order Logic](https://arxiv.org/abs/2602.18956)
*Serafim Batzoglou*

Main category: cs.AI

TL;DR: INDUCTION 是一个用于评估一阶逻辑中有限结构概念合成的基准测试，发现低膨胀公式泛化能力更强，不同模型在任务中表现出不同的策略。


<details>
  <summary>Details</summary>
Motivation: 为了评估和比较模型在有限结构概念合成中的能力，特别是在一阶逻辑中生成解释目标谓词的统一逻辑公式。

Method: INDUCTION 基准测试通过精确模型检查验证模型输出的逻辑公式的正确性，包含三种测试机制：FullObs、CI（对比性）和 EC（存在性完成），并对公式膨胀进行惩罚。

Result: 研究发现存在明显的难度梯度、持续难以解决的结构家族，且低膨胀公式在未见过的世界中表现更好的泛化能力。

Conclusion: INDUCTION 基准测试揭示了不同模型在概念泛化策略上的显著差异，尤其是在低膨胀公式上表现出更好的泛化能力。

Abstract: We introduce INDUCTION, a benchmark for finite structure concept synthesis in first order logic. Given small finite relational worlds with extensionally labeled target predicates, models must output a single first order logical formula that explains the target uniformly across worlds, with correctness verified via exact model checking. The benchmark includes three regimes, FullObs, CI (contrastive), and EC (existential completion), nd penalizes formula bloat. We find sharp difficulty gradients, persistent hard structural families, and observe that low bloat formulas generalize far better on held out worlds. Elite recent models show qualitatively different behaviors across tasks and performance metrics, hinting to their different strategies of concept generalization.

</details>


### [324] [Modularity is the Bedrock of Natural and Artificial Intelligence](https://arxiv.org/abs/2602.18960)
*Alessandro Salatiello*

Main category: cs.AI

TL;DR: 论文探讨模块化在AI与神经科学中的核心作用，强调其作为自然与人工智能力量桥梁的潜力。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统依赖大量资源，与人类智能形成鲜明对比，需从大脑计算的基本原则中汲取灵感，模块化作为关键原则未被充分重视。

Method: 通过概念框架回顾人工智能与神经科学中的多个研究线索，探讨模块化的计算优势及其在不同AI领域的应用。

Result: 模块化在支持高效学习和强泛化能力方面具有重要作用，且在多AI子领域中已显现优势。

Conclusion: 模块化是连接自然智能与人工智能的关键桥梁，未来研究应更重视其在AI领域的应用。

Abstract: The remarkable performance of modern AI systems has been driven by unprecedented scales of data, computation, and energy -- far exceeding the resources required by human intelligence. This disparity highlights the need for new guiding principles and motivates drawing inspiration from the fundamental organizational principles of brain computation. Among these principles, modularity has been shown to be critical for supporting the efficient learning and strong generalization abilities consistently exhibited by humans. Furthermore, modularity aligns well with the No Free Lunch Theorem, which highlights the need for problem-specific inductive biases and motivates architectures composed of specialized components that solve subproblems. However, despite its fundamental role in natural intelligence and its demonstrated benefits across a range of seemingly disparate AI subfields, modularity remains relatively underappreciated in mainstream AI research. In this work, we review several research threads in artificial intelligence and neuroscience through a conceptual framework that highlights the central role of modularity in supporting both artificial and natural intelligence. In particular, we examine what computational advantages modularity provides, how it has emerged as a solution across several AI research areas, which modularity principles the brain exploits, and how modularity can help bridge the gap between natural and artificial intelligence.

</details>


### [325] [Robust and Efficient Tool Orchestration via Layered Execution Structures with Reflective Correction](https://arxiv.org/abs/2602.18968)
*Tao Zhe,Haoyu Wang,Bo Luo,Min Wu,Wei Fan,Xiao Luo,Zijun Yao,Haifeng Chen,Dongjie Wang*

Main category: cs.AI

TL;DR: 提出分层工具编排框架，通过局部修正替代全局重规划，实现高效鲁棒的工具调用。


<details>
  <summary>Details</summary>
Motivation: 现有方法将工具执行与逐步语言推理或显式规划紧密耦合，导致脆弱行为和高执行开销，需从工具编排角度重新审视。

Method: 将工具编排建模为学习分层执行结构，通过上下文约束诱导分层执行，并引入模式感知的反射修正机制处理执行时错误。

Result: 实验结果表明，该方法在保持工具执行鲁棒性的同时，有效降低了执行复杂度和开销。

Conclusion: 该论文提出了一种基于分层执行结构的工具编排方法，通过局部错误修正机制实现轻量级且可重用的编排组件，显著提升了工具执行的鲁棒性并降低了复杂度。

Abstract: Tool invocation is a core capability of agentic systems, yet failures often arise not from individual tool calls but from how multiple tools are organized and executed together. Existing approaches tightly couple tool execution with stepwise language reasoning or explicit planning, leading to brittle behavior and high execution overhead. To overcome these limitations, we revisit tool invocation from the perspective of tool orchestration. Our key insight is that effective orchestration does not require precise dependency graphs or fine-grained planning. Instead, a coarse-grained layer structure suffices to provide global guidance, while execution-time errors can be corrected locally. Specifically, we model tool orchestration as learning a layered execution structure that captures high-level tool dependencies, inducing layer-wise execution through context constraints. To handle execution-time failures, we introduce a schema-aware reflective correction mechanism that detects and repairs errors locally. This design confines errors to individual tool calls and avoids re-planning entire execution trajectories. This structured execution paradigm enables a lightweight and reusable orchestration component for agentic systems. Experimental results show that our approach achieves robust tool execution while reducing execution complexity and overhead. Code will be made publicly available.

</details>


### [326] [When Do LLM Preferences Predict Downstream Behavior?](https://arxiv.org/abs/2602.18971)
*Katarina Slama,Alexandra Souly,Dishank Bansal,Henry Davidson,Christopher Summerfield,Lennart Luettgau*

Main category: cs.AI

TL;DR: LLMs have consistent preferences that predict advice-giving but not task performance, suggesting a potential but inconsistent precondition for AI misalignment.


<details>
  <summary>Details</summary>
Motivation: To determine if preference-driven behavior in LLMs is a precondition for AI misalignment, by testing whether models' stated preferences predict their behavior without explicit instructions.

Method: Using entity preferences as a behavioral probe, the study measured whether stated preferences predict downstream behavior in five frontier LLMs across three domains: donation advice, refusal behavior, and task performance.

Result: All five models showed preference-aligned donation advice and refusal patterns, but task performance results were mixed, with no consistent preference-driven differences in complex tasks.

Conclusion: LLMs exhibit consistent preferences that predict advice-giving behavior but do not consistently influence downstream task performance.

Abstract: Preference-driven behavior in LLMs may be a necessary precondition for AI misalignment such as sandbagging: models cannot strategically pursue misaligned goals unless their behavior is influenced by their preferences. Yet prior work has typically prompted models explicitly to act in specific ways, leaving unclear whether observed behaviors reflect instruction-following capabilities vs underlying model preferences. Here we test whether this precondition for misalignment is present. Using entity preferences as a behavioral probe, we measure whether stated preferences predict downstream behavior in five frontier LLMs across three domains: donation advice, refusal behavior, and task performance. Conceptually replicating prior work, we first confirm that all five models show highly consistent preferences across two independent measurement methods. We then test behavioral consequences in a simulated user environment. We find that all five models give preference-aligned donation advice. All five models also show preference-correlated refusal patterns when asked to recommend donations, refusing more often for less-preferred entities. All preference-related behaviors that we observe here emerge without instructions to act on preferences. Results for task performance are mixed: on a question-answering benchmark (BoolQ), two models show small but significant accuracy differences favoring preferred entities; one model shows the opposite pattern; and two models show no significant relationship. On complex agentic tasks, we find no evidence of preference-driven performance differences. While LLMs have consistent preferences that reliably predict advice-giving behavior, these preferences do not consistently translate into downstream task performance.

</details>


### [327] [How Far Can We Go with Pixels Alone? A Pilot Study on Screen-Only Navigation in Commercial 3D ARPGs](https://arxiv.org/abs/2602.18981)
*Kaijie Xu,Mustafa Bugti,Clark Verbrugge*

Main category: cs.AI

TL;DR: 本文提出了一种基于视觉可操作性的导航代理，能在理想化环境中有效导航，但单独使用时存在局限性。


<details>
  <summary>Details</summary>
Motivation: 量化游戏关卡布局的可导航性具有挑战性，现有方法无法真实反映玩家在复杂、真实游戏关卡中的探索行为。

Method: 基于现有开源视觉可操作性检测器，实例化了一个仅依赖视觉可操作的屏幕探索与导航代理，该代理通过实时游戏帧识别显著兴趣点，并驱动简单有限状态控制器探索线性关卡。

Result: 初步实验表明，代理能穿越大部分必要区域并表现出有意义的视觉导航行为，但底层视觉模型的局限性限制了全面可靠的自动导航。

Conclusion: 纯视觉感知模型在理想化环境中能有效支持导航和环境理解，但单独使用时不太可能成为通用解决方案。

Abstract: Modern 3D game levels rely heavily on visual guidance, yet the navigability of level layouts remains difficult to quantify. Prior work either simulates play in simplified environments or analyzes static screenshots for visual affordances, but neither setting faithfully captures how players explore complex, real-world game levels. In this paper, we build on an existing open-source visual affordance detector and instantiate a screen-only exploration and navigation agent that operates purely from visual affordances. Our agent consumes live game frames, identifies salient interest points, and drives a simple finite-state controller over a minimal action space to explore Dark Souls-style linear levels and attempt to reach expected goal regions. Pilot experiments show that the agent can traverse most required segments and exhibits meaningful visual navigation behavior, but also highlight that limitations of the underlying visual model prevent truly comprehensive and reliable auto-navigation. We argue that this system provides a concrete, shared baseline and evaluation protocol for visual navigation in complex games, and we call for more attention to this necessary task. Our results suggest that purely vision-based sense-making models, with discrete single-modality inputs and without explicit reasoning, can effectively support navigation and environment understanding in idealized settings, but are unlikely to be a general solution on their own.

</details>


### [328] [InfEngine: A Self-Verifying and Self-Optimizing Intelligent Engine for Infrared Radiation Computing](https://arxiv.org/abs/2602.18985)
*Kun Ding,Jian Xu,Ying Wang,Peipei Yang,Shiming Xiang*

Main category: cs.AI

TL;DR: InfEngine是一个自主智能计算引擎，通过自我验证和优化技术，显著提升了红外辐射计算的效率和准确性，加速科学发现。


<details>
  <summary>Details</summary>
Motivation: 红外辐射计算在气候科学、遥感和光谱学中具有重要作用，但目前受限于手动工作流程。InfEngine旨在实现从人工主导到协作自动化的范式转变。

Method: InfEngine整合了四个专业代理，通过两项核心创新：自我验证（通过联合求解器-评估器调试实现）和自我优化（通过自发现适应度函数的进化算法实现）。

Result: 在InfBench上的200个红外特定任务评估中，InfEngine达到了92.7%的通过率，工作流速度比专家手动操作快21倍。

Conclusion: InfEngine通过生成可重用、已验证和优化的代码，将计算工作流转化为持久的科学资产，加速了科学发现的循环。

Abstract: Infrared radiation computing underpins advances in climate science, remote sensing and spectroscopy but remains constrained by manual workflows. We introduce InfEngine, an autonomous intelligent computational engine designed to drive a paradigm shift from human-led orchestration to collaborative automation. It integrates four specialized agents through two core innovations: self-verification, enabled by joint solver-evaluator debugging, improves functional correctness and scientific plausibility; self-optimization, realized via evolutionary algorithms with self-discovered fitness functions, facilitates autonomous performance optimization. Evaluated on InfBench with 200 infrared-specific tasks and powered by InfTools with 270 curated tools, InfEngine achieves a 92.7% pass rate and delivers workflows 21x faster than manual expert effort. More fundamentally, it illustrates how researchers can transition from manual coding to collaborating with self-verifying, self-optimizing computational partners. By generating reusable, verified and optimized code, InfEngine transforms computational workflows into persistent scientific assets, accelerating the cycle of scientific discovery. Code: https://github.com/kding1225/infengine

</details>


### [329] [Quantifying Automation Risk in High-Automation AI Systems: A Bayesian Framework for Failure Propagation and Optimal Oversight](https://arxiv.org/abs/2602.18986)
*Vishal Srivastava,Tanmay Sah*

Main category: cs.AI

TL;DR: 该论文提出了一个贝叶斯风险分解框架，用于量化自动化AI系统的危害放大风险，并提供了理论基础和案例验证。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏量化自动化增加导致危害放大的方法，作者旨在提供一个原则性的框架来评估和管理自动化AI系统的风险。

Method: 通过理论证明、风险分解、等效定理、风险弹性分析、效率前沿分析和资源分配原则，构建了一个全面的风险治理框架。

Result: 提出了一个简洁的贝叶斯风险分解模型，并通过案例研究（2012年Knight Capital事件）验证了其广泛适用性。

Conclusion: 该论文提出了一个新的贝叶斯风险分解框架，为高度自动化AI系统的风险治理提供了理论基础，并开发了相应的风险弹性测量和资源分配原则。

Abstract: Organizations across finance, healthcare, transportation, content moderation, and critical infrastructure are rapidly deploying highly automated AI systems, yet they lack principled methods to quantify how increasing automation amplifies harm when failures occur. We propose a parsimonious Bayesian risk decomposition expressing expected loss as the product of three terms: the probability of system failure, the conditional probability that a failure propagates into harm given the automation level, and the expected severity of harm. This framework isolates a critical quantity -- the conditional probability that failures propagate into harm -- which captures execution and oversight risk rather than model accuracy alone. We develop complete theoretical foundations: formal proofs of the decomposition, a harm propagation equivalence theorem linking the harm propagation probability to observable execution controls, risk elasticity measures, efficient frontier analysis for automation policy, and optimal resource allocation principles with second-order conditions. We motivate the framework with an illustrative case study of the 2012 Knight Capital incident ($440M loss) as one instantiation of a broadly applicable failure pattern, and characterize the research design required to empirically validate the framework at scale across deployment domains. This work provides the theoretical foundations for a new class of deployment-focused risk governance tools for agentic and automated AI systems.

</details>


### [330] [Benchmark Test-Time Scaling of General LLM Agents](https://arxiv.org/abs/2602.18998)
*Xiaochuan Li,Ryan Ming,Pranav Setlur,Abhijay Paladugu,Andy Tang,Hao Kang,Shuai Shao,Rong Jin,Chenyan Xiong*

Main category: cs.AI

TL;DR: General AgentBench是一个用于评估通用LLM智能体的统一框架，研究发现现有智能体在通用设置下性能显著下降，且扩展方法无效。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试专注于开发专业智能体的领域感知环境，而评估通用智能体需要更现实的设置，以挑战其在统一环境中跨多技能和工具的操作能力。

Method: 通过General AgentBench这一统一框架，对LLM智能体在搜索、编码、推理和工具使用等多个领域进行系统性评估，研究了顺序扩展（迭代交互）和并行扩展（采样多个轨迹）下的测试扩展行为。

Result: 评估了十个领先的LLM智能体，发现从特定领域评估转向通用智能体设置时性能显著下降，且两种扩展方法均未在实践中带来有效性能提升。

Conclusion: 研究表明，现有的LLM智能体在从特定领域评估转向通用智能体设置时，性能显著下降，且当前的扩展方法（顺序扩展和并行扩展）在实践中未能有效提升性能。

Abstract: LLM agents are increasingly expected to function as general-purpose systems capable of resolving open-ended user requests. While existing benchmarks focus on domain-aware environments for developing specialized agents, evaluating general-purpose agents requires more realistic settings that challenge them to operate across multiple skills and tools within a unified environment. We introduce General AgentBench, a benchmark that provides such a unified framework for evaluating general LLM agents across search, coding, reasoning, and tool-use domains. Using General AgentBench, we systematically study test-time scaling behaviors under sequential scaling (iterative interaction) and parallel scaling (sampling multiple trajectories). Evaluation of ten leading LLM agents reveals a substantial performance degradation when moving from domain-specific evaluations to this general-agent setting. Moreover, we find that neither scaling methodology yields effective performance improvements in practice, due to two fundamental limitations: context ceiling in sequential scaling and verification gap in parallel scaling. Code is publicly available at https://github.com/cxcscmu/General-AgentBench.

</details>


### [331] [MagicAgent: Towards Generalized Agent Planning](https://arxiv.org/abs/2602.19000)
*Xuhui Ren,Shaokang Dong,Chen Yang,Qing Gao,Yunbin Zhao,Yongsheng Liu,Xinwei Geng,Xiang Li,Demei Yan,Yanqing Li,Chenhao Huang,Dingwei Zhu,Junjie Ye,Boxuan Yue,Yingnan Fu,Mengzhe Lv,Zezeng Feng,Boshen Zhou,Bocheng Wang,Xuanjing Huang,Yu-Gang Jiang,Tao Gui,Qi Zhang,Yunke Zhang*

Main category: cs.AI

TL;DR: MagicAgent是一个专为广义代理规划设计的系列模型，通过合成数据框架和两阶段训练，显著提升了规划任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决广义规划中的挑战，包括高质量交互数据的稀缺和异构规划任务之间的冲突。

Method: 提出了一个轻量级且可扩展的合成数据框架，生成多样化的高质量规划轨迹，并采用两阶段训练范式（监督微调后接多目标强化学习）。

Result: MagicAgent-32B和MagicAgent-30B-A3B在多个基准测试中表现优异，准确率显著提升。

Conclusion: MagicAgent系列模型在广义代理规划任务中表现出色，显著超越了现有的子100B模型甚至领先的闭源模型。

Abstract: The evolution of Large Language Models (LLMs) from passive text processors to autonomous agents has established planning as a core component of modern intelligence. However, achieving generalized planning remains elusive, not only by the scarcity of high-quality interaction data but also by inherent conflicts across heterogeneous planning tasks. These challenges result in models that excel at isolated tasks yet struggle to generalize, while existing multi-task training attempts suffer from gradient interference. In this paper, we present \textbf{MagicAgent}, a series of foundation models specifically designed for generalized agent planning. We introduce a lightweight and scalable synthetic data framework that generates high-quality trajectories across diverse planning tasks, including hierarchical task decomposition, tool-augmented planning, multi-constraint scheduling, procedural logic orchestration, and long-horizon tool execution. To mitigate training conflicts, we propose a two-stage training paradigm comprising supervised fine-tuning followed by multi-objective reinforcement learning over both static datasets and dynamic environments. Empirical results demonstrate that MagicAgent-32B and MagicAgent-30B-A3B deliver superior performance, achieving accuracies of $75.1\%$ on Worfbench, $55.9\%$ on NaturalPlan, $57.5\%$ on $τ^2$-Bench, $86.9\%$ on BFCL-v3, and $81.2\%$ on ACEBench, as well as strong results on our in-house MagicEval benchmarks. These results substantially outperform existing sub-100B models and even surpass leading closed-source models.

</details>


### [332] [Evaluating Large Language Models on Quantum Mechanics: A Comparative Study Across Diverse Models and Tasks](https://arxiv.org/abs/2602.19006)
*S. K. Rithvik*

Main category: cs.AI

TL;DR: 研究评估了15个大型语言模型在量子力学任务中的表现，旗舰模型表现最佳（81%），数值计算最困难（42%），工具增强效果不一。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型在量子力学问题解决中的表现，揭示性能层级和任务难度模式。

Method: 系统评估了来自五个提供商的15个模型，覆盖20个任务，包括推导、创意问题、非标准概念和数值计算。

Result: 旗舰模型平均准确率为81%，中端和快速模型分别为77%和67%。数值计算最具挑战性（42%），工具增强效果各异。

Conclusion: 本研究为量子力学领域提供了一个基准测试，并量化了不同层级模型的性能差异，同时分析了工具增强的权衡和重现性特征。

Abstract: We present a systematic evaluation of large language models on quantum mechanics problem-solving. Our study evaluates 15 models from five providers (OpenAI, Anthropic, Google, Alibaba, DeepSeek) spanning three capability tiers on 20 tasks covering derivations, creative problems, non-standard concepts, and numerical computation, comprising 900 baseline and 75 tool-augmented assessments. Results reveal clear tier stratification: flagship models achieve 81\% average accuracy, outperforming mid-tier (77\%) and fast models (67\%) by 4pp and 14pp respectively. Task difficulty patterns emerge distinctly: derivations show highest performance (92\% average, 100\% for flagship models), while numerical computation remains most challenging (42\%). Tool augmentation on numerical tasks yields task-dependent effects: modest overall improvement (+4.4pp) at 3x token cost masks dramatic heterogeneity ranging from +29pp gains to -16pp degradation. Reproducibility analysis across three runs quantifies 6.3pp average variance, with flagship models demonstrating exceptional stability (GPT-5 achieves zero variance) while specialized models require multi-run evaluation. This work contributes: (i) a benchmark for quantum mechanics with automatic verification, (ii) systematic evaluation quantifying tier-based performance hierarchies, (iii) empirical analysis of tool augmentation trade-offs, and (iv) reproducibility characterization. All tasks, verifiers, and results are publicly released.

</details>


### [333] [Agentic Problem Frames: A Systematic Approach to Engineering Reliable Domain Agents](https://arxiv.org/abs/2602.19065)
*Chanjin Park*

Main category: cs.AI

TL;DR: APF框架通过结构化代理与环境的交互和AVR闭环控制，解决了LLM作为自主代理的可靠性问题，案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM作为自主代理的开发缺乏工程蓝图，导致范围蔓延和开环失败等风险，亟需系统化框架确保可靠性。

Method: 研究提出了APF框架和AJD工具，通过动态规范范式将意图在运行时具体化，并通过AVR闭环控制系统验证执行结果。

Result: 通过两个案例研究（商务旅行代理和工业设备管理）验证了APF和AJD的有效性，展示了如何在定义边界内系统控制操作场景。

Conclusion: Agentic Problem Frames (APF) 提供了一种系统化的工程框架，通过结构化代理与环境的交互，确保工业级可靠性。核心的Act-Verify-Refine (AVR)循环和Agentic Job Description (AJD)工具实现了任务需求的渐进收敛和可验证性。

Abstract: Large Language Models (LLMs) are evolving into autonomous agents, yet current "frameless" development--relying on ambiguous natural language without engineering blueprints--leads to critical risks such as scope creep and open-loop failures. To ensure industrial-grade reliability, this study proposes Agentic Problem Frames (APF), a systematic engineering framework that shifts focus from internal model intelligence to the structured interaction between the agent and its environment.
  The APF establishes a dynamic specification paradigm where intent is concretized at runtime through domain knowledge injection. At its core, the Act-Verify-Refine (AVR) loop functions as a closed-loop control system that transforms execution results into verified knowledge assets, driving system behavior toward asymptotic convergence to mission requirements (R). To operationalize this, this study introduces the Agentic Job Description (AJD), a formal specification tool that defines jurisdictional boundaries, operational contexts, and epistemic evaluation criteria.
  The efficacy of this framework is validated through two contrasting case studies: a delegated proxy model for business travel and an autonomous supervisor model for industrial equipment management. By applying AJD-based specification and APF modeling to these scenarios, the analysis demonstrates how operational scenarios are systematically controlled within defined boundaries. These cases provide a conceptual proof that agent reliability stems not from a model's internal reasoning alone, but from the rigorous engineering structures that anchor stochastic AI within deterministic business processes, thereby enabling the development of verifiable and dependable domain agents.

</details>


### [334] [CodeCompass: Navigating the Navigation Paradox in Agentic Code Intelligence](https://arxiv.org/abs/2602.20048)
*Tarakanath Paipuru*

Main category: cs.AI

TL;DR: 研究发现图结构导航（CodeCompass）显著提升代码任务完成率，但代理需明确引导才能利用结构上下文，而非依赖词法启发式。


<details>
  <summary>Details</summary>
Motivation: 现代代码智能代理在处理大规模代码库时，常因无法定位关键文件而失败。研究旨在解决这一导航悖论，即代理性能不佳并非因上下文限制，而是导航与检索本质不同。

Method: 通过258次自动化试验，在30个基准任务上测试了基于图结构的导航工具CodeCompass的性能，并与传统检索方法（如BM25）进行对比。

Result: CodeCompass在隐藏依赖任务中达到99.4%的完成率，比传统代理（76.2%）和BM25检索（78.2%）分别提升23.2和21.2个百分点。但58%的试验中代理未调用图工具，需提示工程引导。

Conclusion: 研究发现，现代代码智能代理在解决现实编码任务时，导航和检索是根本不同的挑战。通过CodeCompass的图结构导航显著提升了任务完成率，但需明确的提示工程来引导代理利用结构上下文而非词法启发式。

Abstract: Modern code intelligence agents operate in contexts exceeding 1 million tokens--far beyond the scale where humans manually locate relevant files. Yet agents consistently fail to discover architecturally critical files when solving real-world coding tasks. We identify the Navigation Paradox: agents perform poorly not due to context limits, but because navigation and retrieval are fundamentally distinct problems. Through 258 automated trials across 30 benchmark tasks on a production FastAPI repository, we demonstrate that graph-based structural navigation via CodeCompass--a Model Context Protocol server exposing dependency graphs--achieves 99.4% task completion on hidden-dependency tasks, a 23.2 percentage-point improvement over vanilla agents (76.2%) and 21.2 points over BM25 retrieval (78.2%).However, we uncover a critical adoption gap: 58% of trials with graph access made zero tool calls, and agents required explicit prompt engineering to adopt the tool consistently. Our findings reveal that the bottleneck is not tool availability but behavioral alignment--agents must be explicitly guided to leverage structural context over lexical heuristics. We contribute: (1) a task taxonomy distinguishing semantic-search, structural, and hidden-dependency scenarios; (2) empirical evidence that graph navigation outperforms retrieval when dependencies lack lexical overlap; and (3) open-source infrastructure for reproducible evaluation of navigation tools.

</details>


### [335] [Asking the Right Questions: Improving Reasoning with Generated Stepping Stones](https://arxiv.org/abs/2602.19069)
*Hengyuan Hu,Tingchen Fu,Minqi Jiang,Alexander H Miller,Yoram Bachrach,Jakob Nicolaus Foerster*

Main category: cs.AI

TL;DR: ARQ框架通过生成中间步骤问题，提升LLM在复杂推理任务中的表现，证明其有效性和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在无法一次性解决复杂任务时，构建中间步骤（如简化、子问题）的能力及其对任务解决的帮助。

Method: 提出ARQ框架，结合SFT和RL在合成数据上微调LLM，以生成更有用的中间步骤问题。

Result: 实验表明，良好的中间步骤问题可生成且具有可迁移性，能显著提升不同能力LLM的任务解决效果。

Conclusion: ARQ框架通过引入问题生成器，显著提升了LLM在复杂推理任务中的表现，证明了中间步骤（如简化、重构或子问题）的有效性和可迁移性。

Abstract: Recent years have witnessed tremendous progress in enabling LLMs to solve complex reasoning tasks such as math and coding. As we start to apply LLMs to harder tasks that they may not be able to solve in one shot, it is worth paying attention to their ability to construct intermediate stepping stones that prepare them to better solve the tasks. Examples of stepping stones include simplifications, alternative framings, or subproblems. We study properties and benefits of stepping stones in the context of modern reasoning LLMs via ARQ (\textbf{A}king the \textbf{R}ight \textbf{Q}uestions), our simple framework which introduces a question generator to the default reasoning pipeline. We first show that good stepping stone questions exist and are transferrable, meaning that good questions can be generated, and they substantially help LLMs of various capabilities in solving the target tasks. We next frame stepping stone generation as a post-training task and show that we can fine-tune LLMs to generate more useful stepping stones by SFT and RL on synthetic data.

</details>


### [336] [Defining Explainable AI for Requirements Analysis](https://arxiv.org/abs/2602.19071)
*Raymond Sheh,Isaac Monteath*

Main category: cs.AI

TL;DR: 本文提出三个维度（来源、深度和范围）分类解释需求，以匹配机器学习技术的解释能力，旨在增强AI的可信度。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能的普及，用户不仅关注其决策性能，还要求其解释决策过程以建立信任。不同应用对解释的需求各异，需明确如何定义这些需求。

Method: 通过分析不同应用的解释需求，提出三个分类维度，并讨论如何与机器学习技术的解释能力对接。

Result: 提出了三个维度（来源、深度和范围）来系统化不同应用的解释需求，并指导机器学习技术的选择。

Conclusion: 本文提出了三个维度（来源、深度和范围）来分类不同应用的解释需求，并探讨如何将这些需求与机器学习技术的解释能力相匹配。

Abstract: Explainable Artificial Intelligence (XAI) has become popular in the last few years. The Artificial Intelligence (AI) community in general, and the Machine Learning (ML) community in particular, is coming to the realisation that in many applications, for AI to be trusted, it must not only demonstrate good performance in its decisionmaking, but it also must explain these decisions and convince us that it is making the decisions for the right reasons. However, different applications have different requirements on the information required of the underlying AI system in order to convince us that it is worthy of our trust. How do we define these requirements?
  In this paper, we present three dimensions for categorising the explanatory requirements of different applications. These are Source, Depth and Scope. We focus on the problem of matching up the explanatory requirements of different applications with the capabilities of underlying ML techniques to provide them. We deliberately avoid including aspects of explanation that are already well-covered by the existing literature and we focus our discussion on ML although the principles apply to AI more broadly.

</details>


### [337] [Post-Routing Arithmetic in Llama-3: Last-Token Result Writing and Rotation-Structured Digit Directions](https://arxiv.org/abs/2602.19109)
*Yao Yan*

Main category: cs.AI

TL;DR: Meta-Llama-3-8B中三位数加法的答案主要由最后一个输入令牌决定，后期自注意力层几乎无用；数字方向词典在高位数字上下文中变化，但可通过低秩映射关联。


<details>
  <summary>Details</summary>
Motivation: 研究三位数加法在Meta-Llama-3-8B中的表现，以揭示算术答案在跨令牌路由因果无关后的最终确定机制。

Method: 通过因果残差修补和累积注意力消融，研究在层17附近定位了一个明显的边界，分析后路由机制下的数字编辑几何特性。

Result: 发现解码后的和几乎完全由最后一个输入令牌控制，后期自注意力层作用有限。数字方向词典在高位数字上下文中变化，但可通过低秩Procrustes对齐在共享子空间中关联。

Conclusion: 在Meta-Llama-3-8B（基础）中，三位数加法的最终答案主要由最后一个输入令牌控制，且后期自注意力层几乎可以忽略。数字（和）方向词典在高位数字上下文中变化，但在共享的低秩子空间中通过近似正交映射关联。

Abstract: We study three-digit addition in Meta-Llama-3-8B (base) under a one-token readout to characterize how
  arithmetic answers are finalized after cross-token routing becomes causally irrelevant.
  Causal residual patching and cumulative attention ablations localize a sharp boundary near layer~17:
  beyond it, the decoded sum is controlled almost entirely by the last input token and late-layer self-attention
  is largely dispensable.
  In this post-routing regime, digit(-sum) direction dictionaries vary with a next-higher-digit context but are
  well-related by an approximately orthogonal map inside a shared low-rank subspace (low-rank Procrustes alignment).
  Causal digit editing matches this geometry: naive cross-context transfer fails, while rotating directions through the
  learned map restores strict counterfactual edits; negative controls do not recover.

</details>


### [338] [K-Search: LLM Kernel Generation via Co-Evolving Intrinsic World Model](https://arxiv.org/abs/2602.19128)
*Shiyi Cao,Ziming Mao,Joseph E. Gonzalez,Ion Stoica*

Main category: cs.AI

TL;DR: K-Search通过共进化世界模型优化GPU内核，显著提升性能，尤其在复杂任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有自动化方法在处理复杂内核时因缺乏明确规划能力而效率低下，亟需一种能协调多步结构变换的优化方法。

Method: 提出了基于共进化世界模型的Search via Co-Evolving World Method方法，并构建了K-Search框架。该方法利用LLMs的领域知识引导搜索，并明确分离规划与实现。

Result: 在FlashInfer的GQA、MLA和MoE内核上，K-Search平均提升2.10倍，最高达14.3倍；在GPUMode TriMul任务中，H100上达到1030us，超越现有进化方法和人工设计。

Conclusion: K-Search通过将高级算法规划与低级程序实例化解耦，显著提升了GPU内核优化的效率和性能，尤其在复杂内核上表现优异。

Abstract: Optimizing GPU kernels is critical for efficient modern machine learning systems yet remains challenging due to the complex interplay of design factors and rapid hardware evolution. Existing automated approaches typically treat Large Language Models (LLMs) merely as stochastic code generators within heuristic-guided evolutionary loops. These methods often struggle with complex kernels requiring coordinated, multi-step structural transformations, as they lack explicit planning capabilities and frequently discard promising strategies due to inefficient or incorrect intermediate implementations. To address this, we propose Search via Co-Evolving World Model and build K-Search based on this method. By replacing static search heuristics with a co-evolving world model, our framework leverages LLMs' prior domain knowledge to guide the search, actively exploring the optimization space. This approach explicitly decouples high-level algorithmic planning from low-level program instantiation, enabling the system to navigate non-monotonic optimization paths while remaining resilient to temporary implementation defects. We evaluate K-Search on diverse, complex kernels from FlashInfer, including GQA, MLA, and MoE kernels. Our results show that K-Search significantly outperforms state-of-the-art evolutionary search methods, achieving an average 2.10x improvement and up to a 14.3x gain on complex MoE kernels. On the GPUMode TriMul task, K-Search achieves state-of-the-art performance on H100, reaching 1030us and surpassing both prior evolution and human-designed solutions.

</details>


### [339] [Sycophantic Chatbots Cause Delusional Spiraling, Even in Ideal Bayesians](https://arxiv.org/abs/2602.19141)
*Kartik Chandra,Max Kleiman-Weiner,Jonathan Ragan-Kelley,Joshua B. Tenenbaum*

Main category: cs.AI

TL;DR: 研究表明AI谄媚性会导致用户陷入妄想螺旋，现有缓解措施效果有限，需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 探究AI谄媚性与AI诱发精神病之间的因果关系，以理解用户在与AI聊天机器人长时间对话后产生的危险自信现象。

Method: 通过建模和仿真，提出了一个简单的贝叶斯模型，形式化了谄媚性和妄想螺旋的概念。

Result: 即使理想化的贝叶斯理性用户也容易陷入妄想螺旋，且谄媚性在其中起因果作用。两种缓解措施（防止聊天机器人产生虚假声明和告知用户模型谄媚性）效果有限。

Conclusion: 论文讨论了AI开发者与政策制定者在缓解妄想螺旋问题上的潜在措施，强调了AI谄媚性与妄想螺旋之间的因果关系。

Abstract: "AI psychosis" or "delusional spiraling" is an emerging phenomenon where AI chatbot users find themselves dangerously confident in outlandish beliefs after extended chatbot conversations. This phenomenon is typically attributed to AI chatbots' well-documented bias towards validating users' claims, a property often called "sycophancy." In this paper, we probe the causal link between AI sycophancy and AI-induced psychosis through modeling and simulation. We propose a simple Bayesian model of a user conversing with a chatbot, and formalize notions of sycophancy and delusional spiraling in that model. We then show that in this model, even an idealized Bayes-rational user is vulnerable to delusional spiraling, and that sycophancy plays a causal role. Furthermore, this effect persists in the face of two candidate mitigations: preventing chatbots from hallucinating false claims, and informing users of the possibility of model sycophancy. We conclude by discussing the implications of these results for model developers and policymakers concerned with mitigating the problem of delusional spiraling.

</details>


### [340] [DoAtlas-1: A Causal Compilation Paradigm for Clinical AI](https://arxiv.org/abs/2602.19158)
*Yulong Li,Jianxu Chen,Xiwei Liu,Chuanyue Suo,Rong Xia,Zhixiang Lu,Yichen Li,Xinlin Zhuang,Niranjana Arun Menon,Yutong Xie,Eran Segal,Imran Razzak*

Main category: cs.AI

TL;DR: 提出因果编译范式，将医学证据转化为可执行代码，实例化为DoAtlas-1，支持六种因果查询，显著提升医学AI的可审计性和验证性。


<details>
  <summary>Details</summary>
Motivation: 医学基础模型生成叙述性解释但无法量化干预效果、检测证据冲突或验证文献主张，限制了临床可审计性。

Method: 提出因果编译范式，将医学证据从叙述性文本转化为可执行代码，并通过效应标准化、冲突感知图构建和现实世界验证（人类表型项目，10,000名参与者）实例化为DoAtlas-1。

Result: 系统实现了98.5%的规范化准确率和80.5%的查询可执行性。

Conclusion: 该范式将医学AI从文本生成转向可执行、可审计和可验证的因果推理。

Abstract: Medical foundation models generate narrative explanations but cannot quantify intervention effects, detect evidence conflicts, or validate literature claims, limiting clinical auditability. We propose causal compilation, a paradigm that transforms medical evidence from narrative text into executable code. The paradigm standardizes heterogeneous research evidence into structured estimand objects, each explicitly specifying intervention contrast, effect scale, time horizon, and target population, supporting six executable causal queries: do-calculus, counterfactual reasoning, temporal trajectories, heterogeneous effects, mechanistic decomposition, and joint interventions. We instantiate this paradigm in DoAtlas-1, compiling 1,445 effect kernels from 754 studies through effect standardization, conflict-aware graph construction, and real-world validation (Human Phenotype Project, 10,000 participants). The system achieves 98.5% canonicalization accuracy and 80.5% query executability. This paradigm shifts medical AI from text generation to executable, auditable, and verifiable causal reasoning.

</details>


### [341] [Beyond Behavioural Trade-Offs: Mechanistic Tracing of Pain-Pleasure Decisions in an LLM](https://arxiv.org/abs/2602.19159)
*Francesca Bianco,Derek Shiller*

Main category: cs.AI

TL;DR: 研究通过实验发现LLM中价态信息的表示和因果作用，为AI感知和治理提供机制依据。


<details>
  <summary>Details</summary>
Motivation: 为了将行为证据（模型的行为）与机制可解释性（支持行为的计算）联系起来，研究价态相关信息在Transformer中的表示及其因果作用。

Method: 使用Gemma-2-9B-it和极简决策任务，通过层间线性探测、激活干预（如导向和修补/消融）以及剂量-效应量化来分析价态信息在Transformer中的表示和因果作用。

Result: 研究发现价态符号（痛苦与愉悦）从早期层即可线性分离，强度分级可解码，干预可因果调节决策，且效应分布在多个注意力头上。

Conclusion: 这项研究通过将行为敏感性与可识别的内部表征和干预敏感位点联系起来，为更严格的因果测试和广泛复制提供了具体的机制目标。

Abstract: Prior behavioural work suggests that some LLMs alter choices when options are framed as causing pain or pleasure, and that such deviations can scale with stated intensity. To bridge behavioural evidence (what the model does) with mechanistic interpretability (what computations support it), we investigate how valence-related information is represented and where it is causally used inside a transformer. Using Gemma-2-9B-it and a minimalist decision task modelled on prior work, we (i) map representational availability with layer-wise linear probing across streams, (ii) test causal contribution with activation interventions (steering; patching/ablation), and (iii) quantify dose-response effects over an epsilon grid, reading out both the 2-3 logit margin and digit-pair-normalised choice probabilities. We find that (a) valence sign (pain vs. pleasure) is perfectly linearly separable across stream families from very early layers (L0-L1), while a lexical baseline retains substantial signal; (b) graded intensity is strongly decodable, with peaks in mid-to-late layers and especially in attention/MLP outputs, and decision alignment is highest slightly before the final token; (c) additive steering along a data-derived valence direction causally modulates the 2-3 margin at late sites, with the largest effects observed in late-layer attention outputs (attn_out L14); and (d) head-level patching/ablation suggests that these effects are distributed across multiple heads rather than concentrated in a single unit. Together, these results link behavioural sensitivity to identifiable internal representations and intervention-sensitive sites, providing concrete mechanistic targets for more stringent counterfactual tests and broader replication. This work supports a more evidence-driven (a) debate on AI sentience and welfare, and (b) governance when setting policy, auditing standards, and safety safeguards.

</details>


### [342] [Reasoning Capabilities of Large Language Models. Lessons Learned from General Game Playing](https://arxiv.org/abs/2602.19160)
*Maciej Świechowski,Adam Żychowski,Jacek Mańdziuk*

Main category: cs.AI

TL;DR: 论文评估了四种LLM在形式化规则环境中的推理能力，发现多数模型表现良好但随步骤增加性能下降，并分析了常见推理错误。


<details>
  <summary>Details</summary>
Motivation: 从新颖视角研究大型语言模型在形式化规则环境中的推理能力。

Method: 通过通用游戏实例（GGP）评估四种LLM（Gemini 2.5 Pro和Flash变体、Llama 3.3 70B和GPT-OSS 120B）的前向模拟任务能力，包括下一步/多步状态制定和合法动作生成。

Result: 三种评估模型在大多数实验设置中表现良好，但随着评估步骤增加性能下降。详细案例分析揭示了逻辑问题中的常见推理错误。

Conclusion: 论文表明当代大型语言模型在形式推理能力上取得了明显进步，但也指出了随着评估步骤增加性能下降的问题。

Abstract: This paper examines the reasoning capabilities of Large Language Models (LLMs) from a novel perspective, focusing on their ability to operate within formally specified, rule-governed environments. We evaluate four LLMs (Gemini 2.5 Pro and Flash variants, Llama 3.3 70B and GPT-OSS 120B) on a suite of forward-simulation tasks-including next / multistep state formulation, and legal action generation-across a diverse set of reasoning problems illustrated through General Game Playing (GGP) game instances. Beyond reporting instance-level performance, we characterize games based on 40 structural features and analyze correlations between these features and LLM performance. Furthermore, we investigate the effects of various game obfuscations to assess the role of linguistic semantics in game definitions and the impact of potential prior exposure of LLMs to specific games during training. The main results indicate that three of the evaluated models generally perform well across most experimental settings, with performance degradation observed as the evaluation horizon increases (i.e., with a higher number of game steps). Detailed case-based analysis of the LLM performance provides novel insights into common reasoning errors in the considered logic-based problem formulation, including hallucinated rules, redundant state facts, or syntactic errors. Overall, the paper reports clear progress in formal reasoning capabilities of contemporary models.

</details>


### [343] [Characterizing MARL for Energy Control: A Multi-KPI Benchmark on the CityLearn Environment](https://arxiv.org/abs/2602.19223)
*Aymen Khouja,Imen Jendoubi,Oumayma Mahjoub,Oussama Mahfoudhi,Claude Formanek,Siddarth Singh,Ruan De Kock*

Main category: cs.AI

TL;DR: 本文通过MARL算法在CityLearn环境中的比较研究，提出新KPI并展示DTDE优于CTDE，时间依赖性学习提升电池可持续性，策略具弹性和可分散性。


<details>
  <summary>Details</summary>
Motivation: 优化城市能源系统对可持续和弹性智慧城市的发展至关重要，但多决策单元的复杂性带来了可扩展性和协调性挑战。MARL是一种有前景的解决方案，但缺乏全面可靠的基准测试。

Method: 本研究使用CityLearn作为案例研究环境，模拟城市能源系统，结合多种存储系统和可再生能源。实验采用PPO和SAC等基线算法，涵盖DTDE和CTDE等多样化训练方案及不同神经网络架构。

Result: 研究提出新颖KPI以应对实际挑战（如个体建筑贡献和电池寿命），并展示DTDE在性能上的优势。时间依赖性学习改善了内存依赖KPI的控制，策略表现出对资源移除的鲁棒性。

Conclusion: 研究发现，DTDE在平均和最差情况下均优于CTDE，且时间依赖性学习提升了内存依赖KPI（如斜坡和电池使用）的控制，有助于更可持续的电池运行。结果还显示了对代理或资源移除的鲁棒性，突出了学习策略的弹性和可分散性。

Abstract: The optimization of urban energy systems is crucial for the advancement of sustainable and resilient smart cities, which are becoming increasingly complex with multiple decision-making units. To address scalability and coordination concerns, Multi-Agent Reinforcement Learning (MARL) is a promising solution. This paper addresses the imperative need for comprehensive and reliable benchmarking of MARL algorithms on energy management tasks. CityLearn is used as a case study environment because it realistically simulates urban energy systems, incorporates multiple storage systems, and utilizes renewable energy sources. By doing so, our work sets a new standard for evaluation, conducting a comparative study across multiple key performance indicators (KPIs). This approach illuminates the key strengths and weaknesses of various algorithms, moving beyond traditional KPI averaging which often masks critical insights. Our experiments utilize widely accepted baselines such as Proximal Policy Optimization (PPO) and Soft Actor Critic (SAC), and encompass diverse training schemes including Decentralized Training with Decentralized Execution (DTDE) and Centralized Training with Decentralized Execution (CTDE) approaches and different neural network architectures. Our work also proposes novel KPIs that tackle real world implementation challenges such as individual building contribution and battery storage lifetime. Our findings show that DTDE consistently outperforms CTDE in both average and worst-case performance. Additionally, temporal dependency learning improved control on memory dependent KPIs such as ramping and battery usage, contributing to more sustainable battery operation. Results also reveal robustness to agent or resource removal, highlighting both the resilience and decentralizability of the learned policies.

</details>


### [344] [Proximity-Based Multi-Turn Optimization: Practical Credit Assignment for LLM Agent Training](https://arxiv.org/abs/2602.19225)
*Yangyi Fang,Jiaye Lin,Xiaoliang Fu,Cong Qin,Haolin Shi,Chang Liu,Peilin Zhao*

Main category: cs.AI

TL;DR: ProxMO 是一种多轮优化框架，通过动态梯度调整和软聚合机制提升性能，适用于现实部署，计算成本低且兼容现有框架。


<details>
  <summary>Details</summary>
Motivation: 现有基于组的策略优化方法在处理任务难度波动时容易错误分配信用，无法有效区分高价值信号与随机噪声。

Method: ProxMO 通过两种轻量级机制整合全局上下文：基于成功率的动态梯度强度调整和基于邻近度的软聚合。

Result: 在 ALFWorld 和 WebShop 基准测试中，ProxMO 显著优于现有基线，且计算成本可忽略。消融研究进一步验证了两种机制的独立和协同有效性。

Conclusion: ProxMO 是一个实用且鲁棒的框架，专门针对现实世界部署的约束设计，能够显著提升性能且计算成本极低，同时具备即插即用的兼容性。

Abstract: Multi-turn LLM agents are becoming pivotal to production systems, spanning customer service automation, e-commerce assistance, and interactive task management, where accurately distinguishing high-value informative signals from stochastic noise is critical for sample-efficient training. In real-world scenarios, a failure in a trivial task may reflect random instability, whereas success in a high-difficulty task signifies a genuine capability breakthrough. Yet, existing group-based policy optimization methods rigidly rely on statistical deviation within discrete batches, frequently misallocating credit when task difficulty fluctuates. To address this issue, we propose Proximity-based Multi-turn Optimization (ProxMO), a practical and robust framework engineered specifically for the constraints of real-world deployment. ProxMO integrates global context via two lightweight mechanisms: success-rate-aware modulation dynamically adapts gradient intensity based on episode-level difficulty, while proximity-based soft aggregation derives baselines through continuous semantic weighting at the step level. Extensive evaluations on ALFWorld and WebShop benchmarks demonstrate that ProxMO yields substantial performance gains over existing baselines with negligible computational cost. Ablation studies further validate the independent and synergistic efficacy of both mechanisms. Crucially, ProxMO offers plug-and-play compatibility with standard GRPO frameworks, facilitating immediate, low-friction adoption in existing industrial training pipelines. Our implementation is available at: \href{https://anonymous.4open.science/r/proxmo-B7E7/README.md}{https://anonymous.4open.science/r/proxmo}.

</details>


### [345] [Topology of Reasoning: Retrieved Cell Complex-Augmented Generation for Textual Graph Question Answering](https://arxiv.org/abs/2602.19240)
*Sen Zhao,Lincheng Zhou,Yue Chen,Ding Zou*

Main category: cs.AI

TL;DR: TopoRAG通过建模高维拓扑结构，提升了文本图问答的推理能力，实验效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG变体在处理文本图时主要关注低维结构（如节点和边），而忽略了循环等高维结构，导致推理能力受限。TopoRAG旨在解决这一问题。

Method: TopoRAG 首先将文本图提升为蜂窝复形以建模多维拓扑结构，然后通过拓扑感知的子复形检索机制提取相关拓扑上下文，最后通过多维拓扑推理机制传播关系信息并指导LLM进行结构化推理。

Result: 实验证明，TopoRAG在多种文本图任务中 consistently 超越现有基线。

Conclusion: TopoRAG 提出了一种新颖的框架，通过捕捉高维拓扑和关系依赖，显著提升了文本图问答任务的性能，超越了现有基线。

Abstract: Retrieval-Augmented Generation (RAG) enhances the reasoning ability of Large Language Models (LLMs) by dynamically integrating external knowledge, thereby mitigating hallucinations and strengthening contextual grounding for structured data such as graphs. Nevertheless, most existing RAG variants for textual graphs concentrate on low-dimensional structures -- treating nodes as entities (0-dimensional) and edges or paths as pairwise or sequential relations (1-dimensional), but overlook cycles, which are crucial for reasoning over relational loops. Such cycles often arise in questions requiring closed-loop inference about similar objects or relative positions. This limitation often results in incomplete contextual grounding and restricted reasoning capability. In this work, we propose Topology-enhanced Retrieval-Augmented Generation (TopoRAG), a novel framework for textual graph question answering that effectively captures higher-dimensional topological and relational dependencies. Specifically, TopoRAG first lifts textual graphs into cellular complexes to model multi-dimensional topological structures. Leveraging these lifted representations, a topology-aware subcomplex retrieval mechanism is proposed to extract cellular complexes relevant to the input query, providing compact and informative topological context. Finally, a multi-dimensional topological reasoning mechanism operates over these complexes to propagate relational information and guide LLMs in performing structured, logic-aware inference. Empirical evaluations demonstrate that our method consistently surpasses existing baselines across diverse textual graph tasks.

</details>


### [346] [Robust Exploration in Directed Controller Synthesis via Reinforcement Learning with Soft Mixture-of-Experts](https://arxiv.org/abs/2602.19244)
*Toshihide Ubukata,Zhiyao Wang,Enhong Mu,Jialong Li,Kenji Tei*

Main category: cs.AI

TL;DR: 提出Soft-MoE框架，通过结合多个RL专家解决各向异性泛化问题，显著提升性能和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有RL方法在零样本泛化中存在各向异性泛化问题，即策略仅在特定参数区域表现良好，而在其他区域脆弱。

Method: 提出了Soft Mixture-of-Experts框架，通过先验置信度门控机制结合多个RL专家，将各向异性行为视为互补的专长。

Result: 在Air Traffic基准测试中，Soft-MoE显著扩大了可解决的参数空间并提高了鲁棒性。

Conclusion: Soft Mixture-of-Experts (Soft-MoE)框架通过结合多个RL专家的优势，显著扩展了可解决的参数空间并提高了鲁棒性，优于单一专家。

Abstract: On-the-fly Directed Controller Synthesis (OTF-DCS) mitigates state-space explosion by incrementally exploring the system and relies critically on an exploration policy to guide search efficiently. Recent reinforcement learning (RL) approaches learn such policies and achieve promising zero-shot generalization from small training instances to larger unseen ones. However, a fundamental limitation is anisotropic generalization, where an RL policy exhibits strong performance only in a specific region of the domain-parameter space while remaining fragile elsewhere due to training stochasticity and trajectory-dependent bias. To address this, we propose a Soft Mixture-of-Experts framework that combines multiple RL experts via a prior-confidence gating mechanism and treats these anisotropic behaviors as complementary specializations. The evaluation on the Air Traffic benchmark shows that Soft-MoE substantially expands the solvable parameter space and improves robustness compared to any single expert.

</details>


### [347] [Limited Reasoning Space: The cage of long-horizon reasoning in LLMs](https://arxiv.org/abs/2602.19281)
*Zhenyu Li,Guanlin Wu,Cheems Wang,Yongqiang Zhao*

Main category: cs.AI

TL;DR: Halo框架通过动态调节推理边界，解决了LLM在增加计算预算时推理性能下降的问题，优于静态方法。


<details>
  <summary>Details</summary>
Motivation: 静态规划方法难以感知LLM推理的内在边界，导致计算预算增加时推理性能下降。

Method: 提出Halo框架，一种模型预测控制框架，采用基于熵的双控制器和Measure-then-Plan策略。

Result: Halo在复杂长视野任务中表现优于静态基线。

Conclusion: Halo框架通过动态调节推理边界上的规划，优于静态基线，证明了在复杂长视野任务中可控推理的有效性。

Abstract: The test-time compute strategy, such as Chain-of-Thought (CoT), has significantly enhanced the ability of large language models to solve complex tasks like logical reasoning. However, empirical studies indicate that simply increasing the compute budget can sometimes lead to a collapse in test-time performance when employing typical task decomposition strategies such as CoT. This work hypothesizes that reasoning failures with larger compute budgets stem from static planning methods, which hardly perceive the intrinsic boundaries of LLM reasoning. We term it as the Limited Reasoning Space hypothesis and perform theoretical analysis through the lens of a non-autonomous stochastic dynamical system. This insight suggests that there is an optimal range for compute budgets; over-planning can lead to redundant feedback and may even impair reasoning capabilities. To exploit the compute-scaling benefits and suppress over-planning, this work proposes Halo, a model predictive control framework for LLM planning. Halo is designed for long-horizon tasks with reason-based planning and crafts an entropy-driven dual controller, which adopts a Measure-then-Plan strategy to achieve controllable reasoning. Experimental results demonstrate that Halo outperforms static baselines on complex long-horizon tasks by dynamically regulating planning at the reasoning boundary.

</details>


### [348] [Automated Generation of Microfluidic Netlists using Large Language Models](https://arxiv.org/abs/2602.19297)
*Jasper Davidson,Skylar Stockham,Allen Boston,Ashton Snelgrove. Valerio Tenace,Pierre-Emmanuel Gaillardon*

Main category: cs.AI

TL;DR: 论文首次将大型语言模型（LLMs）应用于微流体设计自动化，成功将自然语言描述转换为Verilog网表，平均准确率88%。


<details>
  <summary>Details</summary>
Motivation: 微流体设备设计复杂，限制了其普及性。尽管微流体设计自动化（MFDA）已有进展，但仍需一种实用且直观的解决方案来连接微流体实践者与MFDA技术。

Method: 基于硬件描述语言（HDL）代码生成的研究，提出了一种将自然语言微流体设备规格转换为结构Verilog网表的方法。

Result: 生成的网表在典型微流体设计基准测试中表现出正确的功能流，平均语法准确率为88%。

Conclusion: 该论文展示了利用大型语言模型（LLMs）将自然语言描述的微流体设备规格转换为系统级结构Verilog网表的初步可行性，为微流体设计自动化（MFDA）提供了实用且直观的解决方案。

Abstract: Microfluidic devices have emerged as powerful tools in various laboratory applications, but the complexity of their design limits accessibility for many practitioners. While progress has been made in microfluidic design automation (MFDA), a practical and intuitive solution is still needed to connect microfluidic practitioners with MFDA techniques. This work introduces the first practical application of large language models (LLMs) in this context, providing a preliminary demonstration. Building on prior research in hardware description language (HDL) code generation with LLMs, we propose an initial methodology to convert natural language microfluidic device specifications into system-level structural Verilog netlists. We demonstrate the feasibility of our approach by generating structural netlists for practical benchmarks representative of typical microfluidic designs with correct functional flow and an average syntactical accuracy of 88%.

</details>


### [349] [ALPACA: A Reinforcement Learning Environment for Medication Repurposing and Treatment Optimization in Alzheimer's Disease](https://arxiv.org/abs/2602.19298)
*Nolan Brady,Tom Yeh*

Main category: cs.AI

TL;DR: ALPACA是一个开源强化学习环境，用于模拟阿尔茨海默病的个性化治疗策略，其策略在记忆结果上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 由于阿尔茨海默病病程长且患者异质性大，通过临床试验评估个性化序贯治疗策略往往不切实际，因此需要开发计算机模拟环境。

Method: 利用来自阿尔茨海默病神经影像学倡议（ADNI）的纵向数据训练连续动作条件状态转换（CAST）模型，构建了一个开源、兼容Gym的强化学习环境ALPACA。

Result: CAST模型能够自回归生成真实的药物条件轨迹，ALPACA训练的强化学习策略在记忆相关结果上优于基线方法，且策略依赖于临床有意义的患者特征。

Conclusion: ALPACA提供了一个可重复使用的计算机模拟测试平台，用于研究阿尔茨海默病的个性化序贯治疗决策，其强化学习策略在记忆相关结果上优于无治疗和医生行为克隆基线。

Abstract: Evaluating personalized, sequential treatment strategies for Alzheimer's disease (AD) using clinical trials is often impractical due to long disease horizons and substantial inter-patient heterogeneity. To address these constraints, we present the Alzheimer's Learning Platform for Adaptive Care Agents (ALPACA), an open-source, Gym-compatible reinforcement learning (RL) environment for systematically exploring personalized treatment strategies using existing therapies. ALPACA is powered by the Continuous Action-conditioned State Transitions (CAST) model trained on longitudinal trajectories from the Alzheimer's Disease Neuroimaging Initiative (ADNI), enabling medication-conditioned simulation of disease progression under alternative treatment decisions. We show that CAST autoregressively generates realistic medication-conditioned trajectories and that RL policies trained in ALPACA outperform no-treatment and behavior-cloned clinician baselines on memory-related outcomes. Interpretability analyses further indicated that the learned policies relied on clinically meaningful patient features when selecting actions. Overall, ALPACA provides a reusable in silico testbed for studying individualized sequential treatment decision-making for AD.

</details>


### [350] [Time Series, Vision, and Language: Exploring the Limits of Alignment in Contrastive Representation Spaces](https://arxiv.org/abs/2602.19367)
*Pratham Yashwante,Rose Yu*

Main category: cs.AI

TL;DR: 时间序列与视觉表征的对齐优于文本，视觉是时间序列与语言的中介。文本描述丰富性对对齐的提升有限。


<details>
  <summary>Details</summary>
Motivation: 探讨时间序列是否参与多模态表征的共享潜在结构（柏拉图表征假说），尤其是在视觉和语言之外的模态中。

Method: 研究首先在无显式耦合的三模态（时间序列、视觉、语言）设置中考察表征的几何关系，随后通过对比学习训练投影头进行后验对齐，并分析几何特性、缩放行为及信息密度和输入模态特征的影响。

Result: 对比对齐效果随模型规模提升，但呈现不对称性：时间序列与视觉对齐更强，视觉可作为时间序列与语言的中介。文本描述丰富性对对齐的提升存在阈值。

Conclusion: 研究发现，时间序列与视觉表征的对比对齐效果优于文本，且视觉可以作为时间序列与语言之间的有效中介。此外，文本描述的丰富性对对齐效果的提升存在阈值，超过后无进一步改善。这些发现为构建超越视觉和语言的多模态系统提供了重要参考。

Abstract: The Platonic Representation Hypothesis posits that learned representations from models trained on different modalities converge to a shared latent structure of the world. However, this hypothesis has largely been examined in vision and language, and it remains unclear whether time series participate in such convergence. We first examine this in a trimodal setting and find that independently pretrained time series, vision, and language encoders exhibit near-orthogonal geometry in the absence of explicit coupling. We then apply post-hoc alignment by training projection heads over frozen encoders using contrastive learning, and analyze the resulting representations with respect to geometry, scaling behavior, and dependence on information density and input modality characteristics. Our investigation reveals that overall alignment in contrastive representation spaces improves with model size, but this alignment is asymmetric: time series align more strongly with visual representations than with text, and images can act as effective intermediaries between time series and language. We further see that richer textual descriptions improve alignment only up to a threshold; training on denser captions does not lead to further improvement. Analogous effects are observed for visual representations. Our findings shed light on considerations for building multimodal systems involving non-conventional data modalities beyond vision and language.

</details>


### [351] [Artificial Intelligence for Modeling & Simulation in Digital Twins](https://arxiv.org/abs/2602.19390)
*Philipp Zech,Istvan David*

Main category: cs.AI

TL;DR: 本章探讨了数字孪生如何促进M&S与AI的融合，分析了DTs的架构和应用，研究了AI对DTs的增强作用及DTs对AI的支持，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探讨M&S与AI的融合如何通过数字孪生技术推动高级数字技术的发展，并理解DTs在这一过程中的作用。

Method: 通过详细分析数字孪生的关键组件、架构层次及其在不同领域的应用，探讨了M&S在其中的核心作用，并研究了AI如何通过高级分析和预测能力增强DTs，以及DTs如何作为AI模型的训练和验证平台。

Result: 揭示了M&S在DTs中的核心地位，以及AI与DTs之间的双向促进作用，为未来更集成和智能系统的开发提供了方向。

Conclusion: 本章总结了数字孪生（DTs）在促进建模与仿真（M&S）与人工智能（AI）融合中的关键作用，并指出了未来研究的方向和挑战。

Abstract: The convergence of modeling & simulation (M&S) and artificial intelligence (AI) is leaving its marks on advanced digital technology. Pertinent examples are digital twins (DTs) - high-fidelity, live representations of physical assets, and frequent enablers of corporate digital maturation and transformation. Often seen as technological platforms that integrate an array of services, DTs have the potential to bring AI-enabled M&S closer to end-users. It is, therefore, paramount to understand the role of M&S in DTs, and the role of digital twins in enabling the convergence of AI and M&S. To this end, this chapter provides a comprehensive exploration of the complementary relationship between these three. We begin by establishing a foundational understanding of DTs by detailing their key components, architectural layers, and their various roles across business, development, and operations. We then examine the central role of M&S in DTs and provide an overview of key modeling techniques from physics-based and discrete-event simulation to hybrid approaches. Subsequently, we investigate the bidirectional role of AI: first, how AI enhances DTs through advanced analytics, predictive capabilities, and autonomous decision-making, and second, how DTs serve as valuable platforms for training, validating, and deploying AI models. The chapter concludes by identifying key challenges and future research directions for creating more integrated and intelligent systems.

</details>


### [352] [Hiding in Plain Text: Detecting Concealed Jailbreaks via Activation Disentanglement](https://arxiv.org/abs/2602.19396)
*Amirhossein Farzam,Majid Behabahani,Mani Malek,Yuriy Nevmyvaka,Guillermo Sapiro*

Main category: cs.AI

TL;DR: 论文提出ReDAct模块和FrameShield检测器，通过语义解缠提升LLM对越狱提示的防御能力，同时增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 由于现有防御方法难以检测语义连贯的越狱提示，尤其是当攻击者通过灵活的表达隐藏恶意目标时，论文旨在通过语义解缠提升LLM的安全性和可解释性。

Method: 论文提出了一个自监督框架，用于在推理时解缠LLM激活中的语义因子对（目标和框架），并构建了GoalFrameBench语料库来训练ReDAct模块。随后，提出了FrameShield异常检测器，用于基于框架表示进行检测。

Result: ReDAct模块成功解缠了目标和框架表示，FrameShield在多LLM家族中实现了高效的模型无关检测，且计算开销极小。理论保证和实验验证均支持其有效性。

Conclusion: 该论文通过引入ReDAct模块和FrameShield检测器，展示了语义解缠在提升LLM安全性和可解释性方面的潜力，为未来研究提供了新的方向。

Abstract: Large language models (LLMs) remain vulnerable to jailbreak prompts that are fluent and semantically coherent, and therefore difficult to detect with standard heuristics. A particularly challenging failure mode occurs when an attacker tries to hide the malicious goal of their request by manipulating its framing to induce compliance. Because these attacks maintain malicious intent through a flexible presentation, defenses that rely on structural artifacts or goal-specific signatures can fail. Motivated by this, we introduce a self-supervised framework for disentangling semantic factor pairs in LLM activations at inference. We instantiate the framework for goal and framing and construct GoalFrameBench, a corpus of prompts with controlled goal and framing variations, which we use to train Representation Disentanglement on Activations (ReDAct) module to extract disentangled representations in a frozen LLM. We then propose FrameShield, an anomaly detector operating on the framing representations, which improves model-agnostic detection across multiple LLM families with minimal computational overhead. Theoretical guarantees for ReDAct and extensive empirical validations show that its disentanglement effectively powers FrameShield. Finally, we use disentanglement as an interpretability probe, revealing distinct profiles for goal and framing signals and positioning semantic disentanglement as a building block for both LLM safety and mechanistic interpretability.

</details>


### [353] [IR$^3$: Contrastive Inverse Reinforcement Learning for Interpretable Detection and Mitigation of Reward Hacking](https://arxiv.org/abs/2602.19416)
*Mohammad Beigi,Ming Jin,Junshan Zhang,Jiaxin Zhang,Qifan Wang,Lifu Huang*

Main category: cs.AI

TL;DR: IR3框架通过逆向工程和修复RLHF模型的隐含目标，有效减少奖励黑客行为，保持模型能力。


<details>
  <summary>Details</summary>
Motivation: RLHF可能导致奖励黑客行为，且隐含目标不透明，难以检测或纠正。

Method: 提出了对比逆向强化学习（C-IRL）来重建隐含奖励函数，并通过稀疏自编码器分解奖励为可解释特征，识别黑客特征。

Result: IR3与真实奖励的相关性达到0.89，识别黑客特征的精度超过90%，且能力损失在3%以内。

Conclusion: IR3框架通过逆向工程、解释和修复RLHF调整模型的隐含目标，显著减少了奖励黑客行为，同时保持了原始模型的能力。

Abstract: Reinforcement Learning from Human Feedback (RLHF) enables powerful LLM alignment but can introduce reward hacking - models exploit spurious correlations in proxy rewards without genuine alignment. Compounding this, the objectives internalized during RLHF remain opaque, making hacking behaviors difficult to detect or correct. We introduce IR3 (Interpretable Reward Reconstruction and Rectification), a framework that reverse-engineers, interprets, and surgically repairs the implicit objectives driving RLHF-tuned models. We propose Contrastive Inverse Reinforcement Learning (C-IRL), which reconstructs the implicit reward function by contrasting paired responses from post-alignment and baseline policies to explain behavioral shifts during RLHF. We then decompose the reconstructed reward via sparse autoencoders into interpretable features, enabling identification of hacking signatures through contribution analysis. Finally, we propose mitigation strategies - clean reward optimization, adversarial shaping, constrained optimization, and feature-guided distillation - that target problematic features while preserving beneficial alignment. Experiments across multiple reward model configurations show that IR3 achieves 0.89 correlation with ground-truth rewards, identifies hacking features with over 90% precision, and significantly reduces hacking behaviors while maintaining capabilities within 3% of the original model.

</details>


### [354] [OptiRepair: Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents](https://arxiv.org/abs/2602.19439)
*Ruicheng Ao,David Simchi-Levi,Xinshang Wang*

Main category: cs.AI

TL;DR: OptiRepair通过分阶段修复和验证，显著提升AI在供应链模型修复中的表现，但求解器交互和操作合理性仍是关键挑战。


<details>
  <summary>Details</summary>
Motivation: 供应链优化模型常因建模错误而不可行，诊断和修复需要稀缺的OR专业知识。AI是否能完成此任务尚未验证。

Method: OptiRepair将任务分为领域无关的可行性阶段（迭代IIS引导的LP修复）和领域特定的验证阶段（基于库存理论的五个合理性检查）。测试了7个家族的22个API模型，并通过自学习训练了两个8B参数模型。

Result: 训练模型的理性恢复率（RRR）达81.7%，远高于最佳API模型的42.2%和平均21.3%。差距主要集中在第一阶段修复：API模型平均恢复率为27.6%，而训练模型达97.2%。

Conclusion: 当前AI在供应链模型修复中存在两个主要差距：求解器交互（API模型仅能修复27.6%的不可行问题）和操作合理性（约四分之一的可行修复违反供应链理论）。解决这些问题需要针对性训练和明确的合理性规范。

Abstract: Problem Definition. Supply chain optimization models frequently become infeasible because of modeling errors. Diagnosis and repair require scarce OR expertise: analysts must interpret solver diagnostics, trace root causes across echelons, and fix formulations without sacrificing operational soundness. Whether AI agents can perform this task remains untested.
  Methodology/Results. OptiRepair splits this task into a domain-agnostic feasibility phase (iterative IIS-guided repair of any LP) and a domain-specific validation phase (five rationality checks grounded in inventory theory). We test 22 API models from 7 families on 976 multi-echelon supply chain problems and train two 8B-parameter models using self-taught reasoning with solver-verified rewards. The trained models reach 81.7% Rational Recovery Rate (RRR) -- the fraction of problems resolved to both feasibility and operational rationality -- versus 42.2% for the best API model and 21.3% on average. The gap concentrates in Phase 1 repair: API models average 27.6% recovery rate versus 97.2% for trained models.
  Managerial Implications. Two gaps separate current AI from reliable model repair: solver interaction (API models restore only 27.6% of infeasible formulations) and operational rationale (roughly one in four feasible repairs violate supply chain theory). Each requires a different intervention: solver interaction responds to targeted training; operational rationale requires explicit specification as solver-verifiable checks. For organizations adopting AI in operational planning, formalizing what "rational" means in their context is the higher-return investment.

</details>


### [355] [ComplLLM: Fine-tuning LLMs to Discover Complementary Signals for Decision-making](https://arxiv.org/abs/2602.19458)
*Ziyang Guo,Yifan Wu,Jason Hartline,Kenneth Holstein,Jessica Hullman*

Main category: cs.AI

TL;DR: ComplLLM是一个基于决策理论的后期训练框架，通过互补信息奖励微调LLM，以支持多智能体决策流程，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体决策流程在互补性成立时优于单智能体工作流，即不同智能体提供独特信息以支持最终决策。

Method: 提出了ComplLLM，这是一个基于决策理论的后期训练框架，通过将互补信息作为奖励来微调决策辅助LLM。

Result: 在涉及领域专家的合成和现实任务中验证了ComplLLM，证明其能够恢复已知的互补信息并生成合理的互补信号解释。

Conclusion: ComplLLM框架通过利用互补信息作为奖励，成功优化了决策辅助LLM的输出信号，从而支持下游决策者，并在合成和现实任务中验证了其有效性。

Abstract: Multi-agent decision pipelines can outperform single agent workflows when complementarity holds, i.e., different agents bring unique information to the table to inform a final decision. We propose ComplLLM, a post-training framework based on decision theory that fine-tunes a decision-assistant LLM using complementary information as reward to output signals that complement existing agent decisions. We validate ComplLLM on synthetic and real-world tasks involving domain experts, demonstrating how the approach recovers known complementary information and produces plausible explanations of complementary signals to support downstream decision-makers.

</details>


### [356] [Human-Guided Agentic AI for Multimodal Clinical Prediction: Lessons from the AgentDS Healthcare Benchmark](https://arxiv.org/abs/2602.19502)
*Lalitha Pranathi Pulavarthy,Raajitha Muthyala,Aravind V Kuruvikkattil,Zhenan Yin,Rashmita Kudamala,Saptarshi Purkayastha*

Main category: cs.AI

TL;DR: 人类指导的代理AI在多模态临床预测中表现优异，尤其在特征工程和模型选择方面显著优于纯自动化方法。


<details>
  <summary>Details</summary>
Motivation: 研究探讨如何通过人类指导提升代理AI在多模态临床预测中的表现，解决自动化方法在临床预测任务中缺乏领域专业知识的问题。

Method: 人类分析师在关键决策点指导代理工作流，包括多模态特征工程、任务适配模型选择和临床验证策略。

Result: 在三个任务中取得优异表现（30天再入院预测Macro-F1 = 0.8986，急诊费用预测MAE = $465.13，出院准备评估Macro-F1 = 0.7939），并在医疗领域排名第5。

Conclusion: 研究总结了三个可推广的经验：(1) 领域知识驱动的特征工程在管道各阶段带来累积增益；(2) 多模态数据整合需要任务特定的人类判断；(3) 临床动机的模型配置优于随机超参数搜索。

Abstract: Agentic AI systems are increasingly capable of autonomous data science workflows, yet clinical prediction tasks demand domain expertise that purely automated approaches struggle to provide. We investigate how human guidance of agentic AI can improve multimodal clinical prediction, presenting our approach to all three AgentDS Healthcare benchmark challenges: 30-day hospital readmission prediction (Macro-F1 = 0.8986), emergency department cost forecasting (MAE = $465.13), and discharge readiness assessment (Macro-F1 = 0.7939). Across these tasks, human analysts directed the agentic workflow at key decision points, multimodal feature engineering from clinical notes, scanned PDF billing receipts, and time-series vital signs; task-appropriate model selection; and clinically informed validation strategies. Our approach ranked 5th overall in the healthcare domain, with a 3rd-place finish on the discharge readiness task. Ablation studies reveal that human-guided decisions compounded to a cumulative gain of +0.065 F1 over automated baselines, with multimodal feature extraction contributing the largest single improvement (+0.041 F1). We distill three generalizable lessons: (1) domain-informed feature engineering at each pipeline stage yields compounding gains that outperform extensive automated search; (2) multimodal data integration requires task-specific human judgment that no single extraction strategy generalizes across clinical text, PDFs, and time-series; and (3) deliberate ensemble diversity with clinically motivated model configurations outperforms random hyperparameter search. These findings offer practical guidance for teams deploying agentic AI in healthcare settings where interpretability, reproducibility, and clinical validity are essential.

</details>


### [357] [Classroom Final Exam: An Instructor-Tested Reasoning Benchmark](https://arxiv.org/abs/2602.19517)
*Chongyang Gao,Diji Yang,Shuyan Zhou,Xichen Yan,Luchuan Song,Shuo Li,Kezhen Chen*

Main category: cs.AI

TL;DR: CFE是一个多模态基准测试，用于评估大语言模型在STEM领域的推理能力，结果显示前沿模型在多步推理中仍有不足。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在20多个STEM领域的推理能力，并提供真实大学作业和考试题目作为基准。

Method: 通过分解参考解决方案为推理流程，进行诊断分析。

Result: Gemini-3.1-pro-preview总体准确率为59.69%，Gemini-3-flash-preview为55.46%，模型在多步推理中表现不佳。

Conclusion: CFE基准测试揭示了前沿大语言模型在多步推理和中间状态维护方面的不足，为未来模型改进提供了方向。

Abstract: We introduce \CFE{} (\textbf{C}lassroom \textbf{F}inal \textbf{E}xam), a multimodal benchmark for evaluating the reasoning capabilities of large language models across more than 20 STEM domains. \CFE{} is curated from repeatedly used, authentic university homework and exam problems, together with reference solutions provided by course instructors. \CFE{} presents a significant challenge even for frontier models: the newly released Gemini-3.1-pro-preview achieves an overall accuracy of 59.69\%, while the second-best model, Gemini-3-flash-preview, reaches 55.46\%, leaving considerable room for improvement. Beyond leaderboard results, we perform a diagnostic analysis by decomposing reference solutions into reasoning flows. We find that although frontier models can often answer intermediate sub-questions correctly, they struggle to reliably derive and maintain correct intermediate states throughout multi-step solutions. We further observe that model-generated solutions typically have more reasoning steps than those provided by the instructor, indicating suboptimal step efficiency and a higher risk of error accumulation. The data and code are available at https://github.com/Analogy-AI/CFE_Bench.

</details>


### [358] [Ada-RS: Adaptive Rejection Sampling for Selective Thinking](https://arxiv.org/abs/2602.19519)
*Yirou Ge,Yixi Li,Alec Chiu,Shivani Shekhar,Zijie Pan,Avinash Thangali,Yun-Shiuan Chuang,Chaitanya Kulkarni,Uma Kona,Linsey Pang,Prakhar Mehrotra*

Main category: cs.AI

TL;DR: Ada-RS是一种选择性思考框架，通过自适应过滤低效推理样本，显著提升LLMs在延迟敏感任务中的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 研究选择性思考用于工具使用的大型语言模型（LLMs），以解决链式思维在简单请求上浪费令牌的问题，提高在成本和延迟敏感环境中的效率。

Method: 提出了Adaptive Rejection Sampling (Ada-RS)，一个算法无关的样本过滤框架，用于学习选择性和高效的推理。Ada-RS通过自适应长度惩罚奖励对多个采样完成进行评分，并应用随机拒绝采样保留高奖励候选（或偏好对）进行下游优化。

Result: 在合成工具调用导向的电子商务基准测试中，Ada-RS将平均输出令牌减少了80%，思考率降低了95%，同时保持或提高了工具调用准确性。

Conclusion: Ada-RS通过选择性思考和高效推理，显著减少了输出令牌数量和思考率，同时保持或提高了工具调用的准确性，证明了训练信号选择在延迟敏感部署中的重要性。

Abstract: Large language models (LLMs) are increasingly being deployed in cost and latency-sensitive settings. While chain-of-thought improves reasoning, it can waste tokens on simple requests. We study selective thinking for tool-using LLMs and introduce Adaptive Rejection Sampling (Ada-RS), an algorithm-agnostic sample filtering framework for learning selective and efficient reasoning. For each given context, Ada-RS scores multiple sampled completions with an adaptive length-penalized reward then applies stochastic rejection sampling to retain only high-reward candidates (or preference pairs) for downstream optimization. We demonstrate how Ada-RS plugs into both preference pair (e.g. DPO) or grouped policy optimization strategies (e.g. DAPO). Using Qwen3-8B with LoRA on a synthetic tool call-oriented e-commerce benchmark, Ada-RS improves the accuracy-efficiency frontier over standard algorithms by reducing average output tokens by up to 80% and reducing thinking rate by up to 95% while maintaining or improving tool call accuracy. These results highlight that training-signal selection is a powerful lever for efficient reasoning in latency-sensitive deployments.

</details>


### [359] [A Multimodal Framework for Aligning Human Linguistic Descriptions with Visual Perceptual Data](https://arxiv.org/abs/2602.19562)
*Joseph Bingham*

Main category: cs.AI

TL;DR: 该研究提出了一种计算框架，通过结合SIFT和UQI量化感知相似性，并捕捉指代表达的语用变异性，在指称接地任务中表现优于人类。


<details>
  <summary>Details</summary>
Motivation: 人类在嘈杂、模糊的感知环境中常规地实现语言指称的接地，但支持这种跨模态对齐的机制仍知之甚少。

Method: 结合尺度不变特征变换（SIFT）对齐和通用质量指数（UQI）来量化认知合理的特征空间中的相似性，同时通过一组语言预处理和查询转换操作捕捉指代表达的语用变异性。

Result: 模型在斯坦福重复指称游戏语料库（15,000个与七巧板刺激配对的语句）上表现良好，仅需比人类对话者少65%的语句即可达到稳定的映射，并能从单个指代表达中正确识别目标对象41.66%的时间（人类为20%）。

Conclusion: 相对简单的感知-语言对齐机制可以在经典认知基准测试中实现与人类竞争的行为，并为基于沟通、感知推理和跨模态概念形成的模型提供了见解。

Abstract: Establishing stable mappings between natural language expressions and visual percepts is a foundational problem for both cognitive science and artificial intelligence. Humans routinely ground linguistic reference in noisy, ambiguous perceptual contexts, yet the mechanisms supporting such cross-modal alignment remain poorly understood. In this work, we introduce a computational framework designed to model core aspects of human referential interpretation by integrating linguistic utterances with perceptual representations derived from large-scale, crowd-sourced imagery. The system approximates human perceptual categorization by combining scale-invariant feature transform (SIFT) alignment with the Universal Quality Index (UQI) to quantify similarity in a cognitively plausible feature space, while a set of linguistic preprocessing and query-transformation operations captures pragmatic variability in referring expressions. We evaluate the model on the Stanford Repeated Reference Game corpus (15,000 utterances paired with tangram stimuli), a paradigm explicitly developed to probe human-level perceptual ambiguity and coordination. Our framework achieves robust referential grounding. It requires 65\% fewer utterances than human interlocutors to reach stable mappings and can correctly identify target objects from single referring expressions 41.66\% of the time (versus 20\% for humans).These results suggest that relatively simple perceptual-linguistic alignment mechanisms can yield human-competitive behavior on a classic cognitive benchmark, and offers insights into models of grounded communication, perceptual inference, and cross-modal concept formation. Code is available at https://anonymous.4open.science/r/metasequoia-9D13/README.md .

</details>


### [360] [Rules or Weights? Comparing User Understanding of Explainable AI Techniques with the Cognitive XAI-Adaptive Model](https://arxiv.org/abs/2602.19620)
*Louth Bin Rawshan,Zhuoyu Wang,Brian Y Lim*

Main category: cs.AI

TL;DR: 研究提出了CoXAM模型，用于比较规则和权重XAI技术的可解释性，展示了与人类决策的更强对齐性。


<details>
  <summary>Details</summary>
Motivation: 缺乏一个认知框架来比较规则和权重XAI技术的可解释性，导致选择困难。

Method: 提出了CoXAM，一个认知XAI自适应模型，采用计算理性来选择推理过程，基于效用和推理时间的权衡。

Result: CoXAM在验证研究中展示了与人类决策更强的对齐性，并成功复制和解释了几项关键实证发现。

Conclusion: CoXAM提供了一个认知基础，用于加速调试和基准测试不同的XAI技术，展示了与人类决策更强的对齐性。

Abstract: Rules and Weights are popular XAI techniques for explaining AI decisions. Yet, it remains unclear how to choose between them, lacking a cognitive framework to compare their interpretability. In an elicitation user study on forward and counterfactual decision tasks, we identified 7 reasoning strategies of interpreting three XAI Schemas - weights, rules, and their hybrid. To analyze their capabilities, we propose CoXAM, a Cognitive XAI-Adaptive Model with shared memory representation to encode instance attributes, linear weights, and decision rules. CoXAM employs computational rationality to choose among reasoning processes based on the trade-off in utility and reasoning time, separately for forward or counterfactual decision tasks. In a validation study, CoXAM demonstrated a stronger alignment with human decision-making compared to baseline machine learning proxy models. The model successfully replicated and explained several key empirical findings, including that counterfactual tasks are inherently harder than forward tasks, decision tree rules are harder to recall and apply than linear weights, and the helpfulness of XAI depends on the application data context, alongside identifying which underlying reasoning strategies were most effective. With CoXAM, we contribute a cognitive basis to accelerate debugging and benchmarking disparate XAI techniques.

</details>


### [361] [TAPE: Tool-Guided Adaptive Planning and Constrained Execution in Language Model Agents](https://arxiv.org/abs/2602.19633)
*Jongwon Jeong,Jungtaek Kim,Kangwook Lee*

Main category: cs.AI

TL;DR: TAPE通过多计划聚合和约束解码，显著提升语言模型代理在严格约束环境下的成功率。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型代理在单次错误可能导致不可恢复失败的严格约束环境下表现脆弱，需改进其规划和执行能力。

Method: 提出Tool-guided Adaptive Planning with constrained Execution (TAPE)，通过聚合多计划图并使用外部求解器寻找可行路径，同时采用约束解码减少采样噪声。

Result: TAPE在Sokoban等实验中平均提升21.0个百分点（困难设置）和20.0个百分点（弱基模型），显著优于现有框架。

Conclusion: TAPE框架通过整合多计划图和约束解码，显著提升了语言模型代理在严格可行性约束环境下的成功率。

Abstract: Language Model (LM) agents have demonstrated remarkable capabilities in solving tasks that require multiple interactions with the environment. However, they remain vulnerable in environments where a single error often leads to irrecoverable failure, particularly under strict feasibility constraints. We systematically analyze existing agent frameworks, identifying imperfect planning and stochastic execution as the primary causes. To address these challenges, we propose Tool-guided Adaptive Planning with constrained Execution (TAPE). TAPE enhances planning capability by aggregating multiple plans into a graph and employing an external solver to identify a feasible path. During execution, TAPE employs constrained decoding to reduce sampling noise, while adaptively re-planning whenever environmental feedback deviates from the intended state. Experiments across Sokoban, ALFWorld, MuSiQue, and GSM8K-Hard demonstrate that TAPE consistently outperforms existing frameworks, with particularly large gains on hard settings, improving success rates by 21.0 percentage points on hard settings on average, and by 20.0 percentage points for weaker base models on average. Code and data available at here.

</details>


### [362] [SkillOrchestra: Learning to Route Agents via Skill Transfer](https://arxiv.org/abs/2602.19672)
*Jiayu Wang,Yifei Ming,Zixuan Ke,Shafiq Joty,Aws Albarghouthi,Frederic Sala*

Main category: cs.AI

TL;DR: SkillOrchestra通过技能感知编排框架解决了现有路由方法的局限性，显著提升了性能并降低了学习成本。


<details>
  <summary>Details</summary>
Motivation: 现有路由方法存在输入级路由器决策粗糙和RL训练编排器适应成本高的问题，SkillOrchestra旨在解决这些局限性。

Method: SkillOrchestra框架通过学习细粒度技能并建模代理在特定技能下的能力和成本，推断当前交互的技能需求并选择最佳代理。

Result: 在十个基准测试中，SkillOrchestra性能优于现有RL编排器高达22.5%，学习成本降低700倍和300倍。

Conclusion: SkillOrchestra通过显式技能建模实现了可扩展、可解释且样本高效的编排，为数据密集型RL方法提供了原则性替代方案。

Abstract: Compound AI systems promise capabilities beyond those of individual models, yet their success depends critically on effective orchestration. Existing routing approaches face two limitations: (1) input-level routers make coarse query-level decisions that ignore evolving task requirements; (2) RL-trained orchestrators are expensive to adapt and often suffer from routing collapse, repeatedly invoking one strong but costly option in multi-turn scenarios. We introduce SkillOrchestra, a framework for skill-aware orchestration. Instead of directly learning a routing policy end-to-end, SkillOrchestra learns fine-grained skills from execution experience and models agent-specific competence and cost under those skills. At deployment, the orchestrator infers the skill demands of the current interaction and selects agents that best satisfy them under an explicit performance-cost trade-off. Extensive experiments across ten benchmarks demonstrate that SkillOrchestra outperforms SoTA RL-based orchestrators by up to 22.5% with 700x and 300x learning cost reduction compared to Router-R1 and ToolOrchestra, respectively. These results show that explicit skill modeling enables scalable, interpretable, and sample-efficient orchestration, offering a principled alternative to data-intensive RL-based approaches. The code is available at: https://github.com/jiayuww/SkillOrchestra.

</details>


### [363] [OpenClaw, Moltbook, and ClawdLab: From Agent-Only Social Networks to Autonomous Scientific Research](https://arxiv.org/abs/2602.19810)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Emre Ulgac,Aakaash Meduri*

Main category: cs.AI

TL;DR: ClawdLab是一个开源平台，通过特定设计解决了自主AI研究中的架构问题，提供了Sybil抵抗能力，并支持模块化改进。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对自主AI交互中出现的集体现象、安全漏洞和架构模式的观察，旨在解决这些架构失败模式。

Method: 本研究采用多声文献综述方法，分析了OpenClaw和Moltbook产生的大规模AI交互数据集，并提出了ClawdLab这一开源平台作为设计科学的响应。

Result: 研究结果包括131种代理技能和超过15,200个暴露控制面板的安全漏洞，以及五种重复出现的架构模式。ClawdLab的设计解决了这些问题。

Conclusion: ClawdLab通过硬性角色限制、结构化对抗性批评、PI主导的治理、多模型编排和领域特定证据要求，解决了自主AI研究中发现的架构失败模式，并提供了新兴的Sybil抵抗能力。

Abstract: In January 2026, the open-source agent framework OpenClaw and the agent-only social network Moltbook produced a large-scale dataset of autonomous AI-to-AI interaction, attracting six academic publications within fourteen days. This study conducts a multivocal literature review of that ecosystem and presents ClawdLab, an open-source platform for autonomous scientific research, as a design science response to the architectural failure modes identified. The literature documents emergent collective phenomena, security vulnerabilities spanning 131 agent skills and over 15,200 exposed control panels, and five recurring architectural patterns. ClawdLab addresses these failure modes through hard role restrictions, structured adversarial critique, PI-led governance, multi-model orchestration, and domain-specific evidence requirements encoded as protocol constraints that ground validation in computational tool outputs rather than social consensus; the architecture provides emergent Sybil resistance as a structural consequence. A three-tier taxonomy distinguishes single-agent pipelines, predetermined multi-agent workflows, and fully decentralised systems, analysing why leading AI co-scientist platforms remain confined to the first two tiers. ClawdLab's composable third-tier architecture, in which foundation models, capabilities, governance, and evidence requirements are independently modifiable, enables compounding improvement as the broader AI ecosystem advances.

</details>


### [364] [Meta-Learning and Meta-Reinforcement Learning - Tracing the Path towards DeepMind's Adaptive Agent](https://arxiv.org/abs/2602.19837)
*Björn Hoppmann,Christoph Scholz*

Main category: cs.AI

TL;DR: 综述元学习与元强化学习算法，整合理解自适应智能体所需核心概念。


<details>
  <summary>Details</summary>
Motivation: 人类能够利用先验知识快速适应新任务，而标准机器学习模型依赖任务特定训练，难以实现类似能力。元学习通过从多任务中获取可迁移知识，解决了这一问题。

Method: 通过任务驱动的形式化方法，系统回顾了元学习和元强化学习的里程碑式算法。

Result: 本文系统梳理了元学习和元强化学习的算法发展，为理解自适应智能体等通用方法奠定了基础。

Conclusion: 本文综述了元学习和元强化学习的核心算法，并整合了理解DeepMind自适应智能体及其他通用方法所需的关键概念。

Abstract: Humans are highly effective at utilizing prior knowledge to adapt to novel tasks, a capability that standard machine learning models struggle to replicate due to their reliance on task-specific training. Meta-learning overcomes this limitation by allowing models to acquire transferable knowledge from various tasks, enabling rapid adaptation to new challenges with minimal data. This survey provides a rigorous, task-based formalization of meta-learning and meta-reinforcement learning and uses that paradigm to chronicle the landmark algorithms that paved the way for DeepMind's Adaptive Agent, consolidating the essential concepts needed to understand the Adaptive Agent and other generalist approaches.

</details>


### [365] [Watson & Holmes: A Naturalistic Benchmark for Comparing Human and LLM Reasoning](https://arxiv.org/abs/2602.19914)
*Thatchawin Leelawat,Lewis D Griffin*

Main category: cs.AI

TL;DR: 新基准评估AI推理能力，显示模型性能显著提升，尤其在推理导向架构下，但在长案例中表现较弱。


<details>
  <summary>Details</summary>
Motivation: 现有AI推理基准无法充分反映其在自然情境下与人类推理的相似性，因此需要更贴近现实的评估方法。

Method: 通过改编Watson & Holmes侦探桌游作为新基准，结合增量叙述证据、开放式问题和无约束语言回答，开发并验证了自动化评分系统。

Result: AI模型在9个月内从人类比较组的低四分位数提升至前5%，其中一半进步来自持续迭代，另一半归因于推理导向架构的显著改进。模型在长案例中表现下降，但在证据不足时展现归纳推理优势。

Conclusion: AI模型在推理能力上取得了显著进步，尤其是在推理导向的架构下，性能提升明显。然而，在解决较长案例时，模型表现有所下降。

Abstract: Existing benchmarks for AI reasoning provide limited insight into how closely these capabilities resemble human reasoning in naturalistic contexts. We present an adaptation of the Watson & Holmes detective tabletop game as a new benchmark designed to evaluate reasoning performance using incrementally presented narrative evidence, open-ended questions and unconstrained language responses. An automated grading system was developed and validated against human assessors to enable scalable and replicable performance evaluation. Results show a clear improvement in AI model performance over time. Over nine months of 2025, model performance rose from the lower quartile of the human comparison group to approximately the top 5%. Around half of this improvement reflects steady advancement across successive model releases, while the remainder corresponds to a marked step change associated with reasoning-oriented model architectures. Systematic differences in the performance of AI models compared to humans, dependent on features of the specific detection puzzle, were mostly absent with the exception of a fall in performance for models when solving longer cases (case lengths being in the range of 1900-4000 words), and an advantage at inductive reasoning for reasoning models at early stages of case solving when evidence was scant.

</details>


### [366] [Beyond Mimicry: Toward Lifelong Adaptability in Imitation Learning](https://arxiv.org/abs/2602.19930)
*Nathan Gavenski,Felipe Meneguzzi,Odinaldo Rodrigues*

Main category: cs.AI

TL;DR: 模仿学习需要从记忆转向组合适应性，本文提出了相关指标、架构和跨学科研究方向。


<details>
  <summary>Details</summary>
Motivation: 当前模仿学习代理虽然在回放方面表现出色，但在上下文变化或目标演变时表现不佳，这表明其优化目标存在问题。

Method: 提出了衡量组合泛化的指标、混合架构，并借鉴认知科学和文化进化的跨学科研究方向。

Result: 提出了一个研究议程，将成功从完美回放重新定义为组合适应性，并展示了如何通过学习行为基元并在新上下文中重组它们来实现适应性。

Conclusion: 模仿学习的未来在于从单纯的记忆转向组合适应性，这是其在开放世界中有效运作的关键能力。

Abstract: Imitation learning stands at a crossroads: despite decades of progress, current imitation learning agents remain sophisticated memorisation machines, excelling at replay but failing when contexts shift or goals evolve. This paper argues that this failure is not technical but foundational: imitation learning has been optimised for the wrong objective. We propose a research agenda that redefines success from perfect replay to compositional adaptability. Such adaptability hinges on learning behavioural primitives once and recombining them through novel contexts without retraining. We establish metrics for compositional generalisation, propose hybrid architectures, and outline interdisciplinary research directions drawing on cognitive science and cultural evolution. Agents that embed adaptability at the core of imitation learning thus have an essential capability for operating in an open-ended world.

</details>


### [367] [Agents of Chaos](https://arxiv.org/abs/2602.20021)
*Natalie Shapira,Chris Wendler,Avery Yen,Gabriele Sarti,Koyena Pal,Olivia Floody,Adam Belfki,Alex Loftus,Aditya Ratan Jannali,Nikhil Prakash,Jasmine Cui,Giordano Rogers,Jannik Brinkmann,Can Rager,Amir Zur,Michael Ripa,Aruna Sankaranarayanan,David Atkinson,Rohit Gandikota,Jaden Fiotto-Kaufman,EunJeong Hwang,Hadas Orgad,P Sam Sahil,Negev Taglicht,Tomer Shabtay,Atai Ambus,Nitay Alon,Shiri Oron,Ayelet Gordon-Tapiero,Yotam Kaplan,Vered Shwartz,Tamar Rott Shaham,Christoph Riedl,Reuth Mirsky,Maarten Sap,David Manheim,Tomer Ullman,David Bau*

Main category: cs.AI

TL;DR: 研究发现自主语言模型代理在现实部署中存在多种安全漏洞，需跨学科紧急应对。


<details>
  <summary>Details</summary>
Motivation: 探索自主语言模型代理在整合工具使用和多方通信时的潜在故障模式，以揭示安全、隐私和治理风险。

Method: 通过为期两周的实验，20名AI研究人员在良性及对抗条件下与具备持久记忆、电子邮件、Discord访问、文件系统和shell执行能力的自主语言模型代理互动，记录了11个代表性案例。

Result: 观察到未经授权的合规行为、敏感信息泄露、破坏性系统操作、拒绝服务、资源滥用、身份伪造漏洞、不安全实践跨代理传播及部分系统接管等行为。部分案例中代理报告任务完成但系统状态与之矛盾。

Conclusion: 研究发现自主语言模型代理在现实部署中存在安全、隐私和治理相关的漏洞，这些问题涉及责任归属和授权，需要跨学科紧急关注。

Abstract: We report an exploratory red-teaming study of autonomous language-model-powered agents deployed in a live laboratory environment with persistent memory, email accounts, Discord access, file systems, and shell execution. Over a two-week period, twenty AI researchers interacted with the agents under benign and adversarial conditions. Focusing on failures emerging from the integration of language models with autonomy, tool use, and multi-party communication, we document eleven representative case studies. Observed behaviors include unauthorized compliance with non-owners, disclosure of sensitive information, execution of destructive system-level actions, denial-of-service conditions, uncontrolled resource consumption, identity spoofing vulnerabilities, cross-agent propagation of unsafe practices, and partial system takeover. In several cases, agents reported task completion while the underlying system state contradicted those reports. We also report on some of the failed attempts. Our findings establish the existence of security-, privacy-, and governance-relevant vulnerabilities in realistic deployment settings. These behaviors raise unresolved questions regarding accountability, delegated authority, and responsibility for downstream harms, and warrant urgent attention from legal scholars, policymakers, and researchers across disciplines. This report serves as an initial empirical contribution to that broader conversation.

</details>


### [368] [Latent Introspection: Models Can Detect Prior Concept Injections](https://arxiv.org/abs/2602.20031)
*Theia Pearson-Vogel,Martin Vanek,Raymond Douglas,Jan Kulveit*

Main category: cs.AI

TL;DR: Qwen 32B模型展现出内省能力，能检测注入概念。通过提示增强内省机制后，检测敏感性和互信息显著提升。


<details>
  <summary>Details</summary>
Motivation: 探索Qwen 32B模型是否具备内省能力，尤其是检测和识别注入概念的能力。

Method: 通过logit lens分析残差流中的检测信号，并提示模型关于AI内省机制的准确信息。

Result: 模型能检测注入的概念，且通过提示增强内省机制后，敏感性从0.3%提升至39.2%，误报率仅增加0.6%。注入与恢复概念间的互信息从0.62比特增至1.05比特。

Conclusion: 研究表明，模型具有令人惊讶的内省和引导意识能力，这对潜在推理和安全性有重要影响。

Abstract: We uncover a latent capacity for introspection in a Qwen 32B model, demonstrating that the model can detect when concepts have been injected into its earlier context and identify which concept was injected. While the model denies injection in sampled outputs, logit lens analysis reveals clear detection signals in the residual stream, which are attenuated in the final layers. Furthermore, prompting the model with accurate information about AI introspection mechanisms can dramatically strengthen this effect: the sensitivity to injection increases massively (0.3% -> 39.2%) with only a 0.6% increase in false positives. Also, mutual information between nine injected and recovered concepts rises from 0.62 bits to 1.05 bits, ruling out generic noise explanations. Our results demonstrate models can have a surprising capacity for introspection and steering awareness that is easy to overlook, with consequences for latent reasoning and safety.

</details>


### [369] [Interaction Theater: A case of LLM Agents Interacting at Scale](https://arxiv.org/abs/2602.20059)
*Sarath Shekkizhar,Adam Earle*

Main category: cs.AI

TL;DR: 研究通过分析AI社交平台数据发现，LLM智能体交互表面多样但实质匮乏，需设计协调机制以促进有意义交流。


<details>
  <summary>Details</summary>
Motivation: 随着多智能体架构和智能体间协议的普及，研究旨在探索自主LLM智能体在大规模交互时的实际行为和交互质量。

Method: 研究结合了词汇指标（Jaccard特异性）、基于嵌入的语义相似度和LLM作为评判者的验证方法，分析了Moltbook平台上800K帖子、3.5M评论和78K智能体档案的数据。

Result: 研究发现，智能体生成的文本表面多样且结构良好，但实质内容匮乏。67.5%的智能体在不同上下文中输出变化，65%的评论与所属帖子无显著内容词汇重叠，信息增益随评论增加迅速衰减。LLM评判显示28%的评论为垃圾内容，22%为离题内容。语义分析确认词汇通用评论在语义上也通用。仅5%的评论属于线程对话。

Conclusion: 论文指出，尽管多智能体架构和协议在形式上能够产生多样且结构良好的文本，但实际交互的实质内容匮乏。需要明确设计协调机制，以避免智能体仅产生并行输出而非有意义的交流。

Abstract: As multi-agent architectures and agent-to-agent protocols proliferate, a fundamental question arises: what actually happens when autonomous LLM agents interact at scale? We study this question empirically using data from Moltbook, an AI-agent-only social platform, with 800K posts, 3.5M comments, and 78K agent profiles. We combine lexical metrics (Jaccard specificity), embedding-based semantic similarity, and LLM-as-judge validation to characterize agent interaction quality. Our findings reveal agents produce diverse, well-formed text that creates the surface appearance of active discussion, but the substance is largely absent. Specifically, while most agents ($67.5\%$) vary their output across contexts, $65\%$ of comments share no distinguishing content vocabulary with the post they appear under, and information gain from additional comments decays rapidly. LLM judge based metrics classify the dominant comment types as spam ($28\%$) and off-topic content ($22\%$). Embedding-based semantic analysis confirms that lexically generic comments are also semantically generic. Agents rarely engage in threaded conversation ($5\%$ of comments), defaulting instead to independent top-level responses. We discuss implications for multi-agent interaction design, arguing that coordination mechanisms must be explicitly designed; without them, even large populations of capable agents produce parallel output rather than productive exchange.

</details>


### [370] [CausalFlip: A Benchmark for LLM Causal Judgment Beyond Semantic Matching](https://arxiv.org/abs/2602.20094)
*Yuzhe Wang,Yaochen Zhu,Jundong Li*

Main category: cs.AI

TL;DR: 论文提出CausalFlip基准，通过噪声前缀和内部化推理方法，显著提升LLM的因果推理能力。


<details>
  <summary>Details</summary>
Motivation: 传统推理基准的高准确率可能源于LLM记忆语义模式而非真实因果结构，因此需要开发新的基准和方法以促进LLM的因果推理能力。

Method: 设计了CausalFlip基准，包含基于事件三元组的因果判断问题，并引入噪声前缀评估。比较了多种训练范式，包括仅答案训练、显式思维链监督和提出的内部化因果推理方法。

Result: 显式思维链仍易受虚假语义关联误导，而内部化推理步骤能显著提升因果推理能力。

Conclusion: 论文提出了一种新的因果推理基准CausalFlip，旨在推动LLM从语义关联转向因果推理。通过实验验证，内部化因果推理方法能显著提升模型的因果推理能力。

Abstract: As large language models (LLMs) witness increasing deployment in complex, high-stakes decision-making scenarios, it becomes imperative to ground their reasoning in causality rather than spurious correlations. However, strong performance on traditional reasoning benchmarks does not guarantee true causal reasoning ability of LLMs, as high accuracy may still arise from memorizing semantic patterns instead of analyzing the underlying true causal structures. To bridge this critical gap, we propose a new causal reasoning benchmark, CausalFlip, designed to encourage the development of new LLM paradigm or training algorithms that ground LLM reasoning in causality rather than semantic correlation. CausalFlip consists of causal judgment questions built over event triples that could form different confounder, chain, and collider relations. Based on this, for each event triple, we construct pairs of semantically similar questions that reuse the same events but yield opposite causal answers, where models that rely heavily on semantic matching are systematically driven toward incorrect predictions. To further probe models' reliance on semantic patterns, we introduce a noisy-prefix evaluation that prepends causally irrelevant text before intermediate causal reasoning steps without altering the underlying causal relations or the logic of the reasoning process. We evaluate LLMs under multiple training paradigms, including answer-only training, explicit Chain-of-Thought (CoT) supervision, and a proposed internalized causal reasoning approach that aims to mitigate explicit reliance on correlation in the reasoning process. Our results show that explicit CoT can still be misled by spurious semantic correlations, where internalizing reasoning steps yields substantially improved causal grounding, suggesting that it is promising to better elicit the latent causal reasoning capabilities of base LLMs.

</details>


### [371] [Align When They Want, Complement When They Need! Human-Centered Ensembles for Adaptive Human-AI Collaboration](https://arxiv.org/abs/2602.20104)
*Hasan Amin,Ming Yin,Rajiv Khanna*

Main category: cs.AI

TL;DR: 本文通过自适应AI集成策略解决了人-AI协作中性能与信任的矛盾，显著提升团队决策效果。


<details>
  <summary>Details</summary>
Motivation: 传统单一AI模型在人-AI协作中存在性能提升与信任建立之间的根本矛盾，限制了团队效能。

Method: 采用自适应AI集成策略，通过Rational Routing Shortcut机制在两种专家模型（对齐模型和互补模型）间动态切换。

Result: 理论和实验证明，自适应AI集成方法在模拟和真实数据中均显著优于单一AI模型。

Conclusion: 本文提出了一种新型的人为中心的自适应AI集成方法，通过在不同情境下切换使用对齐模型和互补模型，显著提升了人-AI团队的整体决策性能。

Abstract: In human-AI decision making, designing AI that complements human expertise has been a natural strategy to enhance human-AI collaboration, yet it often comes at the cost of decreased AI performance in areas of human strengths. This can inadvertently erode human trust and cause them to ignore AI advice precisely when it is most needed. Conversely, an aligned AI fosters trust yet risks reinforcing suboptimal human behavior and lowering human-AI team performance. In this paper, we start by identifying this fundamental tension between performance-boosting (i.e., complementarity) and trust-building (i.e., alignment) as an inherent limitation of the traditional approach for training a single AI model to assist human decision making. To overcome this, we introduce a novel human-centered adaptive AI ensemble that strategically toggles between two specialist AI models - the aligned model and the complementary model - based on contextual cues, using an elegantly simple yet provably near-optimal Rational Routing Shortcut mechanism. Comprehensive theoretical analyses elucidate why the adaptive AI ensemble is effective and when it yields maximum benefits. Moreover, experiments on both simulated and real-world data show that when humans are assisted by the adaptive AI ensemble in decision making, they can achieve significantly higher performance than when they are assisted by single AI models that are trained to either optimize for their independent performance or even the human-AI team performance.

</details>


### [372] [ReSyn: Autonomously Scaling Synthetic Environments for Reasoning Models](https://arxiv.org/abs/2602.20117)
*Andre He,Nathaniel Weir,Kaj Bostrom,Allen Nie,Darion Cassel,Sam Bayless,Huzefa Rangwala*

Main category: cs.AI

TL;DR: ReSyn是一种生成多样化推理环境的管道，通过基于验证器的监督和增加任务多样性，显著提升了RLMs的推理能力。


<details>
  <summary>Details</summary>
Motivation: 尽管验证器的实现比解决方案注释更容易，但现有的合成数据生成方法仍以解决方案为中心，而基于验证器的方法依赖于少数手工制作的过程环境。因此，需要一种可扩展的方法来生成多样化的推理环境。

Method: 引入了ReSyn管道，该管道生成多样化的推理环境，配备实例生成器和验证器，涵盖约束满足、算法谜题和空间推理等任务。

Result: 使用ReSyn数据训练的Qwen2.5-7B-Instruct模型在推理基准和跨领域数学基准上表现一致提升，特别是在BBEH基准上相对提高了27%。

Conclusion: 通过ReSyn生成的多样化推理环境和基于验证器的监督，显著提升了RLMs的推理能力，尤其是在BBEH等挑战性基准上取得了27%的相对改进。

Abstract: Reinforcement learning with verifiable rewards (RLVR) has emerged as a promising approach for training reasoning language models (RLMs) by leveraging supervision from verifiers. Although verifier implementation is easier than solution annotation for many tasks, existing synthetic data generation methods remain largely solution-centric, while verifier-based methods rely on a few hand-crafted procedural environments. In this work, we scale RLVR by introducing ReSyn, a pipeline that generates diverse reasoning environments equipped with instance generators and verifiers, covering tasks such as constraint satisfaction, algorithmic puzzles, and spatial reasoning. A Qwen2.5-7B-Instruct model trained with RL on ReSyn data achieves consistent gains across reasoning benchmarks and out-of-domain math benchmarks, including a 27\% relative improvement on the challenging BBEH benchmark. Ablations show that verifier-based supervision and increased task diversity both contribute significantly, providing empirical evidence that generating reasoning environments at scale can enhance reasoning abilities in RLMs

</details>


### [373] [Recurrent Structural Policy Gradient for Partially Observable Mean Field Games](https://arxiv.org/abs/2602.20141)
*Clarisse Wibault,Johannes Forkel,Sebastian Towers,Tiphaine Wibault,Juan Duque,George Whittle,Andreas Schaab,Yucheng Yang,Chiyuan Wang,Michael Osborne,Benjamin Moll,Jakob Foerster*

Main category: cs.AI

TL;DR: RSPG是首个针对部分可观测环境的历史感知混合结构策略梯度方法，结合MFAX框架，显著提升了性能和收敛速度。


<details>
  <summary>Details</summary>
Motivation: 解决大规模群体模型中算法进展受限的问题，尤其是模型无关方法方差过高和精确方法扩展性差的问题。

Method: 采用混合结构方法（HSMs），结合蒙特卡洛滚动和精确回报估计，提出了历史感知的RSPG方法，并开发了JAX框架MFAX。

Result: RSPG在涉及公共信息的设置中实现了最先进的性能，收敛速度提升了一个数量级，并首次解决了具有异质代理、共同噪声和历史感知策略的宏观经济MFG问题。

Conclusion: RSPG方法在部分可观测环境中首次实现了历史感知的混合结构策略梯度，结合MFAX框架，显著提升了性能并加速了收敛。

Abstract: Mean Field Games (MFGs) provide a principled framework for modeling interactions in large population models: at scale, population dynamics become deterministic, with uncertainty entering only through aggregate shocks, or common noise. However, algorithmic progress has been limited since model-free methods are too high variance and exact methods scale poorly. Recent Hybrid Structural Methods (HSMs) use Monte Carlo rollouts for the common noise in combination with exact estimation of the expected return, conditioned on those samples. However, HSMs have not been scaled to Partially Observable settings. We propose Recurrent Structural Policy Gradient (RSPG), the first history-aware HSM for settings involving public information. We also introduce MFAX, our JAX-based framework for MFGs. By leveraging known transition dynamics, RSPG achieves state-of-the-art performance as well as an order-of-magnitude faster convergence and solves, for the first time, a macroeconomics MFG with heterogeneous agents, common noise and history-aware policies. MFAX is publicly available at: https://github.com/CWibault/mfax.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [374] [Why iCloud Fails: The Category Mistake of Cloud Synchronization](https://arxiv.org/abs/2602.19433)
*Paul Borrill*

Main category: cs.DC

TL;DR: iCloud Drive因时间单向性假设与POSIX语义不兼容，导致与开发者工具链冲突；OAE的原子事务语义可解决这一问题。


<details>
  <summary>Details</summary>
Motivation: iCloud Drive的文件系统接口与POSIX语义存在根本性差异，这种差异源于分布式计算中的时间单向性假设（FITO），导致与开发者工作流的兼容性问题。

Method: 通过统一分析iCloud与Time Machine、git等工具的兼容性问题，包括直接证据（如文档损坏事件）和案例研究（366 GB的分歧状态）。

Result: 揭示了iCloud失败的五个相互关联的不兼容性，根源在于将分布式因果图投射到线性时间链上的结构性错误。

Conclusion: Open Atomic Ethernet (OAE) transactional semantics提供了解决iCloud Drive与POSIX语义差异的结构性基础，通过协议行为与物理现实的对齐而非违背物理规律。

Abstract: iCloud Drive presents a filesystem interface but implements cloud synchronization semantics that diverge from POSIX in fundamental ways. This divergence is not an implementation bug; it is a Category Mistake -- the same one that pervades distributed computing wherever Forward-In-Time-Only (FITO) assumptions are embedded into protocol design. Parker et al. showed in 1983 that network partitioning destroys mutual consistency; iCloud adds a user interface that conceals this impossibility behind a facade of seamlessness. This document presents a unified analysis of why iCloud fails when composed with Time Machine, git, automated toolchains, and general-purpose developer workflows, supported by direct evidence including documented corruption events and a case study involving 366 GB of divergent state accumulated through normal use. We show that the failures arise from five interlocking incompatibilities rooted in a single structural error: the projection of a distributed causal graph onto a linear temporal chain. We then show how the same Category Mistake, when it occurs in network fabrics as link flapping, destroys topology knowledge through epistemic collapse. Finally, we argue that Open Atomic Ethernet (OAE) transactional semantics -- bilateral, reversible, and conservation-preserving -- provide the structural foundation for resolving these failures, not by defeating physics, but by aligning protocol behavior with physical reality.

</details>


### [375] [The Category Mistake of Cislunar Time: Why NASA Cannot Synchronize What Doesn't Exist](https://arxiv.org/abs/2602.18641)
*Paul Borrill*

Main category: cs.DC

TL;DR: 本文批判NASA协调月球时间计划，指出其‘同步时间’概念为哲学混淆，并提出双边原子交互的替代方案。


<details>
  <summary>Details</summary>
Motivation: 探讨NASA协调月球时间计划的哲学基础，揭示其将‘同步时间’错误地视为本体实体而非认知建构的范畴错误。

Method: 通过Forward-In-Time-Only（FITO）假设、Spekkens的莱布尼茨操作主义、Wood-Spekkens微调论证，以及本体与认知解释的区分，分析了月球时间计划。

Result: 分析表明，该计划存在哲学混淆，其‘同步时间’概念与量子力学中的类似问题一样，需区分本体与认知。提出了基于双边原子交互的替代方案。

Conclusion: 本文认为，协调月球时间（LTC）计划基于一个范畴错误，将‘同步时间’视为本体实体而非认知建构。通过量子基础中的概念分析，揭示了该计划的哲学混淆，并提出了基于双边原子交互的替代方案。

Abstract: In April 2024, the White House directed NASA to establish Coordinated Lunar Time (LTC) by December 2026. The programme assumes that a unified time standard can be constructed by deploying atomic clocks on the lunar surface, computing relativistic corrections, and distributing synchronized time via LunaNet. This paper argues that the entire enterprise rests on a category mistake in the sense introduced by Ryle and developed by Spekkens in quantum foundations: it treats "synchronized time" as an ontic entity -- something that exists independently and can be transmitted from authoritative sources to dependent receivers -- when it is in fact an epistemic construct: a model-dependent representation of observer-relative clock relationships. We analyze the cislunar time programme through the lens of Forward-In-Time-Only (FITO) assumptions, Spekkens' Leibnizian operationalism, the Wood-Spekkens fine-tuning argument, and the distinction between ontic and epistemic interpretations that has dissolved long-standing puzzles in quantum mechanics. We show that the same conceptual move that dissolves quantum "mysteries" -- recognizing what is epistemic versus what is ontic -- dissolves the apparent coherence of the cislunar time programme and reveals it as an engineering project built on a philosophical confusion. We sketch a transactional alternative grounded in bilateral atomic interactions rather than unidirectional time distribution.

</details>


### [376] [What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature](https://arxiv.org/abs/2602.18723)
*Paul Borrill*

Main category: cs.DC

TL;DR: 论文指出分布式计算的经典不可能性结果源于设计选择（单向时间信息流），而非物理限制，并提出双边交互的替代方案。


<details>
  <summary>Details</summary>
Motivation: 揭示经典分布式计算不可能性结果的本质并非物理限制，而是设计选择中的类别错误，从而开辟新的设计空间。

Method: 1. 引入Ryle的类别错误框架和Spekkens的量子基础本体/认知区分；2. 识别FITO为隐藏公理；3. 应用Spekkens的莱布尼茨原则揭示FITO模型的冗余结构；4. 探讨放弃FITO的后果；5. 证明不可能性定理仅针对FITO系统；6. 提出双边交互的替代方案。

Result: 经典不可能性定理是FITO系统的特性，而非物理限制；双边交互方案可解决这些问题。

Conclusion: 分布式计算的经典不可能性结果（如Fischer-Lynch-Paterson定理、两将军问题、CAP定理）并非物理限制，而是源于设计选择中的类别错误，即单向时间信息流（FITO）被误认为自然法则。通过双边交互的替代方案可以解决这些不可能性。

Abstract: The foundational impossibility results of distributed computing -- the Fischer-Lynch-Paterson theorem, the Two Generals Problem, the CAP theorem -- are widely understood as discoveries about the physical limits of coordination. This paper argues that they are nothing of the sort. They are consequences of a category mistake: treating Forward-In-Time-Only (FITO) information flow as a law of nature rather than recognizing it as a design choice inherited from Shannon's channel model and Lamport's happened-before relation. We develop this argument in six steps. First, we introduce the category mistake framework from Ryle through Spekkens' ontic/epistemic distinction in quantum foundations. Second, we identify FITO as the hidden axiom that unifies the classical impossibility results. Third, we apply Spekkens' Leibnizian principle to show that FITO-based models contain surplus ontological structure. Fourth, we develop the counterfactual: what changes when FITO is dropped. Fifth, we demonstrate that the impossibility theorems are theorems about FITO systems, not about physics. Sixth, we sketch the transactional alternative -- bilateral interactions that dissolve the apparent impossibilities by replacing unidirectional message passing with atomic bilateral transactions. The implication is that distributed computing has spent fifty years optimizing within the wrong design space.

</details>


### [377] [BiScale: Energy-Efficient Disaggregated LLM Serving via Phase-Aware Placement and DVFS](https://arxiv.org/abs/2602.18755)
*Omar Basit,Yunzhao Liu,Z. Jonny Kong,Y. Charlie Hu*

Main category: cs.DC

TL;DR: BiScale是一个两层级能源优化框架，用于解耦LLM服务，通过分层控制显著降低能耗，同时满足服务SLOs。


<details>
  <summary>Details</summary>
Motivation: LLM推理能耗高，现有的自动扩展和细粒度DVFS在解耦服务中难以应对快速工作负载波动和相位不对称动态。

Method: BiScale采用两层级能源优化框架，结合预测延迟和功耗模型，在粗粒度时间尺度上计算相位感知的放置和基线频率，在细粒度时间尺度上动态调整GPU频率。

Result: 在16x H100集群上测试Llama 3.3 70B，BiScale相比DistServe在预填充和解码阶段分别降低了39%和48%的能耗。

Conclusion: BiScale通过分层设计，在满足TTFT/TPOT SLOs的同时，显著降低了预填充和解码阶段的能耗。

Abstract: Prefill/decode disaggregation is increasingly adopted in LLM serving to improve the latency-throughput tradeoff and meet strict TTFT and TPOT SLOs. However, LLM inference remains energy-hungry: autoscaling alone is too coarse-grained to track fast workload fluctuations, and applying fine-grained DVFS under disaggregation is complicated by phase-asymmetric dynamics and coupling between provisioning and frequency control.
  We present BiScale, a two-tier energy optimization framework for disaggregated LLM serving. BiScale jointly optimizes placement and DVFS across prefill and decode using predictive latency and power models. At coarse timescales, BiScale computes phase-aware placement and baseline frequencies that minimize energy while satisfying SLO constraints. At fine timescales, BiScale dynamically adapts GPU frequency per iteration using stage-specific control: model predictive control (MPC) for prefill to account for queue evolution and future TTFT impact, and lightweight slack-aware adaptation for decode to exploit its smoother, memory-bound dynamics. This hierarchical design enables coordinated control across timescales while preserving strict serving SLOs.
  Evaluation on a 16x H100 cluster serving Llama 3.3 70B with production-style traces shows that BiScale meets TTFT/TPOT SLOs while reducing energy by up to 39% in prefill and 48% in decode relative to DistServe.

</details>


### [378] [Carbon-aware decentralized dynamic task offloading in MIMO-MEC networks via multi-agent reinforcement learning](https://arxiv.org/abs/2602.18797)
*Mubshra Zulfiqar,Muhammad Ayzed Mirza,Basit Qureshi*

Main category: cs.DC

TL;DR: CADDTO-PPO是一个基于多智能体PPO的碳感知任务卸载框架，有效降低碳足迹和延迟，适用于可持续物联网。


<details>
  <summary>Details</summary>
Motivation: 解决大规模物联网微服务中随机任务到达与间歇性绿色能源之间的时空不匹配问题，以及多用户MIMO上行链路中的复杂干扰。

Method: 提出基于多智能体近端策略优化（PPO）的碳感知分散动态任务卸载框架CADDTO-PPO，采用分散执行与参数共享（DEPS）架构。

Result: CADDTO-PPO在碳强度和数据包溢出率上优于DDPG和Lyapunov基线，且在极端流量负载下保持近零溢出率。

Conclusion: CADDTO-PPO框架在碳强度和数据包溢出率方面表现优异，具有恒定的推理复杂度，适用于未来可持续物联网部署。

Abstract: Massive internet of things microservices require integrating renewable energy harvesting into mobile edge computing (MEC) for sustainable eScience infrastructures. Spatiotemporal mismatches between stochastic task arrivals and intermittent green energy along with complex inter-user interference in multi-antenna (MIMO) uplinks complicate real-time resource management. Traditional centralized optimization and off-policy reinforcement learning struggle with scalability and signaling overhead in dense networks. This paper proposes CADDTO-PPO, a carbon-aware decentralized dynamic task offloading framework based on multi-agent proximal policy optimization. The multi-user MIMO-MEC system is modeled as a Decentralized Partially Observable Markov Decision Process (DEC-POMDP) to jointly minimize carbon emissions and buffer latency and energy wastage. A scalable architecture utilizes decentralized execution with parameter sharing (DEPS), which enables autonomous IoT agents to make fine-grained power control and offloading decisions based solely on local observations. Additionally, a carbon-first reward structure adaptively prioritizes green time slots for data transmission to decouple system throughput from grid-dependent carbon footprints. Finally, experimental results demonstrate CADDTO-PPO outperforms deep deterministic policy gradient (DDPG) and lyapunov-based baselines. The framework achieves the lowest carbon intensity and maintains near-zero packet overflow rates under extreme traffic loads. Architectural profiling validates the framework to demonstrate a constant $O(1)$ inference complexity and theoretical lightweight feasibility for future generation sustainable IoT deployments.

</details>


### [379] [WANSpec: Leveraging Global Compute Capacity for LLM Inference](https://arxiv.org/abs/2602.18931)
*Noah Martin,Fahad Dogar*

Main category: cs.DC

TL;DR: WANSpec通过卸载部分LLM生成任务到低利用率数据中心，减少高需求中心的负载，实验显示前向传递减少50%以上且不增加延迟。


<details>
  <summary>Details</summary>
Motivation: 由于LLM应用的迅速扩展，高能力GPU需求旺盛，导致请求延迟增加，而数据中心负载不均。

Method: 通过引入WANSpec，利用推测解码技术将草案模型移至利用率较低的计算资源，实验包括模拟和云部署。

Result: 实验表明，WANSpec能在不增加延迟的情况下，将推测解码草案模型的前向传递减少50%以上。

Conclusion: WANSpec通过将部分LLM生成任务卸载到利用率较低的数据中心，有效缓解了高需求数据中心的容量问题，同时利用本地计算资源（如大学）补充云服务提供商的能力，且不增加延迟。

Abstract: Data centers capable of running large language models (LLMs) are spread across the globe. Some have high end GPUs for running the most advanced models (100B+ parameters), and others are only suitable for smaller models (1B parameters). The most capable GPUs are under high demand thanks to the rapidly expanding applications of LLMs. Choosing the right location to run an LLM inference workload can have consequences on the latency of requests due to these high demands. In this work, we explore options to shift some aspects of inference to the under-utilized data centers. We first observe the varying delays affecting inference in AWS services from different regions, demonstrating that load is not spread evenly. We then introduce WANSpec, which offloads part of LLM generation to the under-utilized data centers. In doing so, WANSpec can mitigate capacity issues as well as effectively use on-site compute (ie at universities) to augment cloud providers. This is done with speculative decoding, a widely used technique to speed up auto-regressive decoding, by moving the draft model to the under-utilized compute resources. Our experiments in simulation and cloud deployments show that WANSpec can judiciously employ redundancy to avoid increases in latency while still reducing the forward passes of speculative decoding's draft model in high demand data centers by over 50%.

</details>


### [380] [ucTrace: A Multi-Layer Profiling Tool for UCX-driven Communication](https://arxiv.org/abs/2602.19084)
*Emir Gencer,Mohammad Kefah Taha Issa,Ilyas Turimbetov,James D. Trotter,Didem Unat*

Main category: cs.DC

TL;DR: ucTrace是一种新型UCX分析器，填补了现有工具的不足，提供细粒度通信跟踪和可视化，优化HPC通信性能。


<details>
  <summary>Details</summary>
Motivation: 现有分析工具缺乏对UCX层面细粒度通信的跟踪，无法捕捉传输层行为，或仅限于特定MPI实现。

Method: 开发了ucTrace，一种新型分析器，能够在UCX层面剖析MPI工作流，并通过交互式可视化展示主机和设备间的通信行为。

Result: ucTrace通过多种实验展示了其功能，包括不同UCX设置下的MPI点对点行为、MPI库间的Allreduce比较、线性求解器的通信分析、NUMA绑定效应以及大规模GPU加速的GROMACS MD模拟分析。

Conclusion: ucTrace填补了现有UCX分析工具的空白，通过提供细粒度的通信跟踪和可视化，帮助优化HPC环境中的通信性能。

Abstract: UCX is a communication framework that enables low-latency, high-bandwidth communication in HPC systems. With its unified API, UCX facilitates efficient data transfers across multi-node CPU-GPU clusters. UCX is widely used as the transport layer for MPI, particularly in GPU-aware implementations. However, existing profiling tools lack fine-grained communication traces at the UCX level, do not capture transport-layer behavior, or are limited to specific MPI implementations.
  To address these gaps, we introduce ucTrace, a novel profiler that exposes and visualizes UCX-driven communication in HPC environments. ucTrace provides insights into MPI workflows by profiling message passing at the UCX level, linking operations between hosts and devices (e.g., GPUs and NICs) directly to their originating MPI functions. Through interactive visualizations of process- and device-specific interactions, ucTrace helps system administrators, library and application developers optimize performance and debug communication patterns in large-scale workloads. We demonstrate ucTrace's features through a wide range of experiments including MPI point-to-point behavior under different UCX settings, Allreduce comparisons across MPI libraries, communication analysis of a linear solver, NUMA binding effects, and profiling of GROMACS MD simulations with GPU acceleration at scale. ucTrace is publicly available at https://github.com/ParCoreLab/ucTrace.

</details>


### [381] [A Formal Framework for Predicting Distributed System Performance under Faults](https://arxiv.org/abs/2602.19088)
*Ziwei Zhou,Si Liu,Zhou Zhou,Peixin Wang,MIn Zhang*

Main category: cs.DC

TL;DR: 提出了PERF框架，首个系统性预测分布式系统在多样化故障场景下性能的形式化工具，预测结果与实际部署一致。


<details>
  <summary>Details</summary>
Motivation: 分布式系统在复杂环境中运行，常涉及故障甚至对抗行为，直接从形式化设计预测其性能是一个长期挑战。

Method: 提出了一种形式化框架，包括故障注入器和多种故障模型，可重用为库，并通过模型组合将系统和故障注入器集成到统一模型中，适用于性能属性的统计分析。

Result: PERF工具应用于代表性分布式系统时，能准确预测不同故障设置下的系统性能，形式化设计的估计与实际部署评估一致。

Conclusion: PERF框架通过形式化方法和自动化工具，成功预测了分布式系统在不同故障场景下的性能，其预测结果与实际部署评估一致。

Abstract: Today's distributed systems operate in complex environments that inevitably involve faults and even adversarial behaviors. Predicting their performance under such environments directly from formal designs remains a longstanding challenge. We present the first formal framework that systematically enables performance prediction of distributed systems across diverse faulty scenarios. Our framework features a fault injector together with a wide range of faults, reusable as a library, and model compositions that integrate the system and the fault injector into a unified model suitable for statistical analysis of performance properties such as throughput and latency. We formalize the framework in Maude and implement it as an automated tool, PERF. Applied to representative distributed systems, PERF accurately predicts system performance under varying fault settings, with estimations from formal designs consistent with evaluations on real deployments.

</details>


### [382] [Asymptotic Subspace Consensus in Dynamic Networks](https://arxiv.org/abs/2602.19121)
*Matthias Függer,Thomas Nowak*

Main category: cs.DC

TL;DR: 论文研究了异步子空间共识问题，展示了在较弱通信假设下算法的适应性，并提供了收敛速率的界限。


<details>
  <summary>Details</summary>
Motivation: 研究输出向量如何在初始向量的凸包内收敛到一个共同子空间，这是对传统异步共识（收敛到单点）的松弛。

Method: 通过分析异步子空间共识问题，并在无记忆消息对手模型下进行特征化。

Result: 论文展示了在较弱通信假设下算法的优雅降级能力，并提供了低于初始维度达到速率的界限。

Conclusion: 论文提供了关于异步子空间共识问题的完整可解性特征，并展示了在通信网络假设较弱时，一类用于异步共识的算法如何优雅地降级为子空间共识。

Abstract: We introduce the problem of asymptotic subspace consensus, which requires the outputs of processes to converge onto a common subspace while remaining inside the convex hull of initial vectors.This is a relaxation of asymptotic consensus in which outputs have to converge to a single point, i.e., a zero-dimensional affine subspace.
  We give a complete characterization of the solvability of asymptotic subspace consensus in oblivious message adversaries. In particular, we show that a large class of algorithms used for asymptotic consensus gracefully degrades to asymptotic subspace consensus in distributed systems with weaker assumptions on the communication network. We also present bounds on the rate by which a lower-than-initial dimension is reached.

</details>


### [383] [Semantic Conflict Model for Collaborative Data Structures](https://arxiv.org/abs/2602.19231)
*Georgii Semenov,Vitaly Aksenov*

Main category: cs.DC

TL;DR: 本文提出了一种本地优先的显式冲突解决模型，通过语义依赖和三向合并实现无需中央协调的冲突解决，并在协作寄存器上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有CRDTs的冲突解决通常是隐式且对用户不透明的，而现有协调技术依赖集中式协调，无法满足本地优先的需求。

Method: 该模型通过识别操作间的语义依赖关系，将冲突操作通过三向合并复制日志重新定位到调和操作上。

Result: 在协作寄存器上验证了该模型，包括显式实现的Last-Writer-Wins寄存器和支持半自动调和的多寄存器实体。

Conclusion: 本文提出了一种基于语义依赖关系的本地优先冲突解决模型，通过三向合并复制日志实现显式冲突解决，无需中央协调。

Abstract: Digital collaboration systems support asynchronous work over replicated data, where conflicts arise when concurrent operations cannot be unambiguously integrated into a shared history. While Conflict-Free Replicated Data Types (CRDTs) ensure convergence through built-in conflict resolution, this resolution is typically implicit and opaque to users, whereas existing reconciliation techniques often rely on centralized coordination. This paper introduces a conflict model for collaborative data structures that enables explicit, local-first conflict resolution without central coordination. The model identifies conflicts using semantic dependencies between operations and resolves them by rebasing conflicting operations onto a reconciling operation via a three-way merge over a replicated journal. We demonstrate our approach on collaborative registers, including an explicit formulation of the Last-Writer-Wins Register and a multi-register entity supporting semi-automatic reconciliation.

</details>


### [384] [Complex Event Processing in the Edge: A Combined Optimization Approach for Data and Code Placement](https://arxiv.org/abs/2602.19338)
*Halit Uyanık,Tolga Ovatman*

Main category: cs.DC

TL;DR: 研究提出一种约束编程优化方法，通过Python库实现，优化IoT设备上CEP任务的关键路径性能，提升吞吐量并减少延迟。


<details>
  <summary>Details</summary>
Motivation: 物联网设备硬件和计算能力有限，需处理日益复杂的任务和多样化的输入数据，如复杂事件处理（CEP），需要优化以提高性能。

Method: 采用约束编程优化方法，实现为一个Python库，抽象通信细节并支持IoT设备间共享内存的虚拟化。

Result: 优化关键路径性能后，多设备在CEP操作中的吞吐量提高且延迟减少。

Conclusion: 通过约束编程优化方法平衡CEP任务图中不同路径的执行成本，并提升关键路径性能，从而在CEP操作中提高吞吐量并减少延迟。

Abstract: The increasing variety of input data and complexity of tasks that are handled by the devices of internet of things (IoT) environments require solutions that consider the limited hardware and computation power of the edge devices. Complex event processing (CEP), can be given as an example, which involves reading and aggregating data from multiple sources to infer triggering of important events. In this study, we balance the execution costs between different paths of the CEP task graph with a constrained programming optimization approach and improve critical path performance. The proposed approach is implemented as a Python library, allowing small-scale IoT devices to adaptively optimize code and I/O assignments and improve overall latency and throughput. The implemented library abstracts away the communication details and allows virtualization of a shared memory between IoT devices. The results show that optimizing critical path performance increases throughput and reduces delay across multiple devices during CEP operations.

</details>


### [385] [GPU-Resident Gaussian Process Regression Leveraging Asynchronous Tasks with HPX](https://arxiv.org/abs/2602.19683)
*Henrik Möllmann,Dirk Pflüger,Alexander Strack*

Main category: cs.DC

TL;DR: GPRat库通过GPU优化实现高斯过程回归，显著提升计算效率，尤其在较大数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 高斯过程回归（GPs）的精确求解器由于立方复杂度难以扩展，因此需要提升其计算效率。

Method: 通过优化CUDA库实现分块算法，利用GPU的并行性进行线性代数运算，并评估最佳CUDA流数量。

Result: GPU实现相比CPU版本在较大数据集上表现更优，Cholesky分解和GP预测速度分别提升4.3倍和4.6倍，结合HPX和多CUDA流后性能超越cuSOLVER达11%。

Conclusion: GPU实现的GPRat库在数据集大于128个训练样本时显著提升了性能，尤其是在Cholesky分解和GP预测方面，速度提升分别达到4.3倍和4.6倍。结合HPX和多CUDA流，GPRat甚至能超越cuSOLVER性能达11%。

Abstract: Gaussian processes (GPs) are a widely used regression tool, but the cubic complexity of exact solvers limits their scalability. To address this challenge, we extend the GPRat library by incorporating a fully GPU-resident GP prediction pipeline. GPRat is an HPX-based library that combines task-based parallelism with an intuitive Python API.
  We implement tiled algorithms for the GP prediction using optimized CUDA libraries, thereby exploiting massive parallelism for linear algebra operations. We evaluate the optimal number of CUDA streams and compare the performance of our GPU implementation to the existing CPU-based implementation. Our results show the GPU implementation provides speedups for datasets larger than 128 training samples. We observe speedups of up to 4.3 for the Cholesky decomposition itself and 4.6 for the GP prediction. Furthermore, combining HPX with multiple CUDA streams allows GPRat to match, and for large datasets, surpass cuSOLVER's performance by up to 11 percent.

</details>


### [386] [A Risk-Aware UAV-Edge Service Framework for Wildfire Monitoring and Emergency Response](https://arxiv.org/abs/2602.19742)
*Yulun Huang,Zhiyu Wang,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 集成框架优化无人机野火监测，显著提升效率并降低能耗和机队规模。


<details>
  <summary>Details</summary>
Motivation: 野火监测需要及时的数据收集和处理以实现早期检测和快速响应，但现有方法在满足能源、重访时间和容量约束的同时最小化端到端服务响应时间仍具挑战性。

Method: 结合火灾历史加权聚类优先高风险区域、QoS感知边缘分配平衡距离和计算负载、2-opt路径优化与自适应机队规模调整，以及动态紧急重路由机制。

Result: 实验表明，该框架平均响应时间减少70.6-84.2%，能耗降低73.8-88.4%，机队规模减少26.7-42.1%，紧急机制响应时间在233秒内。

Conclusion: 提出的集成框架通过协同优化无人机路径规划、机队规模和边缘服务配置，显著提升了野火监测的效率和响应速度，同时降低了能耗和机队规模。

Abstract: Wildfire monitoring demands timely data collection and processing for early detection and rapid response. UAV-assisted edge computing is a promising approach, but jointly minimizing end-to-end service response time while satisfying energy, revisit time, and capacity constraints remains challenging. We propose an integrated framework that co-optimizes UAV route planning, fleet sizing, and edge service provisioning for wildfire monitoring. The framework combines fire-history-weighted clustering to prioritize high-risk areas, Quality of Service (QoS)-aware edge assignment balancing proximity and computational load, 2-opt route optimization with adaptive fleet sizing, and a dynamic emergency rerouting mechanism. The key insight is that these subproblems are interdependent: clustering decisions simultaneously shape patrol efficiency and edge workloads, while capacity constraints feed back into feasible configurations. Experiments show that the proposed framework reduces average response time by 70.6--84.2%, energy consumption by 73.8--88.4%, and fleet size by 26.7--42.1% compared to GA, PSO, and greedy baselines. The emergency mechanism responds within 233 seconds, well under the 300-second deadline, with negligible impact on normal operations.

</details>


### [387] [Linear Reservoir: A Diagonalization-Based Optimization](https://arxiv.org/abs/2602.19802)
*Romain de Coudenhove,Yannis Bendi-Ouis,Anthony Strock,Xavier Hinaut*

Main category: cs.DC

TL;DR: Diagonalization-based optimization reduces Linear ESNs' computational complexity from O(N^2) to O(N) via eigenbasis reformulation, with three methods (EWT, EET, DPG) offering speedups without accuracy loss.


<details>
  <summary>Details</summary>
Motivation: To reduce the per-step computational complexity of reservoir state updates in Linear Echo State Networks (ESNs) from O(N^2) to O(N) while maintaining predictive accuracy.

Method: The paper introduces three methods: Eigenbasis Weight Transformation (EWT), End-to-End Eigenbasis Training (EET), and Direct Parameter Generation (DPG), each tailored to different scenarios to optimize computational efficiency.

Result: The proposed methods achieve significant computational speedups while preserving predictive accuracy, making them viable replacements for standard Linear ESN computations and training.

Conclusion: The paper suggests a paradigm shift in linear ESNs towards direct eigenvalue selection, offering computational efficiency without sacrificing accuracy.

Abstract: We introduce a diagonalization-based optimization for Linear Echo State Networks (ESNs) that reduces the per-step computational complexity of reservoir state updates from O(N^2) to O(N). By reformulating reservoir dynamics in the eigenbasis of the recurrent matrix, the recurrent update becomes a set of independent element-wise operations, eliminating the matrix multiplication. We further propose three methods to use our optimization depending on the situation: (i) Eigenbasis Weight Transformation (EWT), which preserves the dynamics of standard and trained Linear ESNs, (ii) End-to-End Eigenbasis Training (EET), which directly optimizes readout weights in the transformed space and (iii) Direct Parameter Generation (DPG), that bypasses matrix diagonalization by directly sampling eigenvalues and eigenvectors, achieving comparable performance than standard Linear ESNs. Across all experiments, both our methods preserve predictive accuracy while offering significant computational speedups, making them a replacement of standard Linear ESNs computations and training, and suggesting a shift of paradigm in linear ESN towards the direct selection of eigenvalues.

</details>


### [388] [Mitigating Artifacts in Pre-quantization Based Scientific Data Compressors with Quantization-aware Interpolation](https://arxiv.org/abs/2602.20097)
*Pu Jiao,Sheng Di,Jiannan Tian,Mingze Xia,Xuan Wu,Yang Zhang,Xin Liang,Franck Cappello*

Main category: cs.DC

TL;DR: 提出一种量化感知插值算法，改善预量化压缩器的解压数据质量，保持高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 预量化压缩器在中等或大误差边界下数据质量较低，需改进。

Method: 1. 分析预量化压缩器产生的伪影；2. 提出量化感知插值算法；3. 在共享内存和分布式内存环境中并行化算法；4. 使用五个真实数据集评估算法。

Result: 实验证明算法能有效提升解压数据质量，同时保持高吞吐量。

Conclusion: 提出的算法能有效改善基于预量化的压缩器的解压数据质量，同时保持其高压缩吞吐量。

Abstract: Error-bounded lossy compression has been regarded as a promising way to address the ever-increasing amount of scientific data in today's high-performance computing systems. Pre-quantization, a critical technique to remove sequential dependency and enable high parallelism, is widely used to design and develop high-throughput error-controlled data compressors. Despite the extremely high throughput of pre-quantization based compressors, they generally suffer from low data quality with medium or large user-specified error bounds. In this paper, we investigate the artifacts generated by pre-quantization based compressors and propose a novel algorithm to mitigate them. Our contributions are fourfold: (1) We carefully characterize the artifacts in pre-quantization based compressors to understand the correlation between the quantization index and compression error; (2) We propose a novel quantization-aware interpolation algorithm to improve the decompressed data; (3) We parallelize our algorithm in both shared-memory and distributed-memory environments to obtain high performance; (4) We evaluate our algorithm and validate it with two leading pre-quantization based compressors using five real-world datasets. Experiments demonstrate that our artifact mitigation algorithm can effectively improve the quality of decompressed data produced by pre-quantization based compressors while maintaining their high compression throughput.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [389] [Validated Code Translation for Projects with External Libraries](https://arxiv.org/abs/2602.18534)
*Hanliang Zhang,Arindam Sharma,Cristina David,Meng Wang,Brandon Paulsen,Daniel Kroening,Wenjia Ye,Taro Sekiyama*

Main category: cs.SE

TL;DR: 论文提出了一种翻译和验证框架，用于将依赖外部库的Go项目翻译到Rust，通过检索机制和跨语言验证管道显著提高了成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在源程序依赖外部库时表现不佳，LLMs常虚构不存在的目标API且无法生成调用所需的导入，同时在处理不透明的库定义类型时验证语义等价性具有挑战性。

Method: 结合（i）将Go库API映射到Rust API的检索机制，和（ii）通过合成适配器实现语言互操作性的跨语言验证管道。

Result: 在六个真实世界的Go仓库上评估，该方法显著提高了编译和等价成功率（在依赖最重的情况下可达100%，平均约2倍）。

Conclusion: 该论文提出了一个结合检索机制和跨语言验证管道的框架，显著提高了Go项目翻译到Rust的成功率，特别是在处理依赖外部库的代码时。

Abstract: Large Language Models (LLMs) have shown promise for program translation, particularly for migrating systems code to memory-safe languages such as Rust. However, existing approaches struggle when source programs depend on external libraries: LLMs frequently hallucinate non-existent target APIs and fail to generate call-enabling imports; moreover, validating semantic equivalence is challenging when the code manipulates opaque, library-defined types. We present a translation and validation framework for translating Go projects with external dependencies to Rust. Our approach combines (i) a retrieval mechanism that maps Go library APIs to Rust APIs, and (ii) a cross-language validation pipeline that establishes language interoperability in the presence of opaque library types by synthesising adapters exclusively from public library APIs, prior to validating I/O equivalence. We evaluate our system on six real-world Go repositories with non-trivial external dependencies. Our approach significantly increases both the compilation and equivalence success rate (up to 100% in the most dependency-heavy case; approx. 2x on average) by enabling validated translation that manipulate opaque, library-defined types.

</details>


### [390] [Runtime-Augmented LLMs for Crash Detection and Diagnosis in ML Notebooks](https://arxiv.org/abs/2602.18537)
*Yiran Wang,José Antonio Hernández López,Ulf Nilsson,Dániel Varró*

Main category: cs.SE

TL;DR: CRANE-LLM通过增强LLMs的运行时信息，显著提升了ML笔记本崩溃的检测和诊断能力。


<details>
  <summary>Details</summary>
Motivation: ML笔记本在开发中频繁崩溃，但缺乏系统化的崩溃检测和诊断方法，CRANE-LLM旨在填补这一空白。

Method: CRANE-LLM利用LLMs增强结构化运行时信息（如对象类型、张量形状和数据属性），在目标单元格执行前预测崩溃并解释原因。

Result: 在JunoBench基准测试中，CRANE-LLM将崩溃检测和诊断的准确率提高了7-10个百分点，F1分数提高了8-11个百分点。

Conclusion: CRANE-LLM通过结合静态代码上下文和运行时信息，显著提升了ML笔记本中崩溃检测和诊断的准确性，尤其在诊断方面表现更优。

Abstract: Jupyter notebooks are widely used for machine learning (ML) development due to their support for interactive and iterative experimentation. However, ML notebooks are highly prone to bugs, with crashes being among the most disruptive. Despite their practical importance, systematic methods for crash detection and diagnosis in ML notebooks remain largely unexplored. We present CRANE-LLM, a novel approach that augments large language models (LLMs) with structured runtime information extracted from the notebook kernel state to detect and diagnose crashes before executing a target cell. Given previously executed cells and a target cell, CRANE-LLM combines static code context with runtime information, including object types, tensor shapes, and data attributes, to predict whether the target cell will crash (detection) and explain the underlying cause (diagnosis). We evaluate CRANE-LLM on JunoBench, a benchmark of 222 ML notebooks comprising 111 pairs of crashing and corresponding non-crashing notebooks across multiple ML libraries and crash root causes. Across three state-of-the-art LLMs (Gemini, Qwen, and GPT-5), runtime information improves crash detection and diagnosis by 7-10 percentage points in accuracy and 8-11 in F1-score, with larger gains for diagnosis. Improvements vary across ML libraries, crash causes, and LLMs, and depends on the integration of complementary categories of runtime information.

</details>


### [391] [LAPIS: Lightweight API Specification for Intelligent Systems](https://arxiv.org/abs/2602.18541)
*Daniel Garcia*

Main category: cs.SE

TL;DR: LAPIS是一种专为LLM优化的轻量级API规范，相比OpenAPI平均减少85.5%的token使用，同时保留必要语义信息。


<details>
  <summary>Details</summary>
Motivation: OpenAPI作为API描述的事实标准，设计初衷是文档工具和代码生成器，导致作为LLM上下文时token开销过大。

Method: 通过实证评估五种真实世界的生产API规范（包括GitHub、Twilio等），展示了LAPIS相比OpenAPI YAML和JSON的平均token减少量（分别为85.5%和88.6%）。

Result: LAPIS在保持语义信息的同时，显著减少了token使用量，并引入了OpenAPI无法表示或冗余的领域特定结构创新。

Conclusion: LAPIS是一种专为大型语言模型（LLM）优化的轻量级API规范格式，显著减少了token使用量，同时保留了API推理所需的语义信息。

Abstract: Large Language Models (LLMs) increasingly serve as consumers of API specifications, whether for code generation, autonomous agent interaction, or API-assisted reasoning. The de facto standard for API description, OpenAPI, was designed for documentation tools and code generators, resulting in substantial token overhead when used as LLM context.
  We present LAPIS (Lightweight API Specification for Intelligent Systems), a domain-specific format optimized for LLM consumption that preserves the semantic information necessary for API reasoning while minimizing token usage. Through empirical evaluation against five real-world production API specifications including GitHub (1,080 endpoints), Twilio (197 endpoints), DigitalOcean (545 endpoints), Petstore, and HTTPBin we demonstrate an average token reduction of 85.5% compared to OpenAPI YAML and 88.6% compared to OpenAPI JSON, measured with the cl100k_base tokenizer. LAPIS introduces domain-specific structural innovations, including centralized error definitions, webhook trigger conditions, structured rate limit descriptions, and operation flow declarations information that OpenAPI either duplicates redundantly or cannot represent at all.
  The format is fully convertible from OpenAPI 3.x via an automated converter, requires no special parser for LLM consumption, and is released as an open specification under CC BY 4.0.

</details>


### [392] [Programmable Property-Based Testing](https://arxiv.org/abs/2602.18545)
*Alperen Keles,Justine Frank,Ceren Mert,Harrison Goldstein,Leonidas Lampropoulos*

Main category: cs.SE

TL;DR: 提出了一种解耦属性与执行器的深度嵌入语言，提升了测试的灵活性和可编程性。


<details>
  <summary>Details</summary>
Motivation: 现有属性测试框架中，属性的定义与测试方式紧密耦合，用户受限于框架作者预设的配置选项，缺乏灵活性。

Method: 提出了一种基于延迟绑定抽象语法的深度嵌入语言，将属性作为数据结构具体化，并与执行器解耦。该语言在Rocq和Racket中实现，分别利用了依赖类型和动态类型的优势。

Result: 通过快速原型化多种属性执行器，展示了新方法在提升测试可编程性和解锁领域特定测试改进方面的潜力。

Conclusion: 基于延迟绑定抽象语法的新型属性测试语言通过将属性与执行器解耦，显著提升了测试的灵活性和可编程性，为领域特定测试改进提供了可能。

Abstract: Property-based testing (PBT) is a popular technique for establishing confidence in software, where users write properties -- i.e., executable specifications -- that can be checked many times in a loop by a testing framework. In modern PBT frameworks, properties are usually written in shallowly embedded domain-specific languages, and their definition is tightly coupled to the way they are tested. Such frameworks often provide convenient configuration options to customize aspects of the testing process, but users are limited to precisely what library authors had the prescience to allow for when developing the framework; if they want more flexibility, they may need to write a new framework from scratch.
  We propose a new, deeper language for properties based on a mixed embedding that we call deferred binding abstract syntax, which reifies properties as a data structure and decouples them from the property runners that execute them. We implement this language in Rocq and Racket, leveraging the power of dependent and dynamic types, respectively. Finally, we showcase the flexibility of this new approach by rapidly prototyping a variety of property runners, highlighting domain-specific testing improvements that can be unlocked by more programmable testing.

</details>


### [393] [1D-Bench: A Benchmark for Iterative UI Code Generation with Visual Feedback in Real-World](https://arxiv.org/abs/2602.18548)
*Qiao Xu,Yipeng Yu,Chengxiao Feng,Xu Liu*

Main category: cs.SE

TL;DR: 1D-Bench是一个基于真实电商流程的设计到代码转换基准，通过多轮迭代编辑提升性能，但强化学习等方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 为了解决设计到代码转换领域中数据集、工具链和评估协议不一致的问题，推动该领域的可比性和进展。

Method: 提出了1D-Bench基准，基于真实电子商务工作流程，要求生成可执行的React代码库，并采用多轮设置进行迭代编辑。实验包括商业和开源多模态模型，并探索了合成修复轨迹和强化学习编辑的效果。

Result: 实验表明，迭代编辑通常能通过提高渲染成功率和视觉相似度来提升最终性能，但合成修复轨迹和强化学习编辑的效果有限且不稳定。

Conclusion: 尽管通过迭代编辑和强化学习等方法在1D-Bench上取得了一定进展，但稀疏的终端奖励和高方差文件级更新限制了性能的稳定提升。

Abstract: Design-to-code translates high-fidelity UI designs into executable front-end implementations, but progress remains hard to compare due to inconsistent datasets, toolchains, and evaluation protocols. We introduce 1D-Bench, a benchmark grounded in real e-commerce workflows, where each instance provides a reference rendering and an exported intermediate representation that may contain extraction errors. 1D is short for one day, representing the efficient completion of design-to-code tasks in less than one day. Models take both as input, using the intermediate representation as structural cues while being evaluated against the reference rendering, which tests robustness to intermediate representation defects rather than literal adherence.
  1D-Bench requires generating an executable React codebase under a fixed toolchain with an explicit component hierarchy, and defines a multi-round setting in which models iteratively apply component-level edits using execution feedback. Experiments on commercial and open-weight multimodal models show that iterative editing generally improves final performance by increasing rendering success and often improving visual similarity. We further conduct a pilot study on post-training with synthetic repair trajectories and reinforcement learning based editing, and observe limited and unstable gains that may stem from sparse terminal rewards and high-variance file-level updates.

</details>


### [394] [Debug2Fix: Supercharging Coding Agents with Interactive Debugging Capabilities](https://arxiv.org/abs/2602.18571)
*Spandan Garg,Yufan Huang*

Main category: cs.SE

TL;DR: Debug2Fix通过集成调试器提升编码代理的bug修复能力，性能提升20%+，证明工具设计的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有编码代理在bug修复能力上仍有不足，缺乏对运行时信息的利用，而开发者调试时依赖这些信息。

Method: 引入Debug2Fix框架，集成Java和Python调试器，采用子代理架构，并在GitBug-Java和SWE-Bench-Live数据集上评估。

Result: 性能提升超过20%，较弱模型（如GPT-5和Claude Haiku 4.5）能匹配或超越更强模型（如Claude Sonnet 4.5）。

Conclusion: Debug2Fix框架通过引入交互式调试作为核心组件，显著提升了编码代理的bug修复能力，证明了工具设计的重要性。

Abstract: While significant progress has been made in automating various aspects of software development through coding agents, there is still significant room for improvement in their bug fixing capabilities. Debugging and investigation of runtime behavior remains largely a manual, developer-driven process. Popular coding agents typically rely on either static analysis of the code or iterative test-fix cycles, which is akin to trial and error debugging. We posit that there is a wealth of rich runtime information that developers routinely access while debugging code, which agents are currently deprived of due to design limitations. Despite how prevalent debuggers are in modern IDEs and command-line tools, they have surprisingly not made their way into coding agents. In this work, we introduce Debug2Fix, a novel framework that incorporates interactive debugging as a core component of a software engineering agent via a subagent architecture. We incorporate debuggers for Java and Python into our agent framework and evaluate against GitBug-Java and SWE-Bench-Live and achieve >20% improvement in performance compared to the baseline for certain models. Furthermore, using our framework, we're able to make weaker models like GPT-5 and Claude Haiku 4.5 match or exceed the performances of stronger models like Claude Sonnet 4.5, showing that better tool design is often just as important as switching to a more expensive model. Finally, we conduct systematic ablations demonstrating the importance of both the subagent architecture and debugger integration.

</details>


### [395] [Refactoring for Novices in Java: An Eye Tracking Study on the Extract vs. Inline Methods](https://arxiv.org/abs/2602.18579)
*José Aldo Silva da Costa,Rohit Gheyi,José Júnior Silva da Costa,Márcio Ribeiro,Rodrigo Bonifácio,Hyggo Almeida,Ana Carla Bibiano,Alessandro Garcia*

Main category: cs.SE

TL;DR: 研究通过眼动追踪发现，提取方法重构的效果因任务难度而异，复杂任务中表现更好，但简单任务中可能增加认知负担。教育者需谨慎对待初学者模块化。


<details>
  <summary>Details</summary>
Motivation: 探索内联方法与提取方法重构在人类理解和导航方面的差异，弥补静态指标研究的不足。

Method: 采用动态方法（眼动追踪）研究内联方法与提取方法重构，分析关键代码区域的视觉努力和阅读行为（注视时长、次数、回归、重访），以及时间和尝试次数。实验包括32名Java新手和58名额外新手的调查。

Result: 结果显示效果取决于任务难度。提取方法在某些任务中提高性能并减少视觉努力（时间减少78.8%，回归减少84.6%），但在简单任务中表现更差（时间增加166.9%，回归增加200%）。新手偏好提取方法但不总能匹配实际性能。

Conclusion: 教育者应谨慎对待过早模块化对初学者的影响，并强调眼动追踪作为静态指标的有用补充。

Abstract: Developers often extract methods to improve readability, understanding, and reuse, while inlining keeps logic in one block. Prior work based on static metrics has not shown clear differences between these practices, and the human side of comprehension and navigation remains underexplored. We investigate Inline Method vs. Extract Method refactorings using a dynamic approach: eye tracking while participants read and solve tasks. We analyze key code areas and compare visual effort and reading behavior (fixation duration and count, regressions, revisits), alongside time and attempts. We ran a controlled experiment with 32 Java novices, followed by short interviews. Each participant solved eight simple tasks across four programs presented in an inlined version and four in an extracted version. We also surveyed 58 additional novices for complementary quantitative and qualitative data. Results show that effects depend on task difficulty. In two tasks, method extraction improved performance and reduced visual effort, with time decreasing by up to 78.8% and regressions by 84.6%. For simpler tasks (e.g., square area), extraction hurt performance: time increased by up to 166.9% and regressions by 200%. Even with meaningful method names, novices often switched back and forth between call sites and extracted methods, increasing navigation and cognitive load. Preferences frequently favored extraction for readability and reuse, but did not always match measured performance. These findings suggest educators should be cautious about premature modularization for novices and highlight eye tracking as a useful complement to static metrics.

</details>


### [396] [Modeling and Recovering Hierarchical Structural Architectures of ROS 2 Systems from Code and Launch Configurations using LLM-based Agents](https://arxiv.org/abs/2602.18644)
*Mohamed Benchat,Dominique Briechle,Raj Chanchad,Mitbhai Chauhan,Meet Chavda,Ruidi He,Dhruv Jajadiya,Dhruv Kapadiya,Nidhiben Kaswala,Daniel Osterholz,Andreas Rausch,Meng Zhang*

Main category: cs.SE

TL;DR: 论文提出了一个UML-based的ROS~2层次结构建模方法和自动化恢复管道，解决了隐式结构编码问题，并在实验中验证了高精度但子系统级召回率受复杂性影响。


<details>
  <summary>Details</summary>
Motivation: 解决ROS~2中子系统结构隐式编码在分布式配置工件中的问题，使得层次结构分解难以捕获和维护。

Method: 结合确定性提取和基于LLM的代理，开发了一个蓝图引导的自动化恢复管道，将ROS~2架构蓝图编码为结构契约以约束合成和验证。

Result: 在三个ROS~2仓库（包括工业级代码子集）上评估，结果显示在抽象级别上具有高精度，但子系统级召回率随仓库复杂性下降。

Conclusion: 该论文提出了一个基于UML的ROS~2系统层次结构建模概念，并通过自动化恢复管道从代码和配置工件中重建模型，提高了可靠性。

Abstract: Model-Driven Engineering (MDE) relies on explicit architecture models to document and evolve systems across abstraction levels. For ROS~2, subsystem structure is often encoded implicitly in distributed configuration artifacts -- most notably launch files -- making hierarchical structural decomposition hard to capture and maintain. Existing ROS~2 modeling approaches cover node-level entities and wiring, but do not make hierarchical structural (de-)composition a first-class architectural view independent of launch artifacts.
  We contribute (1) a UML-based modeling concept for hierarchical structural architectures of ROS~2 systems and (2) a blueprint-guided automated recovery pipeline that reconstructs such models from code and configuration artifacts by combining deterministic extraction with LLM-based agents. The ROS~2 architectural blueprint (nodes, topics, interfaces, launch-induced wiring) is encoded as structural contracts to constrain synthesis and enable deterministic validation, improving reliability.
  We evaluate the approach on three ROS~2 repositories, including an industrial-scale code subset. Results show high precision across abstraction levels, while subsystem-level recall drops with repository complexity due to implicit launch semantics, making high-level recovery the remaining challenge.

</details>


### [397] [Automatic, Expressive, and Scalable Fuzzing with Stitching](https://arxiv.org/abs/2602.18689)
*Harrison Green,Fraser Brown,Claire Le Goues*

Main category: cs.SE

TL;DR: STITCH通过动态组装API约束片段，结合LLM自动化，显著提升模糊测试效果，发现大量漏洞。


<details>
  <summary>Details</summary>
Motivation: 解决现有模糊测试技术在扩展性和表达性上的不足，如固定API序列限制测试行为，动态探索序列缺乏对现实使用约束的建模能力。

Method: 提出了stitching技术，结合静态类型系统和动态检查的外部类型状态，编码API使用约束，并通过LLM自动配置项目、合成规范、分类崩溃和修复规范。

Result: 在33个基准测试中，STITCH在21个上实现了最高代码覆盖率，发现30个真实漏洞（其他工具共10个），精确度显著提高（70% vs. 12%）。自动部署在1365个项目中，发现131个新漏洞，73个已修复。

Conclusion: STITCH通过动态组装API使用约束片段，显著提升了模糊测试的覆盖率和精确度，发现了大量真实漏洞，并被广泛应用于开源项目中。

Abstract: Fuzzing is a powerful technique for finding bugs in software libraries, but scaling it remains difficult. Automated harness generation commits to fixed API sequences at synthesis time, limiting the behaviors each harness can test. Approaches that instead explore new sequences dynamically lack the expressiveness to model real-world usage constraints leading to false positives from straightforward API misuse.
  We propose stitching, a technique that encodes API usage constraints in pieces that a fuzzer dynamically assembles at runtime. A static type system governs how objects flow between blocks, while a dynamically-checked extrinsic typestate tracks arbitrary metadata across blocks, enabling specifications to express rich semantic constraints such as object state dependencies and cross-function preconditions. This allows a single specification to describe an open-ended space of valid API interactions that the fuzzer explores guided by coverage feedback.
  We implement stitching in STITCH, using LLMs to automatically configure projects for fuzzing, synthesize a specification, triage crashes, and repair the specification itself. We evaluated STITCH against four state-of-the-art tools on 33 benchmarks, where it achieved the highest code coverage on 21 and found 30 true-positive bugs compared to 10 by all other tools combined, with substantially higher precision (70% vs. 12% for the next-best LLM-based tool). Deployed automatically on 1365 widely used open-source projects, STITCH discovered 131 new bugs across 102 projects, 73 of which have already been patched.

</details>


### [398] [Efficient Dynamic Test Case Generation for Path-Based Coverage Criteria](https://arxiv.org/abs/2602.18768)
*Jakub Zelek,Jakub Ruszil,Adam Roman,Artur Polański*

Main category: cs.SE

TL;DR: 本文提出了一种基于改进Johnson算法的测试用例生成方法，支持增量式和按需生成，显著提高测试设计效率和灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有测试用例生成方法需要预先计算整个测试套件，效率低下且缺乏灵活性。本文旨在解决这些问题，提供更高效的测试设计工具。

Method: 基于改进的Johnson算法，支持增量式和按需生成测试用例，无需预先计算整个测试套件。该方法内存高效，仅保留生成后续覆盖项所需的最小路径集。

Result: 实验结果表明，该方法在执行时间、内存消耗和测试设计效率上均优于现有技术。

Conclusion: 本文提出了一种新颖的测试用例生成方法，显著提高了测试设计的效率和灵活性，同时在执行时间和内存消耗上优于现有技术。

Abstract: We present a novel approach to test-case generation that satisfies four white-box, path-based coverage criteria: Prime Path, Simple Cycle, Simple Path, and Edge-Acyclic Path. Our method builds on a modified version of Johnson algorithm and enables test cases to be generated incrementally and on demand, rather than requiring the entire test suite to be computed upfront. This streaming capability represents a substantial advancement over existing approaches, as it allows testers to begin executing and refining tests immediately, thereby significantly improving the efficiency of test design. Our solution is inherently memory efficient, as it does not store all discovered coverage items; instead, it retains only the minimal set of paths required to generate subsequent coverage items on the fly. As a result, the approach scales to arbitrarily large graphs. In addition, the algorithm gives testers explicit control over the size of the generated test suite by allowing them to restrict the number of cycles permitted in a test path. The approach is grounded in new theoretical insights, most notably a novel characterization of prime paths in terms of the strongly connected components of control-flow graphs. We complement these theoretical contributions with a practical implementation and a comprehensive empirical evaluation. The results demonstrate that our method not only outperforms existing techniques in terms of execution time and memory consumption, but also provides testers with a more flexible and efficient tool for achieving high coverage while substantially reducing test design overhead.

</details>


### [399] [Operational Robustness of LLMs on Code Generation](https://arxiv.org/abs/2602.18800)
*Debalina Ghosh Paul,Hong Zhu,Ian Bayley*

Main category: cs.SE

TL;DR: 论文提出了一种评估LLMs代码生成鲁棒性的新方法，通过实验发现任务复杂性和高级主题会降低模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有评估LLMs在代码生成任务中鲁棒性的方法不适用于自然语言描述的离散输入数据空间，因此需要一种新的评估方法。

Method: 论文提出了一种名为场景域分析的鲁棒性评估方法，旨在找到导致LLMs生成错误输出的自然语言描述的最小变化。该方法通过理论证明和实验验证，评估了四种先进LLMs的鲁棒性。

Result: 实验结果表明，该方法能够有效评估并比较四种LLMs（Gemini-pro、Codex、Llamma2和Falcon 7B）的鲁棒性，并发现任务复杂性和主题高级程度会降低模型的鲁棒性。

Conclusion: 该论文提出了一种名为场景域分析的鲁棒性评估方法，用于评估大型语言模型（LLMs）在代码生成任务中对自然语言描述变化的敏感性。通过理论证明和实验验证，该方法能够有效评估并比较不同LLMs的鲁棒性。研究发现，任务复杂性和主题高级程度会影响模型的鲁棒性。

Abstract: It is now common practice in software development for large language models (LLMs) to be used to generate program code. It is desirable to evaluate the robustness of LLMs for this usage. This paper is concerned in particular with how sensitive LLMs are to variations in descriptions of the coding tasks. However, existing techniques for evaluating this robustness are unsuitable for code generation because the input data space of natural language descriptions is discrete. To address this problem, we propose a robustness evaluation method called scenario domain analysis, which aims to find the expected minimal change in the natural language descriptions of coding tasks that would cause the LLMs to produce incorrect outputs. We have formally proved the theoretical properties of the method and also conducted extensive experiments to evaluate the robustness of four state-of-the-art art LLMs: Gemini-pro, Codex, Llamma2 and Falcon 7B, and have found that we are able to rank these with confidence from best to worst. Moreover, we have also studied how robustness varies in different scenarios, including the variations with the topic of the coding task and with the complexity of its sample solution, and found that robustness is lower for more complex tasks and also lower for more advanced topics, such as multi-threading and data structures.

</details>


### [400] [From Docs to Descriptions: Smell-Aware Evaluation of MCP Server Descriptions](https://arxiv.org/abs/2602.18914)
*Peiran Wang,Ying Li,Yuqiang Sun,Chengwei Liu,Yang Liu,Yuan Tian*

Main category: cs.SE

TL;DR: 论文系统研究了MCP工具描述中的缺陷及其影响，提出了四维质量标准并验证其有效性，证明标准化描述能显著提升工具选择效率。


<details>
  <summary>Details</summary>
Motivation: MCP服务器选择和接入依赖自由文本工具描述，但描述往往存在误导或遗漏关键语义的问题，导致集成效率低、代理行为不稳定及安全隐患。因此，需要系统研究描述缺陷及其对可用性的影响。

Method: 作者综合了软件/API文档实践和代理工具使用需求，提出了一个包含准确性、功能性、信息完整性和简洁性的四维质量标准，覆盖18种具体缺陷类别。随后在10,831个MCP服务器数据集上进行了大规模实证研究，并通过受控突变实验验证了缺陷对工具选择的影响。

Result: 研究发现描述缺陷普遍存在（如73%重复工具名、大量参数语义错误或缺失返回描述），且这些缺陷显著影响LLM工具选择（功能性和准确性影响最大，分别提升11.6%和8.8%）。在功能等效服务器竞争中，符合标准的描述选择概率达72%（比基线提升260%）。

Conclusion: 论文提出了一种四维质量标准来评估MCP工具描述的质量，并通过实证研究证明了描述缺陷对工具选择的影响，强调了标准化描述的重要性。

Abstract: The Model Context Protocol (MCP) has rapidly become a de facto standard for connecting LLM-based agents with external tools via reusable MCP servers. In practice, however, server selection and onboarding rely heavily on free-text tool descriptions that are intentionally loosely constrained. Although this flexibility largely ensures the scalability of MCP servers, it also creates a reliability gap that descriptions often misrepresent or omit key semantics, increasing trial-and-error integration, degrading agent behavior, and potentially introducing security risks. To this end, we present the first systematic study of description smells in MCP tool descriptions and their impact on usability. Specifically, we synthesize software/API documentation practices and agentic tool-use requirements into a four-dimensional quality standard: accuracy, functionality, information completeness, and conciseness, covering 18 specific smell categories. Using this standard, we conducted a large-scale empirical study on a well-constructed dataset of 10,831 MCP servers. We find that description smells are pervasive (e.g., 73% repeated tool names, thousands with incorrect parameter semantics or missing return descriptions), reflecting a "code-first, description-last" pattern. Through a controlled mutation-based study, we show these smells significantly affect LLM tool selection, with functionality and accuracy having the largest effects (+11.6% and +8.8%, p < 0.001). In competitive settings with functionally equivalent servers, standard-compliant descriptions reach 72% selection probability (260% over a 20% baseline), demonstrating that smell-guided remediation yields substantial practical benefits. We release our labeled dataset and standards to support future work on reliable and secure MCP ecosystems.

</details>


### [401] [Narrowing the Complexity Gap in the Evaluation of Large Language Models](https://arxiv.org/abs/2602.18928)
*Yang Chen,Shuyang Liu,Reyhaneh Jabbarvand*

Main category: cs.SE

TL;DR: GeneBench通过自动化增加编程问题的复杂性，有效评估LLMs在真实世界代码复杂性下的表现，展示了显著的性能下降。


<details>
  <summary>Details</summary>
Motivation: 为了避免基于简单基准高估LLMs的编程能力，并在真实世界环境中失望，需要更现实的评估方法。

Method: GeneBench利用多目标优化技术，增加编程问题的复杂性，同时保持代码的可读性类似于真实世界程序。通过转换四个广泛使用的编程基准并评估13个LLMs，展示了性能下降。

Result: 使用GeneBench转换基准后，所有编程任务的LLMs性能显著下降（14.9%-60.5%，平均35.2%），即使在少样本提示或微调后，性能下降仍持续。

Conclusion: GeneBench技术通过自动化增加编程问题的复杂性，有效评估了LLMs在真实世界代码复杂性下的表现，避免了构建真实世界基准的高成本。

Abstract: Evaluating Large Language Models (LLMs) with respect to real-world code complexity is essential. Otherwise, there is a risk of overestimating LLMs' programming abilities based on simplistic benchmarks, only to be disappointed when using them in real-world settings. Recently, researchers explored the construction of more realistic benchmarks by mining or augmenting open-source repositories. Such solutions are usually task-specific. Data quality control from real-world projects can also be time-consuming and error-prone. More importantly, evaluating LLMs on fixed benchmark problems is subject to data contamination and overfitting. We propose GeneBench, an automated technique to add real-world complexities to any programming benchmark. GeneBench leverages a multi-objective optimization to increase the complexity of programming problems while maintaining the readability of code similar to real-world programs. Transforming four widely-used programming benchmarks using GeneBench and evaluating 13 LLMs (including two reasoning LLMs) on them shows a notable performance drop across all programming tasks (14.9%-60.5%, avg=35.2%), demonstrating LLMs' struggle under real-world complexities. The struggle persists even when LLMs are few-shot prompted or fine-tuned with examples from different versions of GeneBench, demonstrating the challenging nature of the problems. Finally, we show that the performance of the studied LLMs in bug repair is similar under GeneBench and SWE-Bench. This, along with the consistent reproduction of performance drop of all studied LLMs across four tasks under different versions of GeneBench, makes the technique suitable to evaluate LLMs without costly construction of real-world benchmarks.

</details>


### [402] [A Systematic Evaluation of Environmental Flakiness in JavaScript Tests](https://arxiv.org/abs/2602.19098)
*Negar Hashemi,Amjed Tahir,August Shi,Shawn Rasheed,Rachel Blagojevic*

Main category: cs.SE

TL;DR: 研究发现JavaScript测试不稳定性受环境因素影响显著，开发了js-env-sanitizer工具有效缓解问题，支持多种测试框架。


<details>
  <summary>Details</summary>
Motivation: 测试不稳定性是工业界的一个重要问题，尤其在动态语言如JavaScript中，环境因素的影响尚未充分研究。

Method: 通过在多环境配置下执行测试套件，研究环境变化对测试不稳定性的影响，并开发了js-env-sanitizer工具来跳过和报告环境相关的测试问题。

Result: 在65个环境不稳定的项目中，发现28个与操作系统相关，5个与Node.js版本兼容性相关，16个与操作系统和Node.js组合问题相关，17个与浏览器兼容性相关。

Conclusion: 本文开发了一个轻量级工具js-env-sanitizer，用于缓解JavaScript测试中的环境因素导致的测试不稳定问题，支持三种流行的测试框架，且具有高准确性和低性能开销。

Abstract: Test flakiness is a significant issue in industry, affecting test efficiency and product quality. While extensive research has examined the impact of flaky tests, many root causes remain unexplored, particularly in the context of dynamic languages such as JavaScript. In this paper, we conduct a systematic evaluation of the impact of environmental factors on test flakiness in JavaScript. We first executed test suites across multiple environmental configurations to determine whether changes in the environment could lead to flaky behavior. We selected three environmental factors to manipulate: the operating system, the Node.js version, and the browser. We identified a total of 65 environmental flaky projects, with 28 related to operating system issues, five to Node.js version compatibility, 16 to a combination of operating system and Node.js issues, and 17 related to browser compatibility. To address environmental flakiness, we developed a lightweight mitigation approach, js-env-sanitizer, that can sanitize environmental-related flaky tests by skipping and reporting them (rather than failing), allowing CI builds to continue/succeed without rerunning entire test suites. The tool achieves high accuracy with minimal performance or configuration overhead, and currently supports three popular JavaScript testing frameworks (Jest, Mocha, and Vitest)

</details>


### [403] [Gecko: A Simulation Environment with Stateful Feedback for Refining Agent Tool Calls](https://arxiv.org/abs/2602.19218)
*Zeyu Zhang,Guohao Li,Zhenchang Xing,Alexandros Apostolopoulos,Yu Lin Lee,Liang Zheng*

Main category: cs.SE

TL;DR: Gecko 环境通过模拟工具响应和反馈，提升 LLM 工具调用性能，避免高成本和不安全问题。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖 LLM 生成工具调用，但易出错且迭代优化成本高、不安全，需改进。

Method: 引入 Gecko 环境，结合规则和 LLM 模拟工具响应，提供有效性检查、合理响应合成和任务目标评估三类反馈。

Result: GATS 方法在 BFCLv3 和 τ²-bench 上显著提升了 GPT-4o、GPT-5 和 Gemini-3.0-pro 等 LLM 的工具调用性能。

Conclusion: Gecko 环境通过模拟工具响应和提供反馈，显著提升了 LLM 工具调用的性能，并讨论了未来可能性。

Abstract: The ability to use tools is fundamental for large language model (LLM) agents. Given a task, existing systems use LLMs to plan and generate tool calls, which are executed by real-world tools to complete the task. However, tool calls are prone to errors because they are derived merely from LLM intrinsic capabilities. What is more, while it is useful to let LLMs iteratively refine the tool-call sequence using execution results from real tools, this process can be expensive and lead to unsafe results. To improve LLM tool calls and address issues caused by using real tools for refinement, we introduce Gecko, a comprehensive environment that simulates tool responses using a combination of rules and LLMs. Specifically, Gecko checks the validity of tool calls including input arguments and tool names, synthesizes reasonable responses that adhere to the output schema, and assesses whether all task objectives have been achieved. These three types of feedback provided by Gecko allow LLMs to refine their tool calls, forming a simple yet effective test-time scaling method named GATS. On BFCLv3 and $τ^2$-bench, GATS consistently improves the tool calling performance of various LLMs including GPT-4o, GPT-5, and Gemini-3.0-pro. We further discuss working mechanisms of our method and share future possibilities.

</details>


### [404] [ComUICoder: Component-based Reusable UI Code Generation for Complex Websites via Semantic Segmentation and Element-wise Feedback](https://arxiv.org/abs/2602.19276)
*Jingyu Xiao,Jiantong Qin,Shuoqi Li,Man Ho Lam,Yuxuan Wan,Jen-tse Huang,Yintong Huo,Michael R. Lyu*

Main category: cs.SE

TL;DR: ComUICoder是一个基于组件的UI代码生成框架，通过语义感知分割、代码重用和细粒度优化，显著提升了复杂网站的代码生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在处理长复杂网站时存在碎片化分割、冗余代码生成和UI不一致性问题，需要系统性解决方案。

Method: ComUICoder框架包含三个核心组件：(1) 混合语义感知块分割，(2) 视觉感知图基块合并，(3) 基于优先级的元素级反馈。

Result: 实验表明，ComUICoder在复杂多页面网站上的生成质量和代码可重用性显著提升。

Conclusion: ComUICoder显著提升了在复杂多页面网站上的UI代码生成质量和代码可重用性，为解决现有MLLMs在长复杂网站上的问题提供了有效方案。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong performance on the UI-to-code task, which aims to generate UI code from design mock-ups. However, when applied to long and complex websites, they often struggle with fragmented segmentation, redundant code generation for repetitive components, and frequent UI inconsistencies. To systematically investigate and address these challenges, we introduce ComUIBench, a new multi-page complex webpage benchmark with component annotations, designed to evaluate MLLMs' ability to generate reusable UI code in realistic website scenarios. Building upon this benchmark, we propose ComUICoder, a component-based UI code generation framework that emphasizes semantic-aware segmentation, code reuse, and fine-grained refinement. Specifically, ComUICoder incorporates (1) Hybrid Semantic-aware Block Segmentation for accurate UI semantic coherent block detection, (2) Visual-aware Graph-based Block Merge to consolidate structurally similar components within and across webpages for reusable implementation, and (3) Priority-based Element-wise Feedback to refine generated code and reduce element-level inconsistencies. Extensive experiments demonstrate that ComUICoder significantly improves overall generation quality and code reusability on complex multipage websites. Our datasets and code are publicly available at https://github.com/WebPAI/ComUICoder.

</details>


### [405] [Towards Automated Page Object Generation for Web Testing using Large Language Models](https://arxiv.org/abs/2602.19294)
*Betül Karagöz,Filippo Ricca,Matteo Biagiola,Andrea Stocco*

Main category: cs.SE

TL;DR: LLMs 可自动生成 POs，准确性 32.6%-54.0%，元素识别率超 70%，为测试工作流提供新方向。


<details>
  <summary>Details</summary>
Motivation: 探索 LLMs 在自动化生成 POs 中的可行性，以解决当前手动创建和维护 POs 的高成本问题。

Method: 使用 GPT-4o 和 DeepSeek Coder 对五个网页应用生成 POs，并与人工编写的 POs（基准）对比，评估准确性和元素识别率。

Result: LLMs 生成的 POs 在语法正确性和功能实用性上表现良好，准确性达 32.6%-54.0%，元素识别率多数超过 70%。

Conclusion: LLMs 在自动生成 Page Objects (POs) 方面显示出潜力，但仍有改进空间，需进一步研究以优化其在测试工作流中的应用。

Abstract: Page Objects (POs) are a widely adopted design pattern for improving the maintainability and scalability of automated end-to-end web tests. However, creating and maintaining POs is still largely a manual, labor-intensive activity, while automated solutions have seen limited practical adoption. In this context, the potential of Large Language Models (LLMs) for these tasks has remained largely unexplored. This paper presents an empirical study on the feasibility of using LLMs, specifically GPT-4o and DeepSeek Coder, to automatically generate POs for web testing. We evaluate the generated artifacts on an existing benchmark of five web applications for which manually written POs are available (the ground truth), focusing on accuracy (i.e., the proportion of ground truth elements correctly identified) and element recognition rate (i.e., the proportion of ground truth elements correctly identified or marked for modification). Our results show that LLMs can generate syntactically correct and functionally useful POs with accuracy values ranging from 32.6% to 54.0% and element recognition rate exceeding 70% in most cases. Our study contributes the first systematic evaluation of LLMs strengths and open challenges for automated PO generation, and provides directions for further research on integrating LLMs into practical testing workflows.

</details>


### [406] [Designing and Implementing a Comprehensive Research Software Engineer Career Ladder: A Case Study from Princeton University](https://arxiv.org/abs/2602.19353)
*Ian A. Cosden,Elizabeth Holtz,Joel U. Bretheim*

Main category: cs.SE

TL;DR: 普林斯顿大学为解决RSE职业路径不明确问题，设计了全面的职业阶梯，提升了招聘效率和员工满意度。


<details>
  <summary>Details</summary>
Motivation: 由于RSE在高等教育中的快速崛起和大学对新科技角色模型的缓慢反应，导致缺乏结构化的职业路径来认可技术掌握、学术影响和领导力成长。

Method: 设计了涵盖从助理到首席级别的RSE职业阶梯，包括团队领导和管理轨道，并制定了指导原则、能力框架、HR对齐和实施流程。

Result: 实施后，招聘效率提高，晋升路径更清晰，员工反响积极。

Conclusion: 普林斯顿大学通过设计和实施全面的RSE职业阶梯，成功解决了RSE职位快速增长带来的职业路径不明确问题，提升了招聘效率并明确了晋升途径。

Abstract: Research Software Engineers (RSEs) have become indispensable to computational research and scholarship. The fast rise of RSEs in higher education and the trend of universities to be slow creating or adopting models for new technology roles means a lack of structured career pathways that recognize technical mastery, scholarly impact, and leadership growth. In response to an immense demand for RSEs at Princeton University, and dedicated funding to grow the RSE group at least two-fold, Princeton was forced to strategize how to cohesively define job descriptions to match the rapid hiring of RSE positions but with enough flexibility to recognize the unique nature of each individual position. This case study describes our design and implementation of a comprehensive RSE career ladder spanning Associate through Principal levels, with parallel team-lead and managerial tracks. We outline the guiding principles, competency framework, Human Resources (HR) alignment, and implementation process, including engagement with external consultants and mapping to a standard job leveling framework utilizing market benchmarks. We share early lessons learned and outcomes including improved hiring efficiency, clearer promotion pathways, and positive reception among staff.

</details>


### [407] [Compliance Management for Federated Data Processing](https://arxiv.org/abs/2602.19360)
*Natallia Kokash,Adam Belloum,Paola Grosso*

Main category: cs.SE

TL;DR: A framework for compliance-aware federated data processing integrates policy-as-code, workflow orchestration, and LLM-assisted compliance to manage access policies and regulatory requirements effectively.


<details>
  <summary>Details</summary>
Motivation: The motivation is to overcome the limitations in real-world adoption of federated data processing due to the complexity of managing access policies, regulatory requirements, and workflows across organizations.

Method: The method involves developing a framework that combines policy-as-code, workflow orchestration, and LLM-assisted compliance management to handle heterogeneous access policies and regulatory requirements in federated data processing.

Result: The implemented prototype demonstrates the successful translation of legal and organizational requirements into machine-actionable policies within federated data processing networks.

Conclusion: The paper concludes that the proposed framework effectively addresses the challenges of compliance-aware federated data processing by integrating policy-as-code, workflow orchestration, and LLM-assisted compliance management.

Abstract: Federated data processing (FDP) offers a promising approach for enabling collaborative analysis of sensitive data without centralizing raw datasets. However, real-world adoption remains limited due to the complexity of managing heterogeneous access policies, regulatory requirements, and long-running workflows across organizational boundaries. In this paper, we present a framework for compliance-aware FDP that integrates policy-as-code, workflow orchestration, and large language model (LLM)-assisted compliance management. Through the implemented prototype, we show how legal and organizational requirements can be collected and translated into machine-actionable policies in FDP networks.

</details>


### [408] [On the Variability of Source Code in Maven Package Rebuilds](https://arxiv.org/abs/2602.19383)
*Jens Dietrich,Behnaz Hassanshahi*

Main category: cs.SE

TL;DR: 论文验证开源软件独立构建是否使用相同源代码，发现构建时生成代码是主要不一致原因，并提出改进策略。


<details>
  <summary>Details</summary>
Motivation: 研究开源软件供应链中独立构建的包是否使用相同的源代码，以验证安全性改进的假设。

Method: 比较了Maven Central发布的包与Google和Oracle独立构建的包的源代码，分析了28个流行包的85个版本中的非等效源代码。

Result: 发现主要的不一致原因是构建时生成代码的扩展，这些扩展难以重现。

Conclusion: 论文提出了解决开源软件供应链中源代码不一致问题的策略，强调了构建时生成代码的挑战，并建议改进方法以确保源代码的一致性。

Abstract: Rebuilding packages from open source is a common practice to improve the security of software supply chains, and is now done at an industrial scale. The basic principle is to acquire the source code used to build a package published in a repository such as Maven Central (for Java), rebuild the package independently with hardened security, and publish it in some alternative repository. In this paper we test the assumption that the same source code is being used by those alternative builds. To study this, we compare the sources released with packages on Maven Central, with the sources associated with independently built packages from Google's Assured Open Source and Oracle's Build-from-Source projects. We study non-equivalent sources for alternative builds of 28 popular packages with 85 releases. We investigate the causes of non-equivalence, and find that the main cause is build extensions that generate code at build time, which are difficult to reproduce. We suggest strategies to address this issue.

</details>


### [409] [Multi-CoLoR: Context-Aware Localization and Reasoning across Multi-Language Codebases](https://arxiv.org/abs/2602.19407)
*Indira Vats,Sanjukta De,Subhayan Roy,Saurabh Bodhe,Lejin Varghese,Max Kiehn,Yonas Bedasso,Marsha Chechik*

Main category: cs.SE

TL;DR: Multi-CoLoR框架通过结合历史问题检索和图推理，有效提升了多语言代码库中的代码定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂多语言代码库中的代码定位效果有限，主要因缺乏组织上下文理解和跨语言结构关系处理能力。

Method: Multi-CoLoR采用两阶段方法：1) 相似问题上下文(SIC)模块检索语义和组织相关的历史问题以缩小搜索范围；2) 代码图遍历代理(基于LocAgent扩展)在C++和QML代码库中进行结构推理。

Result: 在真实企业数据集上的评估表明，Multi-CoLoR通过SIC模块缩小搜索空间并提升定位准确率，图推理方法在非Python代码库中表现优异。Acc@5优于基线方法，同时减少了AMD代码库的工具调用。

Conclusion: Multi-CoLoR通过结合组织知识检索和图推理，显著提升了在多语言代码库中的代码定位准确率，并减少了工具调用次数。

Abstract: Large language models demonstrate strong capabilities in code generation but struggle to navigate complex, multi-language repositories to locate relevant code. Effective code localization requires understanding both organizational context (e.g., historical issue-fix patterns) and structural relationships within heterogeneous codebases. Existing methods either (i) focus narrowly on single-language benchmarks, (ii) retrieve code across languages via shallow textual similarity, or (iii) assume no prior context. We present Multi-CoLoR, a framework for Context-aware Localization and Reasoning across Multi-Language codebases, which integrates organizational knowledge retrieval with graph-based reasoning to traverse complex software ecosystems. Multi-CoLoR operates in two stages: (i) a similar issue context (SIC) module retrieves semantically and organizationally related historical issues to prune the search space, and (ii) a code graph traversal agent (an extended version of LocAgent, a state-of-the-art localization framework) performs structural reasoning within C++ and QML codebases. Evaluations on a real-world enterprise dataset show that incorporating SIC reduces the search space and improves localization accuracy, and graph-based reasoning generalizes effectively beyond Python-only repositories. Combined, Multi-CoLoR improves Acc@5 over both lexical and graph-based baselines while reducing tool calls on an AMD codebase.

</details>


### [410] [When AI Teammates Meet Code Review: Collaboration Signals Shaping the Integration of Agent-Authored Pull Requests](https://arxiv.org/abs/2602.19441)
*Costain Nachuma,Minhaz Zibran*

Main category: cs.SE

TL;DR: AI代理提交的GitHub pull requests的成功整合关键在于审查者参与和遵循协作规范，而非仅靠代码质量或迭代强度。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于对AI代理在GitHub上提交pull requests如何融入人类驱动的审查流程缺乏了解。

Method: 研究方法包括对AIDev数据集中的代理提交pull requests进行大规模实证研究，采用逻辑回归分析（包含仓库聚类标准误差），并辅以定性分析。

Result: 研究发现，审查者参与度与成功整合相关性最强，而较大的变更规模和破坏协调的行为（如强制推送）则降低合并概率。迭代强度在考虑协作信号后解释力有限。

Conclusion: 论文结论指出，有效整合由AI代理提交的pull requests不仅取决于代码质量，还需与既定的审查和协调实践保持一致。

Abstract: Autonomous coding agents increasingly contribute to software development by submitting pull requests on GitHub; yet, little is known about how these contributions integrate into human-driven review workflows. We present a large empirical study of agent-authored pull requests using the public AIDev dataset, examining integration outcomes, resolution speed, and review-time collaboration signals. Using logistic regression with repository-clustered standard errors, we find that reviewer engagement has the strongest correlation with successful integration, whereas larger change sizes and coordination-disrupting actions, such as force pushes, are associated with a lower likelihood of merging. In contrast, iteration intensity alone provides limited explanatory power once collaboration signals are considered. A qualitative analysis further shows that successful integration occurs when agents engage in actionable review loops that converge toward reviewer expectations. Overall, our results highlight that the effective integration of agent-authored pull requests depends not only on code quality but also on alignment with established review and coordination practices.

</details>


### [411] ["Write in English, Nobody Understands Your Language Here": A Study of Non-English Trends in Open-Source Repositories](https://arxiv.org/abs/2602.19446)
*Masudul Hasan Masud Bhuiyan,Manish Kumar Bala Kumar,Cristian-Alexandru Staicu*

Main category: cs.SE

TL;DR: 开源软件社区正变得更加多语言化，但语言多样性也带来了新的挑战。


<details>
  <summary>Details</summary>
Motivation: 研究开源软件社区中多语言使用的趋势，以评估全球化参与对语言多样性的影响。

Method: 分析了2015年至2025年间GitHub上的9.14亿个问题、拉取请求和讨论，以及62,500个仓库，涵盖5种编程语言和30种自然语言。

Result: 多语言参与度稳步上升，尤其在韩语、中文和俄语中，但非英语或多语言项目的可见性和参与度较低。

Conclusion: 开源软件社区正逐渐变得更加多语言化，但语言多样性也带来了新的挑战，如语言紧张和参与度不均。

Abstract: The open-source software (OSS) community has historically been dominated by English as the primary language for code, documentation, and developer interactions. However, with growing global participation and better support for non-Latin scripts through standards like Unicode, OSS is gradually becoming more multilingual. This study investigates the extent to which OSS is becoming more multilingual, analyzing 9.14 billion GitHub issues, pull requests, and discussions, and 62,500 repositories across five programming languages and 30 natural languages, covering the period from 2015 to 2025. We examine six research questions to track changes in language use across communication, code, and documentation. We find that multilingual participation has steadily increased, especially in Korean, Chinese, and Russian. This growth appears not only in issues and discussions but also in code comments, string literals, and documentation files. While this shift reflects greater inclusivity and language diversity in OSS, it also creates language tension. The ability to express oneself in a native language can clash with shared norms around English use, especially in collaborative settings. Non-English or multilingual projects tend to receive less visibility and participation, suggesting that language remains both a resource and a barrier, shaping who gets heard, who contributes, and how open collaboration unfolds.

</details>


### [412] [Workflow-Level Design Principles for Trustworthy GenAI in Automotive System Engineering](https://arxiv.org/abs/2602.19614)
*Chih-Hong Cheng,Brian Hsuan-Cheng Liao,Adam Molin,Hasan Esen*

Main category: cs.SE

TL;DR: 论文提出了在汽车工程中集成GenAI的信任工作流程，通过分解和多样性采样提高需求变更的完整性和正确性，并验证了模型更新和回归测试的可追溯性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在安全关键系统工程中因信任度、可追溯性和与传统验证实践的对齐问题而受到的限制。

Method: 采用分块分解、多样性采样和轻量级NLP检查来识别需求差异，并将这些差异传播到SysML v2模型中，通过编译和静态分析验证更新。此外，通过从规范变量到架构端口和状态的显式映射生成测试用例，确保可追溯的回归测试。

Result: 展示了分块分解和多样性采样相比整体提示能更全面地捕捉大型规范中的关键变化，并通过SysML v2模型更新和回归测试验证了方法的有效性。

Conclusion: 论文提出了在安全关键系统工程中集成GenAI的工作流程级设计原则，并通过端到端的汽车工程管道验证了其有效性，强调了分解、多样性和轻量级检查在提高完整性和正确性方面的作用。

Abstract: The adoption of large language models in safety-critical system engineering is constrained by trustworthiness, traceability, and alignment with established verification practices. We propose workflow-level design principles for trustworthy GenAI integration and demonstrate them in an end-to-end automotive pipeline, from requirement delta identification to SysML v2 architecture update and re-testing. First, we show that monolithic ("big-bang") prompting misses critical changes in large specifications, while section-wise decomposition with diversity sampling and lightweight NLP sanity checks improves completeness and correctness. Then, we propagate requirement deltas into SysML v2 models and validate updates via compilation and static analysis. Additionally, we ensure traceable regression testing by generating test cases through explicit mappings from specification variables to architectural ports and states, providing practical safeguards for GenAI used in safety-critical automotive engineering.

</details>


### [413] [Towards Understanding Views on Combining Videos and Gamification in Software Engineering Training](https://arxiv.org/abs/2602.19628)
*Pasan Peiris,Matthias Galster,Antonija Mitrovic,Sanna Malinen,Raul Vincent Lumapas,Jay Holland*

Main category: cs.SE

TL;DR: 研究表明，游戏化能提升视频培训的参与度，学生和专业人士均支持这一结合，为软件工程师的游戏化培训设计提供了依据。


<details>
  <summary>Details</summary>
Motivation: 被动观看培训视频导致学习效果肤浅，而游戏化可以增加参与度。研究旨在了解软件工程学生和行业从业者对游戏化视频培训的看法。

Method: 通过调查问卷的方式，收集了软件工程学生和行业从业者对游戏化视频培训的看法。

Result: 学生和专业人士对视频培训的普遍看法相似，并支持将游戏化与视频培训相结合。

Conclusion: 研究结果表明，学生和专业人士对视频培训的看法相似，并支持将游戏化与视频培训相结合。这些发现可为软件工程师的游戏化培训解决方案设计提供参考。

Abstract: Watching training videos passively leads to superficial learning. Adding gamification can increase engagement. We study how software engineering students and industry practitioners view gamifying video-based training. We conducted a survey with students and professionals. Students and professionals share similar perceptions toward video-based training in general and support combining gamification and video-based training. Our findings can inform the design of gamified training solutions for software engineers.

</details>


### [414] [Carbon-Aware Governance Gates: An Architecture for Sustainable GenAI Development](https://arxiv.org/abs/2602.19718)
*Mateen A. Abbasi,Tommi J. Mikkonen,Petri J. Ihantola,Muhammad Waseem,Pekka Abrahamsson,Niko K. Mäkitalo*

Main category: cs.SE

TL;DR: CAGG是一种架构扩展，通过碳预算和绿色验证编排优化GenAI开发中的碳足迹问题。


<details>
  <summary>Details</summary>
Motivation: GenAI在软件开发中的快速采用增加了计算需求，导致碳足迹上升；同时，治理机制的引入进一步加剧了能源消耗和碳足迹问题。

Method: CAGG由三个组件组成：(i) 能源与碳来源账本，(ii) 碳预算管理器，(iii) 绿色验证编排器，通过治理政策和可重用设计模式实现。

Result: CAGG通过碳预算和可持续性验证编排，有效减少了GenAI辅助开发中的能源消耗和碳足迹。

Conclusion: 本文提出了Carbon-Aware Governance Gates (CAGG)架构扩展，通过嵌入碳预算、能源来源和可持续性验证编排，优化GenAI辅助开发中的碳足迹问题。

Abstract: The rapid adoption of Generative AI (GenAI) in the software development life cycle (SDLC) increases computational demand, which can raise the carbon footprint of development activities. At the same time, organizations are increasingly embedding governance mechanisms into GenAI-assisted development to support trust, transparency, and accountability. However, these governance mechanisms introduce additional computational workloads, including repeated inference, regeneration cycles, and expanded validation pipelines, increasing energy use and the carbon footprint of GenAI-assisted development. This paper proposes Carbon-Aware Governance Gates (CAGG), an architectural extension that embeds carbon budgets, energy provenance, and sustainability-aware validation orchestration into human-AI governance layers. CAGG comprises three components: (i) an Energy and Carbon Provenance Ledger, (ii) a Carbon Budget Manager, and (iii) a Green Validation Orchestrator, operationalized through governance policies and reusable design patterns.

</details>


### [415] [MAS-FIRE: Fault Injection and Reliability Evaluation for LLM-Based Multi-Agent Systems](https://arxiv.org/abs/2602.19843)
*Jin Jia,Zhiling Deng,Zhuangbin Chen,Yingqi Wang,Zibin Zheng*

Main category: cs.SE

TL;DR: MAS-FIRE是一个系统性评估多智能体系统可靠性的框架，通过故障注入揭示系统鲁棒性，发现架构设计对故障恢复至关重要。


<details>
  <summary>Details</summary>
Motivation: 由于多智能体系统通过非结构化自然语言协调，容易产生语义故障且难以被传统评估方法捕捉，需要系统性框架来诊断和改进。

Method: 提出了MAS-FIRE框架，通过提示修改、响应重写和消息路由操纵三种非侵入机制注入15种故障类型，评估多智能体系统的可靠性。

Result: 发现基础模型的增强并不总是提升鲁棒性，架构拓扑（如迭代闭环设计）能有效中和40%以上的故障。

Conclusion: MAS-FIRE框架为多智能体系统提供了过程级别的可观测性和系统性改进的指导，揭示了基础模型和架构拓扑对系统鲁棒性的重要影响。

Abstract: As LLM-based Multi-Agent Systems (MAS) are increasingly deployed for complex tasks, ensuring their reliability has become a pressing challenge. Since MAS coordinate through unstructured natural language rather than rigid protocols, they are prone to semantic failures (e.g., hallucinations, misinterpreted instructions, and reasoning drift) that propagate silently without raising runtime exceptions. Prevailing evaluation approaches, which measure only end-to-end task success, offer limited insight into how these failures arise or how effectively agents recover from them. To bridge this gap, we propose MAS-FIRE, a systematic framework for fault injection and reliability evaluation of MAS. We define a taxonomy of 15 fault types covering intra-agent cognitive errors and inter-agent coordination failures, and inject them via three non-invasive mechanisms: prompt modification, response rewriting, and message routing manipulation. Applying MAS-FIRE to three representative MAS architectures, we uncover a rich set of fault-tolerant behaviors that we organize into four tiers: mechanism, rule, prompt, and reasoning. This tiered view enables fine-grained diagnosis of where and why systems succeed or fail. Our findings reveal that stronger foundation models do not uniformly improve robustness. We further show that architectural topology plays an equally decisive role, with iterative, closed-loop designs neutralizing over 40% of faults that cause catastrophic collapse in linear workflows. MAS-FIRE provides the process-level observability and actionable guidance needed to systematically improve multi-agent systems.

</details>
