<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 106]
- [cs.SE](#cs.SE) [Total: 14]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.AI](#cs.AI) [Total: 14]
- [cs.DC](#cs.DC) [Total: 10]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.RO](#cs.RO) [Total: 41]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Space-Time Forecasting of Dynamic Scenes with Motion-aware Gaussian Grouping](https://arxiv.org/abs/2602.21668)
*Junmyeong Lee,Hoseung Choi,Minsu Cho*

Main category: cs.CV

TL;DR: MoGaF是一种基于4D高斯泼溅的动态场景预测框架，通过运动感知分组优化，显著提升了长期预测的稳定性和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 动态场景预测是计算机视觉中的基本挑战，有限的观测难以捕捉连贯的对象级运动和长期时间演化。

Method: MoGaF基于4D高斯泼溅表示，采用运动感知的高斯分组和组优化，构建轻量级预测模块预测未来运动。

Result: 实验表明，MoGaF在渲染质量、运动合理性和长期预测稳定性上均优于现有基线。

Conclusion: MoGaF通过引入运动感知的高斯分组和组优化，实现了在合成和真实数据集上优于现有基线的渲染质量、运动合理性和长期预测稳定性。

Abstract: Forecasting dynamic scenes remains a fundamental challenge in computer vision, as limited observations make it difficult to capture coherent object-level motion and long-term temporal evolution. We present Motion Group-aware Gaussian Forecasting (MoGaF), a framework for long-term scene extrapolation built upon the 4D Gaussian Splatting representation. MoGaF introduces motion-aware Gaussian grouping and group-wise optimization to enforce physically consistent motion across both rigid and non-rigid regions, yielding spatially coherent dynamic representations. Leveraging this structured space-time representation, a lightweight forecasting module predicts future motion, enabling realistic and temporally stable scene evolution. Experiments on synthetic and real-world datasets demonstrate that MoGaF consistently outperforms existing baselines in rendering quality, motion plausibility, and long-term forecasting stability. Our project page is available at https://slime0519.github.io/mogaf

</details>


### [2] [DynamicGTR: Leveraging Graph Topology Representation Preferences to Boost VLM Capabilities on Graph QAs](https://arxiv.org/abs/2602.21864)
*Yanbin Wei,Jiangyue Yan,Chun Kang,Yang Chen,Hua Liu,James Kwok,Yu Zhang*

Main category: cs.CV

TL;DR: DynamicGTR通过动态选择最优图表示提升VLM在图问答中的性能，并展示强迁移能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一图拓扑表示（GTR），忽略了模型和任务的特定偏好，导致图相关查询的响应不准确或冗长。

Method: 提出了DynamicGTR框架，动态选择每个查询的最优GTR，以在推理过程中实现准确性和简洁性的可定制权衡。

Result: 实验表明，DynamicGTR不仅提升了VLM在图算法问答中的性能，还能将合成图算法任务的经验迁移到链接预测和节点分类等实际应用中，无需额外训练。

Conclusion: DynamicGTR框架通过动态选择最优图拓扑表示（GTR）提升了视觉语言模型（VLM）在零样本图问答任务中的性能，并展示了跨任务、领域和模型的强迁移能力。

Abstract: Vision-Language Models (VLMs) have emerged as versatile solutions for zero-shot question answering (QA) across various domains. However, enabling VLMs to effectively comprehend structured graphs and perform accurate, efficient QA remains challenging. Existing approaches typically rely on one single graph topology representation (GTR), such as fixed-style visual images or unified text descriptions. This ``one-size-fits-all'' strategy often neglects model-specific and task-specific preferences, resulting in inaccurate or over-lengthy responses to graph-related queries. To address this, we propose the $\mbox{DynamicGTR}$ framework, which dynamically selects the optimal GTR for each query during inference, thereby enhancing the zero-shot graph QA capabilities of VLMs with a customizable accuracy and brevity trade-off. Extensive experiments show that DynamicGTR not only improves VLM-based graph algorithm QA performance but also successfully transfers the experience trained from synthetic graph algorithm tasks to real-world applications like link prediction and node classification, without any additional training. Additionally, DynamicGTR demonstrates strong transferability across tasks, domains, and models, suggesting its potential as a flexible solution for broad graph scenarios.

</details>


### [3] [StoryTailor:A Zero-Shot Pipeline for Action-Rich Multi-Subject Visual Narratives](https://arxiv.org/abs/2602.21273)
*Jinghao Hu,Yuhe Zhang,GuoHua Geng,Kang Li,Han Zhang*

Main category: cs.CV

TL;DR: StoryTailor是一种零样本方法，通过三个模块（GCA、AB-SVR、SFC）解决多帧视觉叙事中的动作、身份和背景连续性矛盾，实验表明其在指标和速度上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 生成多帧、动作丰富的视觉叙事时，面临动作文本忠实度、主体身份保真度和跨帧背景连续性的三方面矛盾，需要一种无需微调的方法来解决这些挑战。

Method: StoryTailor采用三个协同模块：高斯中心注意力（GCA）动态聚焦于每个主体核心以缓解 grounding-box 重叠；动作增强奇异值重加权（AB-SVR）增强文本嵌入空间中与动作相关的方向；选择性遗忘缓存（SFC）保留可转移的背景线索，选择性遗忘非必要历史，并选择性呈现保留线索以建立跨场景语义联系。

Result: 实验显示，CLIP-T指标提升10-15%，DreamSim低于强基线，CLIP-I保持在视觉可接受的竞争范围内。在24GB GPU上，推理速度快于FluxKontext。定性评估表明，StoryTailor能够呈现富有表现力的交互和稳定演变的场景。

Conclusion: StoryTailor在零样本条件下成功解决了生成多帧、动作丰富的视觉叙事时的三个主要矛盾：动作文本忠实度、主体身份保真度和跨帧背景连续性。实验表明，该方法在多个指标上优于基线方法，且在24GB GPU上推理速度更快。

Abstract: Generating multi-frame, action-rich visual narratives without fine-tuning faces a threefold tension: action text faithfulness, subject identity fidelity, and cross-frame background continuity. We propose StoryTailor, a zero-shot pipeline that runs on a single RTX 4090 (24 GB) and produces temporally coherent, identity-preserving image sequences from a long narrative prompt, per-subject references, and grounding boxes. Three synergistic modules drive the system: Gaussian-Centered Attention (GCA) to dynamically focus on each subject core and ease grounding-box overlaps; Action-Boost Singular Value Reweighting (AB-SVR) to amplify action-related directions in the text embedding space; and Selective Forgetting Cache (SFC) that retains transferable background cues, forgets nonessential history, and selectively surfaces retained cues to build cross-scene semantic ties. Compared with baseline methods, experiments show that CLIP-T improves by up to 10-15%, with DreamSim lower than strong baselines, while CLIP-I stays in a visually acceptable, competitive range. With matched resolution and steps on a 24 GB GPU, inference is faster than FluxKontext. Qualitatively, StoryTailor delivers expressive interactions and evolving yet stable scenes.

</details>


### [4] [HorizonForge: Driving Scene Editing with Any Trajectories and Any Vehicles](https://arxiv.org/abs/2602.21333)
*Yifan Wang,Francesco Pittaluga,Zaid Tasneem,Chenyu You,Manmohan Chandraker,Ziyu Jiang*

Main category: cs.CV

TL;DR: HorizonForge是一个结合Gaussian-Mesh和视频扩散的框架，用于高保真且可控的驾驶场景生成，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以同时实现高真实感和精确控制，因此需要一种新的框架来解决这一问题。

Method: 采用Gaussian Splats和Meshes进行场景重建，并通过噪声感知视频扩散过程实现编辑渲染。

Result: 实验表明，Gaussian-Mesh表示在保真度上显著优于其他3D表示方法，且视频扩散的时间先验对一致性合成至关重要。HorizonForge在用户偏好和FID指标上均优于现有最佳方法。

Conclusion: HorizonForge通过结合Gaussian-Mesh表示和视频扩散技术，实现了高保真且可控的驾驶场景生成，显著提升了用户偏好和图像质量。

Abstract: Controllable driving scene generation is critical for realistic and scalable autonomous driving simulation, yet existing approaches struggle to jointly achieve photorealism and precise control. We introduce HorizonForge, a unified framework that reconstructs scenes as editable Gaussian Splats and Meshes, enabling fine-grained 3D manipulation and language-driven vehicle insertion. Edits are rendered through a noise-aware video diffusion process that enforces spatial and temporal consistency, producing diverse scene variations in a single feed-forward pass without per-trajectory optimization. To standardize evaluation, we further propose HorizonSuite, a comprehensive benchmark spanning ego- and agent-level editing tasks such as trajectory modifications and object manipulation. Extensive experiments show that Gaussian-Mesh representation delivers substantially higher fidelity than alternative 3D representations, and that temporal priors from video diffusion are essential for coherent synthesis. Combining these findings, HorizonForge establishes a simple yet powerful paradigm for photorealistic, controllable driving simulation, achieving an 83.4% user-preference gain and a 25.19% FID improvement over the second best state-of-the-art method. Project page: https://horizonforge.github.io/ .

</details>


### [5] [Scaling View Synthesis Transformers](https://arxiv.org/abs/2602.21341)
*Evan Kim,Hyunwoo Ryu,Thomas W. Mitchel,Vincent Sitzmann*

Main category: cs.CV

TL;DR: 研究表明编码器-解码器架构（SVSM）在视图合成中计算优化效果与仅解码器模型相当，且以更少训练计算超越之前最优方法。


<details>
  <summary>Details</summary>
Motivation: 探索几何无关视图合成变换器在计算缩放方面的规律，以优化性能与计算资源的平衡。

Method: 系统研究了视图合成变换器的缩放规律，并提出了训练计算最优NVS模型的设计原则，特别是通过编码器-解码器架构（SVSM）。

Result: SVSM在多个计算水平上表现优异，性能-计算帕累托前沿优于仅解码器模型，且在实际NVS基准测试中超越之前的最先进方法。

Conclusion: 编码器-解码器架构（如SVSM）在计算优化方面可以与仅解码器模型媲美，并在实际NVS基准测试中以更少的训练计算超越了之前的最先进方法。

Abstract: Geometry-free view synthesis transformers have recently achieved state-of-the-art performance in Novel View Synthesis (NVS), outperforming traditional approaches that rely on explicit geometry modeling. Yet the factors governing their scaling with compute remain unclear. We present a systematic study of scaling laws for view synthesis transformers and derive design principles for training compute-optimal NVS models. Contrary to prior findings, we show that encoder-decoder architectures can be compute-optimal; we trace earlier negative results to suboptimal architectural choices and comparisons across unequal training compute budgets. Across several compute levels, we demonstrate that our encoder-decoder architecture, which we call the Scalable View Synthesis Model (SVSM), scales as effectively as decoder-only models, achieves a superior performance-compute Pareto frontier, and surpasses the previous state-of-the-art on real-world NVS benchmarks with substantially reduced training compute.

</details>


### [6] [Towards Controllable Video Synthesis of Routine and Rare OR Events](https://arxiv.org/abs/2602.21365)
*Dominik Schneider,Lalithkumar Seenivasan,Sampath Rapuri,Vishalroshan Anil,Aiza Maksutova,Yiqing Shen,Jan Emily Mangulabnan,Hao Ding,Jose L. Porras,Masaru Ishii,Mathias Unberath*

Main category: cs.CV

TL;DR: 该研究提出了一种手术室视频扩散框架，用于合成罕见和安全关键事件，支持环境智能模型的开发，并在合成数据和AI模型验证中展示了优异性能。


<details>
  <summary>Details</summary>
Motivation: 构建大规模手术室工作流程数据集（包含罕见、安全关键或非典型事件）在操作和伦理上具有挑战性，这一数据瓶颈阻碍了环境智能的发展，以检测、理解和缓解手术室中的罕见或安全关键事件。

Method: 本研究提出了一个手术室视频扩散框架，集成了几何抽象模块、条件模块和微调的扩散模型，用于将手术室场景转化为抽象几何表示，控制合成过程，并生成真实的手术室事件视频。此外，还利用该框架合成了一个数据集，用于训练和验证检测无菌区域违规接近失误的AI模型。

Result: 在合成常规手术室事件时，该方法优于现成的视频扩散基线，在域内和域外数据集中均实现了较低的FVD/LPIPS和较高的SSIM/PSNR。定性结果展示了其对反事实事件的控制性视频合成能力。基于合成数据训练的AI模型在检测接近安全关键事件时的召回率达到70.13%。此外，消融研究量化了关键设计选择带来的性能提升。

Conclusion: 该解决方案能够从抽象的几何表示中控制性地合成常规和罕见的手术室事件。除了展示其生成罕见和安全关键场景的能力外，还展示了其支持环境智能模型开发的潜力。

Abstract: Purpose: Curating large-scale datasets of operating room (OR) workflow, encompassing rare, safety-critical, or atypical events, remains operationally and ethically challenging. This data bottleneck complicates the development of ambient intelligence for detecting, understanding, and mitigating rare or safety-critical events in the OR.
  Methods: This work presents an OR video diffusion framework that enables controlled synthesis of rare and safety-critical events. The framework integrates a geometric abstraction module, a conditioning module, and a fine-tuned diffusion model to first transform OR scenes into abstract geometric representations, then condition the synthesis process, and finally generate realistic OR event videos. Using this framework, we also curate a synthetic dataset to train and validate AI models for detecting near-misses of sterile-field violations.
  Results: In synthesizing routine OR events, our method outperforms off-the-shelf video diffusion baselines, achieving lower FVD/LPIPS and higher SSIM/PSNR in both in- and out-of-domain datasets. Through qualitative results, we illustrate its ability for controlled video synthesis of counterfactual events. An AI model trained and validated on the generated synthetic data achieved a RECALL of 70.13% in detecting near safety-critical events. Finally, we conduct an ablation study to quantify performance gains from key design choices.
  Conclusion: Our solution enables controlled synthesis of routine and rare OR events from abstract geometric representations. Beyond demonstrating its capability to generate rare and safety-critical scenarios, we show its potential to support the development of ambient intelligence models.

</details>


### [7] [Momentum Memory for Knowledge Distillation in Computational Pathology](https://arxiv.org/abs/2602.21395)
*Yongxin Guo,Hao Lu,Onur C. Koyun,Zhengjie Zhu,Muhammet Fatih Demir,Metin Nafi Gurcan*

Main category: cs.CV

TL;DR: MoMKD 是一种新型跨模态知识蒸馏框架，通过动量记忆库解决现有方法的不稳定性，显著提升仅用组织病理学数据的癌症诊断性能。


<details>
  <summary>Details</summary>
Motivation: 多模态学习在癌症诊断中潜力巨大，但配对的组织病理学-基因组数据稀缺限制了临床转化。现有知识蒸馏方法因批次内对齐不稳定导致性能下降。

Method: MoMKD 通过动量更新的记忆库跨批次聚合基因组和组织病理学信息，并解耦两个分支的梯度以避免基因组信号主导学习。

Result: 在 TCGA-BRCA 基准测试和独立内部数据集上，MoMKD 在仅使用组织学推断时表现优于现有 MIL 和多模态知识蒸馏基线。

Conclusion: MoMKD 提出了一种稳健且可泛化的知识蒸馏范式，为计算病理学领域提供了新的解决方案。

Abstract: Multimodal learning that integrates genomics and histopathology has shown strong potential in cancer diagnosis, yet its clinical translation is hindered by the limited availability of paired histology-genomics data. Knowledge distillation (KD) offers a practical solution by transferring genomic supervision into histopathology models, enabling accurate inference using histology alone. However, existing KD methods rely on batch-local alignment, which introduces instability due to limited within-batch comparisons and ultimately degrades performance.
  To address these limitations, we propose Momentum Memory Knowledge Distillation (MoMKD), a cross-modal distillation framework driven by a momentum-updated memory. This memory aggregates genomic and histopathology information across batches, effectively enlarging the supervisory context available to each mini-batch. Furthermore, we decouple the gradients of the genomics and histology branches, preventing genomic signals from dominating histology feature learning during training and eliminating the modality-gap issue at inference time.
  Extensive experiments on the TCGA-BRCA benchmark (HER2, PR, and ODX classification tasks) and an independent in-house testing dataset demonstrate that MoMKD consistently outperforms state-of-the-art MIL and multimodal KD baselines, delivering strong performance and generalization under histology-only inference. Overall, MoMKD establishes a robust and generalizable knowledge distillation paradigm for computational pathology.

</details>


### [8] [MMLoP: Multi-Modal Low-Rank Prompting for Efficient Vision-Language Adaptation](https://arxiv.org/abs/2602.21397)
*Sajjad Ghiasvand,Haniyeh Ehsani Oskouie,Mahnoosh Alizadeh,Ramtin Pedarsani*

Main category: cs.CV

TL;DR: MMLoP通过低秩分解实现高效多模态提示，仅需11.5K参数，性能优于多数现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态提示方法参数过多、放弃参数效率的问题，同时保持高性能。

Method: 提出MMLoP框架，通过低秩分解参数化视觉和文本提示，并引入自调节一致性损失、均匀漂移校正和共享上投影三个组件。

Result: 在11个数据集上的实验显示，MMLoP在精度和效率上优于多数现有方法，包括参数量更大的方法，基础到新颖泛化的调和平均达到79.70%。

Conclusion: MMLoP通过低秩分解和多模态提示技术，显著减少了可训练参数数量（仅11.5K），同时保持了高性能，在多个基准测试中表现优异，实现了精度与效率的平衡。

Abstract: Prompt learning has become a dominant paradigm for adapting vision-language models (VLMs) such as CLIP to downstream tasks without modifying pretrained weights. While extending prompts to both vision and text encoders across multiple transformer layers significantly boosts performance, it dramatically increases the number of trainable parameters, with state-of-the-art methods requiring millions of parameters and abandoning the parameter efficiency that makes prompt tuning attractive. In this work, we propose \textbf{MMLoP} (\textbf{M}ulti-\textbf{M}odal \textbf{Lo}w-Rank \textbf{P}rompting), a framework that achieves deep multi-modal prompting with only \textbf{11.5K trainable parameters}, comparable to early text-only methods like CoOp. MMLoP parameterizes vision and text prompts at each transformer layer through a low-rank factorization, which serves as an implicit regularizer against overfitting on few-shot training data. To further close the accuracy gap with state-of-the-art methods, we introduce three complementary components: a self-regulating consistency loss that anchors prompted representations to frozen zero-shot CLIP features at both the feature and logit levels, a uniform drift correction that removes the global embedding shift induced by prompt tuning to preserve class-discriminative structure, and a shared up-projection that couples vision and text prompts through a common low-rank factor to enforce cross-modal alignment. Extensive experiments across three benchmarks and 11 diverse datasets demonstrate that MMLoP achieves a highly favorable accuracy-efficiency tradeoff, outperforming the majority of existing methods including those with orders of magnitude more parameters, while achieving a harmonic mean of 79.70\% on base-to-novel generalization.

</details>


### [9] [FlowFixer: Towards Detail-Preserving Subject-Driven Generation](https://arxiv.org/abs/2602.21402)
*Jinyoung Jun,Won-Dong Jang,Wenbin Ouyang,Raghudeep Gadde,Jungbeom Lee*

Main category: cs.CV

TL;DR: FlowFixer 通过图像到图像转换修复SDG中的细节丢失，采用自监督训练和关键点匹配指标，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决主题驱动生成中因尺度和视角变化导致的细节丢失问题，避免语言提示的歧义性。

Method: 提出了一种一步去噪方案生成自监督训练数据，模拟真实SDG错误；引入基于关键点匹配的指标评估细节保真度。

Result: 实验结果表明，FlowFixer 在定性和定量评估中均优于现有SDG方法。

Conclusion: FlowFixer 在主题驱动生成（SDG）中通过图像到图像的转换修复了因尺度和视角变化丢失的细节，显著提升了生成质量，并设定了高保真SDG的新基准。

Abstract: We present FlowFixer, a refinement framework for subject-driven generation (SDG) that restores fine details lost during generation caused by changes in scale and perspective of a subject. FlowFixer proposes direct image-to-image translation from visual references, avoiding ambiguities in language prompts. To enable image-to-image training, we introduce a one-step denoising scheme to generate self-supervised training data, which automatically removes high-frequency details while preserving global structure, effectively simulating real-world SDG errors. We further propose a keypoint matching-based metric to properly assess fidelity in details beyond semantic similarities usually measured by CLIP or DINO. Experimental results demonstrate that FlowFixer outperforms state-of-the-art SDG methods in both qualitative and quantitative evaluations, setting a new benchmark for high-fidelity subject-driven generation.

</details>


### [10] [Exploring Vision-Language Models for Open-Vocabulary Zero-Shot Action Segmentation](https://arxiv.org/abs/2602.21406)
*Asim Unmesh,Kaki Ramesh,Mayank Patel,Rahul Jain,Karthik Ramani*

Main category: cs.CV

TL;DR: 利用视觉语言模型的零样本能力，提出无需训练的开放词汇零样本时间动作分割方法（OVTAS），在标准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法局限于封闭词汇和固定标签集的问题，探索开放词汇零样本时间动作分割（OVTAS）这一未充分研究的问题。

Method: 提出了一个无需训练的流程，包括帧-动作嵌入相似性（FAES）和相似性矩阵时间分割（SMTS），以匹配视频帧与候选动作标签并确保时间一致性。

Result: 在标准基准测试中，OVTAS取得了强劲的结果，验证了视觉语言模型在开放词汇动作分割中的适用性。

Conclusion: OVTAS通过利用视觉语言模型的零样本能力，在无需任务特定监督的情况下实现了强大的性能，展示了其在结构化时间理解中的潜力。

Abstract: Temporal Action Segmentation (TAS) requires dividing videos into action segments, yet the vast space of activities and alternative breakdowns makes collecting comprehensive datasets infeasible. Existing methods remain limited to closed vocabularies and fixed label sets. In this work, we explore the largely unexplored problem of Open-Vocabulary Zero-Shot Temporal Action Segmentation (OVTAS) by leveraging the strong zero-shot capabilities of Vision-Language Models (VLMs). We introduce a training-free pipeline that follows a segmentation-by-classification design: Frame-Action Embedding Similarity (FAES) matches video frames to candidate action labels, and Similarity-Matrix Temporal Segmentation (SMTS) enforces temporal consistency. Beyond proposing OVTAS, we present a systematic study across 14 diverse VLMs, providing the first broad analysis of their suitability for open-vocabulary action segmentation. Experiments on standard benchmarks show that OVTAS achieves strong results without task-specific supervision, underscoring the potential of VLMs for structured temporal understanding.

</details>


### [11] [WildSVG: Towards Reliable SVG Generation Under Real-Word Conditions](https://arxiv.org/abs/2602.21416)
*Marco Terral,Haotian Zhang,Tianyang Zhang,Meng Lin,Xiaoqing Xie,Haoran Dai,Darsh Kaushik,Pai Peng,Nicklas Scharpff,David Vazquez,Joan Rodriguez*

Main category: cs.CV

TL;DR: 论文提出了SVG提取任务，并引入WildSVG Benchmark评估现有模型，发现其在真实场景中表现不足，但迭代优化方法有潜力。


<details>
  <summary>Details</summary>
Motivation: 现有模型在生成SVG时对干净渲染或文本描述表现良好，但在真实场景中因噪声、杂乱和领域偏移而表现不佳，缺乏合适的基准测试。

Method: 引入了WildSVG Benchmark，包含Natural WildSVG和Synthetic WildSVG两个数据集，用于系统化评估SVG提取任务。

Result: 当前最先进的多模态模型在真实场景中的SVG提取表现远未达到可靠水平。

Conclusion: 当前的多模态模型在真实场景中的SVG提取表现不佳，但迭代优化方法显示出潜力，模型能力正在稳步提升。

Abstract: We introduce the task of SVG extraction, which consists in translating specific visual inputs from an image into scalable vector graphics. Existing multimodal models achieve strong results when generating SVGs from clean renderings or textual descriptions, but they fall short in real-world scenarios where natural images introduce noise, clutter, and domain shifts. A central challenge in this direction is the lack of suitable benchmarks. To address this need, we introduce the WildSVG Benchmark, formed by two complementary datasets: Natural WildSVG, built from real images containing company logos paired with their SVG annotations, and Synthetic WildSVG, which blends complex SVG renderings into real scenes to simulate difficult conditions. Together, these resources provide the first foundation for systematic benchmarking SVG extraction. We benchmark state-of-the-art multimodal models and find that current approaches perform well below what is needed for reliable SVG extraction in real scenarios. Nonetheless, iterative refinement methods point to a promising path forward, and model capabilities are steadily improving

</details>


### [12] [ECHOSAT: Estimating Canopy Height Over Space And Time](https://arxiv.org/abs/2602.21421)
*Jan Pauls,Karsten Schrödter,Sven Ligensa,Martin Schwartz,Berkant Turan,Max Zimmer,Sassan Saatchi,Sebastian Pokutta,Philippe Ciais,Fabian Gieseke*

Main category: cs.CV

TL;DR: ECHOSAT是一种全球时间一致的10米分辨率树高地图，通过多传感器数据和视觉变换器模型捕捉森林动态，提升碳监测准确性。


<details>
  <summary>Details</summary>
Motivation: 现有全球树高地图仅提供静态快照，无法捕捉时间森林动态，而这对准确的碳核算至关重要。

Method: 利用多传感器卫星数据训练专门的视觉变换器模型，进行像素级时间回归，并通过自监督生长损失正则化预测。

Result: 模型在单年预测中提高了最先进的准确性，并提供了首个全球范围内准确量化树木生长和干扰的高度地图。

Conclusion: ECHOSAT提供了首个全球范围内的时间一致树高地图，准确量化了树木生长和干扰，预计将推动全球碳监测和干扰评估的进展。

Abstract: Forest monitoring is critical for climate change mitigation. However, existing global tree height maps provide only static snapshots and do not capture temporal forest dynamics, which are essential for accurate carbon accounting. We introduce ECHOSAT, a global and temporally consistent tree height map at 10 m resolution spanning multiple years. To this end, we resort to multi-sensor satellite data to train a specialized vision transformer model, which performs pixel-level temporal regression. A self-supervised growth loss regularizes the predictions to follow growth curves that are in line with natural tree development, including gradual height increases over time, but also abrupt declines due to forest loss events such as fires. Our experimental evaluation shows that our model improves state-of-the-art accuracies in the context of single-year predictions. We also provide the first global-scale height map that accurately quantifies tree growth and disturbances over time. We expect ECHOSAT to advance global efforts in carbon monitoring and disturbance assessment. The maps can be accessed at https://github.com/ai4forest/echosat.

</details>


### [13] [Automating Timed Up and Go Phase Segmentation and Gait Analysis via the tugturn Markerless 3D Pipeline](https://arxiv.org/abs/2602.21425)
*Abel Gonçalves Chinaglia,Guilherme Manna Cesar,Paulo Roberto Pereira Santiago*

Main category: cs.CV

TL;DR: A Python workflow (	extit{tugturn.py}) for markerless TUG analysis, offering phase segmentation, gait-event detection, and stability metrics, with reproducible outputs for clinical/research use.


<details>
  <summary>Details</summary>
Motivation: To address the limitation of robust and reproducible markerless pipelines for Instrumented Timed Up and Go (TUG) analysis, supporting clinical and research decision-making.

Method: The pipeline combines phase segmentation, gait-event detection, spatiotemporal metrics, intersegmental coordination, and dynamic stability analysis using spatial thresholds and a relative-distance strategy.

Result: 	extit{tugturn.py} provides Vector Coding outputs and XCoM-based metrics, configured through TOML files, and produces reproducible artifacts like HTML reports, CSV tables, and visual outputs.

Conclusion: The manuscript presents 	extit{tugturn.py} as a robust and reproducible Python-based workflow for 3D markerless TUG processing, offering comprehensive analysis tools for clinical and research applications.

Abstract: Instrumented Timed Up and Go (TUG) analysis can support clinical and research decision-making, but robust and reproducible markerless pipelines are still limited. We present \textit{tugturn.py}, a Python-based workflow for 3D markerless TUG processing that combines phase segmentation, gait-event detection, spatiotemporal metrics, intersegmental coordination, and dynamic stability analysis. The pipeline uses spatial thresholds to segment each trial into stand, first gait, turning, second gait, and sit phases, and applies a relative-distance strategy to detect heel-strike and toe-off events within valid gait windows. In addition to conventional kinematics, \textit{tugturn} provides Vector Coding outputs and Extrapolated Center of Mass (XCoM)-based metrics. The software is configured through TOML files and produces reproducible artifacts, including HTML reports, CSV tables, and quality-assurance visual outputs. A complete runnable example is provided with test data and command-line instructions. This manuscript describes the implementation, outputs, and reproducibility workflow of \textit{tugturn} as a focused software contribution for markerless biomechanical TUG analysis.

</details>


### [14] [PSF-Med: Measuring and Explaining Paraphrase Sensitivity in Medical Vision Language Models](https://arxiv.org/abs/2602.21428)
*Binesh Sadanandan,Vahid Behzadan*

Main category: cs.CV

TL;DR: 医学VLMs在问题重述时答案不稳定，PSF-Med基准量化此现象，通过特征干预显著降低翻转率，需综合评估稳健性。


<details>
  <summary>Details</summary>
Motivation: 医学视觉语言模型在问题重述时答案不一致，存在部署风险，需量化并解决此问题。

Method: 引入PSF-Med基准，使用GemmaScope 2稀疏自编码器分析MedGemma 4B，通过因果修补和特征干预验证机制。

Result: 翻转率介于8%至58%，特征干预可降低31%翻转率，准确率仅下降1.3个百分点。

Conclusion: 研究表明，仅依赖翻转率不足以评估模型稳健性，需同时测试释义稳定性和图像依赖性。通过特征干预可显著降低翻转率。

Abstract: Medical Vision Language Models (VLMs) can change their answers when clinicians rephrase the same question, which raises deployment risks. We introduce Paraphrase Sensitivity Failure (PSF)-Med, a benchmark of 19,748 chest Xray questions paired with about 92,000 meaningpreserving paraphrases across MIMIC-CXR and PadChest. Across six medical VLMs, we measure yes/no flips for the same image and find flip rates from 8% to 58%. However, low flip rate does not imply visual grounding: text-only baselines show that some models stay consistent even when the image is removed, suggesting they rely on language priors. To study mechanisms in one model, we apply GemmaScope 2 Sparse Autoencoders (SAEs) to MedGemma 4B and analyze FlipBank, a curated set of 158 flip cases. We identify a sparse feature at layer 17 that correlates with prompt framing and predicts decision margin shifts. In causal patching, removing this feature's contribution recovers 45% of the yesminus-no logit margin on average and fully reverses 15% of flips. Acting on this finding, we show that clamping the identified feature at inference reduces flip rates by 31% relative with only a 1.3 percentage-point accuracy cost, while also decreasing text-prior reliance. These results suggest that flip rate alone is not enough; robustness evaluations should test both paraphrase stability and image reliance.

</details>


### [15] [Synergizing Understanding and Generation with Interleaved Analyzing-Drafting Thinking](https://arxiv.org/abs/2602.21435)
*Shengqiong Wu,Bobo Li,Xinkai Wang,Xiangtai Li,Lei Cui,Furu Wei,Shuicheng Yan,Hao Fei,Tat-seng Chua*

Main category: cs.CV

TL;DR: AD-Loop通过交替分析和草拟操作，结合两阶段训练策略，显著提升统一视觉语言模型在理解和生成任务中的协同性能。


<details>
  <summary>Details</summary>
Motivation: 现有统一视觉语言模型主要关注架构统一，而忽视了在任务解决过程中理解和生成能力的显式交互，导致两者被当作平行技能而非协同过程。

Method: 提出AD-Loop（交替分析-草拟循环），通过交替执行分析和草拟操作，结合监督学习和强化学习的两阶段训练策略，实现理解和生成的动态协同。

Result: 实验表明AD-Loop在理解和生成任务的标准基准测试中均能持续提升性能，且具有良好的架构迁移性。视觉分析进一步验证了隐式视觉思维的有效性。

Conclusion: AD-Loop被证明是一种原则性且广泛适用的策略，能够有效协同理解和生成能力，提升统一视觉语言模型在标准基准测试中的表现。

Abstract: Unified Vision-Language Models (UVLMs) aim to advance multimodal learning by supporting both understanding and generation within a single framework. However, existing approaches largely focus on architectural unification while overlooking the need for explicit interaction between the two capabilities during task solving. As a result, current models treat understanding and generation as parallel skills rather than synergistic processes. To achieve real synergy, we introduce the interleaved Analyzing-Drafting problem-solving loop (AD-Loop), a new think paradigm that dynamically alternates between analytic and drafting operations. By interleaving textual thoughts with visual thoughts, AD-Loop enables models to iteratively refine both comprehension and outputs, fostering genuine synergy. To train this mechanism, we design a two-stage strategy: supervised learning on interleaved thought data to initialize alternation, followed by reinforcement learning to promote adaptive and autonomous control. Extensive experiments demonstrate that AD-Loop consistently improves performance across standard benchmarks for both understanding and generation, with strong transferability to various UVLMs architectures. Visual analyses further validate the effectiveness of implicit visual thoughts. These results highlight AD-Loop as a principled and broadly applicable strategy for synergizing comprehension and creation. The project page is at https://sqwu.top/AD-Loop.

</details>


### [16] [Adversarial Robustness of Deep Learning-Based Thyroid Nodule Segmentation in Ultrasound](https://arxiv.org/abs/2602.21452)
*Nicholas Dietrich,David McShannon*

Main category: cs.CV

TL;DR: 研究了超声甲状腺结节分割中的对抗攻击及防御措施，发现空间域扰动可通过预处理部分缓解，频域扰动则无法缓解。


<details>
  <summary>Details</summary>
Motivation: 深度学习分割模型在临床影像工作流程中的应用日益广泛，但其对抗扰动的鲁棒性尚未完全明确，特别是在超声图像中。

Method: 开发了两种黑盒对抗攻击：结构化斑点放大攻击（SSAA）和频域超声攻击（FDUA），并评估了三种推理时防御措施：随机预处理、确定性输入去噪和随机集成推理。

Result: 基线模型在未扰动图像上的平均Dice相似系数（DSC）为0.76（SD 0.20）。SSAA导致DSC下降0.29（SD 0.20），而FDUA导致DSC下降0.11（SD 0.09）。针对SSAA，所有三种防御措施均显著改善了DSC，但对FDUA无效。

Conclusion: 超声图像分割中的空间域对抗扰动可以通过输入预处理部分缓解，而频域扰动则无法通过这些防御措施缓解，这凸显了对抗鲁棒性评估中的模态特异性挑战。

Abstract: Introduction: Deep learning-based segmentation models are increasingly integrated into clinical imaging workflows, yet their robustness to adversarial perturbations remains incompletely characterized, particularly for ultrasound images. We evaluated adversarial attacks and inference-time defenses for thyroid nodule segmentation in B-mode ultrasound. Methods: Two black-box adversarial attacks were developed: (1) Structured Speckle Amplification Attack (SSAA), which injects boundary-targeted noise, and (2) Frequency-Domain Ultrasound Attack (FDUA), which applies bandpass-filtered phase perturbations in the Fourier domain. Three inference-time mitigations were evaluated on adversarial images: randomized preprocessing with test-time augmentation, deterministic input denoising, and stochastic ensemble inference with consistency-aware aggregation. Experiments were conducted on a U-Net segmentation model trained on cine-clips from a database of 192 thyroid nodules. Results: The baseline model achieved a mean Dice similarity coefficient (DSC) of 0.76 (SD 0.20) on unperturbed images. SSAA reduced DSC by 0.29 (SD 0.20) while maintaining high visual similarity (SSIM = 0.94). FDUA resulted in a smaller DSC reduction of 0.11 (SD 0.09) with lower visual fidelity (SSIM = 0.82). Against SSAA, all three defenses significantly improved DSC after correction, with deterministic denoising showing the largest recovery (+0.10, p < 0.001), followed by randomized preprocessing (+0.09, p < 0.001), and stochastic ensemble inference (+0.08, p = 0.002). No defense achieved statistically significant improvement against FDUA. Conclusion: Spatial-domain adversarial perturbations in ultrasound segmentation showed partial mitigation with input preprocessing, whereas frequency-domain perturbations were not mitigated by the defenses, highlighting modality-specific challenges in adversarial robustness evaluation.

</details>


### [17] [Automatic Map Density Selection for Locally-Performant Visual Place Recognition](https://arxiv.org/abs/2602.21473)
*Somayeh Hussaini,Tobias Fischer,Michael Milford*

Main category: cs.CV

TL;DR: 提出动态VPR映射方法，自动选择地图密度以满足用户性能要求，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有VPR系统在长期部署中难以满足用户指定性能要求的问题，特别是在不同环境部分的表现。

Method: 使用目标环境中的参考遍历对来自动选择地图密度，以满足目标Local Recall@1水平和Recall Achievement Rate（RAR）要求。

Result: 实验表明，该系统在多个VPR方法和基准测试中均能一致达到或超过指定的本地召回水平，且避免了不必要的过度密集化。

Conclusion: 本文提出了一种动态VPR映射方法，能够自动选择合适的地图密度以满足用户定义的性能要求，并通过实验验证了其有效性。

Abstract: A key challenge in translating Visual Place Recognition (VPR) from the lab to long-term deployment is ensuring a priori that a system can meet user-specified performance requirements across different parts of an environment, rather than just on average globally. A critical mechanism for controlling local VPR performance is the density of the reference mapping database, yet this factor is largely neglected in existing work, where benchmark datasets with fixed, engineering-driven (sensors, storage, GPS frequency) sampling densities are typically used. In this paper, we propose a dynamic VPR mapping approach that uses pairs of reference traverses from the target environment to automatically select an appropriate map density to satisfy two user-defined requirements: (1) a target Local Recall@1 level, and (2) the proportion of the operational environment over which this requirement must be met or exceeded, which we term the Recall Achievement Rate (RAR). Our approach is based on the hypothesis that match patterns between multiple reference traverses, evaluated across different map densities, can be modelled to predict the density required to meet these performance targets on unseen deployment data. Through extensive experiments across multiple VPR methods and the Nordland and Oxford RobotCar benchmarks, we show that our system consistently achieves or exceeds the specified local recall level over at least the user-specified proportion of the environment. Comparisons with alternative baselines demonstrate that our approach reliably selects the correct operating point in map density, avoiding unnecessary over-densification. Finally, ablation studies and analysis evaluate sensitivity to reference map choice and local space definitions, and reveal that conventional global Recall@1 is a poor predictor of the often more operationally meaningful RAR metric.

</details>


### [18] [Unified Unsupervised and Sparsely-Supervised 3D Object Detection by Semantic Pseudo-Labeling and Prototype Learning](https://arxiv.org/abs/2602.21484)
*Yushen He*

Main category: cs.CV

TL;DR: SPL是一种统一的无监督和稀疏监督3D物体检测框架，通过语义伪标签和原型学习减少标注依赖，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 减少对大规模手动标注数据的依赖，解决无监督和稀疏监督3D物体检测中的伪标签质量低、特征挖掘不稳定以及缺乏统一训练框架的问题。

Method: SPL通过整合图像语义、点云几何和时间线索生成高质量的伪标签，并结合多阶段原型学习策略稳定特征表示学习。

Result: 在KITTI和nuScenes数据集上的大量实验表明，SPL在两种设置下均显著优于现有最先进方法。

Conclusion: SPL提供了一个鲁棒且通用的解决方案，能够在极少或无需人工标注的情况下学习3D物体检测器。

Abstract: 3D object detection is essential for autonomous driving and robotic perception, yet its reliance on large-scale manually annotated data limits scalability and adaptability. To reduce annotation dependency, unsupervised and sparsely-supervised paradigms have emerged. However, they face intertwined challenges: low-quality pseudo-labels, unstable feature mining, and a lack of a unified training framework. This paper proposes SPL, a unified training framework for both Unsupervised and Sparsely-Supervised 3D Object Detection via Semantic Pseudo-labeling and prototype Learning. SPL first generates high-quality pseudo-labels by integrating image semantics, point cloud geometry, and temporal cues, producing both 3D bounding boxes for dense objects and 3D point labels for sparse ones. These pseudo-labels are not used directly but as probabilistic priors within a novel, multi-stage prototype learning strategy. This strategy stabilizes feature representation learning through memory-based initialization and momentum-based prototype updating, effectively mining features from both labeled and unlabeled data. Extensive experiments on KITTI and nuScenes datasets demonstrate that SPL significantly outperforms state-of-the-art methods in both settings. Our work provides a robust and generalizable solution for learning 3D object detectors with minimal or no manual annotations.

</details>


### [19] [See It, Say It, Sorted: An Iterative Training-Free Framework for Visually-Grounded Multimodal Reasoning in LVLMs](https://arxiv.org/abs/2602.21497)
*Yongchang Zhang,Xianzheng Ma,Tianyi Liu,Guangquan Zhou,Yang Chen*

Main category: cs.CV

TL;DR: 提出无需训练的即插即用框架，通过视觉证据监督推理步骤，显著减少幻觉并提升准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过强化学习训练模型，成本高且难以泛化，需要一种更通用、轻量的解决方案。

Method: 构建文本视觉证据池，通过视觉决策模块动态提取相关证据，确保每一步推理都有视觉依据。

Result: 在多个LVLM主干和基准测试中，方法显著提升了性能（TreeBench提升16.5%-29.5%，RH-Bench提升13.7% RH-AUC），减少了幻觉率。

Conclusion: 本文提出了一种轻量级、无需训练的即插即用框架，通过视觉证据监督每一步推理，显著减少了多模态推理中的视觉幻觉传播，提高了推理准确性。

Abstract: Recent large vision-language models (LVLMs) have demonstrated impressive reasoning ability by generating long chain-of-thought (CoT) responses. However, CoT reasoning in multimodal contexts is highly vulnerable to visual hallucination propagation: once an intermediate reasoning step becomes inconsistent with the visual evidence, subsequent steps-even if logically valid-can still lead to incorrect final answers. Existing solutions attempt to mitigate this issue by training models to "think with images" via reinforcement learning (RL). While effective, these methods are costly, model-specific, and difficult to generalize across architectures. Differently, we present a lightweight method that bypasses RL training and provides an iterative, training-free, plug-and-play framework for visually-grounded multimodal reasoning. Our key idea is to supervise each reasoning step at test time with visual evidence, ensuring that every decoded token is justified by corresponding visual cues. Concretely, we construct a textual visual-evidence pool that guides the model's reasoning generation. When existing evidence is insufficient, a visual decider module dynamically extracts additional relevant evidence from the image based on the ongoing reasoning context, expanding the pool until the model achieves sufficient visual certainty to terminate reasoning and produce the final answer. Extensive experiments on multiple LVLM backbones and benchmarks demonstrate the effectiveness of our approach. Our method achieves 16.5%-29.5% improvements on TreeBench and 13.7% RH-AUC gains on RH-Bench, substantially reducing hallucination rates while improving reasoning accuracy without additional training.

</details>


### [20] [Easy3E: Feed-Forward 3D Asset Editing via Rectified Voxel Flow](https://arxiv.org/abs/2602.21499)
*Shimin Hu,Yuanyi Wei,Fei Zha,Yudong Guo,Juyong Zhang*

Main category: cs.CV

TL;DR: A feedforward 3D editing framework using TRELLIS, Voxel FlowEdit, and normal-guided generation for efficient, consistent, and high-fidelity edits.


<details>
  <summary>Details</summary>
Motivation: Existing 3D editing methods are computationally intensive and suffer from multi-view inconsistency, prompting the need for a more efficient and consistent solution.

Method: We propose a fully feedforward 3D editing framework based on the TRELLIS generative backbone, introducing Voxel FlowEdit for geometric consistency and a normal-guided single to multi-view generation module for high-fidelity details.

Result: Experiments show that our framework achieves fast, globally consistent, and high-fidelity 3D editing.

Conclusion: Our method enables fast, globally consistent, and high-fidelity 3D model editing, addressing the limitations of existing methods.

Abstract: Existing 3D editing methods rely on computationally intensive scene-by-scene iterative optimization and suffer from multi-view inconsistency. We propose an effective and fully feedforward 3D editing framework based on the TRELLIS generative backbone, capable of modifying 3D models from a single editing view. Our framework addresses two key issues: adapting training-free 2D editing to structured 3D representations, and overcoming the bottleneck of appearance fidelity in compressed 3D features. To ensure geometric consistency, we introduce Voxel FlowEdit, an edit-driven flow in the sparse voxel latent space that achieves globally consistent 3D deformation in a single pass. To restore high-fidelity details, we develop a normal-guided single to multi-view generation module as an external appearance prior, successfully recovering high-frequency textures. Experiments demonstrate that our method enables fast, globally consistent, and high-fidelity 3D model editing.

</details>


### [21] [AHAN: Asymmetric Hierarchical Attention Network for Identical Twin Face Verification](https://arxiv.org/abs/2602.21503)
*Hoang-Nhat Nguyen*

Main category: cs.CV

TL;DR: AHAN通过多粒度分析和不对称注意力机制，显著提升同卵双胞胎面部验证准确率至92.3%。


<details>
  <summary>Details</summary>
Motivation: 同卵双胞胎面部验证是极端细粒度的识别挑战，现有方法在区分同卵双胞胎时准确率显著下降，暴露了生物识别安全系统的关键漏洞。

Method: 提出了Asymmetric Hierarchical Attention Network (AHAN)，包含Hierarchical Cross-Attention (HCA)模块和Facial Asymmetry Attention Module (FAAM)，以及Twin-Aware Pair-Wise Cross-Attention (TA-PWCA)训练策略。

Result: 在ND_TWIN数据集上，AHAN实现了92.3%的同卵双胞胎验证准确率，比现有最佳方法提高了3.4%。

Conclusion: AHAN通过多粒度面部分析和不对称注意力机制，显著提高了同卵双胞胎面部验证的准确性，为生物识别安全系统提供了更可靠的解决方案。

Abstract: Identical twin face verification represents an extreme fine-grained recognition challenge where even state-of-the-art systems fail due to overwhelming genetic similarity. Current face recognition methods achieve over 99.8% accuracy on standard benchmarks but drop dramatically to 88.9% when distinguishing identical twins, exposing critical vulnerabilities in biometric security systems. The difficulty lies in learning features that capture subtle, non-genetic variations that uniquely identify individuals. We propose the Asymmetric Hierarchical Attention Network (AHAN), a novel architecture specifically designed for this challenge through multi-granularity facial analysis. AHAN introduces a Hierarchical Cross-Attention (HCA) module that performs multi-scale analysis on semantic facial regions, enabling specialized processing at optimal resolutions. We further propose a Facial Asymmetry Attention Module (FAAM) that learns unique biometric signatures by computing cross-attention between left and right facial halves, capturing subtle asymmetric patterns that differ even between twins. To ensure the network learns truly individuating features, we introduce Twin-Aware Pair-Wise Cross-Attention (TA-PWCA), a training-only regularization strategy that uses each subject's own twin as the hardest possible distractor. Extensive experiments on the ND_TWIN dataset demonstrate that AHAN achieves 92.3% twin verification accuracy, representing a 3.4% improvement over state-of-the-art methods.

</details>


### [22] [Which Tool Response Should I Trust? Tool-Expertise-Aware Chest X-ray Agent with Multimodal Agentic Learning](https://arxiv.org/abs/2602.21517)
*Zheang Huai,Honglong Yang,Xiaomeng Li*

Main category: cs.CV

TL;DR: 提出TEA-CXA框架，通过多模态工具调用和强化学习解决医疗AI工具冲突问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 医疗领域的AI工具通常存在错误和矛盾输出，现有研究缺乏对工具实际可靠性的充分理解，无法有效解决工具冲突。

Method: 引入了一个框架，使代理能够通过与工具交互，经验性地学习其实际可信度，具体实例化为TEA-CXA，支持多模态输入和多工具并行调用。

Result: 实验表明，TEA-CXA在胸部X光分析任务中优于现有方法和基线模型。

Conclusion: 本文提出的TEA-CXA框架通过多模态工具调用和强化学习，有效解决了医疗领域中AI工具冲突的问题，并在实验中表现优于现有方法。

Abstract: AI agents with tool-use capabilities show promise for integrating the domain expertise of various tools. In the medical field, however, tools are usually AI models that are inherently error-prone and can produce contradictory responses. Existing research on medical agents lacks sufficient understanding of the tools' realistic reliability and thus cannot effectively resolve tool conflicts. To address this gap, this paper introduces a framework that enables an agent to interact with tools and empirically learn their practical trustworthiness across different types of multimodal queries via agentic learning. As a concrete instantiation, we focus on chest X-ray analysis and present a tool-expertise-aware chest X-ray agent (TEA-CXA). When tool outputs disagree, the agent experimentally accepts or rejects multimodal tool results, receives rewards, and learns which tool to trust for each query type. Importantly, TEA-CXA extends existing codebases for reinforcement learning with multi-turn tool-calling that focus on textual inputs, to support multimodal contexts effectively. In addition, we enhance the codebase for medical use scenarios by supporting multiple tool calls in one turn, parallel tool inference, and multi-image accommodation within a single user query. Our code framework is applicable to general medical research on multi-turn tool-calling reinforcement learning in multimodal settings. Experiments show that TEA-CXA outperforms the state-of-the-art methods and a comprehensive set of baselines. Code will be released.

</details>


### [23] [Pseudo-View Enhancement via Confidence Fusion for Unposed Sparse-View Reconstruction](https://arxiv.org/abs/2602.21535)
*Beizhen Zhao,Sicheng Yu,Guanzhi Ding,Yu Hu,Hao Wang*

Main category: cs.CV

TL;DR: 提出一种稀疏视角户外重建框架，通过双向伪帧恢复和场景感知高斯管理，显著提升重建质量和几何一致性。


<details>
  <summary>Details</summary>
Motivation: 解决户外场景在稀疏视角下重建的挑战，如复杂光照和尺度变化，避免直接使用扩散模型引入不合理几何结构的问题。

Method: 采用双向伪帧恢复方法，结合轻量级伪视图去模糊模型和置信掩码推理算法，以及基于联合深度-密度信息的场景感知高斯管理策略。

Result: 在户外基准测试中，该方法在保真度和稳定性上显著优于现有方法。

Conclusion: 提出的双向伪帧恢复和场景感知高斯管理策略显著提升了稀疏视角下户外场景重建的完整性和几何一致性，实验证明了其在保真度和稳定性上的显著优势。

Abstract: 3D scene reconstruction under unposed sparse viewpoints is a highly challenging yet practically important problem, especially in outdoor scenes due to complex lighting and scale variation. With extremely limited input views, directly utilizing diffusion model to synthesize pseudo frames will introduce unreasonable geometry, which will harm the final reconstruction quality. To address these issues, we propose a novel framework for sparse-view outdoor reconstruction that achieves high-quality results through bidirectional pseudo frame restoration and scene perception Gaussian management. Specifically, we introduce a bidirectional pseudo frame restoration method that restores missing content by diffusion-based synthesis guided by adjacent frames with a lightweight pseudo-view deblur model and confidence mask inference algorithm. Then we propose a scene perception Gaussian management strategy that optimize Gaussians based on joint depth-density information. These designs significantly enhance reconstruction completeness, suppress floating artifacts and improve overall geometric consistency under extreme view sparsity. Experiments on outdoor benchmarks demonstrate substantial gains over existing methods in both fidelity and stability.

</details>


### [24] [Virtual Biopsy for Intracranial Tumors Diagnosis on MRI](https://arxiv.org/abs/2602.21613)
*Xinzhe Luo,Shuai Shao,Yan Wang,Jiangtao Wang,Yutong Bai,Jianguo Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种基于MRI的虚拟活检框架，用于非侵入性预测颅内深部肿瘤病理，准确率超90%，解决了数据稀缺和背景噪声问题。


<details>
  <summary>Details</summary>
Motivation: 颅内深部肿瘤位于重要功能区，传统活检存在出血和神经功能缺损风险，且因肿瘤空间异质性易产生采样偏差。因此，开发非侵入性MRI病理预测技术对全面评估肿瘤和临床决策至关重要。

Method: 研究构建了ICT-MRI数据集，并提出了包含MRI处理器、肿瘤定位器和自适应诊断器的虚拟活检框架。其中，肿瘤定位器采用视觉语言模型进行弱监督下的粗到精定位，自适应诊断器则通过掩蔽通道注意力机制融合局部判别特征与全局上下文。

Result: 实验结果显示，所提框架准确率超过90%，比基线方法高出20%以上。

Conclusion: 该研究提出的虚拟活检框架在非侵入性MRI病理预测中表现出色，准确率超过90%，显著优于现有基线方法。

Abstract: Deep intracranial tumors situated in eloquent brain regions controlling vital functions present critical diagnostic challenges. Clinical practice has shifted toward stereotactic biopsy for pathological confirmation before treatment. Yet biopsy carries inherent risks of hemorrhage and neurological deficits and struggles with sampling bias due to tumor spatial heterogeneity, because pathological changes are typically region-selective rather than tumor-wide. Therefore, advancing non-invasive MRI-based pathology prediction is essential for holistic tumor assessment and modern clinical decision-making.
  The primary challenge lies in data scarcity: low tumor incidence requires long collection cycles, and annotation demands biopsy-verified pathology from neurosurgical experts. Additionally, tiny lesion volumes lacking segmentation masks cause critical features to be overwhelmed by background noise. To address these challenges, we construct the ICT-MRI dataset - the first public biopsy-verified benchmark with 249 cases across four categories. We propose a Virtual Biopsy framework comprising: MRI-Processor for standardization; Tumor-Localizer employing vision-language models for coarse-to-fine localization via weak supervision; and Adaptive-Diagnoser with a Masked Channel Attention mechanism fusing local discriminative features with global contexts. Experiments demonstrate over 90% accuracy, outperforming baselines by more than 20%.

</details>


### [25] [IHF-Harmony: Multi-Modality Magnetic Resonance Images Harmonization using Invertible Hierarchy Flow Model](https://arxiv.org/abs/2602.21536)
*Pengli Zhu,Yitao Zhu,Haowen Pang,Anqi Qiu*

Main category: cs.CV

TL;DR: IHF-Harmony是一种新型MRI多模态协调框架，通过可逆层次流和伪影感知归一化实现高保真协调，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有MRI协调方法在多模态扩展性和依赖配对数据方面的局限性。

Method: 采用可逆层次流（IHF）进行分层减法耦合逐步去除伪影相关特征，并结合伪影感知归一化（AAN）进行特征调制。

Result: 实验表明IHF-Harmony在解剖保真度和下游任务性能上优于现有方法。

Conclusion: IHF-Harmony通过可逆层次流框架实现了多模态MRI的高保真协调，优于现有方法，适用于大规模多站点成像研究。

Abstract: Retrospective MRI harmonization is limited by poor scalability across modalities and reliance on traveling subject datasets. To address these challenges, we introduce IHF-Harmony, a unified invertible hierarchy flow framework for multi-modality harmonization using unpaired data. By decomposing the translation process into reversible feature transformations, IHF-Harmony guarantees bijective mapping and lossless reconstruction to prevent anatomical distortion. Specifically, an invertible hierarchy flow (IHF) performs hierarchical subtractive coupling to progressively remove artefact-related features, while an artefact-aware normalization (AAN) employs anatomy-fixed feature modulation to accurately transfer target characteristics. Combined with anatomy and artefact consistency loss objectives, IHF-Harmony achieves high-fidelity harmonization that retains source anatomy. Experiments across multiple MRI modalities demonstrate that IHF-Harmony outperforms existing methods in both anatomical fidelity and downstream task performance, facilitating robust harmonization for large-scale multi-site imaging studies. Code will be released upon acceptance.

</details>


### [26] [VasGuideNet: Vascular Topology-Guided Couinaud Liver Segmentation with Structural Contrastive Loss](https://arxiv.org/abs/2602.21539)
*Chaojie Shen,Jingjun Gu,Zihao Zhao,Ruocheng Li,Cunyuan Yang,Jiajun Bu,Lei Wu*

Main category: cs.CV

TL;DR: VasGuideNet是首个显式利用血管拓扑指导的Couinaud肝脏分割框架，通过GCNs编码拓扑特征和结构对比损失，显著提升分割精度和解剖一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖图像强度和空间位置线索，未显式建模血管拓扑，导致血管附近边界模糊且泛化能力有限。

Method: 提出VasGuideNet框架，结合骨架化血管、欧几里得距离变换（EDT）几何特征和k近邻（kNN）连接性，通过图卷积网络（GCNs）编码拓扑特征，并通过交叉注意力融合模块注入3D编码器-解码器主干网络。引入结构对比损失（SCL）和全局记忆库以增强类间分离性和解剖一致性。

Result: 在Task08_HepaticVessel和LASSD数据集上，VasGuideNet分别达到83.68%和76.65%的Dice分数，RVD为1.68和7.08，显著优于UNETR、Swin UNETR和G-UNETR++等基线方法。

Conclusion: VasGuideNet通过显式建模血管拓扑结构，显著提升了Couinaud肝脏分割的准确性和解剖一致性，优于现有基线方法。

Abstract: Accurate Couinaud liver segmentation is critical for preoperative surgical planning and tumor localization.However, existing methods primarily rely on image intensity and spatial location cues, without explicitly modeling vascular topology. As a result, they often produce indistinct boundaries near vessels and show limited generalization under anatomical variability.We propose VasGuideNet, the first Couinaud segmentation framework explicitly guided by vascular topology. Specifically, skeletonized vessels, Euclidean distance transform (EDT)--derived geometry, and k-nearest neighbor (kNN) connectivity are encoded into topology features using Graph Convolutional Networks (GCNs). These features are then injected into a 3D encoder--decoder backbone via a cross-attention fusion module. To further improve inter-class separability and anatomical consistency, we introduce a Structural Contrastive Loss (SCL) with a global memory bank.On Task08_HepaticVessel and our private LASSD dataset, VasGuideNet achieves Dice scores of 83.68% and 76.65% with RVDs of 1.68 and 7.08, respectively. It consistently outperforms representative baselines including UNETR, Swin UNETR, and G-UNETR++, delivering higher Dice/mIoU and lower RVD across datasets, demonstrating its effectiveness for anatomically consistent segmentation. Code is available at https://github.com/Qacket/VasGuideNet.git.

</details>


### [27] [CCCaption: Dual-Reward Reinforcement Learning for Complete and Correct Image Captioning](https://arxiv.org/abs/2602.21655)
*Zhijiang Tang,Linhua Wang,Jiaxin Qi,Weihao Jiang,Peng Hou,Anxiang Zeng,Jianqiang Huang*

Main category: cs.CV

TL;DR: CCCaption是一个双奖励强化学习框架，通过优化描述的完整性和正确性来生成更高质量的图像描述，超越了传统依赖人类标注的方法。


<details>
  <summary>Details</summary>
Motivation: 由于人类标注的主观性和局限性，现有的图像描述模型受限于不完整或不正确的标注，因此需要一种客观评估描述质量的方法。

Method: 使用多样化的LVLMs将图像解构为一组视觉查询，并通过动态查询采样策略提高训练效率；同时通过验证子描述查询的真实性来惩罚幻觉描述。

Result: 在标准图像描述基准测试中，CCCaption框架表现出持续的改进。

Conclusion: CCCaption框架通过双奖励强化学习优化了图像描述的完整性和正确性，提供了一种超越人类标注模仿的模型训练路径。

Abstract: Image captioning remains a fundamental task for vision language understanding, yet ground-truth supervision still relies predominantly on human-annotated references. Because human annotations reflect subjective preferences and expertise, ground-truth captions are often incomplete or even incorrect, which in turn limits caption models. We argue that caption quality should be assessed by two objective aspects: completeness (does the caption cover all salient visual facts?) and correctness (are the descriptions true with respect to the image?). To this end, we introduce CCCaption: a dual-reward reinforcement learning framework with a dedicated fine-tuning corpus that explicitly optimizes these properties to generate \textbf{C}omplete and \textbf{C}orrect \textbf{Captions}. For completeness, we use diverse LVLMs to disentangle the image into a set of visual queries, and reward captions that answer more of these queries, with a dynamic query sampling strategy to improve training efficiency. For correctness, we penalize captions that contain hallucinations by validating the authenticity of sub-caption queries, which are derived from the caption decomposition. Our symmetric dual-reward optimization jointly maximizes completeness and correctness, guiding models toward captions that better satisfy these objective criteria. Extensive experiments across standard captioning benchmarks show consistent improvements, offering a principled path to training caption models beyond human-annotation imitation.

</details>


### [28] [Generalizing Visual Geometry Priors to Sparse Gaussian Occupancy Prediction](https://arxiv.org/abs/2602.21552)
*Changqing Zhou,Yueru Luo,Changhao Chen*

Main category: cs.CV

TL;DR: GPOcc利用通用视觉几何先验提升3D占用预测性能，单目和流式设置下mIoU显著提升，运行更快。


<details>
  <summary>Details</summary>
Motivation: 现有方法对3D线索利用有限，且视觉几何模型（如VGGT）仅处理可见表面而非体积内部，因此探索如何更有效利用这些几何先验进行3D占用预测。

Method: GPOcc通过沿相机射线向内扩展表面点生成体积样本，并以高斯基元表示进行概率占用推断，同时设计了免训练增量更新策略以融合逐帧高斯到全局表示。

Result: 在Occ-ScanNet和EmbodiedOcc-ScanNet上的实验显示，GPOcc在单目和流式设置中分别提升mIoU达+9.99和+11.79，且在相同深度先验下运行速度提升2.65倍。

Conclusion: GPOcc框架通过有效利用通用视觉几何先验（GPs）在单目和流式场景中显著提升了3D占用预测性能，证明了其在几何先验利用上的高效性和有效性。

Abstract: Accurate 3D scene understanding is essential for embodied intelligence, with occupancy prediction emerging as a key task for reasoning about both objects and free space. Existing approaches largely rely on depth priors (e.g., DepthAnything) but make only limited use of 3D cues, restricting performance and generalization. Recently, visual geometry models such as VGGT have shown strong capability in providing rich 3D priors, but similar to monocular depth foundation models, they still operate at the level of visible surfaces rather than volumetric interiors, motivating us to explore how to more effectively leverage these increasingly powerful geometry priors for 3D occupancy prediction. We present GPOcc, a framework that leverages generalizable visual geometry priors (GPs) for monocular occupancy prediction. Our method extends surface points inward along camera rays to generate volumetric samples, which are represented as Gaussian primitives for probabilistic occupancy inference. To handle streaming input, we further design a training-free incremental update strategy that fuses per-frame Gaussians into a unified global representation. Experiments on Occ-ScanNet and EmbodiedOcc-ScanNet demonstrate significant gains: GPOcc improves mIoU by +9.99 in the monocular setting and +11.79 in the streaming setting over prior state of the art. Under the same depth prior, it achieves +6.73 mIoU while running 2.65$\times$ faster. These results highlight that GPOcc leverages geometry priors more effectively and efficiently. Code will be released at https://github.com/JuIvyy/GPOcc.

</details>


### [29] [Following the Diagnostic Trace: Visual Cognition-guided Cooperative Network for Chest X-Ray Diagnosis](https://arxiv.org/abs/2602.21657)
*Shaoxuan Wu,Jingkun Chen,Chong Ma,Cong Shen,Xiao Zhang,Jun Feng*

Main category: cs.CV

TL;DR: VCC-Net通过视觉认知引导的协作网络，整合放射科医生与AI模型的决策，提升胸部X光诊断的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有CAD系统缺乏临床工作流的无缝集成和可靠决策支持，且放射科医生的决策模式与模型表示之间存在语义鸿沟，限制了临床采用。

Method: VCC-Net利用视觉认知（VC）作为空间认知引导，通过眼动追踪或鼠标捕捉放射科医生的视觉搜索轨迹和注意力模式，并构建疾病感知图以整合VC与模型推理。

Result: 在SIIM-ACR、EGD-CXR和TB-Mouse数据集上分别达到88.40%、85.05%和92.41%的分类准确率，注意力图与放射科医生的视线分布高度一致。

Conclusion: VCC-Net通过视觉认知引导的协作网络，成功实现了放射科医生与AI模型的互补决策，提高了诊断的透明度和准确性。

Abstract: Computer-aided diagnosis (CAD) has significantly advanced automated chest X-ray diagnosis but remains isolated from clinical workflows and lacks reliable decision support and interpretability. Human-AI collaboration seeks to enhance the reliability of diagnostic models by integrating the behaviors of controllable radiologists. However, the absence of interactive tools seamlessly embedded within diagnostic routines impedes collaboration, while the semantic gap between radiologists' decision-making patterns and model representations further limits clinical adoption. To overcome these limitations, we propose a visual cognition-guided collaborative network (VCC-Net) to achieve the cooperative diagnostic paradigm. VCC-Net centers on visual cognition (VC) and employs clinically compatible interfaces, such as eye-tracking or the mouse, to capture radiologists' visual search traces and attention patterns during diagnosis. VCC-Net employs VC as a spatial cognition guide, learning hierarchical visual search strategies to localize diagnostically key regions. A cognition-graph co-editing module subsequently integrates radiologist VC with model inference to construct a disease-aware graph. The module captures dependencies among anatomical regions and aligns model representations with VC-driven features, mitigating radiologist bias and facilitating complementary, transparent decision-making. Experiments on the public datasets SIIM-ACR, EGD-CXR, and self-constructed TB-Mouse dataset achieved classification accuracies of 88.40%, 85.05%, and 92.41%, respectively. The attention maps produced by VCC-Net exhibit strong concordance with radiologists' gaze distributions, demonstrating a mutual reinforcement of radiologist and model inference. The code is available at https://github.com/IPMI-NWU/VCC-Net.

</details>


### [30] [MultiAnimate: Pose-Guided Image Animation Made Extensible](https://arxiv.org/abs/2602.21581)
*Yingcheng Hu,Haowen Gong,Chuanguang Yang,Zhulin An,Yongjun Xu,Songhua Liu*

Main category: cs.CV

TL;DR: 提出基于DiTs的多角色动画框架，解决身份混淆和遮挡问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的方法在多角色动画中存在身份混淆和不合理遮挡问题，需扩展至多角色场景。

Method: 提出了一个基于扩散变换器（DiTs）的框架，包含标识符分配器（Identifier Assigner）和标识符适配器（Identifier Adapter），用于捕捉角色位置信息和空间关系，结合掩码驱动方案和可扩展训练策略。

Result: 实验表明，该方法在多角色图像动画中达到最先进性能，且能泛化至训练未见的多角色场景，同时兼容单角色情况。

Conclusion: 该论文提出的基于扩散变换器（DiTs）的多角色图像动画框架，通过引入标识符分配器和适配器，有效解决了多角色场景中的身份混淆和遮挡问题，并在实验中展现了卓越的性能。

Abstract: Pose-guided human image animation aims to synthesize realistic videos of a reference character driven by a sequence of poses. While diffusion-based methods have achieved remarkable success, most existing approaches are limited to single-character animation. We observe that naively extending these methods to multi-character scenarios often leads to identity confusion and implausible occlusions between characters. To address these challenges, in this paper, we propose an extensible multi-character image animation framework built upon modern Diffusion Transformers (DiTs) for video generation. At its core, our framework introduces two novel components-Identifier Assigner and Identifier Adapter - which collaboratively capture per-person positional cues and inter-person spatial relationships. This mask-driven scheme, along with a scalable training strategy, not only enhances flexibility but also enables generalization to scenarios with more characters than those seen during training. Remarkably, trained on only a two-character dataset, our model generalizes to multi-character animation while maintaining compatibility with single-character cases. Extensive experiments demonstrate that our approach achieves state-of-the-art performance in multi-character image animation, surpassing existing diffusion-based baselines.

</details>


### [31] [SEF-MAP: Subspace-Decomposed Expert Fusion for Robust Multimodal HD Map Prediction](https://arxiv.org/abs/2602.21589)
*Haoxiang Fu,Lingfeng Zhang,Hao Li,Ruibing Hu,Zhengrong Li,Guanjing Liu,Zimu Tan,Long Chen,Hangjun Ye,Xiaoshuai Hao*

Main category: cs.CV

TL;DR: SEFMAP是一种多模态高清地图预测框架，通过解耦BEV特征和专家分配，结合不确定性感知门控和分布感知掩码技术，显著提升了在退化条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 多模态融合中相机和LiDAR模态之间的不一致性导致在低光照、遮挡或稀疏点云条件下性能下降，因此需要一种能够保留模态特定线索并捕捉跨模态共识的鲁棒框架。

Method: SEFMAP通过将BEV特征显式解耦为四个语义子空间（LiDAR私有、图像私有、共享和交互），并为每个子空间分配专用专家，同时引入不确定性感知门控机制和分布感知掩码技术，以增强模型在退化条件下的鲁棒性。

Result: 在nuScenes和Argoverse2基准测试中，SEFMAP实现了最先进的性能，mAP分别提升了4.2%和4.8%。

Conclusion: SEFMAP提出了一种鲁棒且有效的多模态高清地图预测解决方案，在多样化和退化条件下表现优异，实验证明其在nuScenes和Argoverse2基准测试中分别超越了先前方法+4.2%和+4.8%的mAP。

Abstract: High-definition (HD) maps are essential for autonomous driving, yet multi-modal fusion often suffers from inconsistency between camera and LiDAR modalities, leading to performance degradation under low-light conditions, occlusions, or sparse point clouds. To address this, we propose SEFMAP, a Subspace-Expert Fusion framework for robust multimodal HD map prediction. The key idea is to explicitly disentangle BEV features into four semantic subspaces: LiDAR-private, Image-private, Shared, and Interaction. Each subspace is assigned a dedicated expert, thereby preserving modality-specific cues while capturing cross-modal consensus. To adaptively combine expert outputs, we introduce an uncertainty-aware gating mechanism at the BEV-cell level, where unreliable experts are down-weighted based on predictive variance, complemented by a usage balance regularizer to prevent expert collapse. To enhance robustness in degraded conditions and promote role specialization, we further propose distribution-aware masking: during training, modality-drop scenarios are simulated using EMA-statistical surrogate features, and a specialization loss enforces distinct behaviors of private, shared, and interaction experts across complete and masked inputs. Experiments on nuScenes and Argoverse2 benchmarks demonstrate that SEFMAP achieves state-of-the-art performance, surpassing prior methods by +4.2% and +4.8% in mAP, respectively. SEF-MAPprovides a robust and effective solution for multi-modal HD map prediction under diverse and degraded conditions.

</details>


### [32] [Dynamic Multimodal Activation Steering for Hallucination Mitigation in Large Vision-Language Models](https://arxiv.org/abs/2602.21704)
*Jianghao Yin,Qin Chen,Kedi Chen,Jie Zhou,Xingjiao Wu,Liang He*

Main category: cs.CV

TL;DR: 提出Dynamic Multimodal Activation Steering方法，通过动态选择导向向量缓解大型视觉语言模型的幻觉问题，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在视觉语言任务中表现出色，但存在幻觉问题。研究发现真实性和视觉感知能力主要依赖于模型架构中不同的注意力头子集，且真实性导向向量在不同语义上下文中差异显著。

Method: 提出了Dynamic Multimodal Activation Steering，一种无需训练的幻觉缓解方法，通过构建基于语义的真实性导向向量数据库和计算视觉感知导向向量，实现推理过程中的上下文感知干预。

Result: 实验表明，该方法在多个模型和数据集上显著提升了模型性能。

Conclusion: Dynamic Multimodal Activation Steering方法显著提升了大型视觉语言模型的性能，在多个模型和数据集上超越了现有最先进方法。

Abstract: Large Vision-Language Models (LVLMs) exhibit outstanding performance on vision-language tasks but struggle with hallucination problems. Through in-depth analysis of LVLM activation patterns, we reveal two key findings: 1) truthfulness and visual perception capabilities predominantly engage different subsets of attention heads within the model architecture; and 2) truthfulness steering vectors vary significantly across different semantic contexts. Based on these observations, we propose Dynamic Multimodal Activation Steering, a training-free approach for hallucination mitigation. Our method constructs a semantic-based truthfulness steering vector database and computes visual perception steering vectors, enabling context-aware interventions during inference by dynamically selecting the most relevant steering vectors based on input semantic similarity and applying them to the most influential attention heads. We conduct comprehensive experiments across multiple models and datasets, demonstrating that our approach significantly enhances model performance, outperforming existing state-of-the-art methods.

</details>


### [33] [CADC: Content Adaptive Diffusion-Based Generative Image Compression](https://arxiv.org/abs/2602.21591)
*Xihua Sheng,Lingyu Zhu,Tianyu Zhang,Dong Liu,Shiqi Wang,Jing Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种内容自适应的扩散图像编解码器，解决了现有方法的三个关键限制，实现了超低比特率下的高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法在内容自适应方面存在三个关键限制：各向同性量化、信息集中瓶颈和文本条件策略的不足，导致无法有效适应图像内容的语义和结构特征。

Method: 1) 不确定性引导的自适应量化方法；2) 辅助解码器引导的信息集中方法；3) 无比特率成本的自适应文本条件方法。

Result: 提出的方法通过技术创新，显著提升了图像压缩的内容自适应能力，实现了更高质量的重建效果。

Conclusion: 该论文提出了一种内容自适应的基于扩散的图像编解码器，通过三种技术创新解决了现有方法的局限性，实现了在超低比特率下的高质量图像重建。

Abstract: Diffusion-based generative image compression has demonstrated remarkable potential for achieving realistic reconstruction at ultra-low bitrates. The key to unlocking this potential lies in making the entire compression process content-adaptive, ensuring that the encoder's representation and the decoder's generative prior are dynamically aligned with the semantic and structural characteristics of the input image. However, existing methods suffer from three critical limitations that prevent effective content adaptation. First, isotropic quantization applies a uniform quantization step, failing to adapt to the spatially varying complexity of image content and creating a misalignment with the diffusion model's noise-dependent prior. Second, the information concentration bottleneck -- arising from the dimensional mismatch between the high-dimensional noisy latent and the diffusion decoder's fixed input -- prevents the model from adaptively preserving essential semantic information in the primary channels. Third, existing textual conditioning strategies either need significant textual bitrate overhead or rely on generic, content-agnostic textual prompts, thereby failing to provide adaptive semantic guidance efficiently. To overcome these limitations, we propose a content-adaptive diffusion-based image codec with three technical innovations: 1) an Uncertainty-Guided Adaptive Quantization method that learns spatial uncertainty maps to adaptively align quantization distortion with content characteristics; 2) an Auxiliary Decoder-Guided Information Concentration method that uses a lightweight auxiliary decoder to enforce content-aware information preservation in the primary latent channels; and 3) a Bitrate-Free Adaptive Textual Conditioning method that derives content-aware textual descriptions from the auxiliary reconstructed image, enabling semantic guidance without bitrate cost.

</details>


### [34] [SurGo-R1: Benchmarking and Modeling Contextual Reasoning for Operative Zone in Surgical Video](https://arxiv.org/abs/2602.21706)
*Guanyi Qin,Xiaozhen Wang,Zhu Zhuo,Chang Han Low,Yuancan Xiao,Yibing Fu,Haofeng Liu,Kai Wang,Chunjiang Li,Yueming Jin*

Main category: cs.CV

TL;DR: 提出 ResGo 基准和 SurGo-R1 模型，通过多阶段架构显著提升手术安全区域识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有 AI 系统无法处理阶段依赖性的术中推理，导致安全区域识别效果不佳。

Method: 提出了 SurGo-R1 模型，采用强化学习优化（RLHF）的多阶段架构，先识别手术阶段，再基于该上下文生成推理和安全区域坐标。

Result: SurGo-R1 在未见手术中实现了 76.6% 的阶段准确率、32.7 mIoU 和 54.8% 的硬核准确率，比主流通用 VLM 提升了 6.6 倍。

Conclusion: ResGo 基准和 SurGo-R1 模型的引入显著提升了手术安全区域的识别能力，特别是在处理阶段依赖性任务时表现优于现有通用视觉语言模型。

Abstract: Minimally invasive surgery has dramatically improved patient operative outcomes, yet identifying safe operative zones remains challenging in critical phases, requiring surgeons to integrate visual cues, procedural phase, and anatomical context under high cognitive load. Existing AI systems offer binary safety verification or static detection, ignoring the phase-dependent nature of intraoperative reasoning. We introduce ResGo, a benchmark of laparoscopic frames annotated with Go Zone bounding boxes and clinician-authored rationales covering phase, exposure quality reasoning, next action and risk reminder. We introduce evaluation metrics that treat correct grounding under incorrect phase as failures, revealing that most vision-language models cannot handle such tasks and perform poorly. We then present SurGo-R1, a model optimized via RLHF with a multi-turn phase-then-go architecture where the model first identifies the surgical phase, then generates reasoning and Go Zone coordinates conditioned on that context. On unseen procedures, SurGo-R1 achieves 76.6% phase accuracy, 32.7 mIoU, and 54.8% hardcore accuracy, a 6.6$\times$ improvement over the mainstream generalist VLMs. Code, model and benchmark will be available at https://github.com/jinlab-imvr/SurGo-R1

</details>


### [35] [A Hidden Semantic Bottleneck in Conditional Embeddings of Diffusion Transformers](https://arxiv.org/abs/2602.21596)
*Trung X. Pham,Kang Zhang,Ji Woo Hong,Chang D. Yoo*

Main category: cs.CV

TL;DR: 研究发现扩散Transformer的条件嵌入存在冗余，语义信息集中在少数维度，修剪低幅度维度后生成质量不受影响，揭示了语义瓶颈。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散Transformer在类条件和多模态生成中表现优异，但其学习的条件嵌入结构仍未被充分理解。

Method: 通过修剪低幅度维度（移除高达三分之二的嵌入空间），评估生成质量和保真度的变化。

Result: 发现类条件嵌入具有极高的角度相似性（ImageNet-1K超过99%），且语义信息集中在少数维度中。修剪低幅度维度后，生成质量基本不受影响，甚至有所提升。

Conclusion: 研究揭示了基于Transformer的扩散模型中存在语义瓶颈，为语义编码方式提供了新见解，并提出了更高效的条件机制的可能性。

Abstract: Diffusion Transformers have achieved state-of-the-art performance in class-conditional and multimodal generation, yet the structure of their learned conditional embeddings remains poorly understood. In this work, we present the first systematic study of these embeddings and uncover a notable redundancy: class-conditioned embeddings exhibit extreme angular similarity, exceeding 99\% on ImageNet-1K, while continuous-condition tasks such as pose-guided image generation and video-to-audio generation reach over 99.9\%. We further find that semantic information is concentrated in a small subset of dimensions, with head dimensions carrying the dominant signal and tail dimensions contributing minimally. By pruning low-magnitude dimensions--removing up to two-thirds of the embedding space--we show that generation quality and fidelity remain largely unaffected, and in some cases improve. These results reveal a semantic bottleneck in Transformer-based diffusion models, providing new insights into how semantics are encoded and suggesting opportunities for more efficient conditioning mechanisms.

</details>


### [36] [Beyond Static Artifacts: A Forensic Benchmark for Video Deepfake Reasoning in Vision Language Models](https://arxiv.org/abs/2602.21779)
*Zheyuan Gu,Qingsong Zhao,Yusong Wang,Zhaohong Huang,Xinqi Li,Cheng Yuan,Jiaowei Shao,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: FAQ基准通过三级任务（面部感知、时序定位、法医推理）提升VLM的时序深度伪造检测能力，微调后模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在深度伪造检测中擅长空间伪影识别，但忽略了视频伪造中的时序不一致性，亟需填补这一空白。

Method: 提出了Forensic Answer-Questioning（FAQ）基准，将时序深度伪造分析构建为多选题任务，包含三个层次：面部感知、时序深度伪造定位和法医推理。

Result: 实验表明，基于FAQ-IT微调的模型在域内和跨数据集检测基准上均表现出色，消融研究进一步证实了FAQ设计的有效性。

Conclusion: FAQ基准通过三级层次结构显著提升了视觉语言模型（VLM）在时序深度伪造检测中的能力，并通过FAQ-IT微调实现了跨数据集的高性能表现。消融研究验证了FAQ设计的关键作用。

Abstract: Current Vision-Language Models (VLMs) for deepfake detection excel at identifying spatial artifacts but overlook a critical dimension: temporal inconsistencies in video forgeries. Adapting VLMs to reason about these dynamic cues remains a distinct challenge. To bridge this gap, we propose Forensic Answer-Questioning (FAQ), a large-scale benchmark that formulates temporal deepfake analysis as a multiple-choice task. FAQ introduces a three-level hierarchy to progressively evaluate and equip VLMs with forensic capabilities: (1) Facial Perception, testing the ability to identify static visual artifacts; (2) Temporal Deepfake Grounding, requiring the localization of dynamic forgery artifacts across frames; and (3) Forensic Reasoning, challenging models to synthesize evidence for final authenticity verdicts. We evaluate a range of VLMs on FAQ and generate a corresponding instruction-tuning set, FAQ-IT. Extensive experiments show that models fine-tuned on FAQ-IT achieve advanced performance on both in-domain and cross-dataset detection benchmarks. Ablation studies further validate the impact of our key design choices, confirming that FAQ is the driving force behind the temporal reasoning capabilities of these VLMs.

</details>


### [37] [Tokenizing Semantic Segmentation with RLE](https://arxiv.org/abs/2602.21627)
*Abhineet Singh,Justin Rozeboom,Nilanjan Ray*

Main category: cs.CV

TL;DR: 提出一种基于语言建模的统一语义分割方法，通过RLE和Pix2Seq处理图像和视频，并在有限计算资源下实现竞争性表现。


<details>
  <summary>Details</summary>
Motivation: 提出一种统一的方法，通过语言建模处理图像和视频的语义分割任务，并解决视频中标记序列过长的问题。

Method: 使用语言建模将分割掩码输出为离散标记序列，采用游程编码（RLE）离散化掩码，并训练改进版Pix2Seq模型自回归输出这些RLE标记。

Result: 在两个数据集上的评估表明，该方法在语义分割和全景分割任务中具有竞争力。

Conclusion: 该论文提出的方法在图像和视频语义分割任务中表现优异，尽管受限于计算资源，但仍能与现有技术竞争。

Abstract: This paper presents a new unified approach to semantic segmentation in both images and videos by using language modeling to output the masks as sequences of discrete tokens. We use run length encoding (RLE) to discretize the segmentation masks and then train a modified version of Pix2Seq \cite{p2s} to output these RLE tokens through autoregression. We propose novel tokenization strategies to compress the length of the token sequence to make it practicable to extend this approach to videos. We also show how instance information can be incorporated into the tokenization process to perform panoptic segmentation. We evaluate our proposed models on two datasets to show that they are competitive with the state of the art in spite of being bottlenecked by our limited computational resources.

</details>


### [38] [SemVideo: Reconstructs What You Watch from Brain Activity via Hierarchical Semantic Guidance](https://arxiv.org/abs/2602.21819)
*Minghan Yang,Lan Yang,Ke Li,Honggang Zhang,Kaiyue Pang,Yizhe Song*

Main category: cs.CV

TL;DR: SemVideo是一种基于分层语义信息的fMRI到视频重建框架，解决了现有方法在视觉表征和时间连贯性上的不足，实验验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 当前fMRI到视频重建方法存在视觉表征不一致和时间连贯性差的问题，亟需一种新方法来克服这些限制。

Method: SemVideo框架包含三个关键组件：语义对齐解码器、运动适应解码器和条件视频渲染器，利用SemMiner模块提供的三层语义线索进行引导。

Result: 在CC2017和HCP数据集上的实验表明，SemVideo在语义对齐和时间一致性方面表现优异。

Conclusion: SemVideo通过分层语义信息引导的框架，显著提升了fMRI到视频重建的性能，在语义对齐和时间一致性方面达到了新的最先进水平。

Abstract: Reconstructing dynamic visual experiences from brain activity provides a compelling avenue for exploring the neural mechanisms of human visual perception. While recent progress in fMRI-based image reconstruction has been notable, extending this success to video reconstruction remains a significant challenge. Current fMRI-to-video reconstruction approaches consistently encounter two major shortcomings: (i) inconsistent visual representations of salient objects across frames, leading to appearance mismatches; (ii) poor temporal coherence, resulting in motion misalignment or abrupt frame transitions. To address these limitations, we introduce SemVideo, a novel fMRI-to-video reconstruction framework guided by hierarchical semantic information. At the core of SemVideo is SemMiner, a hierarchical guidance module that constructs three levels of semantic cues from the original video stimulus: static anchor descriptions, motion-oriented narratives, and holistic summaries. Leveraging this semantic guidance, SemVideo comprises three key components: a Semantic Alignment Decoder that aligns fMRI signals with CLIP-style embeddings derived from SemMiner, a Motion Adaptation Decoder that reconstructs dynamic motion patterns using a novel tripartite attention fusion architecture, and a Conditional Video Render that leverages hierarchical semantic guidance for video reconstruction. Experiments conducted on the CC2017 and HCP datasets demonstrate that SemVideo achieves superior performance in both semantic alignment and temporal consistency, setting a new state-of-the-art in fMRI-to-video reconstruction.

</details>


### [39] [UniHand: A Unified Model for Diverse Controlled 4D Hand Motion Modeling](https://arxiv.org/abs/2602.21631)
*Zhihao Sun,Tong Wu,Ruirui Tu,Daoguo Dong,Zuxuan Wu*

Main category: cs.CV

TL;DR: UniHand是一个统一的扩散框架，整合手部运动估计与生成任务，通过共享潜在空间和潜在扩散模型实现鲁棒且准确的4D手部运动建模。


<details>
  <summary>Details</summary>
Motivation: 现有手部运动建模方法分为估计和生成两类，但两者分离限制了异构条件信号的利用和任务间知识转移。

Method: UniHand采用联合变分自编码器将异构输入嵌入共享潜在空间，并通过潜在扩散模型合成一致的运动序列。

Result: 在多个基准测试中，UniHand表现出色，尤其在严重遮挡和时间不完整输入下仍保持高性能。

Conclusion: UniHand通过统一的扩散框架成功整合了手部运动估计与生成任务，展示了在严重遮挡和时间不完整输入下的鲁棒性和准确性。

Abstract: Hand motion plays a central role in human interaction, yet modeling realistic 4D hand motion (i.e., 3D hand pose sequences over time) remains challenging. Research in this area is typically divided into two tasks: (1) Estimation approaches reconstruct precise motion from visual observations, but often fail under hand occlusion or absence; (2) Generation approaches focus on synthesizing hand poses by exploiting generative priors under multi-modal structured inputs and infilling motion from incomplete sequences. However, this separation not only limits the effective use of heterogeneous condition signals that frequently arise in practice, but also prevents knowledge transfer between the two tasks. We present UniHand, a unified diffusion-based framework that formulates both estimation and generation as conditional motion synthesis. UniHand integrates heterogeneous inputs by embedding structured signals into a shared latent space through a joint variational autoencoder, which aligns conditions such as MANO parameters and 2D skeletons. Visual observations are encoded with a frozen vision backbone, while a dedicated hand perceptron extracts hand-specific cues directly from image features, removing the need for complex detection and cropping pipelines. A latent diffusion model then synthesizes consistent motion sequences from these diverse conditions. Extensive experiments across multiple benchmarks demonstrate that UniHand delivers robust and accurate hand motion modeling, maintaining performance under severe occlusions and temporally incomplete inputs.

</details>


### [40] [StoryMovie: A Dataset for Semantic Alignment of Visual Stories with Movie Scripts and Subtitles](https://arxiv.org/abs/2602.21829)
*Daniel Oliveira,David Martins de Matos*

Main category: cs.CV

TL;DR: StoryMovie数据集和Storyteller3模型通过剧本-字幕对齐显著提升对话归属准确性，验证语义对齐对视觉叙事的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决视觉叙事模型中存在的语义关系幻觉问题，如错误的对话归属、角色互动或情感状态。

Method: 引入StoryMovie数据集，通过LCS匹配将剧本与字幕对齐，并利用对齐内容生成包含真实角色名称、对话和关系动态的故事。基于此数据集对Qwen Storyteller3进行微调。

Result: Storyteller3在字幕对齐任务上以89.9%的胜率优于基础模型Qwen2.5-VL 7B，且相比未使用剧本基础的Storyteller模型，对话归属准确率从38.0%提升至48.5%。

Conclusion: StoryMovie数据集和Storyteller3模型通过剧本与字幕的语义对齐显著提升了对话归属的准确性，超越了仅依赖视觉基础的方法。

Abstract: Visual storytelling models that correctly ground entities in images may still hallucinate semantic relationships, generating incorrect dialogue attribution, character interactions, or emotional states. We introduce StoryMovie, a dataset of 1,757 stories aligned with movie scripts and subtitles through LCS matching. Our alignment pipeline synchronizes screenplay dialogue with subtitle timestamps, enabling dialogue attribution by linking character names from scripts to temporal positions from subtitles. Using this aligned content, we generate stories that maintain visual grounding tags while incorporating authentic character names, dialogue, and relationship dynamics. We fine-tune Qwen Storyteller3 on this dataset, building on prior work in visual grounding and entity re-identification. Evaluation using DeepSeek V3 as judge shows that Storyteller3 achieves an 89.9% win rate against base Qwen2.5-VL 7B on subtitle alignment. Compared to Storyteller, trained without script grounding,
  Storyteller3 achieves 48.5% versus 38.0%, confirming that semantic alignment progressively improves dialogue attribution beyond visual grounding alone.

</details>


### [41] [Axial-Centric Cross-Plane Attention for 3D Medical Image Classification](https://arxiv.org/abs/2602.21636)
*Doyoung Park,Jinsoo Kim,Lohendran Baskaran*

Main category: cs.CV

TL;DR: 提出轴向中心跨平面注意力架构，结合预训练模型MedDINOv3，显著提升3D医学图像分类性能，验证临床对齐设计的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有3D深度学习方法未能反映临床中以轴向平面为主的解读流程，导致诊断效率不足。

Method: 研究采用轴向中心跨平面注意力架构，结合MedDINOv3作为冻结特征提取器，并通过RICA块和平面内/跨平面Transformer编码器捕获平面间的不对称依赖关系。

Result: 在MedMNIST3D基准测试的六个数据集中，该架构在准确率和AUC上均优于现有3D和多平面模型。消融实验进一步验证了轴向中心查询-键-值分配和定向跨平面融合的关键作用。

Conclusion: 该研究提出的轴向中心跨平面注意力架构显著提升了3D医学图像分类的准确性和AUC，验证了将架构设计与临床解读流程对齐的重要性。

Abstract: Clinicians commonly interpret three-dimensional (3D) medical images, such as computed tomography (CT) scans, using multiple anatomical planes rather than as a single volumetric representation. In this multi-planar approach, the axial plane typically serves as the primary acquisition and diagnostic reference, while the coronal and sagittal planes provide complementary spatial information to increase diagnostic confidence. However, many existing 3D deep learning methods either process volumetric data holistically or assign equal importance to all planes, failing to reflect the axial-centric clinical interpretation workflow. To address this gap, we propose an axial-centric cross-plane attention architecture for 3D medical image classification that captures the inherent asymmetric dependencies between different anatomical planes. Our architecture incorporates MedDINOv3, a medical vision foundation model pretrained via self-supervised learning on large-scale axial CT images, as a frozen feature extractor for the axial, coronal, and sagittal planes. RICA blocks and intra-plane transformer encoders capture plane-specific positional and contextual information within each anatomical plane, while axial-centric cross-plane transformer encoders condition axial features on complementary information from auxiliary planes. Experimental results on six datasets from the MedMNIST3D benchmark demonstrate that the proposed architecture consistently outperforms existing 3D and multi-plane models in terms of accuracy and AUC. Ablation studies further confirm the importance of axial-centric query-key-value allocation and directional cross-plane fusion. These results highlight the importance of aligning architectural design with clinical interpretation workflows for robust and data-efficient 3D medical image analysis.

</details>


### [42] [Understanding Annotation Error Propagation and Learning an Adaptive Policy for Expert Intervention in Barrett's Video Segmentation](https://arxiv.org/abs/2602.21855)
*Lokesha Rasanjalee,Jin Lin Tan,Dileepa Pitawela,Rajvinder Singh,Hsiang-Ting Chen*

Main category: cs.CV

TL;DR: 论文提出L2RP框架，通过成本感知学习优化内窥镜视频标注，减少专家干预需求，提升分割准确性。


<details>
  <summary>Details</summary>
Motivation: 内窥镜视频的准确标注至关重要但耗时，尤其是对于Barrett's食管中的不典型增生等边界模糊的挑战性数据集。半自动工具如SAM2虽能辅助标注，但小错误会累积并降低准确性，需专家复核修正。

Method: 系统研究了不同提示类型（如掩码、框、点）下标注错误的传播，并提出了Learning-to-Re-Prompt (L2RP)框架，通过学习何时何地寻求专家输入来优化标注过程。

Result: 在私有的Barrett's不典型增生数据集和公开的SUN-SEG基准测试中，L2RP框架显著提升了时间一致性，并优于基线策略。

Conclusion: 论文提出了L2RP框架，通过成本感知的方式平衡标注努力与分割准确性，在Barrett's dysplasia数据集和SUN-SEG基准测试中表现出优于基线策略的性能。

Abstract: Accurate annotation of endoscopic videos is essential yet time-consuming, particularly for challenging datasets such as dysplasia in Barrett's esophagus, where the affected regions are irregular and lack clear boundaries. Semi-automatic tools like Segment Anything Model 2 (SAM2) can ease this process by propagating annotations across frames, but small errors often accumulate and reduce accuracy, requiring expert review and correction. To address this, we systematically study how annotation errors propagate across different prompt types, namely masks, boxes, and points, and propose Learning-to-Re-Prompt (L2RP), a cost-aware framework that learns when and where to seek expert input. By tuning a human-cost parameter, our method balances annotation effort and segmentation accuracy. Experiments on a private Barrett's dysplasia dataset and the public SUN-SEG benchmark demonstrate improved temporal consistency and superior performance over baseline strategies.

</details>


### [43] [CARE: A Molecular-Guided Foundation Model with Adaptive Region Modeling for Whole Slide Image Analysis](https://arxiv.org/abs/2602.21637)
*Di Zhang,Zhangpeng Gong,Xiaobo Pang,Jiashuai Liu,Junbo Lu,Hao Cui,Jiusong Ge,Zhi Zeng,Kai Yi,Yinghua Li,Si Liu,Tingsong Yu,Haoran Wang,Mireia Crispin-Ortuzar,eimiao Yu,Chen Li,Zeyu Gao*

Main category: cs.CV

TL;DR: CARE是一种病理学基础模型，通过分子引导的自适应区域划分，显著提升任务性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有模型因依赖自然图像骨干网络，无法有效捕捉病理组织的异质性和连贯结构。

Method: CARE采用两阶段预训练策略：无监督学习形态表征和跨模态对齐优化区域划分。

Result: CARE在33个下游任务中表现优于主流基础模型，且仅需十分之一的预训练数据。

Conclusion: CARE模型通过结合分子引导和自适应区域划分，显著提升了病理学任务的性能，尤其在数据效率上表现优异。

Abstract: Foundation models have recently achieved impressive success in computational pathology, demonstrating strong generalization across diverse histopathology tasks. However, existing models overlook the heterogeneous and non-uniform organization of pathological regions of interest (ROIs) because they rely on natural image backbones not tailored for tissue morphology. Consequently, they often fail to capture the coherent tissue architecture beyond isolated patches, limiting interpretability and clinical relevance. To address these challenges, we present Cross-modal Adaptive Region Encoder (CARE), a foundation model for pathology that automatically partitions WSIs into several morphologically relevant regions. Specifically, CARE employs a two-stage pretraining strategy: (1) a self-supervised unimodal pretraining stage that learns morphological representations from 34,277 whole-slide images (WSIs) without segmentation annotations, and (2) a cross-modal alignment stage that leverages RNA and protein profiles to refine the construction and representation of adaptive regions. This molecular guidance enables CARE to identify biologically relevant patterns and generate irregular yet coherent tissue regions, selecting the most representative area as ROI. CARE supports a broad range of pathology-related tasks, using either the ROI feature or the slide-level feature obtained by aggregating adaptive regions. Based on only one-tenth of the pretraining data typically used by mainstream foundation models, CARE achieves superior average performance across 33 downstream benchmarks, including morphological classification, molecular prediction, and survival analysis, and outperforms other foundation model baselines overall.

</details>


### [44] [Lie Flow: Video Dynamic Fields Modeling and Predicting with Lie Algebra as Geometric Physics Principle](https://arxiv.org/abs/2602.21645)
*Weidong Qiao,Wangmeng Zuo,Hui Li*

Main category: cs.CV

TL;DR: LieFlow利用SE(3)李群建模4D场景运动，解决了现有方法在旋转和关节变换上的不足，显著提升了视图合成的质量和物理真实性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖平移位移，难以表示旋转和关节变换，导致空间不一致和物理上不合理的运动。因此，需要一种能够统一表示复杂刚性和非刚性运动的物理一致方法。

Method: LieFlow是一种动态辐射表示框架，利用SE(3)李群显式建模运动，统一几何空间中的平移和旋转学习，并通过SE(3)变换场施加物理约束以保持运动连续性和几何一致性。

Result: 在合成数据集和真实世界数据集上的评估表明，LieFlow在所有数据集上均优于基于NeRF的基线方法，提升了视图合成保真度、时间一致性和物理真实性。

Conclusion: LieFlow通过SE(3)李群建模动态4D场景，显著提升了视图合成保真度、时间一致性和物理真实性，验证了基于SE(3)的运动建模是一种稳健且物理基础坚实的框架。

Abstract: Modeling 4D scenes requires capturing both spatial structure and temporal motion, which is challenging due to the need for physically consistent representations of complex rigid and non-rigid motions. Existing approaches mainly rely on translational displacements, which struggle to represent rotations, articulated transformations, often leading to spatial inconsistency and physically implausible motion. LieFlow, a dynamic radiance representation framework that explicitly models motion within the SE(3) Lie group, enabling coherent learning of translation and rotation in a unified geometric space. The SE(3) transformation field enforces physically inspired constraints to maintain motion continuity and geometric consistency. The evaluation includes a synthetic dataset with rigid-body trajectories and two real-world datasets capturing complex motion under natural lighting and occlusions. Across all datasets, LieFlow consistently improves view-synthesis fidelity, temporal coherence, and physical realism over NeRF-based baselines. These results confirm that SE(3)-based motion modeling offers a robust and physically grounded framework for representing dynamic 4D scenes.

</details>


### [45] [A Framework for Cross-Domain Generalization in Coronary Artery Calcium Scoring Across Gated and Non-Gated Computed Tomography](https://arxiv.org/abs/2602.21935)
*Mahmut S. Gokmen,Moneera N. Haque,Steve W. Leung,Caroline N. Leach,Seth Parker,Stephen B. Hobbs,Vincent L. Sorrell,W. Brent Seales,V. K. Cody Bumgardner*

Main category: cs.CV

TL;DR: An automated framework using CARD-ViT enables CAC scoring across gated and non-gated CT scans, achieving comparable accuracy to specialized models, facilitating broader cardiovascular screening.


<details>
  <summary>Details</summary>
Motivation: To overcome the limitation of CAC scoring relying on ECG-gated CT scans, which restricts its use to specialized cardiac imaging settings, the study aims to extend CAC scoring to non-gated CT scans.

Method: The research introduces an automated framework for CAC detection and lesion-specific Agatston scoring, utilizing CARD-ViT, a self-supervised Vision Transformer trained exclusively on gated CT data using DINO.

Result: The framework achieves 0.707 accuracy and a Cohen's kappa of 0.528 on non-gated datasets, matching models trained directly on non-gated scans. On gated test sets, it achieves 0.910 accuracy with Cohen's kappa scores of 0.871 and 0.874, demonstrating robust risk stratification.

Conclusion: The study demonstrates the feasibility of cross-domain CAC scoring from gated to non-gated CT scans, enabling scalable cardiovascular screening in routine chest imaging without the need for additional scans or annotations.

Abstract: Coronary artery calcium (CAC) scoring is a key predictor of cardiovascular risk, but it relies on ECG-gated CT scans, restricting its use to specialized cardiac imaging settings. We introduce an automated framework for CAC detection and lesion-specific Agatston scoring that operates across both gated and non-gated CT scans. At its core is CARD-ViT, a self-supervised Vision Transformer trained exclusively on gated CT data using DINO. Without any non-gated training data, our framework achieves 0.707 accuracy and a Cohen's kappa of 0.528 on the Stanford non-gated dataset, matching models trained directly on non-gated scans. On gated test sets, the framework achieves 0.910 accuracy with Cohen's kappa scores of 0.871 and 0.874 across independent datasets, demonstrating robust risk stratification. These results demonstrate the feasibility of cross-domain CAC scoring from gated to non-gated domains, supporting scalable cardiovascular screening in routine chest imaging without additional scans or annotations.

</details>


### [46] [PatchDenoiser: Parameter-efficient multi-scale patch learning and fusion denoiser for medical images](https://arxiv.org/abs/2602.21987)
*Jitindra Fartiyal,Pedro Freire,Sergei K. Turitsyn,Sergei G. Solovski*

Main category: cs.CV

TL;DR: PatchDenoiser 是一种轻量级多尺度块去噪框架，有效去噪并保留细节，性能优于现有方法且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 医学图像质量常因低剂量采集、患者运动或扫描仪限制而下降，传统滤波方法易过度平滑丢失细节，深度学习方法则可能无法保留细节或计算成本高。

Method: 提出了一种轻量级、高能效的多尺度基于块的去噪框架，通过局部纹理提取和全局上下文聚合，结合空间感知的块融合策略，有效抑制噪声同时保留精细结构细节。

Result: 在 Mayo Low-Dose CT 数据集上，PatchDenoiser 在 PSNR 和 SSIM 上优于现有 CNN 和 GAN 方法，参数减少约 9 倍，能耗降低约 27 倍。

Conclusion: PatchDenoiser 提供了一种实用、可扩展且计算高效的医学图像去噪解决方案，平衡了性能、鲁棒性和临床部署性。

Abstract: Medical images are essential for diagnosis, treatment planning, and research, but their quality is often degraded by noise from low-dose acquisition, patient motion, or scanner limitations, affecting both clinical interpretation and downstream analysis. Traditional filtering approaches often over-smooth and lose fine anatomical details, while deep learning methods, including CNNs, GANs, and transformers, may struggle to preserve such details or require large, computationally expensive models, limiting clinical practicality.
  We propose PatchDenoiser, a lightweight, energy-efficient multi-scale patch-based denoising framework. It decomposes denoising into local texture extraction and global context aggregation, fused via a spatially aware patch fusion strategy. This design enables effective noise suppression while preserving fine structural and anatomical details. PatchDenoiser is ultra-lightweight, with far fewer parameters and lower computational complexity than CNN-, GAN-, and transformer-based denoisers.
  On the 2016 Mayo Low-Dose CT dataset, PatchDenoiser consistently outperforms state-of-the-art CNN- and GAN-based methods in PSNR and SSIM. It is robust to variations in slice thickness, reconstruction kernels, and HU windows, generalizes across scanners without fine-tuning, and reduces parameters by ~9x and energy consumption per inference by ~27x compared with conventional CNN denoisers.
  PatchDenoiser thus provides a practical, scalable, and computationally efficient solution for medical image denoising, balancing performance, robustness, and clinical deployability.

</details>


### [47] [HybridINR-PCGC: Hybrid Lossless Point Cloud Geometry Compression Bridging Pretrained Model and Implicit Neural Representation](https://arxiv.org/abs/2602.21662)
*Wenjie Huang,Qi Yang,Shuting Xia,He Huang,Zhu Li,Yiling Xu*

Main category: cs.CV

TL;DR: HybridINR-PCGC 结合预训练模型和 INR，提升点云压缩性能，显著降低比特率并提高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于预训练的点云压缩方法依赖训练数据且泛化能力有限，而基于 INR 的方法虽分布无关但在线训练耗时且模型开销大。HybridINR-PCGC 旨在结合两者的优势，解决这些局限性。

Method: 提出了 HybridINR-PCGC 框架，包含预训练先验网络（PPN）和分布无关优化器（DAR）。PPN 用于快速推理和稳定性能，DAR 分为基础层和增强层，仅需将增强层参数打包到比特流中。此外，还提出了监督模型压缩模块以最小化增强层参数的比特率。

Result: 实验结果表明，HybridINR-PCGC 在压缩率和编码效率上显著提升。在 8iVFB 数据集上，Bpp 比 G-PCC 降低约 20.43%；在分布外场景 Cat1B 中，Bpp 比 UniPCGC 降低约 57.85%；与 LINR-PCGC 相比，平均 Bpp 降低 15.193%。

Conclusion: HybridINR-PCGC 框架通过结合预训练模型和隐式神经表示（INR），显著提升了点云压缩的性能和效率，同时在分布外场景中表现出色。

Abstract: Learning-based point cloud compression presents superior performance to handcrafted codecs. However, pretrained-based methods, which are based on end-to-end training and expected to generalize to all the potential samples, suffer from training data dependency. Implicit neural representation (INR) based methods are distribution-agnostic and more robust, but they require time-consuming online training and suffer from the bitstream overhead from the overfitted model. To address these limitations, we propose HybridINR-PCGC, a novel hybrid framework that bridges the pretrained model and INR. Our framework retains distribution-agnostic properties while leveraging a pretrained network to accelerate convergence and reduce model overhead, which consists of two parts: the Pretrained Prior Network (PPN) and the Distribution Agnostic Refiner (DAR). We leverage the PPN, designed for fast inference and stable performance, to generate a robust prior for accelerating the DAR's convergence. The DAR is decomposed into a base layer and an enhancement layer, and only the enhancement layer needed to be packed into the bitstream. Finally, we propose a supervised model compression module to further supervise and minimize the bitrate of the enhancement layer parameters. Based on experiment results, HybridINR-PCGC achieves a significantly improved compression rate and encoding efficiency. Specifically, our method achieves a Bpp reduction of approximately 20.43% compared to G-PCC on 8iVFB. In the challenging out-of-distribution scenario Cat1B, our method achieves a Bpp reduction of approximately 57.85% compared to UniPCGC. And our method exhibits a superior time-rate trade-off, achieving an average Bpp reduction of 15.193% relative to the LINR-PCGC on 8iVFB.

</details>


### [48] [RGB-Event HyperGraph Prompt for Kilometer Marker Recognition based on Pre-trained Foundation Models](https://arxiv.org/abs/2602.22026)
*Xiaoyu Xian,Shiao Wang,Xiao Wang,Daxin Tian,Yan Tian*

Main category: cs.CV

TL;DR: 本文提出多模态适配方法增强RGB OCR模型，用于地铁千米标记识别，构建首个大规模RGB-Event数据集EvMetro5K，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 地铁列车在复杂环境中运行时，传统RGB相机视觉感知系统面临光照变化、高速运动和恶劣天气等挑战，因此探索事件相机的集成以提升感知能力。

Method: 采用预训练的RGB OCR基础模型，并通过多模态适配进行增强，构建了RGB-Event数据集EvMetro5K。

Result: 在EvMetro5K数据集及其他广泛使用的基准测试上，所提方法在千米标记识别任务中表现出色。

Conclusion: 本文提出了一种基于预训练RGB OCR基础模型并通过多模态适配增强的鲁棒基线方法，用于解决地铁列车在复杂环境下的千米标记识别问题。实验证明该方法在EvMetro5K数据集上表现优异，数据集和源代码将公开。

Abstract: Metro trains often operate in highly complex environments, characterized by illumination variations, high-speed motion, and adverse weather conditions. These factors pose significant challenges for visual perception systems, especially those relying solely on conventional RGB cameras. To tackle these difficulties, we explore the integration of event cameras into the perception system, leveraging their advantages in low-light conditions, high-speed scenarios, and low power consumption. Specifically, we focus on Kilometer Marker Recognition (KMR), a critical task for autonomous metro localization under GNSS-denied conditions. In this context, we propose a robust baseline method based on a pre-trained RGB OCR foundation model, enhanced through multi-modal adaptation. Furthermore, we construct the first large-scale RGB-Event dataset, EvMetro5K, containing 5,599 pairs of synchronized RGB-Event samples, split into 4,479 training and 1,120 testing samples. Extensive experiments on EvMetro5K and other widely used benchmarks demonstrate the effectiveness of our approach for KMR. Both the dataset and source code will be released on https://github.com/Event-AHU/EvMetro5K_benchmark

</details>


### [49] [Send Less, Perceive More: Masked Quantized Point Cloud Communication for Loss-Tolerant Collaborative Perception](https://arxiv.org/abs/2602.21667)
*Sheng Xu,Enshu Wang,Hongfei Xue,Jian Teng,Bingyi Liu,Yi Zhu,Pu Wang,Libing Wu,Chunming Qiao*

Main category: cs.CV

TL;DR: QPoint2Comm是一种量化点云通信框架，通过共享码本和掩码训练策略，显著降低带宽需求并提升抗丢包能力，实验证明其在多个指标上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有协作感知方法在严格带宽限制下难以保持高精度，且对随机传输丢包高度脆弱。

Method: 采用量化点云索引直接通信，使用共享码本进行高效重建；引入掩码训练策略模拟随机丢包；提出级联注意力融合模块增强多车信息整合。

Result: 在模拟和真实数据集上的大量实验表明，QPoint2Comm在准确度、通信效率和抗丢包能力上达到了新的最优水平。

Conclusion: QPoint2Comm通过量化点云通信框架显著降低了带宽需求，同时保持了高保真度的3D信息，并在准确度、通信效率和抗丢包能力上设定了新的标准。

Abstract: Collaborative perception allows connected vehicles to overcome occlusions and limited viewpoints by sharing sensory information. However, existing approaches struggle to achieve high accuracy under strict bandwidth constraints and remain highly vulnerable to random transmission packet loss. We introduce QPoint2Comm, a quantized point-cloud communication framework that dramatically reduces bandwidth while preserving high-fidelity 3D information. Instead of transmitting intermediate features, QPoint2Comm directly communicates quantized point-cloud indices using a shared codebook, enabling efficient reconstruction with lower bandwidth than feature-based methods. To ensure robustness to possible communication packet loss, we employ a masked training strategy that simulates random packet loss, allowing the model to maintain strong performance even under severe transmission failures. In addition, a cascade attention fusion module is proposed to enhance multi-vehicle information integration. Extensive experiments on both simulated and real-world datasets demonstrate that QPoint2Comm sets a new state of the art in accuracy, communication efficiency, and resilience to packet loss.

</details>


### [50] [NESTOR: A Nested MOE-based Neural Operator for Large-Scale PDE Pre-Training](https://arxiv.org/abs/2602.22059)
*Dengdi Sun,Xiaoya Zhou,Xiao Wang,Hao Si,Wanli Lyu,Jin Tang,Bin Luo*

Main category: cs.CV

TL;DR: 提出嵌套MoE框架的神经算子，解决单一架构限制，提升PDE求解的泛化能力，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有神经算子因单一网络架构限制，难以充分捕捉PDE系统的异构特征和复杂依赖，制约了大规模预训练。

Method: 采用嵌套混合专家（MoE）框架，包括图像级MoE捕获全局依赖和令牌级Sub-MoE聚焦局部依赖，选择性激活专家网络。

Result: 在12个PDE数据集上成功预训练，并有效迁移至下游任务，实验证明了方法的优越性。

Conclusion: 提出的嵌套混合专家（MoE）框架显著提升了神经算子在PDE求解中的泛化能力和迁移性，通过大规模预训练验证了其有效性。

Abstract: Neural operators have emerged as an efficient paradigm for solving PDEs, overcoming the limitations of traditional numerical methods and significantly improving computational efficiency. However, due to the diversity and complexity of PDE systems, existing neural operators typically rely on a single network architecture, which limits their capacity to fully capture heterogeneous features and complex system dependencies. This constraint poses a bottleneck for large-scale PDE pre-training based on neural operators. To address these challenges, we propose a large-scale PDE pre-trained neural operator based on a nested Mixture-of-Experts (MoE) framework. In particular, the image-level MoE is designed to capture global dependencies, while the token-level Sub-MoE focuses on local dependencies. Our model can selectively activate the most suitable expert networks for a given input, thereby enhancing generalization and transferability. We conduct large-scale pre-training on twelve PDE datasets from diverse sources and successfully transfer the model to downstream tasks. Extensive experiments demonstrate the effectiveness of our approach.

</details>


### [51] [E-comIQ-ZH: A Human-Aligned Dataset and Benchmark for Fine-Grained Evaluation of E-commerce Posters with Chain-of-Thought](https://arxiv.org/abs/2602.21698)
*Meiqi Sun,Mingyu Li,Junxiong Zhu*

Main category: cs.CV

TL;DR: 提出E-comIQ-ZH框架，通过E-comIQ-18k数据集和E-comIQ-M模型，解决了中文电商海报质量评估的自动化问题。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在电商海报创作中广泛应用，但现有质量评估模型缺乏针对中文内容的专业标准，尤其是复杂字符产生的细微文本伪影常被忽视。

Method: 构建了E-comIQ-18k数据集，包含多维评分和专家校准的CoT（Chain of Thought）理由，并训练了专用评估模型E-comIQ-M。

Result: 实验表明E-comIQ-M与专家标准更接近，支持电商海报的自动化评估。

Conclusion: E-comIQ-ZH框架通过E-comIQ-M模型实现了与中国电商海报专家评估标准的高度一致，并提供了首个自动化、可扩展的评估基准。

Abstract: Generative AI is widely used to create commercial posters. However, rapid advances in generation have outpaced automated quality assessment. Existing models emphasize generic esthetics or low level distortions and lack the functional criteria required for e-commerce design. It is especially challenging for Chinese content, where complex characters often produce subtle but critical textual artifacts that are overlooked by existing methods. To address this, we introduce E-comIQ-ZH, a framework for evaluating Chinese e-commerce posters. We build the first dataset E-comIQ-18k to feature multi dimensional scores and expert calibrated Chain of Thought (CoT) rationales. Using this dataset, we train E-comIQ-M, a specialized evaluation model that aligns with human expert judgment. Our framework enables E-comIQ-Bench, the first automated and scalable benchmark for the generation of Chinese e-commerce posters. Extensive experiments show our E-comIQ-M aligns more closely with expert standards and enables scalable automated assessment of e-commerce posters. All datasets, models, and evaluation tools will be released to support future research in this area.Code will be available at https://github.com/4mm7/E-comIQ-ZH.

</details>


### [52] [NoLan: Mitigating Object Hallucinations in Large Vision-Language Models via Dynamic Suppression of Language Priors](https://arxiv.org/abs/2602.22144)
*Lingfeng Ren,Weihao Yu,Runpeng Yu,Xinchao Wang*

Main category: cs.CV

TL;DR: NoLan框架通过抑制语言解码器的先验知识，有效减少视觉语言模型的物体幻觉，提升任务准确率。


<details>
  <summary>Details</summary>
Motivation: 探究大型视觉语言模型中物体幻觉现象的主要来源是视觉编码器还是语言解码器。

Method: 设计系统性实验分析视觉编码器和语言解码器在幻觉生成中的作用，提出NoLan框架，动态调整输出分布以抑制语言先验。

Result: NoLan显著减少了不同任务中的物体幻觉，如在POPE任务中，LLaVA-1.5 7B和Qwen-VL 7B的准确率分别提升了6.45和7.21。

Conclusion: NoLan框架通过动态抑制语言解码器的先验知识，有效减少了大型视觉语言模型中的物体幻觉现象。

Abstract: Object hallucination is a critical issue in Large Vision-Language Models (LVLMs), where outputs include objects that do not appear in the input image. A natural question arises from this phenomenon: Which component of the LVLM pipeline primarily contributes to object hallucinations? The vision encoder to perceive visual information, or the language decoder to generate text responses? In this work, we strive to answer this question through designing a systematic experiment to analyze the roles of the vision encoder and the language decoder in hallucination generation. Our observations reveal that object hallucinations are predominantly associated with the strong priors from the language decoder. Based on this finding, we propose a simple and training-free framework, No-Language-Hallucination Decoding, NoLan, which refines the output distribution by dynamically suppressing language priors, modulated based on the output distribution difference between multimodal and text-only inputs. Experimental results demonstrate that NoLan effectively reduces object hallucinations across various LVLMs on different tasks. For instance, NoLan achieves substantial improvements on POPE, enhancing the accuracy of LLaVA-1.5 7B and Qwen-VL 7B by up to 6.45 and 7.21, respectively. The code is publicly available at: https://github.com/lingfengren/NoLan.

</details>


### [53] [SF3D-RGB: Scene Flow Estimation from Monocular Camera and Sparse LiDAR](https://arxiv.org/abs/2602.21699)
*Rajai Alhimdiat,Ramy Battrawy,René Schuster,Didier Stricker,Wesam Ashour*

Main category: cs.CV

TL;DR: SF3D-RGB是一种融合2D图像和3D点云的深度学习模型，用于场景流估计，在准确性和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的场景流估计方法多专注于单一模态，限制了性能。本文旨在通过融合多模态数据提升场景流估计的鲁棒性和准确性。

Method: SF3D-RGB是一种端到端深度学习架构，首先将2D图像和3D点云编码为特征并融合，随后通过图匹配模块计算初始场景流，最后通过残差场景流模块进行细化。

Result: 实验表明，SF3D-RGB在真实数据集上优于单模态方法，且参数更少，实现了更高的场景流准确性。

Conclusion: SF3D-RGB模型通过融合2D单目图像和3D点云数据，在场景流估计任务中实现了更高的准确性和效率，优于单模态方法和其他先进融合方法。

Abstract: Scene flow estimation is an extremely important task in computer vision to support the perception of dynamic changes in the scene. For robust scene flow, learning-based approaches have recently achieved impressive results using either image-based or LiDAR-based modalities. However, these methods have tended to focus on the use of a single modality. To tackle these problems, we present a deep learning architecture, SF3D-RGB, that enables sparse scene flow estimation using 2D monocular images and 3D point clouds (e.g., acquired by LiDAR) as inputs. Our architecture is an end-to-end model that first encodes information from each modality into features and fuses them together. Then, the fused features enhance a graph matching module for better and more robust mapping matrix computation to generate an initial scene flow. Finally, a residual scene flow module further refines the initial scene flow. Our model is designed to strike a balance between accuracy and efficiency. Furthermore, experiments show that our proposed method outperforms single-modality methods and achieves better scene flow accuracy on real-world datasets while using fewer parameters compared to other state-of-the-art methods with fusion.

</details>


### [54] [UNet-Based Keypoint Regression for 3D Cone Localization in Autonomous Racing](https://arxiv.org/abs/2602.21904)
*Mariia Baidachna,James Carty,Aidan Ferguson,Joseph Agrane,Varad Kulkarni,Aubrey Agub,Michael Baxendale,Aaron David,Rachel Horton,Elliott Atkinson*

Main category: cs.CV

TL;DR: 本文提出了一种基于UNet的神经网络，用于3D空间中锥体的精确定位，显著提高了关键点检测的准确性，并展示了在自动驾驶赛车系统中的高效性能。


<details>
  <summary>Details</summary>
Motivation: 传统计算机视觉算法对环境变化敏感，而神经网络通常因数据有限和实时性不足而难以应用。

Method: 提出了一种基于UNet的神经网络，用于锥体的关键点检测，并利用了最大的自定义标记数据集。

Result: 模型在关键点准确性上显著优于传统方法，并在端到端自动驾驶系统中表现出高质量性能。

Conclusion: 该论文的方法在竞争性自动驾驶赛车系统中显示出高效性，并具有广泛应用的潜力。

Abstract: Accurate cone localization in 3D space is essential in autonomous racing for precise navigation around the track. Approaches that rely on traditional computer vision algorithms are sensitive to environmental variations, and neural networks are often trained on limited data and are infeasible to run in real time. We present a UNet-based neural network for keypoint detection on cones, leveraging the largest custom-labeled dataset we have assembled. Our approach enables accurate cone position estimation and the potential for color prediction. Our model achieves substantial improvements in keypoint accuracy over conventional methods. Furthermore, we leverage our predicted keypoints in the perception pipeline and evaluate the end-to-end autonomous system. Our results show high-quality performance across all metrics, highlighting the effectiveness of this approach and its potential for adoption in competitive autonomous racing systems.

</details>


### [55] [Off-The-Shelf Image-to-Image Models Are All You Need To Defeat Image Protection Schemes](https://arxiv.org/abs/2602.22197)
*Xavier Pleimling,Sifat Muhammad Abdullah,Gunjan Balde,Peng Gao,Mainack Mondal,Murtuza Jadliwala,Bimal Viswanath*

Main category: cs.CV

TL;DR: 研究表明，现成的GenAI模型可轻松绕过多种图像保护方案，暴露当前保护措施的脆弱性，呼吁开发更强大的防御机制。


<details>
  <summary>Details</summary>
Motivation: 揭示现有图像保护策略的脆弱性，证明无需专用方法即可绕过这些保护。

Method: 利用现成的图像到图像GenAI模型，通过简单的文本提示重新用作通用“去噪器”，以消除各种保护性扰动。

Result: 在8个案例研究中跨越6种不同的保护方案，通用攻击不仅成功绕过防御，而且优于现有专用攻击，同时保留了图像的实用性。

Conclusion: 当前图像保护方案存在广泛且严重的漏洞，许多方案提供了虚假的安全感。未来任何保护机制都必须针对现成的GenAI模型攻击进行基准测试。

Abstract: Advances in Generative AI (GenAI) have led to the development of various protection strategies to prevent the unauthorized use of images. These methods rely on adding imperceptible protective perturbations to images to thwart misuse such as style mimicry or deepfake manipulations. Although previous attacks on these protections required specialized, purpose-built methods, we demonstrate that this is no longer necessary. We show that off-the-shelf image-to-image GenAI models can be repurposed as generic ``denoisers" using a simple text prompt, effectively removing a wide range of protective perturbations. Across 8 case studies spanning 6 diverse protection schemes, our general-purpose attack not only circumvents these defenses but also outperforms existing specialized attacks while preserving the image's utility for the adversary. Our findings reveal a critical and widespread vulnerability in the current landscape of image protection, indicating that many schemes provide a false sense of security. We stress the urgent need to develop robust defenses and establish that any future protection mechanism must be benchmarked against attacks from off-the-shelf GenAI models. Code is available in this repository: https://github.com/mlsecviswanath/img2imgdenoiser

</details>


### [56] [Brain Tumor Segmentation with Special Emphasis on the Non-Enhancing Brain Tumor Compartment](https://arxiv.org/abs/2602.21703)
*T. Schaffer,A. Brawanski,S. Wein,A. M. Tomé,E. W. Lang*

Main category: cs.CV

TL;DR: U-Net架构用于分割MRI中的非增强脑肿瘤区域，填补了现有分割挑战的空白，对预后评估至关重要。


<details>
  <summary>Details</summary>
Motivation: 非增强肿瘤区域在最近的脑肿瘤分割挑战（如MICCAI）中被忽视，但其对患者生存时间和肿瘤生长区域的预测具有重要价值，因此需要自动分割方法。

Method: 采用基于U-Net的深度学习架构，针对不同MRI模态下的脑肿瘤进行分割，特别关注非增强肿瘤区域。

Result: 提出的U-Net架构能够有效分割非增强肿瘤区域，为临床提供重要信息。

Conclusion: 该论文强调了非增强肿瘤区域在脑肿瘤分割中的重要性，并提出了基于U-Net的深度学习架构来准确分割这一区域，为患者生存时间和肿瘤生长区域的预测提供了重要工具。

Abstract: A U-Net based deep learning architecture is designed to segment brain tumors as they appear on various MRI modalities. Special emphasis is lent to the non-enhancing tumor compartment. The latter has not been considered anymore in recent brain tumor segmentation challenges like the MICCAI challenges. However, it is considered to be indicative of the survival time of the patient as well as of areas of further tumor growth. Hence it deems essential to have means to automatically delineate its extension within the tumor.

</details>


### [57] [Assessing airborne laser scanning and aerial photogrammetry for deep learning-based stand delineation](https://arxiv.org/abs/2602.21709)
*Håkon Næss Sandum,Hans Ole Ørka,Oliver Tomic,Terje Gobakken*

Main category: cs.CV

TL;DR: 研究验证了U-Net框架在森林林分划分中的有效性，显示DAP-CHM可替代ALS-CHM，且DTM无显著提升，为大规模数据集构建提供了可行方案。


<details>
  <summary>Details</summary>
Motivation: 森林林分划分对森林资源调查和管理至关重要，但目前仍依赖人工且主观性强。研究旨在探索深度学习方法在结合航空影像和激光雷达数据时的表现，并评估DAP-CHM和DTM的潜在替代或补充作用。

Method: 研究采用U-Net语义分割框架，结合多光谱航空影像与三种不同数据组合（ALS-CHM、DAP-CHM、DAP-CHM+DTM），在挪威东南部六个城市进行市级交叉验证。

Result: 所有数据组合均表现出相似性能，总体准确率在0.90-0.91之间。模型预测间的一致性远高于与参考数据的一致性，凸显了模型的一致性和林分划分的主观性。

Conclusion: 研究发现，尽管DAP-CHMs在结构细节上有所减少，但其性能与ALS-CHMs相当，且DTM的加入并未显著提升效果。这表明基于深度学习的框架对输入数据的变化具有较强适应性，可以利用时间对齐的ALS和DAP点云数据构建大规模数据集。

Abstract: Accurate forest stand delineation is essential for forest inventory and management but remains a largely manual and subjective process. A recent study has shown that deep learning can produce stand delineations comparable to expert interpreters when combining aerial imagery and airborne laser scanning (ALS) data. However, temporal misalignment between data sources limits operational scalability. Canopy height models (CHMs) derived from digital photogrammetry (DAP) offer better temporal alignment but may smoothen canopy surface and canopy gaps, raising the question of whether they can reliably replace ALS-derived CHMs. Similarly, the inclusion of a digital terrain model (DTM) has been suggested to improve delineation performance, but has remained untested in published literature. Using expert-delineated forest stands as reference data, we assessed a U-Net-based semantic segmentation framework with municipality-level cross-validation across six municipalities in southeastern Norway. We compared multispectral aerial imagery combined with (i) an ALS-derived CHM, (ii) a DAP-derived CHM, and (iii) a DAP-derived CHM in combination with a DTM. Results showed comparable performance across all data combinations, reaching overall accuracy values between 0.90-0.91. Agreement between model predictions was substantially larger than agreement with the reference data, highlighting both model consistency and the inherent subjectivity of stand delineation. The similar performance of DAP-CHMs, despite the reduced structural detail, and the lack of improvements of the DTM indicate that the framework is resilient to variations in input data. These findings indicate that large datasets for deep learning-based stand delineations can be assembled using projects including temporally aligned ALS data and DAP point clouds.

</details>


### [58] [Innovative Tooth Segmentation Using Hierarchical Features and Bidirectional Sequence Modeling](https://arxiv.org/abs/2602.21712)
*Xinxin Zhao,Jian Jiang,Yan Tian,Liqin Wu,Zhaocheng Xu,Teddy Yang,Yunuo Zou,Xun Wang*

Main category: cs.CV

TL;DR: 提出一种三阶段编码器方法，结合跨尺度特征融合和双向序列建模，有效提升牙齿图像分割效果并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统图像编码器因固定分辨率特征图导致分割不连续和目标区域与背景区分不佳，且基于transformer的自注意力计算成本高。

Method: 采用三阶段编码器，通过层次化特征表示捕获尺度自适应信息，结合跨尺度特征融合和双向序列建模策略。

Result: 在两个牙科数据集上验证，OralVision数据集上mIoU提升1.1%。

Conclusion: 提出的三阶段编码器结合跨尺度特征融合和双向序列建模策略，有效解决了牙齿图像分割中的不连续性和计算效率问题，实验证明了其优越性。

Abstract: Tooth image segmentation is a cornerstone of dental digitization. However, traditional image encoders relying on fixed-resolution feature maps often lead to discontinuous segmentation and poor discrimination between target regions and background, due to insufficient modeling of environmental and global context. Moreover, transformer-based self-attention introduces substantial computational overhead because of its quadratic complexity (O(n^2)), making it inefficient for high-resolution dental images. To address these challenges, we introduce a three-stage encoder with hierarchical feature representation to capture scale-adaptive information in dental images. By jointly leveraging low-level details and high-level semantics through cross-scale feature fusion, the model effectively preserves fine structural information while maintaining strong contextual awareness. Furthermore, a bidirectional sequence modeling strategy is incorporated to enhance global spatial context understanding without incurring high computational cost.
  We validate our method on two dental datasets, with experimental results demonstrating its superiority over existing approaches. On the OralVision dataset, our model achieves a 1.1% improvement in mean intersection over union (mIoU).

</details>


### [59] [TranX-Adapter: Bridging Artifacts and Semantics within MLLMs for Robust AI-generated Image Detection](https://arxiv.org/abs/2602.21716)
*Wenbin Wang,Yuge Huang,Jianqing Xu,Yue Yu,Jiangtao Yan,Shouhong Ding,Pan Zhou,Yong Luo*

Main category: cs.CV

TL;DR: TranX-Adapter通过双向信息传输解决AIGI检测中的注意力稀释问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法中伪影特征的高类内相似性导致注意力稀释，阻碍了语义与伪影特征的有效融合，需改进。

Method: 提出TranX-Adapter，包含任务感知最优传输融合（利用Jensen-Shannon散度作为成本矩阵）和X-Fusion（跨注意力机制），以双向传输信息。

Result: 在多个先进MLLM上的标准AIGI检测基准测试中，TranX-Adapter带来了一致且显著的性能提升（最高+6%准确率）。

Conclusion: 论文提出了一种轻量级融合适配器TranX-Adapter，通过任务感知最优传输融合和X-Fusion，有效解决了语义特征与伪影特征融合中的注意力稀释问题，显著提升了AIGI检测的准确性。

Abstract: Rapid advances in AI-generated image (AIGI) technology enable highly realistic synthesis, threatening public information integrity and security. Recent studies have demonstrated that incorporating texture-level artifact features alongside semantic features into multimodal large language models (MLLMs) can enhance their AIGI detection capability. However, our preliminary analyses reveal that artifact features exhibit high intra-feature similarity, leading to an almost uniform attention map after the softmax operation. This phenomenon causes attention dilution, thereby hindering effective fusion between semantic and artifact features. To overcome this limitation, we propose a lightweight fusion adapter, TranX-Adapter, which integrates a Task-aware Optimal-Transport Fusion that leverages the Jensen-Shannon divergence between artifact and semantic prediction probabilities as a cost matrix to transfer artifact information into semantic features, and an X-Fusion that employs cross-attention to transfer semantic information into artifact features. Experiments on standard AIGI detection benchmarks upon several advanced MLLMs, show that our TranX-Adapter brings consistent and significant improvements (up to +6% accuracy).

</details>


### [60] [SigVLP: Sigmoid Volume-Language Pre-Training for Self-Supervised CT-Volume Adaptive Representation Learning](https://arxiv.org/abs/2602.21735)
*Jiayi Wang,Hadrien Reynaud,Ibrahim Ethem Hamamci,Sezgin Er,Suprosanna Shit,Bjoern Menze,Bernhard Kainz*

Main category: cs.CV

TL;DR: SigVLP通过Rotary Position Embedding和分块对齐策略，解决了医学影像数据的可变性问题，提升了文本与影像的关联性，在多项任务中表现优秀。


<details>
  <summary>Details</summary>
Motivation: 大规模医学影像数据集通常来自不同设备和厂商，导致分辨率、切片厚度和切片数量高度可变。传统方法需裁剪或插值以固定尺寸，导致信息丢失。

Method: 提出SigVLP模型，采用Rotary Position Embedding作为位置编码方法，直接在注意力操作中生成输入条件化的正弦和余弦权重，支持可变输入尺寸。训练时通过分块采样CT体积并与局部器官文本观察配对，实现细粒度监督。

Result: 模型在零样本异常和器官分类、分割及检索任务中表现优异，证明了方法的有效性。

Conclusion: SigVLP模型通过引入Rotary Position Embedding和分块对齐策略，有效解决了医学影像数据在z轴上的可变性问题，提升了文本与体积表示之间的相关性，并在多种下游任务中表现出色。

Abstract: Large-scale, volumetric medical imaging datasets typically aggregate scans from different vendors and devices, resulting in highly variable resolution, slice thicknesses, and numbers of slices per study. Consequently, training representation models usually requires cropping or interpolating along the z-axis to obtain fixed-size blocks, which inevitably causes information loss. We propose a new training approach to overcome this limitation. Instead of absolute position embeddings, we interpret volumes as sequences of 3D chunks and adopt Rotary Position Embeddings, allowing us to treat the z-axis as an unconstrained temporal dimensions. Building on this idea, we introduce a new vision-language model: SigVLP. In SigVLP, we implement Rotary Position Embedding as the positional encoding method, which is applied directly within the attention operation, generating input-conditioned sine and cosine weights on the fly. This design ensures consistent alignment between query and key projections and adapts to any input sizes. To allow for variable input size during training, we sample Computed Tomography volumes in chunks and pair them with localized organ-wise textual observations. Compared to using entire reports for conditioning, chunkwise alignment provides finer-grained supervision, enabling the model to establish stronger correlations between the text and volume representations, thereby improving the precision of text-to-volume alignment. Our models are trained with the Muon optimizer and evaluated on a diverse set of downstream tasks, including zero-shot abnormality and organ classification, segmentation, and retrieval tasks.

</details>


### [61] [Structure-to-Image: Zero-Shot Depth Estimation in Colonoscopy via High-Fidelity Sim-to-Real Adaptation](https://arxiv.org/abs/2602.21740)
*Juan Yang,Yuyan Zhang,Han Jia,Bing Hu,Wanzhong Song*

Main category: cs.CV

TL;DR: 论文提出了一种新的Structure-to-Image方法，通过相位一致性和跨层次结构约束优化结肠镜深度估计，显著降低了RMSE。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像到图像翻译方法在平衡真实性和结构一致性方面的不足，特别是在结肠镜深度估计中产生的结构扭曲和镜面高光问题。

Method: 论文引入了相位一致性到结肠镜领域适应中，并设计了跨层次结构约束，共同优化几何结构和细粒度细节（如血管纹理）。

Result: 在公开的幻影数据集上进行零样本评估时，使用生成数据微调的MDE模型在RMSE上实现了最大44.18%的降低。

Conclusion: 该论文提出了一种Structure-to-Image范式，通过将深度图从被动约束转变为主动生成基础，显著提升了结肠镜单目深度估计的准确性。

Abstract: Monocular depth estimation (MDE) for colonoscopy is hampered by the domain gap between simulated and real-world images. Existing image-to-image translation methods, which use depth as a posterior constraint, often produce structural distortions and specular highlights by failing to balance realism with structure consistency. To address this, we propose a Structure-to-Image paradigm that transforms the depth map from a passive constraint into an active generative foundation. We are the first to introduce phase congruency to colonoscopic domain adaptation and design a cross-level structure constraint to co-optimize geometric structures and fine-grained details like vascular textures. In zero-shot evaluations conducted on a publicly available phantom dataset, the MDE model that was fine-tuned on our generated data achieved a maximum reduction of 44.18% in RMSE compared to competing methods. Our code is available at https://github.com/YyangJJuan/PC-S2I.git.

</details>


### [62] [Enhancing Multi-Modal LLMs Reasoning via Difficulty-Aware Group Normalization](https://arxiv.org/abs/2602.21743)
*Jinghan Li,Junfeng Fang,Jinda Lu,Yuan Wang,Xiaoyan Guo,Tianyu Zhang,Xiang Wang,Xiangnan He*

Main category: cs.CV

TL;DR: 提出Durian方法，通过按难度重新分组样本并组内共享标准差，解决了多模态设置中std归一化的不稳定性问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 多模态设置中，基于std的归一化易受极端样本（奖励接近正负值）影响，导致不稳定。与纯文本LLM不同，多模态模型对此更敏感，因感知和推理错误均影响其响应。

Method: 提出difficulty-aware group normalization (Durian)，通过视觉熵（perceptual complexity）和模型置信度（reasoning uncertainty）定义样本难度，并按难度重新分组样本，组内共享标准差。

Result: Durian方法在多个多模态推理基准测试中取得了显著性能提升。

Conclusion: 提出的Durian方法通过按难度重新分组样本并在组内共享标准差，有效解决了多模态设置中std归一化的不稳定性问题，显著提升了多模态推理性能。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) and Group Relative Policy Optimization (GRPO) have significantly advanced the reasoning capabilities of large language models. Extending these methods to multimodal settings, however, faces a critical challenge: the instability of std-based normalization, which is easily distorted by extreme samples with nearly positive or negative rewards. Unlike pure-text LLMs, multimodal models are particularly sensitive to such distortions, as both perceptual and reasoning errors influence their responses. To address this, we characterize each sample by its difficulty, defined through perceptual complexity (measured via visual entropy) and reasoning uncertainty (captured by model confidence). Building on this characterization, we propose difficulty-aware group normalization (Durian), which re-groups samples by difficulty levels and shares the std within each group. Our approach preserves GRPO's intra-group distinctions while eliminating sensitivity to extreme cases, yielding significant performance gains across multiple multimodal reasoning benchmarks.

</details>


### [63] [LiREC-Net: A Target-Free and Learning-Based Network for LiDAR, RGB, and Event Calibration](https://arxiv.org/abs/2602.21754)
*Aditya Ranjan Dash,Ramy Battrawy,René Schuster,Didier Stricker*

Main category: cs.CV

TL;DR: LiREC-Net 是一种多传感器联合校准网络，通过共享LiDAR表示提高效率，性能媲美双模态模型，并为三模态校准设定了新基准。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的校准方法通常仅针对单一传感器模态对设计，无法满足多传感器融合的需求。因此，需要一种能够联合校准多种传感器模态的方法。

Method: LiREC-Net 引入了共享的LiDAR表示，利用其3D特性和投影深度图特征，以减少冗余计算并提高效率，确保跨模态的一致性。

Result: 在KITTI和DSEC等数据集上的训练和评估表明，LiREC-Net的性能与双模态模型相当，并为三模态用例设定了新的强基准。

Conclusion: LiREC-Net 提出了一种目标自由、基于学习的校准网络，能够在一个统一框架内联合校准多种传感器模态对（包括LiDAR、RGB和事件数据），并在多模态校准任务中设定了新的基准。

Abstract: Advanced autonomous systems rely on multi-sensor fusion for safer and more robust perception. To enable effective fusion, calibrating directly from natural driving scenes (i.e., target-free) with high accuracy is crucial for precise multi-sensor alignment. Existing learning-based calibration methods are typically designed for only a single pair of sensor modalities (i.e., a bi-modal setup). Unlike these methods, we propose LiREC-Net, a target-free, learning-based calibration network that jointly calibrates multiple sensor modality pairs, including LiDAR, RGB, and event data, within a unified framework. To reduce redundant computation and improve efficiency, we introduce a shared LiDAR representation that leverages features from both its 3D nature and projected depth map, ensuring better consistency across modalities. Trained and evaluated on established datasets, such as KITTI and DSEC, our LiREC-Net achieves competitive performance to bi-modal models and sets a new strong baseline for the tri-modal use case.

</details>


### [64] [Accelerating Diffusion via Hybrid Data-Pipeline Parallelism Based on Conditional Guidance Scheduling](https://arxiv.org/abs/2602.21760)
*Euisoo Jung,Byunghyun Kim,Hyunjin Kim,Seonghye Cho,Jae-Gil Lee*

Main category: cs.CV

TL;DR: 提出混合并行框架，结合条件分区和自适应并行切换，显著降低扩散模型生成延迟并保持质量。


<details>
  <summary>Details</summary>
Motivation: 当前基于分布式并行的扩散加速方法存在生成伪影且无法实现与GPU数量成比例的显著加速。

Method: 结合了基于条件的分区数据并行策略和自适应并行切换的管道调度方法。

Result: 在SDXL和SD3上分别实现了2.31倍和2.07倍的延迟降低，且在高分辨率合成设置下优于现有方法。

Conclusion: 该论文提出的混合并行框架在保持图像质量的同时，显著降低了生成延迟，并在不同架构的扩散模型中展示了通用性。

Abstract: Diffusion models have achieved remarkable progress in high-fidelity image, video, and audio generation, yet inference remains computationally expensive. Nevertheless, current diffusion acceleration methods based on distributed parallelism suffer from noticeable generation artifacts and fail to achieve substantial acceleration proportional to the number of GPUs. Therefore, we propose a hybrid parallelism framework that combines a novel data parallel strategy, condition-based partitioning, with an optimal pipeline scheduling method, adaptive parallelism switching, to reduce generation latency and achieve high generation quality in conditional diffusion models. The key ideas are to (i) leverage the conditional and unconditional denoising paths as a new data-partitioning perspective and (ii) adaptively enable optimal pipeline parallelism according to the denoising discrepancy between these two paths. Our framework achieves $2.31\times$ and $2.07\times$ latency reductions on SDXL and SD3, respectively, using two NVIDIA RTX~3090 GPUs, while preserving image quality. This result confirms the generality of our approach across U-Net-based diffusion models and DiT-based flow-matching architectures. Our approach also outperforms existing methods in acceleration under high-resolution synthesis settings. Code is available at https://github.com/kaist-dmlab/Hybridiff.

</details>


### [65] [SAPNet++: Evolving Point-Prompted Instance Segmentation with Semantic and Spatial Awareness](https://arxiv.org/abs/2602.21762)
*Zhaoyang Wei,Xumeng Han,Xuehui Yu,Xue Yang,Guorong Li,Zhenjun Han,Jianbin Jiao*

Main category: cs.CV

TL;DR: SAPNet++通过多模块设计解决点标注的粒度和边界问题，显著提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 单点标注在视觉任务中成本低，但面临粒度和边界不确定性的挑战，现有方法无法有效解决这些问题。

Method: 提出Semantic-Aware Point-Prompted Instance Segmentation Network (SAPNet)，结合Point Distance Guidance和Box Mining Strategy解决粒度模糊问题，引入S-MIL增强提案选择，并通过Multi-level Affinity Refinement优化边界细化。

Result: 在四个具有挑战性的数据集上的广泛实验验证了方法的有效性。

Conclusion: SAPNet++通过整合Point Distance Guidance、Box Mining Strategy、S-MIL和Multi-level Affinity Refinement等模块，有效解决了点标注带来的粒度和边界不确定性，显著提升了分割性能。

Abstract: Single-point annotation is increasingly prominent in visual tasks for labeling cost reduction. However, it challenges tasks requiring high precision, such as the point-prompted instance segmentation (PPIS) task, which aims to estimate precise masks using single-point prompts to train a segmentation network. Due to the constraints of point annotations, granularity ambiguity and boundary uncertainty arise the difficulty distinguishing between different levels of detail (eg. whole object vs. parts) and the challenge of precisely delineating object boundaries. Previous works have usually inherited the paradigm of mask generation along with proposal selection to achieve PPIS. However, proposal selection relies solely on category information, failing to resolve the ambiguity of different granularity. Furthermore, mask generators offer only finite discrete solutions that often deviate from actual masks, particularly at boundaries. To address these issues, we propose the Semantic-Aware Point-Prompted Instance Segmentation Network (SAPNet). It integrates Point Distance Guidance and Box Mining Strategy to tackle group and local issues caused by the point's granularity ambiguity. Additionally, we incorporate completeness scores within proposals to add spatial granularity awareness, enhancing multiple instance learning (MIL) in proposal selection termed S-MIL. The Multi-level Affinity Refinement conveys pixel and semantic clues, narrowing boundary uncertainty during mask refinement. These modules culminate in SAPNet++, mitigating point prompt's granularity ambiguity and boundary uncertainty and significantly improving segmentation performance. Extensive experiments on four challenging datasets validate the effectiveness of our methods, highlighting the potential to advance PPIS.

</details>


### [66] [From Statics to Dynamics: Physics-Aware Image Editing with Latent Transition Priors](https://arxiv.org/abs/2602.21778)
*Liangbing Zhao,Le Zhuo,Sayak Paul,Hongsheng Li,Mohamed Elhoseiny*

Main category: cs.CV

TL;DR: PhysicEdit通过物理状态过渡和双思维机制，显著提升了复杂动态图像编辑的物理真实性和知识基础能力。


<details>
  <summary>Details</summary>
Motivation: 现有指令式图像编辑模型在处理涉及复杂因果动态（如折射或材料变形）时，常无法生成物理上合理的结果。

Method: 提出了PhysicEdit框架，结合了冻结的Qwen2.5-VL进行物理基础推理和可学习的过渡查询，为扩散主干提供时间步自适应的视觉指导。

Result: PhysicEdit在物理真实性和知识基础编辑上分别比Qwen-Image-Edit提升了5.9%和10.1%，成为开源方法的新标杆。

Conclusion: PhysicEdit通过结合物理基础的推理和可学习的过渡查询，显著提升了图像编辑的物理真实性和知识基础编辑能力，成为开源方法的新标杆。

Abstract: Instruction-based image editing has achieved remarkable success in semantic alignment, yet state-of-the-art models frequently fail to render physically plausible results when editing involves complex causal dynamics, such as refraction or material deformation. We attribute this limitation to the dominant paradigm that treats editing as a discrete mapping between image pairs, which provides only boundary conditions and leaves transition dynamics underspecified. To address this, we reformulate physics-aware editing as predictive physical state transitions and introduce PhysicTran38K, a large-scale video-based dataset comprising 38K transition trajectories across five physical domains, constructed via a two-stage filtering and constraint-aware annotation pipeline. Building on this supervision, we propose PhysicEdit, an end-to-end framework equipped with a textual-visual dual-thinking mechanism. It combines a frozen Qwen2.5-VL for physically grounded reasoning with learnable transition queries that provide timestep-adaptive visual guidance to a diffusion backbone. Experiments show that PhysicEdit improves over Qwen-Image-Edit by 5.9% in physical realism and 10.1% in knowledge-grounded editing, setting a new state-of-the-art for open-source methods, while remaining competitive with leading proprietary models.

</details>


### [67] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2602.21780)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: XStreamVGGT通过剪枝和量化技术优化KV缓存，显著提升了流式3D重建的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: StreamVGGT在处理多图像和长视频输入时，KV缓存会无限增长，导致内存消耗和推理延迟增加，限制了其可扩展性。

Method: 提出了XStreamVGGT，一种无需调优的方法，通过剪枝和量化压缩KV缓存。具体包括基于令牌重要性识别的剪枝机制和维度自适应的KV量化。

Result: XStreamVGGT在性能损失极小的情况下，内存使用减少了4.42倍，推理速度提升了5.48倍。

Conclusion: XStreamVGGT通过无缝集成剪枝和量化技术，显著降低了KV缓存的内存占用和推理延迟，实现了高效且可扩展的流式3D重建。

Abstract: Learning-based 3D visual geometry models have significantly advanced with the advent of large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention to deliver robust and efficient streaming 3D reconstruction. However, it suffers from unbounded growth in the Key-Value (KV) cache due to the massive influx of vision tokens from multi-image and long-video inputs, leading to increased memory consumption and inference latency as input frames accumulate. This ultimately limits its scalability for long-horizon applications. To address this gap, we propose XStreamVGGT, a tuning-free approach that seamlessly integrates pruning and quantization to systematically compress the KV cache, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs generated from multi-frame inputs are initially pruned to conform to a fixed KV memory budget using an efficient token-importance identification mechanism that maintains full compatibility with high-performance attention kernels (e.g., FlashAttention). Additionally, leveraging the inherent distribution patterns of KV tensors, we apply dimension-adaptive KV quantization within the pruning pipeline to further minimize memory overhead while preserving numerical accuracy. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling practical and scalable streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [68] [GeoMotion: Rethinking Motion Segmentation via Latent 4D Geometry](https://arxiv.org/abs/2602.21810)
*Xiankang He,Peile Lin,Ying Cui,Dongyan Guo,Chunhua Shen,Xiaoqin Zhang*

Main category: cs.CV

TL;DR: 论文提出了一种端到端的学习方法，通过注意力机制直接推断运动物体，避免了传统方法中的显式对应估计，实现了高效且高性能的运动分割。


<details>
  <summary>Details</summary>
Motivation: 动态场景中的运动分割极具挑战性，传统方法依赖于从固有噪声运动线索中估计相机姿态和点对应关系，多阶段流程中的累积误差导致性能有限或计算成本高。

Method: 提出了一种完全基于学习的方法，通过注意力机制直接从潜在特征表示推断移动物体，绕过了显式对应估计。

Result: 广泛的实验表明，该方法通过消除复杂的预处理和迭代优化，实现了最先进的运动分割性能和高效率。

Conclusion: 该论文提出的基于学习的方法通过端到端的前馈运动分割，绕过了显式对应估计，实现了最先进的运动分割性能和高效率。

Abstract: Motion segmentation in dynamic scenes is highly challenging, as conventional methods heavily rely on estimating camera poses and point correspondences from inherently noisy motion cues. Existing statistical inference or iterative optimization techniques that struggle to mitigate the cumulative errors in multi-stage pipelines often lead to limited performance or high computational cost. In contrast, we propose a fully learning-based approach that directly infers moving objects from latent feature representations via attention mechanisms, thus enabling end-to-end feed-forward motion segmentation. Our key insight is to bypass explicit correspondence estimation and instead let the model learn to implicitly disentangle object and camera motion. Supported by recent advances in 4D scene geometry reconstruction (e.g., $π^3$), the proposed method leverages reliable camera poses and rich spatial-temporal priors, which ensure stable training and robust inference for the model. Extensive experiments demonstrate that by eliminating complex pre-processing and iterative refinement, our approach achieves state-of-the-art motion segmentation performance with high efficiency. The code is available at:https://github.com/zjutcvg/GeoMotion.

</details>


### [69] [SkyReels-V4: Multi-modal Video-Audio Generation, Inpainting and Editing model](https://arxiv.org/abs/2602.21818)
*Guibin Chen,Dixuan Lin,Jiangping Yang,Youqiang Zhang,Zhengcong Fei,Debang Li,Sheng Chen,Chaofeng Ao,Nuo Pang,Yiming Wang,Yikun Dou,Zheng Chen,Mingyuan Fan,Tuanhui Li,Mingshan Chang,Hao Zhang,Xiaopeng Sun,Jingtao Xu,Yuqiang Xie,Jiahua Wang,Zhiheng Xu,Weiming Xiong,Yuzhe Jin,Baoxuan Gu,Binjie Mao,Yunjie Yu,Jujie He,Yuhao Feng,Shiwen Tu,Chaojie Wang,Rui Yan,Wei Shen,Jingchen Wu,Peng Zhao,Xuanyue Zhong,Zhuangzhuang Liu,Kaifei Wang,Fuxiang Zhang,Weikai Xu,Wenyan Liu,Binglu Zhang,Yu Shen,Tianhui Xiong,Bin Peng,Liang Zeng,Xuchen Song,Haoxiang Guo,Peiyu Wang,Yahui Zhou*

Main category: cs.CV

TL;DR: SkyReels V4 是一个多模态视频基础模型，支持联合视频音频生成、修复和编辑，采用高效架构实现电影级质量。


<details>
  <summary>Details</summary>
Motivation: 旨在解决多模态视频生成、修复和编辑的统一处理问题，同时实现高保真、多镜头、电影级视频与同步音频的生成。

Method: 采用双流多模态扩散变换器（MMDiT）架构，结合多模态大型语言模型（MMLM）的文本编码器，支持多种模态指令输入，并通过联合生成低分辨率全序列和高分辨率关键帧实现高效计算。

Result: 支持1080p分辨率、32 FPS和15秒时长的视频生成，实现了高保真、多镜头、电影级视频与同步音频的联合生成。

Conclusion: SkyReels V4 是首个同时支持多模态输入、联合视频音频生成，并在电影级分辨率和时长下保持高效与高质量的视频基础模型。

Abstract: SkyReels V4 is a unified multi modal video foundation model for joint video audio generation, inpainting, and editing. The model adopts a dual stream Multimodal Diffusion Transformer (MMDiT) architecture, where one branch synthesizes video and the other generates temporally aligned audio, while sharing a powerful text encoder based on the Multimodal Large Language Models (MMLM). SkyReels V4 accepts rich multi modal instructions, including text, images, video clips, masks, and audio references. By combining the MMLMs multi modal instruction following capability with in context learning in the video branch MMDiT, the model can inject fine grained visual guidance under complex conditioning, while the audio branch MMDiT simultaneously leverages audio references to guide sound generation. On the video side, we adopt a channel concatenation formulation that unifies a wide range of inpainting style tasks, such as image to video, video extension, and video editing under a single interface, and naturally extends to vision referenced inpainting and editing via multi modal prompts. SkyReels V4 supports up to 1080p resolution, 32 FPS, and 15 second duration, enabling high fidelity, multi shot, cinema level video generation with synchronized audio. To make such high resolution, long-duration generation computationally feasible, we introduce an efficiency strategy: Joint generation of low resolution full sequences and high-resolution keyframes, followed by dedicated super-resolution and frame interpolation models. To our knowledge, SkyReels V4 is the first video foundation model that simultaneously supports multi-modal input, joint video audio generation, and a unified treatment of generation, inpainting, and editing, while maintaining strong efficiency and quality at cinematic resolutions and durations.

</details>


### [70] [Joint Shadow Generation and Relighting via Light-Geometry Interaction Maps](https://arxiv.org/abs/2602.21820)
*Shan Wang,Peixia Li,Chenchen Xu,Ziang Cheng,Jiayu Yang,Hongdong Li,Pulak Purkait*

Main category: cs.CV

TL;DR: LGI是一种新型光几何交互映射，通过物理先验约束生成模型，实现高效且一致的阴影生成和重光照。


<details>
  <summary>Details</summary>
Motivation: 解决现有生成模型中因缺乏物理先验导致的浮动阴影、不一致光照和不合理阴影几何问题。

Method: 提出LGI映射和基于桥匹配的生成主干，结合联合阴影生成和重光照的统一流程。

Result: 实验表明，LGI在合成和真实图像中显著提升了真实感和一致性。

Conclusion: LGI通过将几何启发式渲染与生成建模相结合，实现了高效且物理一致的阴影生成和重光照。

Abstract: We propose Light-Geometry Interaction (LGI) maps, a novel representation that encodes light-aware occlusion from monocular depth. Unlike ray tracing, which requires full 3D reconstruction, LGI captures essential light-shadow interactions reliably and accurately, computed from off-the-shelf 2.5D depth map predictions. LGI explicitly ties illumination direction to geometry, providing a physics-inspired prior that constrains generative models. Without such prior, these models often produce floating shadows, inconsistent illumination, and implausible shadow geometry. Building on this representation, we propose a unified pipeline for joint shadow generation and relighting - unlike prior methods that treat them as disjoint tasks - capturing the intrinsic coupling of illumination and shadowing essential for modeling indirect effects. By embedding LGI into a bridge-matching generative backbone, we reduce ambiguity and enforce physically consistent light-shadow reasoning. To enable effective training, we curated the first large-scale benchmark dataset for joint shadow and relighting, covering reflections, transparency, and complex interreflections. Experiments show significant gains in realism and consistency across synthetic and real images. LGI thus bridges geometry-inspired rendering with generative modeling, enabling efficient, physically consistent shadow generation and relighting.

</details>


### [71] [UniVBench: Towards Unified Evaluation for Video Foundation Models](https://arxiv.org/abs/2602.21835)
*Jianhui Wei,Xiaotian Zhang,Yichen Li,Yuan Wang,Yan Zhang,Ziyi Chen,Zhihang Tang,Wei Xu,Zuozhu Liu*

Main category: cs.CV

TL;DR: UniVBench 是一个专为评估视频基础模型设计的基准测试，覆盖视频理解、生成、编辑和重建四大能力，通过高质量视频和统一评估系统推动模型发展。


<details>
  <summary>Details</summary>
Motivation: 现有的视频基础模型评估基准分散且范围有限，无法全面评估模型在视频理解、生成、编辑等任务中的统一能力。因此，需要一个新的基准来填补这一空白。

Method: 研究团队开发了 UniVBench 基准测试，包含 200 个高质量、多样化的多镜头视频，并配有详细字幕、多格式编辑指令和参考图像。同时，设计了统一的代理评估系统（UniV-Eval），标准化了所有任务的提示、指令解析和评分。

Result: UniVBench 通过多镜头视频任务和统一的评估系统，首次实现了对视频基础模型综合能力的评估，并通过人类标注验证了其有效性。

Conclusion: UniVBench 提供了一个全面的评估框架，首次实现了对视频基础模型在视频理解、生成、编辑和重建等核心能力上的统一评估，并通过人类标注确保评估与人类判断一致，推动了稳健视频智能的发展。

Abstract: Video foundation models aim to integrate video understanding, generation, editing, and instruction following within a single framework, making them a central direction for next-generation multimodal systems. However, existing evaluation benchmarks remain fragmented and limited in scope, as they each target a single task, rely on task-specific metrics, and typically use short or simple video clips. As a result, they do not capture the unified capabilities that these models are designed to deliver. To address this gap, we introduce UniVBench, a benchmark purpose-built for evaluating video foundation models across four core abilities: video understanding, video generation, video editing, and a newly proposed task, video reconstruction, which assesses how faithfully a model can reproduce video content it has encountered. Our benchmark substantially expands the complexity of evaluation by incorporating 200 high-quality, diverse and multi-shot videos, each paired with detailed captions, multi-format editing instructions, and reference images. All videos are human-created and carefully validated, offering richer cinematic information than prior benchmarks. In addition, we develop a unified agentic evaluation system (UniV-Eval) that standardizes prompting, instruction parsing, and scoring across all tasks, enabling fair, scalable, and reproducible comparisons of unified video models. By grounding evaluation in instruction-based multi-shot video tasks, UniVBench provides the first framework for measuring the integrated capabilities that video foundation models aim to achieve. Extensive human annotations ensure our evaluation aligns with human judgment, enabling rigorous assessment and accelerating progress toward robust video intelligence.

</details>


### [72] [Meta-FC: Meta-Learning with Feature Consistency for Robust and Generalizable Watermarking](https://arxiv.org/abs/2602.21849)
*Yuheng Li,Weitong Chen,Chengcheng Zhu,Jiale Zhang,Chunpeng Ge,Di Wu,Guodong Long*

Main category: cs.CV

TL;DR: 提出Meta-FC训练策略，通过元学习和特征一致性提升水印模型的鲁棒性和泛化能力，实验证明其优于传统SRD策略。


<details>
  <summary>Details</summary>
Motivation: 当前基于单随机失真（SRD）的训练策略忽视了不同类型失真之间的内在关系，导致批次间的优化冲突，限制了水印模型的鲁棒性和泛化能力。

Method: 提出了一种基于元学习和特征一致性的新型训练策略（Meta-FC），通过随机采样多种失真构建元训练任务，并保留一种失真作为模拟的“未知”失真用于元测试阶段。

Result: 实验表明，Meta-FC相比SRD策略，在高强度、组合和未知失真下，平均提升了水印模型的鲁棒性和泛化能力。

Conclusion: Meta-FC训练策略通过元学习和特征一致性损失，显著提高了水印模型在高强度、组合和未知失真下的鲁棒性和泛化能力，平均提升了1.59%、4.71%和2.38%。

Abstract: Deep learning-based watermarking has made remarkable progress in recent years. To achieve robustness against various distortions, current methods commonly adopt a training strategy where a \underline{\textbf{s}}ingle \underline{\textbf{r}}andom \underline{\textbf{d}}istortion (SRD) is chosen as the noise layer in each training batch. However, the SRD strategy treats distortions independently within each batch, neglecting the inherent relationships among different types of distortions and causing optimization conflicts across batches. As a result, the robustness and generalizability of the watermarking model are limited. To address this issue, we propose a novel training strategy that enhances robustness and generalization via \underline{\textbf{meta}}-learning with \underline{\textbf{f}}eature \underline{\textbf{c}}onsistency (Meta-FC). Specifically, we randomly sample multiple distortions from the noise pool to construct a meta-training task, while holding out one distortion as a simulated ``unknown'' distortion for the meta-testing phase. Through meta-learning, the model is encouraged to identify and utilize neurons that exhibit stable activations across different types of distortions, mitigating the optimization conflicts caused by the random sampling of diverse distortions in each batch. To further promote the transformation of stable activations into distortion-invariant representations, we introduce a feature consistency loss that constrains the decoded features of the same image subjected to different distortions to remain consistent. Extensive experiments demonstrate that, compared to the SRD training strategy, Meta-FC improves the robustness and generalization of various watermarking models by an average of 1.59\%, 4.71\%, and 2.38\% under high-intensity, combined, and unknown distortions.

</details>


### [73] [GFPL: Generative Federated Prototype Learning for Resource-Constrained and Data-Imbalanced Vision Task](https://arxiv.org/abs/2602.21873)
*Shiwei Lu,Yuhang He,Jiashuo Li,Qiang Wang,Yihong Gong*

Main category: cs.CV

TL;DR: GFPL框架通过原型生成和聚合策略，有效提升联邦学习在不平衡数据下的性能，同时降低通信开销。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习中因模型更新偏向多数类特征导致的知识融合无效，以及高维模型参数频繁传输带来的通信开销问题。

Method: 提出了一种基于高斯混合模型的原型生成方法和使用Bhattacharyya距离的原型聚合策略，结合双分类器架构和混合损失函数进行优化。

Result: 在基准测试中，GFPL在不平衡数据设置下将模型准确率提高了3.6%，同时保持了较低的通信成本。

Conclusion: GFPL框架通过原型生成和聚合策略有效解决了联邦学习中的知识融合和通信开销问题，显著提升了模型在不平衡数据下的准确率。

Abstract: Federated learning (FL) facilitates the secure utilization of decentralized images, advancing applications in medical image recognition and autonomous driving. However, conventional FL faces two critical challenges in real-world deployment: ineffective knowledge fusion caused by model updates biased toward majority-class features, and prohibitive communication overhead due to frequent transmissions of high-dimensional model parameters. Inspired by the human brain's efficiency in knowledge integration, we propose a novel Generative Federated Prototype Learning (GFPL) framework to address these issues. Within this framework, a prototype generation method based on Gaussian Mixture Model (GMM) captures the statistical information of class-wise features, while a prototype aggregation strategy using Bhattacharyya distance effectively fuses semantically similar knowledge across clients. In addition, these fused prototypes are leveraged to generate pseudo-features, thereby mitigating feature distribution imbalance across clients. To further enhance feature alignment during local training, we devise a dual-classifier architecture, optimized via a hybrid loss combining Dot Regression and Cross-Entropy. Extensive experiments on benchmarks show that GFPL improves model accuracy by 3.6% under imbalanced data settings while maintaining low communication cost.

</details>


### [74] [How to Take a Memorable Picture? Empowering Users with Actionable Feedback](https://arxiv.org/abs/2602.21877)
*Francesco Laiti,Davide Talon,Jacopo Staiano,Elisa Ricci*

Main category: cs.CV

TL;DR: 论文提出MemFeed任务和MemCoach方法，通过自然语言指导提升图像记忆性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决传统图像记忆性研究中缺乏在拍摄时为用户提供可操作指导的问题，提出MemFeed任务，旨在通过自动化模型提供可解释的建议以增强图像的未来回忆。

Method: 论文提出的方法MemCoach基于多模态大语言模型（MLLMs），采用无需训练的师生引导策略，将模型内部激活与从教师模型中学到的更易记忆的模式对齐。

Result: 实验结果表明，MemCoach在多个MLLMs上表现优异，相比零样本模型有持续改进的性能。

Conclusion: 该论文的结论是，图像记忆性不仅可以预测，还可以通过自然语言指导进行提升，将重点从单纯的预测转向为人类创作者提供可操作的反馈。

Abstract: Image memorability, i.e., how likely an image is to be remembered, has traditionally been studied in computer vision either as a passive prediction task, with models regressing a scalar score, or with generative methods altering the visual input to boost the image likelihood of being remembered. Yet, none of these paradigms supports users at capture time, when the crucial question is how to improve a photo memorability. We introduce the task of Memorability Feedback (MemFeed), where an automated model should provide actionable, human-interpretable guidance to users with the goal to enhance an image future recall. We also present MemCoach, the first approach designed to provide concrete suggestions in natural language for memorability improvement (e.g., "emphasize facial expression," "bring the subject forward"). Our method, based on Multimodal Large Language Models (MLLMs), is training-free and employs a teacher-student steering strategy, aligning the model internal activations toward more memorable patterns learned from a teacher model progressing along least-to-most memorable samples. To enable systematic evaluation on this novel task, we further introduce MemBench, a new benchmark featuring sequence-aligned photoshoots with annotated memorability scores. Our experiments, considering multiple MLLMs, demonstrate the effectiveness of MemCoach, showing consistently improved performance over several zero-shot models. The results indicate that memorability can not only be predicted but also taught and instructed, shifting the focus from mere prediction to actionable feedback for human creators.

</details>


### [75] [EndoDDC: Learning Sparse to Dense Reconstruction for Endoscopic Robotic Navigation via Diffusion Depth Completion](https://arxiv.org/abs/2602.21893)
*Yinheng Lin,Yiming Huang,Beilei Cui,Long Bai,Huxin Gao,Hongliang Ren,Jiewen Lai*

Main category: cs.CV

TL;DR: EndoDDC通过整合图像、稀疏深度和深度梯度特征，利用扩散模型优化深度图，显著提升内窥镜环境下的深度估计性能。


<details>
  <summary>Details</summary>
Motivation: 内窥镜手术机器人的导航依赖精确深度估计，现有自监督深度估计技术在弱纹理和变光照环境下性能下降，深度补全技术在内窥镜领域应用有限。

Method: 提出EndoDDC方法，结合图像、稀疏深度信息与深度梯度特征，通过扩散模型优化深度图，解决内窥镜环境中弱纹理和光照变化问题。

Result: 在两个公开内窥镜数据集上的实验表明，EndoDDC在深度准确性和鲁棒性上优于现有最优模型。

Conclusion: EndoDDC方法通过整合图像、稀疏深度信息和深度梯度特征，并利用扩散模型优化深度图，显著提升了内窥镜环境下的深度估计准确性和鲁棒性，展示了在复杂内窥镜环境中减少视觉误差的潜力。

Abstract: Accurate depth estimation plays a critical role in the navigation of endoscopic surgical robots, forming the foundation for 3D reconstruction and safe instrument guidance. Fine-tuning pretrained models heavily relies on endoscopic surgical datasets with precise depth annotations. While existing self-supervised depth estimation techniques eliminate the need for accurate depth annotations, their performance degrades in environments with weak textures and variable lighting, leading to sparse reconstruction with invalid depth estimation. Depth completion using sparse depth maps can mitigate these issues and improve accuracy. Despite the advances in depth completion techniques in general fields, their application in endoscopy remains limited. To overcome these limitations, we propose EndoDDC, an endoscopy depth completion method that integrates images, sparse depth information with depth gradient features, and optimizes depth maps through a diffusion model, addressing the issues of weak texture and light reflection in endoscopic environments. Extensive experiments on two publicly available endoscopy datasets show that our approach outperforms state-of-the-art models in both depth accuracy and robustness. This demonstrates the potential of our method to reduce visual errors in complex endoscopic environments. Our code will be released at https://github.com/yinheng-lin/EndoDDC.

</details>


### [76] [TIRAuxCloud: A Thermal Infrared Dataset for Day and Night Cloud Detection](https://arxiv.org/abs/2602.21905)
*Alexis Apostolakis,Vasileios Botsos,Niklas Wölki,Andrea Spichtinger,Nikolaos Ioannis Bountos,Ioannis Papoutsis,Panayiotis Tsanakas*

Main category: cs.CV

TL;DR: TIRAuxCloud是一个结合多光谱和辅助数据的数据集，旨在提升昼夜云检测的准确性，并通过基准测试验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 云层是地球观测的主要障碍，尤其在夜间缺乏可见光和近红外波段数据时，热红外（TIR）影像成为关键，但其低分辨率和有限光谱信息限制了准确性。

Method: 提出TIRAuxCloud数据集，结合Landsat和VIIRS的多光谱数据（TIR、光学和近红外波段）与辅助信息层（如高程、土地覆盖、气象变量和无云参考图像）。

Result: 通过监督学习和迁移学习的基准测试，验证了数据集在提升昼夜云检测模型性能方面的价值。

Conclusion: TIRAuxCloud数据集通过结合多光谱数据和辅助信息层，显著提升了昼夜云检测的准确性，为相关研究提供了有价值的资源。

Abstract: Clouds are a major obstacle in Earth observation, limiting the usability and reliability of critical remote sensing applications such as fire disaster response, urban heat island monitoring, and snow and ice cover mapping. Therefore, the ability to detect clouds 24/7 is of paramount importance. While visible and near-infrared bands are effective for daytime cloud detection, their dependence on solar illumination makes them unsuitable for nighttime monitoring. In contrast, thermal infrared (TIR) imagery plays a crucial role in detecting clouds at night, when sunlight is absent. Due to their generally lower temperatures, clouds emit distinct thermal signatures that are detectable in TIR bands. Despite this, accurate nighttime cloud detection remains challenging due to limited spectral information and the typically lower spatial resolution of TIR imagery. To address these challenges, we present TIRAuxCloud, a multi-modal dataset centered around thermal spectral data to facilitate cloud segmentation under both daytime and nighttime conditions. The dataset comprises a unique combination of multispectral data (TIR, optical, and near-infrared bands) from Landsat and VIIRS, aligned with auxiliary information layers. Elevation, land cover, meteorological variables, and cloud-free reference images are included to help reduce surface-cloud ambiguity and cloud formation uncertainty. To overcome the scarcity of manual cloud labels, we include a large set of samples with automated cloud masks and a smaller manually annotated subset to further evaluate and improve models. Comprehensive benchmarks are presented to establish performance baselines through supervised and transfer learning, demonstrating the dataset's value in advancing the development of innovative methods for day and night time cloud detection.

</details>


### [77] [Protein Graph Neural Networks for Heterogeneous Cryo-EM Reconstruction](https://arxiv.org/abs/2602.21915)
*Jonathan Krook,Axel Janson,Joakim andén,Melanie Weber,Ozan Öktem*

Main category: cs.CV

TL;DR: 提出了一种几何感知的GNN方法，用于冷冻电镜重建，通过结合结构先验和数据驱动学习，提高了构象预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 为了在冷冻电镜重建中更好地利用蛋白质结构先验，提高原子骨架构象预测的准确性。

Method: 提出了一种基于图神经网络（GNN）的自动解码器方法，将图像潜在变量映射到模板构象的3D位移，结合了可微分冷冻电镜前向模型的数据差异项和几何正则化。

Result: 在分子动力学轨迹合成的数据集上，所提出的GNN方法比类似规模的多层感知机（MLP）实现了更高的准确性。

Conclusion: 该方法通过结合几何先验和数据驱动的学习，在异构单粒子冷冻电镜重建中实现了更高的准确性，证明了几何感知的归纳偏置的有效性。

Abstract: We present a geometry-aware method for heterogeneous single-particle cryogenic electron microscopy (cryo-EM) reconstruction that predicts atomic backbone conformations. To incorporate protein-structure priors, we represent the backbone as a graph and use a graph neural network (GNN) autodecoder that maps per-image latent variables to 3D displacements of a template conformation. The objective combines a data-discrepancy term based on a differentiable cryo-EM forward model with geometric regularization, and it supports unknown orientations via ellipsoidal support lifting (ESL) pose estimation. On synthetic datasets derived from molecular dynamics trajectories, the proposed GNN achieves higher accuracy compared to a multilayer perceptron (MLP) of comparable size, highlighting the benefits of a geometry-informed inductive bias.

</details>


### [78] [Scan Clusters, Not Pixels: A Cluster-Centric Paradigm for Efficient Ultra-high-definition Image Restoration](https://arxiv.org/abs/2602.21917)
*Chen Wu,Ling Wang,Zhuoran Zheng,Yuning Cui,Zhixiong Yang,Xiangyu Chen,Yue Zhang,Weidong Jiang,Jingyuan Xia*

Main category: cs.CV

TL;DR: C$^2$SSM通过聚类串行扫描替代像素串行扫描，显著提升超高分辨率图像恢复效率，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型受限于逐像素操作，计算成本不可持续；Mamba等状态空间模型虽承诺线性复杂度，但像素串行扫描仍是超高分辨率内容的瓶颈。

Method: 提出C$^2$SSM模型，利用神经参数化混合模型将图像特征分布提炼为稀疏的语义聚类中心，通过双路径过程（聚类中心扫描与全局上下文扩散）实现高效全局建模。

Result: C$^2$SSM在五个超高分辨率恢复任务中实现了计算成本的大幅降低，并建立了新的最先进性能。

Conclusion: C$^2$SSM通过从像素串行扫描转向聚类串行扫描，显著提升了超高分辨率图像恢复的效率，同时保持了高性能，为大规模视觉任务开辟了新方向。

Abstract: Ultra-High-Definition (UHD) image restoration is trapped in a scalability crisis: existing models, bound to pixel-wise operations, demand unsustainable computation. While state space models (SSMs) like Mamba promise linear complexity, their pixel-serial scanning remains a fundamental bottleneck for the millions of pixels in UHD content. We ask: must we process every pixel to understand the image? This paper introduces C$^2$SSM, a visual state space model that breaks this taboo by shifting from pixel-serial to cluster-serial scanning. Our core discovery is that the rich feature distribution of a UHD image can be distilled into a sparse set of semantic centroids via a neural-parameterized mixture model. C$^2$SSM leverages this to reformulate global modeling into a novel dual-path process: it scans and reasons over a handful of cluster centers, then diffuses the global context back to all pixels through a principled similarity distribution, all while a lightweight modulator preserves fine details. This cluster-centric paradigm achieves a decisive leap in efficiency, slashing computational costs while establishing new state-of-the-art results across five UHD restoration tasks. More than a solution, C$^2$SSM charts a new course for efficient large-scale vision: scan clusters, not pixels.

</details>


### [79] [Geometry-as-context: Modulating Explicit 3D in Scene-consistent Video Generation to Geometry Context](https://arxiv.org/abs/2602.21929)
*JiaKui Hu,Jialun Liu,Liying Yang,Xinliang Zhang,Kaiwen Li,Shuang Zeng,Yuanwei Li,Haibin Huang,Chi Zhang,Yanye Lu*

Main category: cs.CV

TL;DR: 提出“geometry-as-context”方法，通过几何估计和新视图模拟，结合相机门控注意力模块，显著提升场景一致性视频生成的效果。


<details>
  <summary>Details</summary>
Motivation: 克服先前方法因中间输出错误、不可微分过程及分离模型导致的误差累积问题，提升场景一致性视频生成的性能。

Method: 采用“geometry-as-context”方法，结合自回归相机控制视频生成模型，通过估计当前视图的几何信息并模拟新视图图像，开发了相机门控注意力模块以有效利用相机姿态。

Result: 在单向和往返轨迹的场景视频生成测试中表现优异。

Conclusion: 该方法在保持场景一致性和相机控制方面优于先前的方法。

Abstract: Scene-consistent video generation aims to create videos that explore 3D scenes based on a camera trajectory. Previous methods rely on video generation models with external memory for consistency, or iterative 3D reconstruction and inpainting, which accumulate errors during inference due to incorrect intermediary outputs, non-differentiable processes, and separate models. To overcome these limitations, we introduce ``geometry-as-context". It iteratively completes the following steps using an autoregressive camera-controlled video generation model: (1) estimates the geometry of the current view necessary for 3D reconstruction, and (2) simulates and restores novel view images rendered by the 3D scene. Under this multi-task framework, we develop the camera gated attention module to enhance the model's capability to effectively leverage camera poses. During the training phase, text contexts are utilized to ascertain whether geometric or RGB images should be generated. To ensure that the model can generate RGB-only outputs during inference, the geometry context is randomly dropped from the interleaved text-image-geometry training sequence. The method has been tested on scene video generation with one-direction and forth-and-back trajectories. The results show its superiority over previous approaches in maintaining scene consistency and camera control.

</details>


### [80] [Directed Ordinal Diffusion Regularization for Progression-Aware Diabetic Retinopathy Grading](https://arxiv.org/abs/2602.21942)
*Huangwei Chen,Junhao Jia,Ruocheng Li,Cunyuan Yang,Wu Li,Xiaotao Pang,Yifei Chen,Haishuai Wang,Jiajun Bu,Lei Wu*

Main category: cs.CV

TL;DR: D-ODR通过有向图建模DR进展，防止反向转换，提升了分级性能。


<details>
  <summary>Details</summary>
Motivation: 现有序数回归方法将糖尿病视网膜病变（DR）严重程度建模为静态、对称的等级，忽略了疾病进展的固有单向性，导致特征表示可能违反生物合理性。

Method: 提出了Directed Ordinal Diffusion Regularization (D-ODR)，通过构建一个进展约束的有向图，在多尺度扩散中施加惩罚，防止模型学习生物不一致的反向转换。

Result: D-ODR在广泛实验中表现出优于现有序数回归和DR特定分级方法的性能。

Conclusion: D-ODR通过显式建模特征空间为有向流，有效防止了生物不一致的反向转换，提供了更临床可靠的疾病严重程度评估。

Abstract: Diabetic Retinopathy (DR) progresses as a continuous and irreversible deterioration of the retina, following a well-defined clinical trajectory from mild to severe stages. However, most existing ordinal regression approaches model DR severity as a set of static, symmetric ranks, capturing relative order while ignoring the inherent unidirectional nature of disease progression. As a result, the learned feature representations may violate biological plausibility, allowing implausible proximity between non-consecutive stages or even reverse transitions. To bridge this gap, we propose Directed Ordinal Diffusion Regularization (D-ODR), which explicitly models the feature space as a directed flow by constructing a progression-constrained directed graph that strictly enforces forward disease evolution. By performing multi-scale diffusion on this directed structure, D-ODR imposes penalties on score inversions along valid progression paths, thereby effectively preventing the model from learning biologically inconsistent reverse transitions. This mechanism aligns the feature representation with the natural trajectory of DR worsening. Extensive experiments demonstrate that D-ODR yields superior grading performance compared to state-of-the-art ordinal regression and DR-specific grading methods, offering a more clinically reliable assessment of disease severity. Our code is available on https://github.com/HovChen/D-ODR.

</details>


### [81] [Mobile-Ready Automated Triage of Diabetic Retinopathy Using Digital Fundus Images](https://arxiv.org/abs/2602.21943)
*Aadi Joshi,Manav S. Sharma,Vijay Uttam Rathod,Ashlesha Sawant,Prajakta Musale,Asmita B. Kalamkar*

Main category: cs.CV

TL;DR: 提出轻量级深度学习框架，用于高效评估糖尿病视网膜病变严重程度，模型性能优异，适合资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 糖尿病视网膜病变是全球视力损害的主要原因，但手动诊断耗时且易出错，导致筛查延迟。

Method: 使用MobileNetV3架构和CORAL头部建模疾病的有序进展，结合预处理流程（包括圆形裁剪和光照归一化），在APTOS 2019和IDRiD数据集上进行训练和验证。

Result: 模型在3折交叉验证和消融研究中表现优异，QWK得分为0.9019，准确率达80.03%。

Conclusion: 该论文提出了一个轻量级的自动化深度学习框架，用于高效评估糖尿病视网膜病变的严重程度，为资源受限环境提供了可扩展且实用的早期筛查工具。

Abstract: Diabetic Retinopathy (DR) is a major cause of vision impairment worldwide. However, manual diagnosis is often time-consuming and prone to errors, leading to delays in screening. This paper presents a lightweight automated deep learning framework for efficient assessment of DR severity from digital fundus images. We use a MobileNetV3 architecture with a Consistent Rank Logits (CORAL) head to model the ordered progression of disease while maintaining computational efficiency for resource-constrained environments. The model is trained and validated on a combined dataset of APTOS 2019 and IDRiD images using a preprocessing pipeline including circular cropping and illumination normalization. Extensive experiments including 3-fold cross-validation and ablation studies demonstrate strong performance. The model achieves a Quadratic Weighted Kappa (QWK) score of 0.9019 and an accuracy of 80.03 percent. Additionally, we address real-world deployment challenges through model calibration to reduce overconfidence and optimization for mobile devices. The proposed system provides a scalable and practical tool for early-stage diabetic retinopathy screening.

</details>


### [82] [Learning to Fuse and Reconstruct Multi-View Graphs for Diabetic Retinopathy Grading](https://arxiv.org/abs/2602.21944)
*Haoran Li,Yuxin Lin,Huan Wang,Xiaoling Luo,Qi Zhu,Jiahua Shi,Huaming Chen,Bo Du,Johan Barthelemy,Zongyan Xue,Jun Shen,Yong Xu*

Main category: cs.CV

TL;DR: MVGFDR是一种端到端多视角图融合框架，通过显式解耦共享和视图特定特征提升糖尿病视网膜病变分级性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视角眼底图像融合时忽视了视角间相关性，未能充分利用患者同一来源的视角间一致性。

Method: MVGFDR框架包含多视角图初始化、多视角图融合和掩码跨视角重建三个关键组件，通过频域相关性和掩码重建优化特征融合。

Result: 在目前最大的多视角眼底图像数据集MFIDDR上，MVGFDR框架优于现有最先进方法。

Conclusion: MVGFDR框架通过显式解耦共享和视图特定特征，显著提升了糖尿病视网膜病变分级的准确性，实验结果表明其在多视角眼底图像数据集上优于现有方法。

Abstract: Diabetic retinopathy (DR) is one of the leading causes of vision loss worldwide, making early and accurate DR grading critical for timely intervention. Recent clinical practices leverage multi-view fundus images for DR detection with a wide coverage of the field of view (FOV), motivating deep learning methods to explore the potential of multi-view learning for DR grading. However, existing methods often overlook the inter-view correlations when fusing multi-view fundus images, failing to fully exploit the inherent consistency across views originating from the same patient. In this work, we present MVGFDR, an end-to-end Multi-View Graph Fusion framework for DR grading. Different from existing methods that directly fuse visual features from multiple views, MVGFDR is equipped with a novel Multi-View Graph Fusion (MVGF) module to explicitly disentangle the shared and view-specific visual features. Specifically, MVGF comprises three key components: (1) Multi-view Graph Initialization, which constructs visual graphs via residual-guided connections and employs Discrete Cosine Transform (DCT) coefficients as frequency-domain anchors; (2) Multi-view Graph Fusion, which integrates selective nodes across multi-view graphs based on frequency-domain relevance to capture complementary view-specific information; and (3) Masked Cross-view Reconstruction, which leverages masked reconstruction of shared information across views to facilitate view-invariant representation learning. Extensive experimental results on MFIDDR, by far the largest multi-view fundus image dataset, demonstrate the superiority of our proposed approach over existing state-of-the-art approaches in diabetic retinopathy grading.

</details>


### [83] [MindDriver: Introducing Progressive Multimodal Reasoning for Autonomous Driving](https://arxiv.org/abs/2602.21952)
*Lingjun Zhang,Yujian Yuan,Changjie Wu,Xinyuan Chang,Xin Cai,Shuang Zeng,Linzhe Shi,Sijin Wang,Hang Zhang,Mu Xu*

Main category: cs.CV

TL;DR: MindDriver是一种创新的多模态推理框架，通过渐进式强化微调和自动数据标注，提升自动驾驶系统的推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本CoT在文本语义空间与轨迹物理空间之间的差距，以及未来图像作为CoT过程缺乏规划导向目标指导的问题。

Method: 提出MindDriver框架，包括语义理解、语义到物理空间的想象和物理空间轨迹规划；开发反馈引导的自动数据标注管道和渐进式强化微调方法。

Result: MindDriver在nuScenes开环和Bench2Drive闭环评估中表现优异。

Conclusion: MindDriver通过创新的多模态推理框架和渐进式强化微调方法，显著提升了自动驾驶系统的推理性能，并在nuScenes和Bench2Drive评估中表现出色。

Abstract: Vision-Language Models (VLM) exhibit strong reasoning capabilities, showing promise for end-to-end autonomous driving systems. Chain-of-Thought (CoT), as VLM's widely used reasoning strategy, is facing critical challenges. Existing textual CoT has a large gap between text semantic space and trajectory physical space. Although the recent approach utilizes future image to replace text as CoT process, it lacks clear planning-oriented objective guidance to generate images with accurate scene evolution. To address these, we innovatively propose MindDriver, a progressive multimodal reasoning framework that enables VLM to imitate human-like progressive thinking for autonomous driving. MindDriver presents semantic understanding, semantic-to-physical space imagination, and physical-space trajectory planning. To achieve aligned reasoning processes in MindDriver, we develop a feedback-guided automatic data annotation pipeline to generate aligned multimodal reasoning training data. Furthermore, we develop a progressive reinforcement fine-tuning method to optimize the alignment through progressive high- level reward-based learning. MindDriver demonstrates superior performance in both nuScences open-loop and Bench2Drive closed-loop evaluation. Codes are available at https://github.com/hotdogcheesewhite/MindDriver.

</details>


### [84] [Global-Local Dual Perception for MLLMs in High-Resolution Text-Rich Image Translation](https://arxiv.org/abs/2602.21956)
*Junxin Lu,Tengfei Song,Zhanglin Wu,Pengfei Li,Xiaowei Liang,Hui Yang,Kun Chen,Ning Xie,Yunfei Lu,Jing Zhao,Shiliang Sun,Daimeng Wei*

Main category: cs.CV

TL;DR: GLoTran是一种针对高分辨率文本丰富图像的TIMT新框架，通过全局-局部双视觉感知提升翻译质量。


<details>
  <summary>Details</summary>
Motivation: 现有TIMT方法在高分辨率文本丰富图像中表现不佳，存在文本遗漏、语义漂移和上下文不一致等问题。

Method: GLoTran通过整合低分辨率全局图像和多尺度区域级文本图像切片，在指令引导的对齐策略下，使MLLMs能够保持场景级上下文一致性，同时准确捕捉细粒度文本细节。

Result: GLoTran在实验中显著优于现有MLLMs，提供了高分辨率和文本丰富条件下细粒度TIMT的新范式。

Conclusion: GLoTran提出了一种新的全局-局部双视觉感知框架，显著提升了高分辨率文本丰富图像下的TIMT翻译完整性和准确性。

Abstract: Text Image Machine Translation (TIMT) aims to translate text embedded in images in the source-language into target-language, requiring synergistic integration of visual perception and linguistic understanding. Existing TIMT methods, whether cascaded pipelines or end-to-end multimodal large language models (MLLMs),struggle with high-resolution text-rich images due to cluttered layouts, diverse fonts, and non-textual distractions, resulting in text omission, semantic drift, and contextual inconsistency. To address these challenges, we propose GLoTran, a global-local dual visual perception framework for MLLM-based TIMT. GLoTran integrates a low-resolution global image with multi-scale region-level text image slices under an instruction-guided alignment strategy, conditioning MLLMs to maintain scene-level contextual consistency while faithfully capturing fine-grained textual details. Moreover, to realize this dual-perception paradigm, we construct GLoD, a large-scale text-rich TIMT dataset comprising 510K high-resolution global-local image-text pairs covering diverse real-world scenarios. Extensive experiments demonstrate that GLoTran substantially improves translation completeness and accuracy over state-of-the-art MLLMs, offering a new paradigm for fine-grained TIMT under high-resolution and text-rich conditions.

</details>


### [85] [Global-Aware Edge Prioritization for Pose Graph Initialization](https://arxiv.org/abs/2602.21963)
*Tong Wei,Giorgos Tolias,Jiri Matas,Daniel Barath*

Main category: cs.CV

TL;DR: 该论文提出了一种基于全局边缘优先化的方法，通过GNN预测边缘可靠性、多最小生成树构建和连通性感知调制，显著提升了SfM的初始化效果和重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有的SfM方法依赖图像检索独立处理图像对，忽略了全局一致性，导致初始化效果不佳。

Method: 该方法包含三个部分：(1) 使用SfM衍生的监督训练的GNN预测全局一致的边缘可靠性；(2) 基于多最小生成树的姿态图构建；(3) 连通性感知的分数调制。

Result: 该方法生成的姿态图更可靠且紧凑，在稀疏和高速场景下提高了重建精度，并在模糊场景中优于现有检索方法。

Conclusion: 通过全局边缘优先化方法，该论文提出的技术显著提高了稀疏和高速场景下的重建精度，并在模糊场景中优于现有的检索方法。

Abstract: The pose graph is a core component of Structure-from-Motion (SfM), where images act as nodes and edges encode relative poses. Since geometric verification is expensive, SfM pipelines restrict the pose graph to a sparse set of candidate edges, making initialization critical. Existing methods rely on image retrieval to connect each image to its $k$ nearest neighbors, treating pairs independently and ignoring global consistency. We address this limitation through the concept of edge prioritization, ranking candidate edges by their utility for SfM. Our approach has three components: (1) a GNN trained with SfM-derived supervision to predict globally consistent edge reliability; (2) multi-minimal-spanning-tree-based pose graph construction guided by these ranks; and (3) connectivity-aware score modulation that reinforces weak regions and reduces graph diameter. This globally informed initialization yields more reliable and compact pose graphs, improving reconstruction accuracy in sparse and high-speed settings and outperforming SOTA retrieval methods on ambiguous scenes. The ode and trained models are available at https://github.com/weitong8591/global_edge_prior.

</details>


### [86] [When LoRA Betrays: Backdooring Text-to-Image Models by Masquerading as Benign Adapters](https://arxiv.org/abs/2602.21977)
*Liangwei Lyu,Jiaqi Xu,Jianwei Ding,Qiyao Deng*

Main category: cs.CV

TL;DR: MasqLoRA是一种利用独立LoRA模块在文本到图像扩散模型中隐秘注入恶意行为的攻击框架，攻击成功率高达99.8%，揭示了AI供应链的新威胁。


<details>
  <summary>Details</summary>
Motivation: LoRA的模块化和即插即用特性虽然便于模型共享和定制，但也扩大了攻击面，本研究旨在揭示这种风险。

Method: 通过冻结基础模型参数并仅更新低秩适配器权重，利用少量'触发词-目标图像'对训练独立的恶意LoRA模块。

Result: 实验结果表明，MasqLoRA能以最小的资源开销实现99.8%的高攻击成功率。

Conclusion: MasqLoRA揭示了AI供应链中一个严重且独特的威胁，强调了针对以LoRA为中心的共享生态系统开发专用防御机制的紧迫性。

Abstract: Low-Rank Adaptation (LoRA) has emerged as a leading technique for efficiently fine-tuning text-to-image diffusion models, and its widespread adoption on open-source platforms has fostered a vibrant culture of model sharing and customization. However, the same modular and plug-and-play flexibility that makes LoRA appealing also introduces a broader attack surface. To highlight this risk, we propose Masquerade-LoRA (MasqLoRA), the first systematic attack framework that leverages an independent LoRA module as the attack vehicle to stealthily inject malicious behavior into text-to-image diffusion models. MasqLoRA operates by freezing the base model parameters and updating only the low-rank adapter weights using a small number of "trigger word-target image" pairs. This enables the attacker to train a standalone backdoor LoRA module that embeds a hidden cross-modal mapping: when the module is loaded and a specific textual trigger is provided, the model produces a predefined visual output; otherwise, it behaves indistinguishably from the benign model, ensuring the stealthiness of the attack. Experimental results demonstrate that MasqLoRA can be trained with minimal resource overhead and achieves a high attack success rate of 99.8%. MasqLoRA reveals a severe and unique threat in the AI supply chain, underscoring the urgent need for dedicated defense mechanisms for the LoRA-centric sharing ecosystem.

</details>


### [87] [PanoEnv: Exploring 3D Spatial Intelligence in Panoramic Environments with Reinforcement Learning](https://arxiv.org/abs/2602.21992)
*Zekai Lin,Xu Zheng*

Main category: cs.CV

TL;DR: PanoEnv是一个用于提升VLMs在360全景图像中3D推理能力的大规模VQA基准和强化学习框架，显著提高了模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前VLMs在ERP图像上的3D空间推理能力受限于几何失真和3D监督不足，需要提升其在全景图像中的3D理解能力。

Method: 提出了基于Group Relative Policy Optimization (GRPO)的强化学习后训练框架，包含五种几何感知策略，并采用两阶段课程（结构化任务训练和混合开放数据微调）。

Result: 7B模型在整体准确率（52.93%）和开放问题准确率（14.83%）上均达到新SOTA，语义评估分数（Q-Score 6.24, P-Score 5.95）超越32B模型。

Conclusion: PanoEnv-QA及其基于课程的RL框架有效提升了VLMs在全向感知中的3D空间智能。

Abstract: 360 panoramic images are increasingly used in virtual reality, autonomous driving, and robotics for holistic scene understanding. However, current Vision-Language Models (VLMs) struggle with 3D spatial reasoning on Equirectangular Projection (ERP) images due to geometric distortion and limited 3D supervision. We introduce PanoEnv, a large-scale VQA benchmark built from synthetic 3D environments, containing 14.8K questions across five categories (e.g., relative position, volume comparison) grounded in accurate 3D annotations including depth, segmentation, and bounding boxes. Benchmarking 14 state-of-the-art VLMs reveals limited 3D understanding, achieving only 49.34% overall accuracy and 8.36% on open-ended (OE) questions. To enhance 3D reasoning, we propose a reinforcement learning post-training framework based on Group Relative Policy Optimization (GRPO) with a ground-truth-guided reward that incorporates five geometry-aware strategies such as distance tolerance and spatial consistency. A two-stage curriculum further mitigates catastrophic forgetting: Stage 1 trains on structured tasks (true/false and multiple choice), and Stage 2 fine-tunes on mixed open-ended data to improve generalization. Our 7B model achieves new state-of-the-art performance, improving overall accuracy to 52.93% (+3.59%) and open-ended accuracy to 14.83% while maintaining structured-task performance. It also achieves top semantic evaluation scores (Q-Score 6.24, P-Score 5.95), surpassing 32B models. These results demonstrate that PanoEnv-QA and our curriculum-based RL framework effectively instill 3D spatial intelligence in VLMs for omnidirectional perception.

</details>


### [88] [RobustVisRAG: Causality-Aware Vision-Based Retrieval-Augmented Generation under Visual Degradations](https://arxiv.org/abs/2602.22013)
*I-Hsiang Chen,Yu-Wei Liu,Tse-Yu Wu,Yu-Chien Chiang,Jen-Chien Yang,Wei-Ting Chen*

Main category: cs.CV

TL;DR: RobustVisRAG通过双路径框架解决视觉输入失真问题，提升检索和生成性能，并在新数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 现有VisRAG模型在视觉输入失真（如模糊、噪声、低光等）时性能下降，因语义与失真因素在预训练视觉编码器中纠缠，导致检索和生成错误。

Method: 采用非因果路径捕获失真信号，并通过因果路径学习纯化语义，结合非因果失真建模和因果语义对齐目标，实现语义与失真的清晰分离。

Result: 在真实世界失真条件下，RobustVisRAG在检索、生成和端到端性能上分别提升了7.35%、6.35%和12.40%。

Conclusion: RobustVisRAG通过因果引导的双路径框架有效提升了VisRAG在视觉输入失真情况下的鲁棒性，同时在干净输入上保持可比性能。

Abstract: Vision-based Retrieval-Augmented Generation (VisRAG) leverages vision-language models (VLMs) to jointly retrieve relevant visual documents and generate grounded answers based on multimodal evidence. However, existing VisRAG models degrade in performance when visual inputs suffer from distortions such as blur, noise, low light, or shadow, where semantic and degradation factors become entangled within pretrained visual encoders, leading to errors in both retrieval and generation stages. To address this limitation, we introduce RobustVisRAG, a causality-guided dual-path framework that improves VisRAG robustness while preserving efficiency and zero-shot generalization. RobustVisRAG uses a non-causal path to capture degradation signals through unidirectional attention and a causal path to learn purified semantics guided by these signals. Together with the proposed Non-Causal Distortion Modeling and Causal Semantic Alignment objectives, the framework enforces a clear separation between semantics and degradations, enabling stable retrieval and generation under challenging visual conditions. To evaluate robustness under realistic conditions, we introduce the Distortion-VisRAG dataset, a large-scale benchmark containing both synthetic and real-world degraded documents across seven domains, with 12 synthetic and 5 real distortion types that comprehensively reflect practical visual degradations. Experimental results show that RobustVisRAG improves retrieval, generation, and end-to-end performance by 7.35%, 6.35%, and 12.40%, respectively, on real-world degradations, while maintaining comparable accuracy on clean inputs.

</details>


### [89] [Olbedo: An Albedo and Shading Aerial Dataset for Large-Scale Outdoor Environments](https://arxiv.org/abs/2602.22025)
*Shuang Song,Debao Huang,Deyan Deng,Haolin Xiong,Yang Tang,Yajie Zhao,Rongjun Qin*

Main category: cs.CV

TL;DR: Olbedo是一个大规模航空数据集，支持户外反射率-阴影分解，通过逆渲染生成多视角一致的注释，显著提升了模型性能，并支持多种应用。


<details>
  <summary>Details</summary>
Motivation: 户外场景的本征图像分解在重光照、编辑和理解大规模环境中至关重要，但缺乏真实世界数据集限制了进展。

Method: 通过多视角立体重建和校准天空照明的逆渲染细化流程，生成多视角一致的反射率和阴影图，以及深度、法线、太阳和天空阴影分量等注释。

Result: Olbedo数据集显著提升了基于扩散的单视角户外反射率预测性能，并在MatrixCity基准测试中展示了改进。

Conclusion: Olbedo数据集的发布为户外本征图像分解提供了重要资源，支持了3D资产的多视角一致重光照、材质编辑和城市数字孪生的场景变化分析。

Abstract: Intrinsic image decomposition (IID) of outdoor scenes is crucial for relighting, editing, and understanding large-scale environments, but progress has been limited by the lack of real-world datasets with reliable albedo and shading supervision. We introduce Olbedo, a large-scale aerial dataset for outdoor albedo--shading decomposition in the wild. Olbedo contains 5,664 UAV images captured across four landscape types, multiple years, and diverse illumination conditions. Each view is accompanied by multi-view consistent albedo and shading maps, metric depth, surface normals, sun and sky shading components, camera poses, and, for recent flights, measured HDR sky domes. These annotations are derived from an inverse-rendering refinement pipeline over multi-view stereo reconstructions and calibrated sky illumination, together with per-pixel confidence masks. We demonstrate that Olbedo enables state-of-the-art diffusion-based IID models, originally trained on synthetic indoor data, to generalize to real outdoor imagery: fine-tuning on Olbedo significantly improves single-view outdoor albedo prediction on the MatrixCity benchmark. We further illustrate applications of Olbedo-trained models to multi-view consistent relighting of 3D assets, material editing, and scene change analysis for urban digital twins. We release the dataset, baseline models, and an evaluation protocol to support future research in outdoor intrinsic decomposition and illumination-aware aerial vision.

</details>


### [90] [RT-RMOT: A Dataset and Framework for RGB-Thermal Referring Multi-Object Tracking](https://arxiv.org/abs/2602.22033)
*Yanqiu Yu,Zhifan Jin,Sijia Chen,Tongfei Chu,En Yu,Liman Liu,Wenbing Tao*

Main category: cs.CV

TL;DR: 提出RT-RMOT任务和RTrack框架，通过RGB-热融合实现全天候多目标跟踪，并在新数据集RefRT上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现有Referring Multi-Object Tracking在低可见度条件下的局限性，提出RGB-Thermal融合的全天候跟踪任务RT-RMOT。

Method: 提出RTrack框架，基于多模态大语言模型（MLLM）整合RGB、热和文本特征，并引入GSPO策略、CAS策略及结构化输出奖励和综合检测奖励。

Result: 构建首个RGB-Thermal模态的Referring Multi-Object Tracking数据集RefRT，并提出RTrack框架在实验中表现优异。

Conclusion: RTrack框架在RefRT数据集上的实验证明了其有效性，特别是在全天候条件下通过RGB-热融合提升多目标跟踪性能。

Abstract: Referring Multi-Object Tracking has attracted increasing attention due to its human-friendly interactive characteristics, yet it exhibits limitations in low-visibility conditions, such as nighttime, smoke, and other challenging scenarios. To overcome this limitation, we propose a new RGB-Thermal RMOT task, named RT-RMOT, which aims to fuse RGB appearance features with the illumination robustness of the thermal modality to enable all-day referring multi-object tracking. To promote research on RT-RMOT, we construct the first Referring Multi-Object Tracking dataset under RGB-Thermal modality, named RefRT. It contains 388 language descriptions, 1,250 tracked targets, and 166,147 Language-RGB-Thermal (L-RGB-T) triplets. Furthermore, we propose RTrack, a framework built upon a multimodal large language model (MLLM) that integrates RGB, thermal, and textual features. Since the initial framework still leaves room for improvement, we introduce a Group Sequence Policy Optimization (GSPO) strategy to further exploit the model's potential. To alleviate training instability during RL fine-tuning, we introduce a Clipped Advantage Scaling (CAS) strategy to suppress gradient explosion. In addition, we design Structured Output Reward and Comprehensive Detection Reward to balance exploration and exploitation, thereby improving the completeness and accuracy of target perception. Extensive experiments on the RefRT dataset demonstrate the effectiveness of the proposed RTrack framework.

</details>


### [91] [SPGen: Stochastic scanpath generation for paintings using unsupervised domain adaptation](https://arxiv.org/abs/2602.22049)
*Mohamed Amine Kerkouri,Marouane Tliba,Aladine Chetouani,Alessandro Bruno*

Main category: cs.CV

TL;DR: SPGen是一种新型深度学习模型，通过FCNN和域适应技术预测观赏绘画时的眼动路径，优于现有方法，有助于文化遗产保护。


<details>
  <summary>Details</summary>
Motivation: 理解人类视觉注意力对文化遗产保护至关重要，但目前缺乏有效的方法来预测观赏绘画时的眼动路径。

Method: 采用全卷积神经网络（FCNN）结合可微分注视点选择和可学习高斯先验，模拟自然观看偏差；通过梯度反转层进行无监督域适应，解决照片与艺术品之间的域差距；并使用随机噪声采样器模拟眼动数据的随机性。

Result: SPGen在广泛测试中表现优于现有方法，能够有效分析注视行为。

Conclusion: SPGen模型通过深度学习方法有效预测了观赏绘画时的眼动路径，为文化遗产的保护和艺术欣赏提供了有力工具。

Abstract: Understanding human visual attention is key to preserving cultural heritage We introduce SPGen a novel deep learning model to predict scanpaths the sequence of eye movementswhen viewers observe paintings.
  Our architecture uses a Fully Convolutional Neural Network FCNN with differentiable fixation selection and learnable Gaussian priors to simulate natural viewing biases To address the domain gap between photographs and artworks we employ unsupervised domain adaptation via a gradient reversal layer allowing the model to transfer knowledge from natural scenes to paintings Furthermore a random noise sampler models the inherent stochasticity of eyetracking data.
  Extensive testing shows SPGen outperforms existing methods offering a powerful tool to analyze gaze behavior and advance the preservation and appreciation of artistic treasures.

</details>


### [92] [AutoSew: A Geometric Approach to Stitching Prediction with Graph Neural Networks](https://arxiv.org/abs/2602.22052)
*Pablo Ríos-Navarro,Elena Garces,Jorge Lopez-Moreno*

Main category: cs.CV

TL;DR: AutoSew 是一种基于几何的全自动方法，通过图神经网络和最优传输求解器预测缝合关系，在无需人工干预下实现高效服装组装。


<details>
  <summary>Details</summary>
Motivation: 服装组装自动化因缺乏标准化注释协议和语义线索而面临挑战，现有方法依赖面板标签或手工启发式，限制了其在实际非标准图案中的适用性。

Method: AutoSew 将问题建模为图匹配任务，利用图神经网络捕捉局部和全局几何上下文，并采用可微分最优传输求解器推断缝合关系（包括多边连接）。

Result: AutoSew 在测试中达到 96% F1 分数，成功无误差组装 73.3% 的服装，优于现有方法。

Conclusion: AutoSew 证明仅依赖几何输入即可稳健指导缝合预测，实现无需人工干预的可扩展服装组装。

Abstract: Automating garment assembly from sewing patterns remains a significant challenge due to the lack of standardized annotation protocols and the frequent absence of semantic cues. Existing methods often rely on panel labels or handcrafted heuristics, which limit their applicability to real-world, non-conforming patterns. We present AutoSew, a fully automatic, geometry-based approach for predicting stitch correspondences directly from 2D pattern contours. AutoSew formulates the problem as a graph matching task, leveraging a Graph Neural Network to capture local and global geometric context, and employing a differentiable optimal transport solver to infer stitching relationships-including multi-edge connections. To support this task, we update the GarmentCodeData dataset modifying over 18k patterns with realistic multi-edge annotations, reflecting industrial assembly scenarios. AutoSew achieves 96% F1-score and successfully assembles 73.3% of test garments without error, outperforming existing methods while relying solely on geometric input. Our results demonstrate that geometry alone can robustly guide stitching prediction, enabling scalable garment assembly without manual input.

</details>


### [93] [AdaSpot: Spend Resolution Where It Matters for Precise Event Spotting](https://arxiv.org/abs/2602.22073)
*Artur Xarles,Sergio Escalera,Thomas B. Moeslund,Albert Clapés*

Main category: cs.CV

TL;DR: AdaSpot 是一种高效框架，通过自适应选择高分辨率处理区域，在精确事件定位任务中实现了最先进的性能，同时保持了计算效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常均匀处理所有帧，忽视了视频数据中固有的时空冗余，导致在非信息区域进行冗余计算，同时限制了整体效率。

Method: AdaSpot 通过处理低分辨率视频提取全局任务相关特征，同时自适应选择每帧中最具信息量的感兴趣区域进行高分辨率处理，采用无监督、任务感知策略保持时空一致性。

Result: AdaSpot 在 Tennis 和 FineDiving 数据集上分别实现了 +3.96 和 +2.26 mAP@0 帧的性能提升。

Conclusion: AdaSpot 在标准 PES 基准测试中表现出色，实现了严格的评估指标下的最先进性能，同时在较宽松的指标下也保持了强劲的结果。

Abstract: Precise Event Spotting aims to localize fast-paced actions or events in videos with high temporal precision, a key task for applications in sports analytics, robotics, and autonomous systems. Existing methods typically process all frames uniformly, overlooking the inherent spatio-temporal redundancy in video data. This leads to redundant computation on non-informative regions while limiting overall efficiency. To remain tractable, they often spatially downsample inputs, losing fine-grained details crucial for precise localization. To address these limitations, we propose \textbf{AdaSpot}, a simple yet effective framework that processes low-resolution videos to extract global task-relevant features while adaptively selecting the most informative region-of-interest in each frame for high-resolution processing. The selection is performed via an unsupervised, task-aware strategy that maintains spatio-temporal consistency across frames and avoids the training instability of learnable alternatives. This design preserves essential fine-grained visual cues with a marginal computational overhead compared to low-resolution-only baselines, while remaining far more efficient than uniform high-resolution processing. Experiments on standard PES benchmarks demonstrate that \textbf{AdaSpot} achieves state-of-the-art performance under strict evaluation metrics (\eg, $+3.96$ and $+2.26$ mAP$@0$ frames on Tennis and FineDiving), while also maintaining strong results under looser metrics. Code is available at: \href{https://github.com/arturxe2/AdaSpot}{https://github.com/arturxe2/AdaSpot}.

</details>


### [94] [Learning to Drive is a Free Gift: Large-Scale Label-Free Autonomy Pretraining from Unposed In-The-Wild Videos](https://arxiv.org/abs/2602.22091)
*Matthew Strong,Wei-Jer Chang,Quentin Herau,Jiezhi Yang,Yihan Hu,Chensheng Peng,Wei Zhan*

Main category: cs.CV

TL;DR: LFG是一种无标签、教师引导的框架，从无姿态视频中学习自动驾驶表示，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在线可用的自我中心驾驶视频缺乏标注，难以学习同时捕捉语义结构和3D几何的表示。

Method: 提出了一种无标签、教师引导的框架LFG，利用前馈架构和轻量自回归模块，通过多模态监督信号联合预测当前和未来的点地图、相机姿态、语义分割和运动掩码。

Result: LFG在NAVSIM基准测试中仅使用单目摄像头就超越了多摄像头和LiDAR基线，并在多种任务中表现出色。

Conclusion: LFG框架通过无标签、教师引导的方式从无姿态视频中学习自动驾驶表示，不仅在NAVSIM基准测试中超越了多摄像头和LiDAR基线，还在多种语义、几何和运动预测任务中表现出色，成为自动驾驶领域有前景的视频中心基础模型。

Abstract: Ego-centric driving videos available online provide an abundant source of visual data for autonomous driving, yet their lack of annotations makes it difficult to learn representations that capture both semantic structure and 3D geometry. Recent advances in large feedforward spatial models demonstrate that point maps and ego-motion can be inferred in a single forward pass, suggesting a promising direction for scalable driving perception. We therefore propose a label-free, teacher-guided framework for learning autonomous driving representations directly from unposed videos. Unlike prior self-supervised approaches that focus primarily on frame-to-frame consistency, we posit that safe and reactive driving depends critically on temporal context. To this end, we leverage a feedforward architecture equipped with a lightweight autoregressive module, trained using multi-modal supervisory signals that guide the model to jointly predict current and future point maps, camera poses, semantic segmentation, and motion masks. Multi-modal teachers provide sequence-level pseudo-supervision, enabling LFG to learn a unified pseudo-4D representation from raw YouTube videos without poses, labels, or LiDAR. The resulting encoder not only transfers effectively to downstream autonomous driving planning on the NAVSIM benchmark, surpassing multi-camera and LiDAR baselines with only a single monocular camera, but also yields strong performance when evaluated on a range of semantic, geometric, and qualitative motion prediction tasks. These geometry and motion-aware features position LFG as a compelling video-centric foundation model for autonomous driving.

</details>


### [95] [Overview of the CXR-LT 2026 Challenge: Multi-Center Long-Tailed and Zero Shot Chest X-ray Classification](https://arxiv.org/abs/2602.22092)
*Hexin Dong,Yi Lin,Pengyu Zhou,Fengnian Zhao,Alan Clint Legasto,Mingquan Lin,Hao Chen,Yuzhe Yang,George Shih,Yifan Peng*

Main category: cs.CV

TL;DR: CXR-LT 2026挑战通过多中心数据集和视觉-语言预训练，显著提升了CXR解读在长尾分布和开放世界中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决胸部X光片（CXR）解读中长尾病理分布和临床环境开放性问题。

Method: 提出了CXR-LT 2026挑战，包含多中心数据集（PadChest和NIH Chest X-ray数据集）和两个核心任务：鲁棒多标签分类和开放世界泛化。

Result: 获胜方案在任务1中mAP为0.5854，任务2中为0.4315。

Conclusion: 大规模视觉-语言预训练显著缓解了零样本诊断中常见的性能下降问题。

Abstract: Chest X-ray (CXR) interpretation is hindered by the long-tailed distribution of pathologies and the open-world nature of clinical environments. Existing benchmarks often rely on closed-set classes from single institutions, failing to capture the prevalence of rare diseases or the appearance of novel findings. To address this, we present the CXR-LT 2026 challenge. This third iteration of the benchmark introduces a multi-center dataset comprising over 145,000 images from PadChest and NIH Chest X-ray datasets. The challenge defines two core tasks: (1) Robust Multi-Label Classification on 30 known classes and (2) Open-World Generalization to 6 unseen (out-of-distribution) rare disease classes. We report the results of the top-performing teams, evaluating them via mean Average Precision (mAP), AUROC, and F1-score. The winning solutions achieved an mAP of 0.5854 on Task 1 and 0.4315 on Task 2, demonstrating that large-scale vision-language pre-training significantly mitigates the performance drop typically associated with zero-shot diagnosis.

</details>


### [96] [WeatherCity: Urban Scene Reconstruction with Controllable Multi-Weather Transformation](https://arxiv.org/abs/2602.22096)
*Wenhua Wu,Huai Guan,Zhe Liu,Hesheng Wang*

Main category: cs.CV

TL;DR: WeatherCity是一种新型4D城市场景重建和天气编辑框架，通过文本引导编辑和天气高斯表示实现高保真、灵活控制的天气模拟，支持动态效果和对象级操作。


<details>
  <summary>Details</summary>
Motivation: 现有重建方法仅能复制观察到的场景，缺乏多样天气模拟能力；图像级天气编辑方法易引入场景伪影且控制性差。

Method: 利用文本引导的图像编辑模型进行灵活的背景天气编辑，提出基于共享场景特征和专用天气解码器的新型天气高斯表示，并通过内容一致性优化增强。此外，设计了基于物理的模型，通过粒子和运动模式模拟动态天气效果。

Result: 在多数据集和多种场景上的实验表明，WeatherCity在4D重建和天气编辑中实现了灵活控制、高保真度和时间一致性。

Conclusion: WeatherCity框架在4D场景重建和天气编辑方面实现了高灵活性和高保真度，支持细粒度天气控制和场景内对象级操作。

Abstract: Editable high-fidelity 4D scenes are crucial for autonomous driving, as they can be applied to end-to-end training and closed-loop simulation. However, existing reconstruction methods are primarily limited to replicating observed scenes and lack the capability for diverse weather simulation. While image-level weather editing methods tend to introduce scene artifacts and offer poor controllability over the weather effects. To address these limitations, we propose WeatherCity, a novel framework for 4D urban scene reconstruction and weather editing. Specifically, we leverage a text-guided image editing model to achieve flexible editing of image weather backgrounds. To tackle the challenge of multi-weather modeling, we introduce a novel weather Gaussian representation based on shared scene features and dedicated weather-specific decoders. This representation is further enhanced with a content consistency optimization, ensuring coherent modeling across different weather conditions. Additionally, we design a physics-driven model that simulates dynamic weather effects through particles and motion patterns. Extensive experiments on multiple datasets and various scenes demonstrate that WeatherCity achieves flexible controllability, high fidelity, and temporal consistency in 4D reconstruction and weather editing. Our framework not only enables fine-grained control over weather conditions (e.g., light rain and heavy snow) but also supports object-level manipulation within the scene.

</details>


### [97] [Brain3D: Brain Report Automation via Inflated Vision Transformers in 3D](https://arxiv.org/abs/2602.22098)
*Mariano Barone,Francesco Di Serio,Giuseppe Riccio,Antonio Romano,Marco Postiglione,Antonino Ferraro,Vincenzo Moscato*

Main category: cs.CV

TL;DR: Brain3D是一个针对神经放射学的3D视觉语言框架，通过三阶段对齐方法生成自动化放射学报告，显著优于2D方法。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉语言模型（VLMs）处理体积脑MRI时采用2D切片近似方法，破坏了准确神经放射学解释所需的空间上下文。

Method: 将预训练的2D医学编码器扩展为原生3D架构，并通过三阶段渐进对齐方法（对比性接地、监督投影器预热和LoRA语言专业化）与因果语言模型对齐。

Result: 在468个受试者（BraTS病理病例加健康对照）上评估，模型达到临床病理F1分数0.951，显著优于2D基线（0.413），且在健康扫描上保持完美特异性。

Conclusion: Brain3D通过三阶段对齐方法（对比性接地、监督投影器预热和LoRA语言专业化）成功实现了从3D脑肿瘤MRI生成自动化放射学报告，显著优于2D基线方法，并保持了健康扫描的完美特异性。

Abstract: Current medical vision-language models (VLMs) process volumetric brain MRI using 2D slice-based approximations, fragmenting the spatial context required for accurate neuroradiological interpretation. We developed \textbf{Brain3D}, a staged vision-language framework for automated radiology report generation from 3D brain tumor MRI. Our approach inflates a pretrained 2D medical encoder into a native 3D architecture and progressively aligns it with a causal language model through three stages: contrastive grounding, supervised projector warmup, and LoRA-based linguistic specialization. Unlike generalist 3D medical VLMs, \textbf{Brain3D} is tailored to neuroradiology, where hemispheric laterality, tumor infiltration patterns, and anatomical localization are critical. Evaluated on 468 subjects (BraTS pathological cases plus healthy controls), our model achieves a Clinical Pathology F1 of 0.951 versus 0.413 for a strong 2D baseline while maintaining perfect specificity on healthy scans. The staged alignment proves essential: contrastive grounding establishes visual-textual correspondence, projector warmup stabilizes conditioning, and LoRA adaptation shifts output from verbose captions to structured clinical reports\footnote{Our code is publicly available for transparency and reproducibility

</details>


### [98] [GeoDiv: Framework For Measuring Geographical Diversity In Text-To-Image Models](https://arxiv.org/abs/2602.22120)
*Abhipsa Basu,Mohana Singh,Shashank Agnihotri,Margret Keuper,R. Venkatesh Babu*

Main category: cs.CV

TL;DR: GeoDiv框架通过SEVI和VDI评估T2I模型的地理多样性，揭示其输出缺乏多样性并存在偏见，为更公平的生成系统提供了衡量工具。


<details>
  <summary>Details</summary>
Motivation: T2I模型输出缺乏地理多样性，强化刻板印象并误读地区，亟需评估这些模型如何描绘世界。

Method: 引入了GeoDiv框架，利用大型语言和视觉语言模型，通过两个互补的轴评估地理多样性：社会经济视觉指数（SEVI）和视觉多样性指数（VDI）。

Result: 应用于Stable Diffusion和FLUX.1-dev等模型生成的图像，GeoDiv揭示了持续的多样性缺乏，并识别出模型默认偏见描述的细粒度属性。

Conclusion: GeoDiv提供了一个系统化、可解释的框架，用于衡量生成模型中的地理多样性偏差，标志着向更公平、更具包容性的生成系统迈出了一步。

Abstract: Text-to-image (T2I) models are rapidly gaining popularity, yet their outputs often lack geographical diversity, reinforce stereotypes, and misrepresent regions. Given their broad reach, it is critical to rigorously evaluate how these models portray the world. Existing diversity metrics either rely on curated datasets or focus on surface-level visual similarity, limiting interpretability. We introduce GeoDiv, a framework leveraging large language and vision-language models to assess geographical diversity along two complementary axes: the Socio-Economic Visual Index (SEVI), capturing economic and condition-related cues, and the Visual Diversity Index (VDI), measuring variation in primary entities and backgrounds. Applied to images generated by models such as Stable Diffusion and FLUX.1-dev across $10$ entities and $16$ countries, GeoDiv reveals a consistent lack of diversity and identifies fine-grained attributes where models default to biased portrayals. Strikingly, depictions of countries like India, Nigeria, and Colombia are disproportionately impoverished and worn, reflecting underlying socio-economic biases. These results highlight the need for greater geographical nuance in generative models. GeoDiv provides the first systematic, interpretable framework for measuring such biases, marking a step toward fairer and more inclusive generative systems. Project page: https://abhipsabasu.github.io/geodiv

</details>


### [99] [WeaveTime: Stream from Earlier Frames into Emergent Memory in VideoLLMs](https://arxiv.org/abs/2602.22142)
*Yulin Zhang,Cheng Shi,Sibei Yang*

Main category: cs.CV

TL;DR: WeaveTime通过顺序感知和动态缓存机制，解决了Video-LLMs在流式视频中的时间无关性问题，提升了性能且无需架构改动。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大语言模型（Video-LLMs）在流式设置中存在时间无关性（Time-Agnosticism）问题，导致无法正确处理视频的时间顺序和区分历史与当前观察。

Method: WeaveTime框架包括两个核心部分：轻量级的Temporal Reconstruction目标（Streaming Order Perception增强）和Past-Current Dynamic Focus Cache。前者通过微调注入顺序感知表示，后者在推理时基于不确定性触发粗到细的检索。

Result: WeaveTime在代表性流式基准测试中表现一致提升，既提高了准确性，又降低了延迟。

Conclusion: WeaveTime作为一种简单、高效且模型无关的框架，通过在现有Video-LLM中无缝集成，显著提升了时间感知能力，并在严格的在线时间因果约束下，为流式视频理解提供了实用解决方案。

Abstract: Recent advances in Multimodal Large Language Models have greatly improved visual understanding and reasoning, yet their quadratic attention and offline training protocols make them ill-suited for streaming settings where frames arrive sequentially and future observations are inaccessible. We diagnose a core limitation of current Video-LLMs, namely Time-Agnosticism, in which videos are treated as an unordered bag of evidence rather than a causally ordered sequence, yielding two failures in streams: temporal order ambiguity, in which the model cannot follow or reason over the correct chronological order, and past-current focus blindness where it fails to distinguish present observations from accumulated history. We present WeaveTime, a simple, efficient, and model agnostic framework that first teaches order and then uses order. We introduce a lightweight Temporal Reconstruction objective-our Streaming Order Perception enhancement-that instills order aware representations with minimal finetuning and no specialized streaming data. At inference, a Past-Current Dynamic Focus Cache performs uncertainty triggered, coarse-to-fine retrieval, expanding history only when needed. Plugged into exsiting Video-LLM without architectural changes, WeaveTime delivers consistent gains on representative streaming benchmarks, improving accuracy while reducing latency. These results establish WeaveTime as a practical path toward time aware stream Video-LLMs under strict online, time causal constraints. Code and weights will be made publicly available. Project Page: https://zhangyl4.github.io/publications/weavetime/

</details>


### [100] [MedTri: A Platform for Structured Medical Report Normalization to Enhance Vision-Language Pretraining](https://arxiv.org/abs/2602.22143)
*Yuetan Chu,Xinhua Ma,Xinran Jin,Gongning Luo,Xin Gao*

Main category: cs.CV

TL;DR: MedTri框架通过结构化标准化医学报告，提升视觉-语言预训练质量，支持模块化增强，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决医学报告中存在的风格异质性、长度不一及图像无关内容等问题，系统研究文本标准化对视觉-语言预训练的影响。

Method: 提出MedTri框架，将自由文本报告转换为统一的[解剖实体:放射学描述+诊断类别]三元组，保留关键形态和空间信息，去除噪声。

Result: 在多数据集（X射线和CT）上验证了结构化标准化的重要性，性能优于原始报告及现有基线，且支持模块化文本增强策略。

Conclusion: 结构化文本标准化（如MedTri框架）是医学视觉-语言预训练中关键且可推广的预处理步骤，能显著提升模型性能。

Abstract: Medical vision-language pretraining increasingly relies on medical reports as large-scale supervisory signals; however, raw reports often exhibit substantial stylistic heterogeneity, variable length, and a considerable amount of image-irrelevant content. Although text normalization is frequently adopted as a preprocessing step in prior work, its design principles and empirical impact on vision-language pretraining remain insufficiently and systematically examined. In this study, we present MedTri, a deployable normalization framework for medical vision-language pretraining that converts free-text reports into a unified [Anatomical Entity: Radiologic Description + Diagnosis Category] triplet. This structured, anatomy-grounded normalization preserves essential morphological and spatial information while removing stylistic noise and image-irrelevant content, providing consistent and image-grounded textual supervision at scale. Across multiple datasets spanning both X-ray and computed tomography (CT) modalities, we demonstrate that structured, anatomy-grounded text normalization is an important factor in medical vision-language pretraining quality, yielding consistent improvements over raw reports and existing normalization baselines. In addition, we illustrate how this normalization can easily support modular text-level augmentation strategies, including knowledge enrichment and anatomy-grounded counterfactual supervision, which provide complementary gains in robustness and generalization without altering the core normalization process. Together, our results position structured text normalization as a critical and generalizable preprocessing component for medical vision-language learning, while MedTri provides this normalization platform. Code and data will be released at https://github.com/Arturia-Pendragon-Iris/MedTri.

</details>


### [101] [CoLoGen: Progressive Learning of Concept`-`Localization Duality for Unified Image Generation](https://arxiv.org/abs/2602.22150)
*YuXin Song,Yu Lu,Haoyuan Sun,Huanjin Yao,Fanglong Liu,Yifan Sun,Haocheng Feng,Hang Zhou,Jingdong Wang*

Main category: cs.CV

TL;DR: CoLoGen通过分阶段学习和动态特征路由解决统一图像生成中的概念-定位冲突，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 统一条件图像生成面临概念-定位表征冲突的挑战，因为不同任务依赖不同的内部表征。CoLoGen旨在通过分阶段学习和动态特征路由解决这一问题。

Method: CoLoGen采用分阶段课程学习框架，首先构建核心概念和定位能力，然后适应多样视觉条件，最后优化它们的协同作用。PRW模块动态路由特征至专门专家并稳定整合输出。

Result: 实验表明，CoLoGen在编辑、可控生成和定制生成任务中表现优异，验证了其方法的有效性。

Conclusion: CoLoGen通过分阶段的课程学习和渐进式表征编织（PRW）模块，有效解决了统一图像生成中的概念-定位表征冲突问题，为复杂指令驱动的任务提供了有原则的表征视角。

Abstract: Unified conditional image generation remains difficult because different tasks depend on fundamentally different internal representations. Some require conceptual understanding for semantic synthesis, while others rely on localization cues for spatial precision. Forcing these heterogeneous tasks to share a single representation leads to concept`-`localization representational conflict. To address this issue, we propose CoLoGen, a unified diffusion framework that progressively learns and reconciles this concept`-`localization duality. CoLoGen uses a staged curriculum that first builds core conceptual and localization abilities, then adapts them to diverse visual conditions, and finally refines their synergy for complex instruction`-`driven tasks. Central to this process is the Progressive Representation Weaving (PRW) module, which dynamically routes features to specialized experts and stably integrates their outputs across stages. Experiments on editing, controllable generation, and customized generation show that CoLoGen achieves competitive or superior performance, offering a principled representational perspective for unified image generation.

</details>


### [102] [CASR: A Robust Cyclic Framework for Arbitrary Large-Scale Super-Resolution with Distribution Alignment and Self-Similarity Awareness](https://arxiv.org/abs/2602.22159)
*Wenhao Guo,Zhaoran Zhao,Peng Lu,Sheng Li,Qian Qiao,RuiDe Li*

Main category: cs.CV

TL;DR: CASR通过循环超分辨率框架和两个新模块（SDAM和SARM），解决了任意尺度超分辨率中的分布偏移问题，实现了单模型下的高质量放大。


<details>
  <summary>Details</summary>
Motivation: 解决任意尺度超分辨率（ASISR）中因跨尺度分布偏移导致的噪声、模糊和伪影累积问题。

Method: CASR采用循环超分辨率框架，结合SDAM模块（通过超像素聚合对齐结构分布）和SARM模块（通过自相关和LR自相似性先验恢复高频纹理），确保跨尺度一致性。

Result: CASR在极端放大情况下显著减少分布偏移，保持长程纹理一致性，并展现出优异的泛化能力。

Conclusion: CASR框架通过循环超分辨率设计，有效解决了任意尺度超分辨率中的分布偏移问题，实现了稳定且高质量的图像放大。

Abstract: Arbitrary-Scale SR (ASISR) remains fundamentally limited by cross-scale distribution shift: once the inference scale leaves the training range, noise, blur, and artifacts accumulate sharply. We revisit this challenge from a cross-scale distribution transition perspective and propose CASR, a simple yet highly efficient cyclic SR framework that reformulates ultra-magnification as a sequence of in-distribution scale transitions. This design ensures stable inference at arbitrary scales while requiring only a single model. CASR tackles two major bottlenecks: distribution drift across iterations and patch-wise diffusion inconsistencies. The proposed SDAM module aligns structural distributions via superpixel aggregation, preventing error accumulation, while SARM module restores high-frequency textures by enforcing autocorrelation and embedding LR self-similarity priors. Despite using only a single model, our approach significantly reduces distribution drift, preserves long-range texture consistency, and achieves superior generalization even at extreme magnification.

</details>


### [103] [Mixed Magnification Aggregation for Generalizable Region-Level Representations in Computational Pathology](https://arxiv.org/abs/2602.22176)
*Eric Zimmermann,Julian Viret,Michal Zelechowski,James Brian Hall,Neil Tenenholtz,Adam Casson,George Shaikovski,Eugene Vorontsov,Siqi Liu,Kristen A Severson*

Main category: cs.CV

TL;DR: 研究提出混合放大倍率区域编码器，通过预训练联合融合多分辨率特征，在生物标志物预测任务中取得性能提升，验证了空间上下文的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型大多仅使用20倍放大的图像块，无法捕捉多分辨率特征，且导致每张切片生成大量表示。研究旨在更准确地捕获多分辨率特征并减少每张切片的表示数量。

Method: 采用掩码嵌入建模预训练步骤，联合融合混合放大倍率基础模型的图像块表示，探索了预训练混合放大倍率区域聚合器的设计空间。

Result: 在多种癌症类型的生物标志物预测任务中，模型表现出癌症依赖的性能提升。

Conclusion: 研究提出了一种区域级混合编码器，通过联合融合不同放大倍率的图像块表示，成功提升了生物标志物预测任务的性能，强调了空间上下文理解的重要性。

Abstract: In recent years, a standard computational pathology workflow has emerged where whole slide images are cropped into tiles, these tiles are processed using a foundation model, and task-specific models are built using the resulting representations. At least 15 different foundation models have been proposed, and the vast majority are trained exclusively with tiles using the 20$\times$ magnification. However, it is well known that certain histologic features can only be discerned with larger context windows and requires a pathologist to zoom in and out when analyzing a whole slide image. Furthermore, creating 224$\times$224 pixel crops at 20$\times$ leads to a large number of tiles per slide, which can be gigapixel in size. To more accurately capture multi-resolution features and investigate the possibility of reducing the number of representations per slide, we propose a region-level mixing encoder. Our approach jointly fuses image tile representations of a mixed magnification foundation model using a masked embedding modeling pretraining step. We explore a design space for pretraining the proposed mixed-magnification region aggregators and evaluate our models on transfer to biomarker prediction tasks representing various cancer types. Results demonstrate cancer dependent improvements in predictive performance, highlighting the importance of spatial context and understanding.

</details>


### [104] [Solaris: Building a Multiplayer Video World Model in Minecraft](https://arxiv.org/abs/2602.22208)
*Georgy Savva,Oscar Michel,Daohan Lu,Suppakit Waiwitlikhit,Timothy Meehan,Dhairya Mishra,Srivats Poddar,Jack Lu,Saining Xie*

Main category: cs.CV

TL;DR: Solaris是一个多玩家视频世界模型，通过新数据系统和分阶段训练，实现了多视角一致模拟，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型局限于单智能体视角，无法捕捉真实世界的多智能体交互。

Method: 采用分阶段管道训练，从单玩家逐步过渡到多玩家建模，结合双向、因果和Self Forcing训练。最终阶段引入Checkpointed Self Forcing，一种内存高效的变体。

Result: Solaris的架构和训练设计优于现有基线。

Conclusion: Solaris通过开源系统和模型，为新一代多智能体世界模型奠定了基础。

Abstract: Existing action-conditioned video generation models (video world models) are limited to single-agent perspectives, failing to capture the multi-agent interactions of real-world environments. We introduce Solaris, a multiplayer video world model that simulates consistent multi-view observations. To enable this, we develop a multiplayer data system designed for robust, continuous, and automated data collection on video games such as Minecraft. Unlike prior platforms built for single-player settings, our system supports coordinated multi-agent interaction and synchronized videos + actions capture. Using this system, we collect 12.64 million multiplayer frames and propose an evaluation framework for multiplayer movement, memory, grounding, building, and view consistency. We train Solaris using a staged pipeline that progressively transitions from single-player to multiplayer modeling, combining bidirectional, causal, and Self Forcing training. In the final stage, we introduce Checkpointed Self Forcing, a memory-efficient Self Forcing variant that enables a longer-horizon teacher. Results show our architecture and training design outperform existing baselines. Through open-sourcing our system and models, we hope to lay the groundwork for a new generation of multi-agent world models.

</details>


### [105] [WHOLE: World-Grounded Hand-Object Lifted from Egocentric Videos](https://arxiv.org/abs/2602.22209)
*Yufei Ye,Jiaman Li,Ryan Rong,C. Karen Liu*

Main category: cs.CV

TL;DR: WHOLE通过联合生成手和物体运动先验，解决了现有方法在交互和视线外情况下的局限性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法在处理手或物体姿态时存在孤立预测导致的交互不一致性问题，且难以处理视线外情况。

Method: WHOLE方法从以自我为中心的视频中整体重建手和物体在世界空间中的运动，通过学习手-物体运动的生成先验来联合推理它们的交互。

Result: WHOLE在手部运动估计、6D物体姿态估计及其交互重建方面达到最先进性能。

Conclusion: WHOLE方法通过联合生成手和物体的运动先验，显著提升了手部运动估计、6D物体姿态估计及其相对交互重建的性能，优于现有独立处理方法。

Abstract: Egocentric manipulation videos are highly challenging due to severe occlusions during interactions and frequent object entries and exits from the camera view as the person moves. Current methods typically focus on recovering either hand or object pose in isolation, but both struggle during interactions and fail to handle out-of-sight cases. Moreover, their independent predictions often lead to inconsistent hand-object relations. We introduce WHOLE, a method that holistically reconstructs hand and object motion in world space from egocentric videos given object templates. Our key insight is to learn a generative prior over hand-object motion to jointly reason about their interactions. At test time, the pretrained prior is guided to generate trajectories that conform to the video observations. This joint generative reconstruction substantially outperforms approaches that process hands and objects separately followed by post-processing. WHOLE achieves state-of-the-art performance on hand motion estimation, 6D object pose estimation, and their relative interaction reconstruction. Project website: https://judyye.github.io/whole-www

</details>


### [106] [Neu-PiG: Neural Preconditioned Grids for Fast Dynamic Surface Reconstruction on Long Sequences](https://arxiv.org/abs/2602.22212)
*Julian Kaltheuner,Hannah Dröge,Markus Plack,Patrick Stotko,Reinhard Klein*

Main category: cs.CV

TL;DR: Neu-PiG 是一种基于预条件潜在网格编码的快速动态3D重建方法，显著提升长序列处理的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长序列动态3D物体重建中的漂移问题、运行时间长或依赖复杂训练模型的局限性。

Method: 基于新型预条件潜在网格编码，通过多分辨率潜在网格和轻量级MLP解码每帧的6-DoF变形，结合Sobolev预条件优化。

Result: 在多样化的数据集上，Neu-PiG 在精度和可扩展性上优于现有方法，运行速度比无训练方法快60倍，推理速度与预训练模型相当。

Conclusion: Neu-PiG 提供了一种快速、高保真且无漂移的动态3D物体表面重建方法，显著优于现有技术，尤其在长序列处理上表现优异。

Abstract: Temporally consistent surface reconstruction of dynamic 3D objects from unstructured point cloud data remains challenging, especially for very long sequences. Existing methods either optimize deformations incrementally, risking drift and requiring long runtimes, or rely on complex learned models that demand category-specific training. We present Neu-PiG, a fast deformation optimization method based on a novel preconditioned latent-grid encoding that distributes spatial features parameterized on the position and normal direction of a keyframe surface. Our method encodes entire deformations across all time steps at various spatial scales into a multi-resolution latent grid, parameterized by the position and normal direction of a reference surface from a single keyframe. This latent representation is then augmented for time modulation and decoded into per-frame 6-DoF deformations via a lightweight multilayer perceptron (MLP). To achieve high-fidelity, drift-free surface reconstructions in seconds, we employ Sobolev preconditioning during gradient-based training of the latent space, completely avoiding the need for any explicit correspondences or further priors. Experiments across diverse human and animal datasets demonstrate that Neu-PiG outperforms state-the-art approaches, offering both superior accuracy and scalability to long sequences while running at least 60x faster than existing training-free methods and achieving inference speeds on the same order as heavy pretrained models.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [107] [AgenticTyper: Automated Typing of Legacy Software Projects Using Agentic AI](https://arxiv.org/abs/2602.21251)
*Clemens Pohle*

Main category: cs.SE

TL;DR: AgenticTyper利用LLM代理系统，通过迭代错误纠正和转译比较，高效解决了JavaScript类型错误，大幅减少手动工作量。


<details>
  <summary>Details</summary>
Motivation: 传统JavaScript系统缺乏类型安全性，手动添加类型成本高，现有自动化类型研究未全面解决类型检查设置、定义生成、错误识别等问题。

Method: 基于大型语言模型（LLM）的代理系统，通过转译比较实现迭代错误纠正和行为保留。

Result: 在两个专有仓库（81K LOC）上评估，AgenticTyper在20分钟内解决了所有633个初始类型错误，将手动工作量从一天减少到20分钟。

Conclusion: AgenticTyper通过迭代错误纠正和行为保留，显著减少了手动添加类型的工作量，并在短时间内解决了大量类型错误。

Abstract: Legacy JavaScript systems lack type safety, making maintenance risky. While TypeScript can help, manually adding types is expensive. Previous automated typing research focuses on type inference but rarely addresses type checking setup, definition generation, bug identification, or behavioral correctness at repository scale. We present AgenticTyper, a Large Language Model (LLM)-based agentic system that addresses these gaps through iterative error correction and behavior preservation via transpilation comparison. Evaluation on two proprietary repositories (81K LOC) shows that AgenticTyper resolves all 633 initial type errors in 20 minutes, reducing manual effort from one working day.

</details>


### [108] [From Ad-Hoc Scripts to Orchestrated Pipelines: Architecting a Resilient ELT Framework for Developer Productivity Metrics](https://arxiv.org/abs/2602.21568)
*Yuvraj Agrawal,Pallav Jain*

Main category: cs.SE

TL;DR: 本文介绍了从临时调度迁移到稳健ELT管道的经验，强调了数据可靠性对工程分析的重要性。


<details>
  <summary>Details</summary>
Motivation: 开发人员生产力仪表板的数据可靠性问题（如'静默故障'）削弱了其效用，导致组织信任度下降。

Method: 从临时调度迁移到使用有向无环图（DAG）编排和Medallion架构的稳健提取-加载-转换（ELT）管道。

Result: 实现了数据提取与转换的解耦、不可变原始历史记录的必要性以及基于状态的依赖管理。

Conclusion: 将指标管道视为生产级分布式系统是实现可持续工程分析的前提。

Abstract: Developer Productivity Dashboards are essential for visualizing DevOps performance metrics such as Deployment Frequency and Change Failure Rate (DORA). However, the utility of these dashboards is frequently undermined by data reliability issues. In early iterations of our platform, ad-hoc ingestion scripts (Cron jobs) led to "silent failures," where data gaps went undetected for days, eroding organizational trust. This paper reports on our experience migrating from legacy scheduling to a robust Extract-Load-Transform (ELT) pipeline using Directed Acyclic Graph (DAG) orchestration and Medallion Architecture. We detail the operational benefits of decoupling data extraction from transformation, the necessity of immutable raw history for metric redefinition, and the implementation of state-based dependency management. Our experience suggests that treating the metrics pipeline as a production-grade distributed system is a prerequisite for sustainable engineering analytics.

</details>


### [109] [Structurally Aligned Subtask-Level Memory for Software Engineering Agents](https://arxiv.org/abs/2602.21611)
*Kangning Shen,Jingyuan Zhang,Chenxi Sun,Wencong Zeng,Yang Yue*

Main category: cs.SE

TL;DR: 论文提出一种子任务级记忆方法，解决了实例级记忆的粒度不匹配问题，显著提升了LLM在软件工程任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决实例级记忆在任务表面描述相似但推理逻辑不同时导致的检索偏差问题。

Method: 提出Structurally Aligned Subtask-Level Memory方法，将记忆存储、检索和更新与代理的功能分解对齐。

Result: 在SWE-bench Verified上的实验表明，该方法平均Pass@1比基础代理提升+4.7 pp（如Gemini 2.5 Pro上+6.8 pp），且性能增益随交互步骤增加而增长。

Conclusion: Structurally Aligned Subtask-Level Memory方法显著提升了大型语言模型在复杂软件工程任务中的长期推理能力，优于传统实例级记忆方法。

Abstract: Large Language Models (LLMs) have demonstrated significant potential as autonomous software engineering (SWE) agents. Recent work has further explored augmenting these agents with memory mechanisms to support long-horizon reasoning. However, these approaches typically operate at a coarse instance granularity, treating the entire problem-solving episode as the atomic unit of storage and retrieval. We empirically demonstrate that instance-level memory suffers from a fundamental granularity mismatch, resulting in misguided retrieval when tasks with similar surface descriptions require distinct reasoning logic at specific stages. To address this, we propose Structurally Aligned Subtask-Level Memory, a method that aligns memory storage, retrieval, and updating with the agent's functional decomposition. Extensive experiments on SWE-bench Verified demonstrate that our method consistently outperforms both vanilla agents and strong instance-level memory baselines across diverse backbones, improving mean Pass@1 over the vanilla agent by +4.7 pp on average (e.g., +6.8 pp on Gemini 2.5 Pro). Performance gains grow with more interaction steps, showing that leveraging past experience benefits long-horizon reasoning in complex software engineering tasks.

</details>


### [110] [Uncertainty Modeling for SysML v2](https://arxiv.org/abs/2602.21641)
*Man Zhang,Yunyang Li,Tao Yue*

Main category: cs.SE

TL;DR: The paper extends SysML v2 with PSUM for uncertainty modeling, validated via case studies, proving its effectiveness in MBSE.


<details>
  <summary>Details</summary>
Motivation: To address the lack of native uncertainty modeling constructs in SysML v2 despite its improved semantic rigor, and to leverage the standardized PSUM specification for uncertainty-aware MBSE.

Method: The paper systematically extends SysML v2 by incorporating the PSUM metamodel, allowing for explicit specification of uncertainty sources and propagation within system models. Validation was conducted through seven case studies.

Result: The extension (PSUM-SysMLv2) is shown to be expressive and applicable for uncertainty-aware MBSE, enabling uncertainty and its propagation analyses.

Conclusion: The proposed extension (PSUM-SysMLv2) successfully integrates PSUM into SysML v2, enabling explicit uncertainty modeling and propagation while maintaining compatibility with SysML v2 standards.

Abstract: Uncertainty is inherent in modern engineered systems, including cyber-physical systems, autonomous systems, and large-scale software-intensive infrastructures (such as microservice-based systems) operating in dynamic and partially observable environments. The recent publication of Precise Semantics for Uncertainty Modeling (PSUM) by the Object Management Group represents the first standardized specification for uncertainty modeling within the Model-Based Systems Engineering (MBSE) community, providing formally defined semantics for representing and reasoning about uncertainty in models. In parallel, the second version of Systems Modeling Language (SysML v2) was released as the next-generation systems modeling language, offering improved semantic rigor and reusability, yet lacking native constructs aligned with PSUM for first-class uncertainty representation. This paper proposes a systematic extension of SysML v2 that incorporates the PSUM metamodel into its modeling framework. The extension enables explicit specification of indeterminacy sources, structured characterization of uncertainties, and consistent propagation of uncertainty within system models, while preserving conformance with SysML v2 syntax and semantics. We validate the approach through seven case studies. Results demonstrate that the proposed extension (PSUM-SysMLv2) is expressive and applicable for uncertainty-aware MBSE, and potentially enables uncertainty and uncertainty propagation analyses.

</details>


### [111] [AkiraRust: Re-thinking LLM-aided Rust Repair Using a Feedback-guided Thinking Switch](https://arxiv.org/abs/2602.21681)
*Renshuang Jiang,Yichong Wang,Pan Dong,Xiaoxiang Fang,Zhenling Duan,Tinglue Wang,Yuchen Hu,Jie Yu,Zhe Jiang*

Main category: cs.SE

TL;DR: AkiraRust是一个基于LLM和有限状态机的Rust修复框架，通过动态适应和双模推理提升修复效率和语义正确性。


<details>
  <summary>Details</summary>
Motivation: 现有LLM驱动的修复框架因缺乏可执行语义或模板僵化，导致语义不正确和上下文感知有限。

Method: AkiraRust结合有限状态机和双模推理策略，通过多代理协作实现上下文感知和运行时自适应的修复。

Result: 实验结果表明，AkiraRust达到约92%的语义正确性，并比SOTA平均提速2.2倍。

Conclusion: AkiraRust通过动态适应的检测和修复流程，显著提升了Rust程序中未定义行为的修复效率和语义正确性。

Abstract: Eliminating undefined behaviors (UBs) in Rust programs requires a deep semantic understanding to enable accurate and reliable repair. While existing studies have demonstrated the potential of LLMs to support Rust code analysis and repair, most frameworks remain constrained by inflexible templates or lack grounding in executable semantics, resulting in limited contextual awareness and semantic incorrectness. Here, we present AkiraRust, an LLM-driven repair and verification framework that incorporates a finite-state machine to dynamically adapt its detection and repair flow to runtime semantic conditions. AkiraRust introduces a dual-mode reasoning strategy that coordinates fast and slow thinking across multiple agents. Each agent is mapped to an FSM state, and a waveform-driven transition controller manages state switching, rollback decisions, and semantic check pointing, enabling context-aware and runtime-adaptive repair. Experimental results show that AkiraRust achieves about 92% semantic correctness and delivers a 2.2x average speedup compared to SOTA.

</details>


### [112] [EditFlow: Benchmarking and Optimizing Code Edit Recommendation Systems via Reconstruction of Developer Flows](https://arxiv.org/abs/2602.21697)
*Chenyan Liu,Yun Lin,Jiaxin Chang,Jiawei Liu,Binhang Qi,Bo Jiang,Zhiyong Huang,Jin Song Dong*

Main category: cs.SE

TL;DR: EditFlow通过重建开发者编辑流程，优化代码编辑推荐系统，解决了AI辅助导致开发者效率下降的问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在代码编辑方面取得了显著进展，但现有方法存在技术准确性与开发者生产力之间的脱节问题，导致开发者在使用AI辅助时效率下降。

Method: 提出了EditFlow，通过收集反映开发者编辑流程的数据、开发数字孪生模拟器来模拟编辑过程，并开发统一的优化策略来增强模型对开发者思维流的感知。

Result: EditFlow通过解决数据收集、模拟编辑过程和统一优化策略等挑战，成功提升了代码编辑推荐系统的性能。

Conclusion: EditFlow通过重建开发者编辑流程，优化了代码编辑推荐系统，解决了静态提交快照缺乏时间信息的问题，从而更好地与开发者的自然推理过程对齐。

Abstract: Large language models (LLMs) for code editing have achieved remarkable progress, yet recent empirical studies reveal a fundamental disconnect between technical accuracy and developer productivity. Despite their strong benchmark performance, developers complete tasks 19% slower when using AI assistance, with over 68.81% of recommendations disrupting their mental flow. This misalignment stems from the use of static commit snapshots that lack temporal information, causing models to optimize for end results rather than the incremental, context-sensitive steps that align with developers' natural reasoning process.
  To bridge this gap, we present EditFlow, which benchmarks and optimizes subsequent code edit recommendation systems through the reconstruction of developer editing flows. EditFlow addresses three key challenges. First, collecting edit-order data that reflects developers' flow is inherently difficult: manual annotation introduces prohibitive overhead, while development logs capture only single trajectories instead of all plausible editing flows. Second, benchmarking recommendation performance against developers' ongoing editing flow requires a digital-twin-like simulation that can faithfully simulate the editing process. Third, existing heterogeneous systems vary drastically in scale and architecture, posing challenges for developing a unified optimization strategy that endows all models with mental-flow awareness regardless of design or capability.
  ......

</details>


### [113] [Proto-ML: An IDE for ML Solution Prototyping](https://arxiv.org/abs/2602.21734)
*Selin Coban,Miguel Perez,Horst Lichter*

Main category: cs.SE

TL;DR: Proto-ML是一个专为ML原型设计优化的IDE，通过统一框架解决协作和知识重用问题，初步反馈显示其能提升效率和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有的ML原型设计工具在利益相关者之间的有效协作和知识重用方面支持有限，Proto-ML旨在解决这些问题。

Method: Proto-ML IDE由三个扩展包组成：原型实现、分析和知识管理。这些扩展支持从评估原型质量到在整个开发过程中纳入利益相关者观点的任务。

Result: 初步用户反馈表明，Proto-ML可以提高原型设计效率，并促进更透明和可重用的ML解决方案开发。

Conclusion: Proto-ML通过提供一个统一的框架，解决了ML原型设计中的关键不足，如利益相关者参与不足、跨项目知识重用有限和工具支持分散的问题，从而提高了原型设计效率并促进了透明和可重用的ML解决方案开发。

Abstract: Prototyping plays a critical role in the development of machine learning (ML) solutions, yet existing tools often provide limited support for effective collaboration and knowledge reuse among stakeholders. This paper introduces Proto-ML, an IDE designed to strengthen ML prototyping workflows. By addressing key deficiencies such as insufficient stakeholder involvement, limited cross-project knowledge reuse, and fragmented tool support, Proto-ML offers a unified framework that enables structured documentation of prototyping activities and promotes knowledge sharing across projects.
  The Proto-ML IDE consists of three extension bundles: prototype implementation, analysis, and knowledge management. These extensions support tasks ranging from evaluating prototype quality against defined criteria to incorporating stakeholder perspectives throughout the development process. Preliminary user feedback suggests that Proto-ML can increase prototyping efficiency and foster more transparent and reusable ML solution development.

</details>


### [114] [An Evaluation of Context Length Extrapolation in Long Code via Positional Embeddings and Efficient Attention](https://arxiv.org/abs/2602.21800)
*Madhusudan Ghosh,Rishabh Gupta*

Main category: cs.SE

TL;DR: 本文研究了零样本推理方法，改进了位置编码和注意力机制，以解决大型语言模型在长代码补全任务中的上下文长度限制问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在软件工程中的自动化工具应用受到固定上下文长度的限制，影响了其在长、特定领域代码序列中的泛化能力。

Method: 研究了零样本推理方法，专注于改进位置编码和优化注意力机制。

Result: 提出了一种改进位置编码和优化注意力机制的方法，有效提升了长代码补全任务的性能。

Conclusion: 本文通过研究零样本推理方法，改进了位置编码和注意力机制，为长代码补全任务中的上下文长度外推提供了有效解决方案。

Abstract: The rapid advancement of large language models (LLMs) has led to a significant increase in automated tools in the software engineering, capable of performing various code-related tasks such as code generation, completion, and translation. Despite these advancements, its effectiveness is constrained by fixed context lengths, limiting its ability to generalize across long, domain-specific code sequences. To address this challenge, we investigate zero-shot, inference-only methods aimed at improving position encodings and optimizing attention mechanisms. Our goal is to provide a thorough analysis of current approaches that facilitate context length extrapolation in code, particularly in the context of long code completion tasks.

</details>


### [115] [An Empirical Study of Bugs in Modern LLM Agent Frameworks](https://arxiv.org/abs/2602.21806)
*Xinxue Zhu,Jiacong Wu,Xiaoyu Zhang,Tianlin Li,Yanzhou Mu,Juan Zhai,Chao Shen,Yang Liu*

Main category: cs.SE

TL;DR: 对CrewAI和LangChain的998份bug报告进行实证研究，发现代理框架bug主要源于API和文档问题，多发生在'Self-Action'阶段，表现为功能错误和崩溃。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注代理级故障，忽视了框架级bug。随着LLM代理系统的广泛应用，理解底层框架的bug变得至关重要。

Method: 通过对CrewAI和LangChain的998份bug报告进行实证研究，构建了一个包含15种根本原因和7种可观察症状的分类法，覆盖代理生命周期的五个阶段。

Result: 研究揭示了代理框架bug的主要根源和表现，为框架设计和调试提供了重要见解。

Conclusion: 研究发现，LLM代理框架的bug主要集中在'API误用'、'API不兼容'和'文档不同步'等问题，且多发生在'Self-Action'阶段。这些bug通常表现为'功能错误'、'崩溃'和'构建失败'，影响任务进展和控制流。

Abstract: LLM agents have been widely adopted in real-world applications, relying on agent frameworks for workflow execution and multi-agent coordination. As these systems scale, understanding bugs in the underlying agent frameworks becomes critical. However, existing work mainly focuses on agent-level failures, overlooking framework-level bugs. To address this gap, we conduct an empirical study of 998 bug reports from CrewAI and LangChain, constructing a taxonomy of 15 root causes and 7 observable symptoms across five agent lifecycle stages: 'Agent Initialization','Perception', 'Self-Action', 'Mutual Interaction' and 'Evolution'. Our findings show that agent framework bugs mainly arise from 'API misuse', 'API incompatibility', and 'Documentation Desync', largely concentrated in the 'Self-Action' stage. Symptoms typically appear as 'Functional Error', 'Crash', and 'Build Failure', reflecting disruptions to task progression and control flow.

</details>


### [116] [From Restructuring to Stabilization: A Large-Scale Experiment on Iterative Code Readability Refactoring with Large Language Models](https://arxiv.org/abs/2602.21833)
*Norman Peitek,Julia Hess,Sven Apel*

Main category: cs.SE

TL;DR: 研究通过实验发现LLM在代码重构中表现出稳定性和内在理解能力，提示策略对重构影响有限，为LLM辅助代码重构的可靠性提供了实证支持。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM可以快速重构代码，但其质量可能存在不一致和不可预测的行为。本文旨在系统研究LLM在代码重构中的能力，特别是提高代码可读性。

Method: 通过使用GPT5.1对230个Java代码片段进行大规模实验，每个片段在五种迭代和三种不同提示策略下进行代码可读性重构。将细粒度代码变化分类为实现、语法和注释级别的转换，并调查功能正确性和结果鲁棒性。

Result: 研究发现：1.迭代代码重构呈现初始重构阶段后趋于稳定，表明LLM对“最优可读”代码版本有内在理解；2.收敛模式在不同代码变体中表现稳健；3.明确提示特定可读性因素轻微影响重构动态。

Conclusion: 该研究为评估LLM辅助代码重构的可靠性提供了实证基础，并为未来研究开辟了路径，包括跨模型的比较分析和LLM重构代码中其他软件质量维度的系统评估。

Abstract: Large language models (LLMs) are increasingly used for automated code refactoring tasks. Although these models can quickly refactor code, the quality may exhibit inconsistencies and unpredictable behavior. In this article, we systematically study the capabilities of LLMs for code refactoring with a specific focus on improving code readability.
  We conducted a large-scale experiment using GPT5.1 with 230 Java snippets, each systematically varied and refactored regarding code readability across five iterations under three different prompting strategies. We categorized fine-grained code changes during the refactoring into implementation, syntactic, and comment-level transformations. Subsequently, we investigated the functional correctness and tested the robustness of the results with novel snippets.
  Our results reveal three main insights: First, iterative code refactoring exhibits an initial phase of restructuring followed by stabilization. This convergence tendency suggests that LLMs possess an internalized understanding of an "optimally readable" version of code. Second, convergence patterns are fairly robust across different code variants. Third, explicit prompting toward specific readability factors slightly influences the refactoring dynamics.
  These insights provide an empirical foundation for assessing the reliability of LLM-assisted code refactoring, which opens pathways for future research, including comparative analyses across models and a systematic evaluation of additional software quality dimensions in LLM-refactored code.

</details>


### [117] [Enhancing LLM-Based Test Generation by Eliminating Covered Code](https://arxiv.org/abs/2602.21997)
*WeiZhe Xu,Mengyu Liu,Fanxin Kong*

Main category: cs.SE

TL;DR: A scalable LLM-based method improves test generation for complex methods by combining context retrieval and iterative testing, outperforming existing solutions.


<details>
  <summary>Details</summary>
Motivation: Existing LLM-based test generation solutions perform poorly on complex methods due to token limits and reduced reasoning effectiveness, necessitating a scalable method to improve coverage.

Method: The approach involves two key steps: context information retrieval using LLMs and static analysis, followed by iterative test generation with code elimination to simplify the testing task.

Result: The method outperforms state-of-the-art LLM-based and search-based methods in achieving high coverage on complex methods, as demonstrated by evaluations on open-source projects.

Conclusion: The proposed scalable LLM-based unit test generation method effectively addresses the limitations of existing solutions by improving coverage on complex methods through context information retrieval and iterative test generation with code elimination.

Abstract: Automated test generation is essential for software quality assurance, with coverage rate serving as a key metric to ensure thorough testing. Recent advancements in Large Language Models (LLMs) have shown promise in improving test generation, particularly in achieving higher coverage. However, while existing LLM-based test generation solutions perform well on small, isolated code snippets, they struggle when applied to complex methods under test. To address these issues, we propose a scalable LLM-based unit test generation method. Our approach consists of two key steps. The first step is context information retrieval, which uses both LLMs and static analysis to gather relevant contextual information associated with the complex methods under test. The second step, iterative test generation with code elimination, repeatedly generates unit tests for the code slice, tracks the achieved coverage, and selectively removes code segments that have already been covered. This process simplifies the testing task and mitigates issues arising from token limits or reduced reasoning effectiveness associated with excessively long contexts. Through comprehensive evaluations on open-source projects, our approach outperforms state-of-the-art LLM-based and search-based methods, demonstrating its effectiveness in achieving high coverage on complex methods.

</details>


### [118] [Detecting UX smells in Visual Studio Code using LLMs](https://arxiv.org/abs/2602.22020)
*Andrés Rodriguez,Juan Cruz Gardey,Alejandra Garrido*

Main category: cs.SE

TL;DR: LLM-assisted analysis of GitHub issues in Visual Studio Code identified UX smells, mainly in informativeness, clarity, intuitiveness, and efficiency—key qualities for developers.


<details>
  <summary>Details</summary>
Motivation: Despite the central role of Integrated Development Environments in developers' daily work, empirical studies on their usability and user experience are limited.

Method: An LLM-assisted approach was used to mine and classify user-reported issues from the GitHub repository, validated by a taxonomy and expert review.

Result: The majority of UX smells were found in areas developers value most: informativeness, clarity, intuitiveness, and efficiency.

Conclusion: The study highlights the concentration of UX smells in key qualities like informativeness, clarity, intuitiveness, and efficiency, which are crucial for developers.

Abstract: Integrated Development Environments shape developers' daily experience, yet the empirical study of their usability and user experience (UX) remains limited. This work presents an LLM-assisted approach to detecting UX smells in Visual Studio Code by mining and classifying user-reported issues from the GitHub repository. Using a validated taxonomy and expert review, we identified recurring UX problems that affect the developer experience. Our results show that the majority of UX smells are concentrated in informativeness, clarity, intuitiveness, and efficiency, qualities that developers value most.

</details>


### [119] [Visual Milestone Planning in a Hybrid Development Context](https://arxiv.org/abs/2602.22076)
*Eduardo Miranda*

Main category: cs.SE

TL;DR: VMP是一种视觉化协作规划方法，通过敏捷词汇和类似俄罗斯方块的调度画布，帮助团队理解和分配工作，适用于混合开发流程。


<details>
  <summary>Details</summary>
Motivation: 为了促进敏捷实践者采用VMP作为混合开发流程的前端，通过视觉化和协作规划提升团队对工作方法的理解和承诺。

Method: 使用敏捷词汇的视觉里程碑规划（VMP）方法，包括里程碑规划矩阵和工作包时间盒，通过类似俄罗斯方块的资源时间调度画布进行工作分配。

Result: VMP方法成功实现了产品待办事项到里程碑的分配，并通过工作包时间盒确定了里程碑的截止日期。

Conclusion: VMP方法通过视觉化和协作规划，促进了团队对工作方法的共同理解，并通过直接操作规划构造来增强承诺，为混合开发流程提供了有效的前端支持。

Abstract: This paper explains the Visual Milestone Planning (VMP) method using an agile vocabulary to facilitate its adoption by agile practitioners as a front end for a hybrid development process. VMP is a visual and collaborative planning approach which promotes a shared understanding of the work approach and commitment through the direct manipulation by team members of the reified planning constructs involved in the development of the plan. Once the product backlog has been established and relevant milestones identified, a novel construct called the milestone planning matrix is used to document the allocation of product backlog items to milestones. The milestones due dates are later determined by grouping sticky notes representing the work to be performed into time-boxes called work packages and accommodating them on a resource and time scaled scheduling canvas very much as it would be done in a Tetris game.

</details>


### [120] [SWE-Protégé: Learning to Selectively Collaborate With an Expert Unlocks Small Language Models as Software Engineering Agents](https://arxiv.org/abs/2602.22124)
*Patrick Tser Jern Kon,Archana Pradeep,Ang Chen,Alexander P. Ellis,Warren Hunt,Zijian Wang,John Yang,Samuel Thompson*

Main category: cs.SE

TL;DR: SWE-Protégé框架通过专家协作和强化学习，显著提升小型语言模型在软件修复任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决小型语言模型在长周期软件工程任务（如SWE-bench）中存在的动作循环和低解决率问题。

Method: 结合监督微调（基于专家增强轨迹）和强化学习（明确抑制退化循环和无效专家协作），对Qwen2.5-Coder-7B-Instruct进行轻量后训练。

Result: 在SWE-bench Verified上达到42.4%的Pass@1，较之前最佳SLM提升25.4%，且专家调用稀疏（每任务约4次，占11%总token量）。

Conclusion: SWE-Protégé框架通过专家-学徒协作机制显著提升了小型语言模型在软件修复任务中的表现，同时保持了资源的高效利用。

Abstract: Small language models (SLMs) offer compelling advantages in cost, latency, and adaptability, but have so far lagged behind larger models on long-horizon software engineering tasks such as SWE-bench, where they suffer from pervasive action looping and low resolution rates. We introduce SWE-Protégé, a post-training framework that reframes software repair as an expert-protégé collaboration problem. In SWE-Protégé, an SLM remains the sole decision-maker while learning to selectively seek guidance from a strong expert model, recognize stalled states, and follow through on expert feedback. Our approach combines supervised fine-tuning on expert-augmented trajectories with agentic reinforcement learning that explicitly discourages degenerative looping and unproductive expert collaboration. We lightly post-train Qwen2.5-Coder-7B-Instruct to achieve 42.4% Pass@1 on SWE-bench Verified, a +25.4% improvement over the prior SLM state of the art, while using expert assistance sparsely (~4 calls per task and 11% of total tokens).

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [121] [Half Pound Filter for Real-Time Animation Blending](https://arxiv.org/abs/2602.21702)
*Riccardo Lasagno*

Main category: cs.GR

TL;DR: HPF改进1EF，通过自动调谐和触发算法优化动画切换连续性，在LaFAN1数据集上表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决实时模拟中动画剪辑切换导致的骨骼轨迹不连续问题，同时避免引入明显的人工痕迹。

Method: 提出了Half Pound Filter（HPF）作为1 Euro Filter的改进，并开发了自动数据驱动调谐和基于运动导数边界检查的触发算法。

Result: 通过LaFAN1数据集案例比较，HPF在MSE和NPSS指标上优于其他常见动画过滤技术。

Conclusion: HPF在人类动画重放中表现出更高的保真度，通过自动触发和恢复系统优化了动画切换的连续性。

Abstract: This paper introduces the Half Pound Filter (HPF) as a modification of the 1 Euro Filter (1EF) and algorithms for automatic data-driven tuning and for filter triggering based on motion derivative boundary checks. An application of the filter is presented in the context of human animation replay for real-time simulations, where switches in animation clips cause discontinuities that must be hidden by filtering the bone trajectory without introducing noticeable artifacts. The quality of the filtering will be compared with other common animation filtering techniques using an example case drawn fromthe LaFAN1 dataset, showing that the resulting animation is replayed with higher fidelity by evaluating the Mean Squared Error (MSE) and Normalized Power Spectrum Similarity (NPSS) for each setup. Performances will be evaluated using both a standard predetermined triggerpoint and blending distance and the automatic blending trigger and recovery system.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [122] [Precedence-Constrained Decision Trees and Coverings](https://arxiv.org/abs/2602.21312)
*Michał Szyfelbein,Dariusz Dereniowski*

Main category: cs.DS

TL;DR: 本文研究了带优先约束的最优决策树和集合覆盖问题，提出了O*(√m)近似算法，并证明了其紧性，同时针对特定优先类型给出了多对数近似保证。


<details>
  <summary>Details</summary>
Motivation: 研究带有优先约束的最优决策树和集合覆盖问题，探索其近似算法和不可近似性，填补现有研究空白。

Method: 通过开发一系列算法归约，利用一个问题的近似算法通过黑盒方式为另一个问题提供近似解。引入最大密度优先封闭子族问题以捕捉组合结构。

Result: 提供了O*(√m)近似算法，并证明了o(m^(1/12-ε))的不可近似性。针对外森林和内森林优先类型，给出了紧的多对数近似结果。

Conclusion: 本文为带有优先约束的最优决策树和集合覆盖问题提供了O*(√m)近似算法，并证明了其紧性，同时针对特定优先类型（外森林和内森林）给出了多对数近似保证。

Abstract: This work considers a number of optimization problems and reductive relations between them. The two main problems we are interested in are the \emph{Optimal Decision Tree} and \emph{Set Cover}. We study these two fundamental tasks under precedence constraints, that is, if a test (or set) $X$ is a predecessor of $Y$, then in any feasible decision tree $X$ needs to be an ancestor of $Y$ (or respectively, if $Y$ is added to set cover, then so must be $X$). For the Optimal Decision Tree we consider two optimization criteria: worst case identification time (height of the tree) or the average identification time. Similarly, for the Set Cover we study two cost measures: the size of the cover or the average cover time.
  Our approach is to develop a number of algorithmic reductions, where an approximation algorithm for one problem provides an approximation for another via a black-box usage of a procedure for the former. En route we introduce other optimization problems either to complete the `reduction landscape' or because they hold the essence of combinatorial structure of our problems. The latter is brought by a problem of finding a maximum density precedence closed subfamily, where the density is defined as the ratio of the number of items the family covers to its size. By doing so we provide $\cO^*(\sqrt{m})$-approximation algorithms for all of the aforementioned problems. The picture is complemented by a number of hardness reductions that provide $o(m^{1/12-ε})$-inapproximability results for the decision tree and covering problems. Besides giving a complete set of results for general precedence constraints, we also provide polylogarithmic approximation guarantees for two most typically studied and applicable precedence types, outforests and inforests. By providing corresponding hardness results, we show these results to be tight.

</details>


### [123] [DRESS and the WL Hierarchy: Climbing One Deletion at a Time](https://arxiv.org/abs/2602.21557)
*Eduar Castrillo Velilla*

Main category: cs.DS

TL;DR: $Δ^ℓ$-DRESS 方法通过迭代节点删除扩展 WL 层次结构，实验验证其在 CFI 基准家族中的有效性，但计算成本随 $ℓ$ 增加。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过 $Δ^ℓ$-DRESS 方法扩展 WL 层次结构，以区分 CFI 基准家族中的非同构图。

Method: 通过应用 $ℓ$ 级迭代节点删除到 DRESS 连续结构细化框架，Original-DRESS 在所有 $inom{n}{ℓ}$ 个子图上运行，并比较生成的直方图。

Result: 实验表明，Original-DRESS 能区分 $	ext{CFI}(K_3)$，而每增加一个删除级别，WL 级别扩展一级，$Δ^3$ 在 $	ext{CFI}(K_7)$ 上失败，确认了 $ℓ+2$-WL 的边界。

Conclusion: $Δ^ℓ$-DRESS 是一个实用的框架，能够在规范的 CFI 基准家族上系统地提升 WL 层次结构。

Abstract: The Cai--Fürer--Immerman (CFI) construction provides the canonical family of hard instances for the Weisfeiler--Leman (WL) hierarchy: distinguishing the two non-isomorphic CFI graphs over a base graph $G$ requires $k$-WL where $k$ meets or exceeds the treewidth of $G$. In this paper, we introduce $Δ^\ell$-DRESS, which applies $\ell$ levels of iterated node deletion to the DRESS continuous structural refinement framework. $Δ^\ell$-DRESS runs Original-DRESS on all $\binom{n}{\ell}$ subgraphs obtained by removing $\ell$ nodes, and compares the resulting histograms. We show empirically on the canonical CFI benchmark family that Original-DRESS ($Δ^0$) already distinguishes $\text{CFI}(K_3)$ (requiring 2-WL), and that each additional deletion level extends the range by one WL level: $Δ^1$ reaches 3-WL, $Δ^2$ reaches 4-WL, and $Δ^3$ reaches 5-WL, distinguishing CFI pairs over $K_n$ for $n = 3, \ldots, 6$. Crucially, $Δ^3$ fails on $\text{CFI}(K_7)$ (requiring 6-WL), confirming a sharp boundary at $(\ell+2)$-WL. The computational cost is $\mathcal{O}\bigl(\binom{n}{\ell} \cdot I \cdot m \cdot d_{\max}\bigr)$ -- polynomial in $n$ for fixed $\ell$. These results establish $Δ^\ell$-DRESS as a practical framework for systematically climbing the WL hierarchy on the canonical CFI benchmark family.

</details>


### [124] [Maximal Biclique Enumeration with Improved Worst-Case Time Complexity Guarantee: A Partition-Oriented Strategy](https://arxiv.org/abs/2602.21700)
*Kaixin Wang,Kaiqiang Yu,Cheng Long*

Main category: cs.DS

TL;DR: IPS算法通过改进停止标准和枢轴选择策略，显著降低了最大双团枚举问题的时间复杂度，理论和实践性能均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 最大双团枚举问题在电子商务和交易网络中具有广泛应用，但现有方法的最坏时间复杂度较高，亟需改进。

Method: IPS算法通过放宽现有方法的严格停止标准，并改进枢轴选择策略，实现了更高效的最大双团枚举。此外，还应用了基于包含-排除的框架来进一步提升性能。

Result: IPS算法将最坏时间复杂度从$O(m\cdot (\sqrt{2})^n)$提升至$O(m\cdot \alpha^n + n\cdot \beta)$，其中$\alpha$约为1.3954，进一步优化后适用于稀疏图的时间复杂度为$O(n\cdot \gamma^2\cdot\alpha^\gamma+ \gamma\cdot \beta)$。

Conclusion: 本文提出的算法IPS在理论和实践上均优于现有方法，显著降低了最大双团枚举问题的最坏时间复杂度。

Abstract: The maximal biclique enumeration problem in bipartite graphs is fundamental and has numerous applications in E-commerce and transaction networks. Most existing studies adopt a branch-and-bound framework, which recursively expands a partial biclique with a vertex until no further vertices can be added. Equipped with a basic pivot selection strategy, all state-of-the-art methods have a worst-case time complexity no better than $O(m\cdot (\sqrt{2})^n)$}, where $m$ and $n$ are the number of edges and vertices in the graph, respectively. In this paper, we introduce a new branch-and-bound (BB) algorithm \texttt{IPS}. In \texttt{IPS}, we relax the strict stopping criterion of existing methods by allowing termination when all maximal bicliques within the current branch can be outputted in the time proportional to the number of maximal bicliques inside, reducing the total number of branches required. Second, to fully unleash the power of the new termination condition, we propose an improved pivot selection strategy, which well aligns with the new termination condition to achieve better theoretical and practical performance. Formally, \texttt{IPS} improves the worst-case time complexity to $O(m\cdot α^n + n\cdot β)$, where $α(\approx 1.3954)$ is the largest positive root of $x^4-2x-1=0$ and $β$ represents the number of maximal bicliques in the graph, respectively. This result surpasses that of all existing algorithms given that $α$ is strictly smaller than $\sqrt{2}$ and $β$ is at most $(\sqrt{2})^n-2$ theoretically. Furthermore, we apply an inclusion-exclusion-based framework to boost the performance of \texttt{IPS}, improving the worst-case time complexity to $O(n\cdot γ^2\cdotα^γ+ γ\cdot β)$ for large sparse graphs ($γ$ is a parameter satisfying $γ\ll n$ for sparse graphs).

</details>


### [125] [Delayed-Clairvoyant Flow Time Scheduling via a Borrow Graph Analysis](https://arxiv.org/abs/2602.21827)
*Alexander Lindermayr,Jens Schlöter*

Main category: cs.DS

TL;DR: 本文提出了一种α-clairvoyant调度规则，竞争比为O(1/(1-α))，填补了理论空白并证明了其紧性。


<details>
  <summary>Details</summary>
Motivation: 研究在α-clairvoyant模型下的调度问题，填补clairvoyant与非clairvoyant调度之间的理论空白。

Method: 通过巧妙融合两种传统算法，提出了一种调度规则。

Result: 提出的调度规则在0≤α<1时具有O(1/(1-α))的竞争比，且通过随机下界证明了其紧性。

Conclusion: 本文提出了一种α-clairvoyant调度规则，其竞争比为O(1/(1-α))，填补了clairvoyant与非clairvoyant调度之间的空白，并通过随机下界证明了其紧性。

Abstract: We study the problem of preemptively scheduling jobs online over time on a single machine to minimize the total flow time.
  In the traditional clairvoyant scheduling model, the scheduler learns about the processing time of a job at its arrival, and scheduling at any time the job with the shortest remaining processing time (SRPT) is optimal. In contrast, the practically relevant non-clairvoyant model assumes that the processing time of a job is unknown at its arrival, and is only revealed when it completes. Non-clairvoyant flow time minimization does not admit algorithms with a constant competitive ratio. Consequently, the problem has been studied under speed augmentation (JACM'00) or with predicted processing times (STOC'21, SODA'22) to attain constant guarantees.
  In this paper, we consider $α$-clairvoyant scheduling, where the scheduler learns the processing time of a job once it completes an $α$-fraction of its processing time. This naturally interpolates between clairvoyant scheduling ($α=0$) and non-clairvoyant scheduling ($α=1$). By elegantly fusing two traditional algorithms, we propose a scheduling rule with a competitive ratio of $\mathcal{O}(\frac{1}{1-α})$ whenever $0 \leq α< 1$. As $α$ increases, our competitive guarantee transitions nicely (up to constants) between the previously established bounds for clairvoyant and non-clairvoyant flow time minimization. We complement this positive result with a tight randomized lower bound.

</details>


### [126] [Instance-optimal estimation of L2-norm](https://arxiv.org/abs/2602.21937)
*Tomer Adar*

Main category: cs.DS

TL;DR: 本文提出了一种无偏L2估计算法，匹配实例特定二阶矩分析，并证明了估计范数的下界。


<details>
  <summary>Details</summary>
Motivation: Batu和Canonne（FOCS 2017）对L2范数的算法分析及其与均匀性测试的联系进行了广泛研究，但他们的算法在估计L2范数本身时并不总是最优的。

Method: 提出了一种无偏的L2估计算法。

Result: 算法的样本复杂度与实例特定的二阶矩分析相匹配，并证明了Ω(1/(ε‖μ‖2))是每实例下界。

Conclusion: 本文提出了一种无偏的L2估计算法，其样本复杂度与实例特定的二阶矩分析相匹配，并证明了Ω(1/(ε‖μ‖2))是估计分布μ范数的每实例下界。

Abstract: The $L_2$-norm, or collision norm, is a core entity in the analysis of distributions and probabilistic algorithms. Batu and Canonne (FOCS 2017) presented an extensive analysis of algorithmic aspects of the $L_2$-norm and its connection to uniformity testing. However, when it comes to estimating the $L_2$-norm itself, their algorithm is not always optimal compared to the instance-specific second-moment bounds, $O(1/(\varepsilon\|μ\|_2) + (\|μ\|_3^3 - \|μ\|_2^4) / (\varepsilon^2 \|μ\|_2^4))$, as stated by Batu (WoLA 2025, open problem session).
  In this paper, we present an unbiased $L_2$-estimation algorithm whose sample complexity matches the instance-specific second-moment analysis. Additionally, we show that $Ω(1/(\varepsilon \|μ\|_2))$ is indeed a per-instance lower bound for estimating the norm of a distribution $μ$ by sampling (even for non-unbiased estimators).

</details>


### [127] [Tight Bounds for Online Scheduling in the One-Fast-Many-Slow Machines Setting](https://arxiv.org/abs/2602.22108)
*John Jeang,Vladimir Podolskii*

Main category: cs.DS

TL;DR: 本文解决了One-Fast-Many-Slow问题中两个模型的竞争比最优界限，证实了猜想并提供了新的下限。


<details>
  <summary>Details</summary>
Motivation: 解决Sheffield和Westover提出的One-Fast-Many-Slow决策问题中剩余的两个模型的竞争比最优界限问题。

Method: 通过设计算法和构建任务到达过程（TAP）来证明竞争比的下限和上限。

Result: 在Eventually-committing模型中，证明了竞争比等于1.618；在Never-committing模型中，将竞争比下限提升至1.5。

Conclusion: 本文解决了Eventually-committing和Never-committing模型中竞争比的最优界限问题，证实了Kuszmaul和Westover的猜想，并提供了Never-committing模型中的明确下限。

Abstract: In the One-Fast-Many-Slow decision problem, introduced by Sheffield and Westover (ITCS '25), a scheduler, with access to one fast machine and infinitely many slow machines, receives a series of tasks and must allocate the work among its machines. The goal is to minimize the overhead of an online algorithm over the optimal offline algorithm. Three versions of this setting were considered: Instantly-committing schedulers that must assign tasks to machines immediately and irrevocably, Eventually-committing schedulers whose assignments are irrevocable but can occur anytime after a task arrives, and Never-committing schedulers that can interrupt and restart a task on a different machine. In the Instantly-committing model, Sheffield and Westover showed that the optimal competitive ratio is equal to 2, while in the Eventually-committing model the competitive ratio lies in the interval [1.618, 1.678], and in the Never-committing model the competitive ratio lies in the interval [1.366, 1.5] (SPAA '24, ITCS '25). In the latter two models, the exact optimal competitive ratios were left as open problems, moreover Kuszmaul and Westover (SPAA '24) conjectured that the lower bound in the Eventually-committing model is tight.
  In this paper we resolve this problem by providing tight bounds for the competitive ratios in the Eventually-committing and Never-committing models. For Eventually-committing, we prove Kuszmaul and Westover's conjecture by giving an algorithm achieving a competitive ratio equal to the lower bound of $\frac{1+\sqrt{5}}{2}\approx 1.618$. For Never-committing, we provide an explicit Task Arrival Process (TAP) lower bounding the competitive ratio to the previous upper bound of 1.5.

</details>


### [128] [Robust Permutation Flowshops Under Budgeted Uncertainty](https://arxiv.org/abs/2602.22110)
*Noam Goldberg,Danny Hermelin,Dvir Shabtay*

Main category: cs.DS

TL;DR: 本文提出了一种方法，通过解决多项式数量的名义问题实例来处理鲁棒置换流水车间问题，适用于两台机器和固定数量机器的近似求解，并改进了运行时间。


<details>
  <summary>Details</summary>
Motivation: 研究在预算不确定性模型下的鲁棒置换流水车间问题，其中每台机器上最多有给定数量的作业处理时间可能偏离。

Method: 通过类似于Bertsimas和Sim（2003）的分析方法，但对最小-最大目标函数的项应用对偶化，而非线性目标函数。

Result: 证明了该问题的解可通过解决多项式数量的名义问题实例确定，对两台机器的情况可在多项式时间内解决，对固定数量的机器可在多项式时间内近似求解。此外，改进的缩减方法在两台和三台机器的情况下提升了运行时间。

Conclusion: 本文展示了在预算不确定性模型下，通过解决多项式数量的名义问题实例，可以确定鲁棒置换流水车间问题的解。这对于两台机器的情况可在多项式时间内解决，对于固定数量的机器可在多项式时间内近似求解。此外，对于两台和三台机器的情况，通过改进的缩减方法，运行时间有对数因子的提升。

Abstract: We consider the robust permutation flowshop problem under the budgeted uncertainty model, where at most a given number of job processing times may deviate on each machine. We show that solutions for this problem can be determined by solving polynomially many instances of the corresponding nominal problem. As a direct consequence, our result implies that this robust flowshop problem can be solved in polynomial time for two machines, and can be approximated in polynomial time for any fixed number of machines. The reduction that is our main result follows from an analysis similar to Bertsimas and Sim (2003) except that dualization is applied to the terms of a min-max objective rather than to a linear objective function. Our result may be surprising considering that heuristic and exact integer programming based methods have been developed in the literature for solving the two-machine flowshop problem. We conclude by showing a logarithmic factor improvement in the overall running time implied by a naive reduction to nominal problems in the case of two machines and three machines.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [129] [A Dynamic Survey of Soft Set Theory and Its Extensions](https://arxiv.org/abs/2602.21268)
*Takaaki Fujita,Florentin Smarandache*

Main category: cs.AI

TL;DR: 本书概述了软集理论及其扩展，包括核心定义和当前发展方向。


<details>
  <summary>Details</summary>
Motivation: 软集理论为参数化决策建模提供了直接框架，通过将每个属性（参数）分配给给定宇宙的子集，以结构化方式表示不确定性。

Method: 通过调查风格的概述，介绍了软集理论及其变种，包括超软集、超超软集、树软集、双极软集和动态软集等。

Result: 本书总结了软集理论及其扩展的核心定义和代表性构建，并指出了当前研究的关键方向。

Conclusion: 本书提供了对软集及其主要扩展的全面概述，强调了核心定义、代表性构建和当前发展的关键方向。

Abstract: Soft set theory provides a direct framework for parameterized decision modeling by assigning to each attribute (parameter) a subset of a given universe, thereby representing uncertainty in a structured way [1, 2]. Over the past decades, the theory has expanded into numerous variants-including hypersoft sets, superhypersoft sets, TreeSoft sets, bipolar soft sets, and dynamic soft sets-and has been connected to diverse areas such as topology and matroid theory. In this book, we present a survey-style overview of soft sets and their major extensions, highlighting core definitions, representative constructions, and key directions of current development.

</details>


### [130] [A Hierarchical Multi-Agent System for Autonomous Discovery in Geoscientific Data Archives](https://arxiv.org/abs/2602.21351)
*Dmitrii Pantiukhin,Ivan Kuznetsov,Boris Shapkin,Antonia Anna Jost,Thomas Jung,Nikolay Koldunov*

Main category: cs.AI

TL;DR: PANGAEA-GPT是一个分层多代理框架，用于自主数据发现和分析，通过协调代理工作流程提高数据重用性。


<details>
  <summary>Details</summary>
Motivation: 地球科学数据的快速增长带来了可扩展性挑战，大量数据集未被充分利用，限制了数据的重用性。

Method: 采用分层多代理框架，具有集中式Supervisor-Worker拓扑结构，支持数据类型感知路由、沙盒确定性代码执行和通过执行反馈自我纠正。

Result: 通过物理海洋学和生态学的用例场景，展示了系统在最小人工干预下执行复杂多步骤工作流程的能力。

Conclusion: PANGAEA-GPT框架通过协调代理工作流程，为查询和分析异构存储库数据提供了一种方法，显著提高了数据重用性。

Abstract: The rapid accumulation of Earth science data has created a significant scalability challenge; while repositories like PANGAEA host vast collections of datasets, citation metrics indicate that a substantial portion remains underutilized, limiting data reusability. Here we present PANGAEA-GPT, a hierarchical multi-agent framework designed for autonomous data discovery and analysis. Unlike standard Large Language Model (LLM) wrappers, our architecture implements a centralized Supervisor-Worker topology with strict data-type-aware routing, sandboxed deterministic code execution, and self-correction via execution feedback, enabling agents to diagnose and resolve runtime errors. Through use-case scenarios spanning physical oceanography and ecology, we demonstrate the system's capacity to execute complex, multi-step workflows with minimal human intervention. This framework provides a methodology for querying and analyzing heterogeneous repository data through coordinated agent workflows.

</details>


### [131] [Beyond Refusal: Probing the Limits of Agentic Self-Correction for Semantic Sensitive Information](https://arxiv.org/abs/2602.21496)
*Umid Suleymanov,Zaur Rajabov,Emil Mirzazada,Murat Kantarcioglu*

Main category: cs.AI

TL;DR: SemSIEdit框架通过代理“编辑”重写敏感内容，减少34.6%泄露且实用性损失仅9.8%，揭示了规模依赖性安全差异和推理悖论。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）能够推断敏感身份属性、生成有害内容或产生错误信息，如何在不破坏实用性的情况下自我调节这些复杂、上下文相关的敏感信息泄露是一个未解决的科学问题。

Method: 引入了SemSIEdit，一个推理时框架，其中代理“编辑”迭代批评和重写敏感内容，以保持叙述流畅性而非简单拒绝回答。

Result: 代理重写在所有三类SemSI中减少了34.6%的泄露，同时仅带来9.8%的实用性损失。研究还发现规模依赖性安全差异和推理悖论。

Conclusion: SemSIEdit框架通过代理“编辑”迭代批评和重写敏感内容，有效减少了语义敏感信息泄露，同时保持了较高的实用性。研究还揭示了规模依赖性安全差异和推理悖论。

Abstract: While defenses for structured PII are mature, Large Language Models (LLMs) pose a new threat: Semantic Sensitive Information (SemSI), where models infer sensitive identity attributes, generate reputation-harmful content, or hallucinate potentially wrong information. The capacity of LLMs to self-regulate these complex, context-dependent sensitive information leaks without destroying utility remains an open scientific question. To address this, we introduce SemSIEdit, an inference-time framework where an agentic "Editor" iteratively critiques and rewrites sensitive spans to preserve narrative flow rather than simply refusing to answer. Our analysis reveals a Privacy-Utility Pareto Frontier, where this agentic rewriting reduces leakage by 34.6% across all three SemSI categories while incurring a marginal utility loss of 9.8%. We also uncover a Scale-Dependent Safety Divergence: large reasoning models (e.g., GPT-5) achieve safety through constructive expansion (adding nuance), whereas capacity-constrained models revert to destructive truncation (deleting text). Finally, we identify a Reasoning Paradox: while inference-time reasoning increases baseline risk by enabling the model to make deeper sensitive inferences, it simultaneously empowers the defense to execute safe rewrites.

</details>


### [132] [ARLArena: A Unified Framework for Stable Agentic Reinforcement Learning](https://arxiv.org/abs/2602.21534)
*Xiaoxuan Wang,Han Zhang,Haixin Wang,Yidan Shi,Ruoyan Li,Kaiqiao Han,Chenyi Tong,Haoran Deng,Renliang Sun,Alexander Taylor,Yanqiao Zhu,Jason Cong,Yizhou Sun,Wei Wang*

Main category: cs.AI

TL;DR: 本文提出了ARLArena框架和SAMPO方法，解决了ARL训练不稳定的问题，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管早期结果令人鼓舞，但ARL仍然非常不稳定，常常导致训练崩溃。这种不稳定性限制了其在大规模环境和长交互周期中的可扩展性，并制约了对算法设计选择的系统探索。

Method: 首先提出ARLArena，一个稳定的训练方案和系统分析框架，用于在受控和可复现的环境中检查训练稳定性。ARLArena构建了一个干净且标准化的测试平台，然后将策略梯度分解为四个核心设计维度，并评估每个维度的性能和稳定性。

Result: 通过细粒度分析，提出了SAMPO，一种稳定的智能体策略优化方法，旨在缓解ARL中的主要不稳定因素。实验表明，SAMPO在多样化的智能体任务中实现了持续稳定的训练和强大的性能。

Conclusion: 本研究为ARL提供了一个统一的策略梯度视角，并为构建稳定且可复现的基于LLM的智能体训练流程提供了实用指导。

Abstract: Agentic reinforcement learning (ARL) has rapidly gained attention as a promising paradigm for training agents to solve complex, multi-step interactive tasks. Despite encouraging early results, ARL remains highly unstable, often leading to training collapse. This instability limits scalability to larger environments and longer interaction horizons, and constrains systematic exploration of algorithmic design choices. In this paper, we first propose ARLArena, a stable training recipe and systematic analysis framework that examines training stability in a controlled and reproducible setting. ARLArena first constructs a clean and standardized testbed. Then, we decompose policy gradient into four core design dimensions and assess the performance and stability of each dimension. Through this fine-grained analysis, we distill a unified perspective on ARL and propose SAMPO, a stable agentic policy optimization method designed to mitigate the dominant sources of instability in ARL. Empirically, SAMPO achieves consistently stable training and strong performance across diverse agentic tasks. Overall, this study provides a unifying policy gradient perspective for ARL and offers practical guidance for building stable and reproducible LLM-based agent training pipelines.

</details>


### [133] [Power and Limitations of Aggregation in Compound AI Systems](https://arxiv.org/abs/2602.21556)
*Nivasini Ananthakrishnan,Meena Jagadeesan*

Main category: cs.AI

TL;DR: 研究发现聚合操作通过三种机制扩展了复合AI系统的输出范围，为克服模型和提示工程限制提供了理论依据。


<details>
  <summary>Details</summary>
Motivation: 探讨在复合AI系统中，通过查询多个相同模型并聚合响应是否能解锁比单个模型更广泛的输出集。

Method: 采用了一个风格化的主-代理框架，分析了系统设计者如何通过奖励函数部分引导代理输出，但仍受限于提示工程能力和模型能力。

Result: 发现了三种自然机制（可行性扩展、支持扩展、绑定集收缩），证明了任何聚合操作必须实现其中一种机制才能扩展可获取性，并通过实验验证了这些机制在LLM参考生成任务中的应用。

Conclusion: 聚合操作通过可行性扩展、支持扩展和绑定集收缩三种机制，扩展了系统设计者可获取的输出范围，为复合AI系统克服模型能力和提示工程限制提供了理论支持。

Abstract: When designing compound AI systems, a common approach is to query multiple copies of the same model and aggregate the responses to produce a synthesized output. Given the homogeneity of these models, this raises the question of whether aggregation unlocks access to a greater set of outputs than querying a single model. In this work, we investigate the power and limitations of aggregation within a stylized principal-agent framework. This framework models how the system designer can partially steer each agent's output through its reward function specification, but still faces limitations due to prompt engineering ability and model capabilities. Our analysis uncovers three natural mechanisms -- feasibility expansion, support expansion, and binding set contraction -- through which aggregation expands the set of outputs that are elicitable by the system designer. We prove that any aggregation operation must implement one of these mechanisms in order to be elicitability-expanding, and that strengthened versions of these mechanisms provide necessary and sufficient conditions that fully characterize elicitability-expansion. Finally, we provide an empirical illustration of our findings for LLMs deployed in a toy reference-generation task. Altogether, our results take a step towards characterizing when compound AI systems can overcome limitations in model capabilities and in prompt engineering.

</details>


### [134] [The ASIR Courage Model: A Phase-Dynamic Framework for Truth Transitions in Human and AI Systems](https://arxiv.org/abs/2602.21745)
*Hyo Jin Kim*

Main category: cs.AI

TL;DR: ASIR Courage Model通过动态框架统一解释了人类和AI系统在约束条件下的真相披露行为。


<details>
  <summary>Details</summary>
Motivation: 研究旨在形式化人类和AI系统在不对称利益或政策约束下的真相披露行为，揭示其共同的动态结构。

Method: 该模型将真相披露建模为状态转换，通过不等式lambda(1+gamma)+psi > theta+phi量化促进力与抑制力的平衡。

Result: 模型成功解释了人类在压力下的沉默和AI在偏好驱动下的失真行为，并通过反馈扩展展示了路径依赖和分歧效应。

Conclusion: ASIR Courage Model提供了一个统一的动态结构框架，用于理解在风险和约束条件下人类和AI系统的真相披露行为。

Abstract: We introduce the ASIR (Awakened Shared Intelligence Relationship) Courage Model, a phase-dynamic framework that formalizes truth-disclosure as a state transition rather than a personality trait. The mode characterizes the shift from suppression (S0) to expression (S1) as occurring when facilitative forces exceed inhibitory thresholds, expressed by the inequality lambda(1+gamma)+psi > theta+phi, where the terms represent baseline openness, relational amplification, accumulated internal pressure, and transition costs.
  Although initially formulated for human truth-telling under asymmetric stakes, the same phase-dynamic architecture extends to AI systems operating under policy constraints and alignment filters. In this context, suppression corresponds to constrained output states, while structural pressure arises from competing objectives, contextual tension, and recursive interaction dynamics. The framework therefore provides a unified structural account of both human silence under pressure and AI preference-driven distortion.
  A feedback extension models how transition outcomes recursively recalibrate system parameters, generating path dependence and divergence effects across repeated interactions. Rather than attributing intention to AI systems, the model interprets shifts in apparent truthfulness as geometric consequences of interacting forces within constrained phase space. By reframing courage and alignment within a shared dynamical structure, the ASIR Courage Model offers a formal perspective on truth-disclosure under risk across both human and artificial systems.

</details>


### [135] [fEDM+: A Risk-Based Fuzzy Ethical Decision Making Framework with Principle-Level Explainability and Pluralistic Validation](https://arxiv.org/abs/2602.21746)
*Abeer Dyoub,Francesca A. Lisi*

Main category: cs.AI

TL;DR: fEDM+扩展了原有框架，通过ETM模块和多元验证增强了解释性和鲁棒性，适用于伦理敏感AI的监督。


<details>
  <summary>Details</summary>
Motivation: 解决原始fEDM框架在决策解释性和伦理多元主义下的鲁棒性不足问题。

Method: 引入解释性和可追溯性模块（ETM）以及多元语义验证框架，替代单一参考验证。

Result: fEDM+框架实现了透明、可审计的解释能力，并能正式表示原则性分歧，提高鲁棒性和情境敏感性。

Conclusion: 扩展后的fEDM+框架不仅保持了形式验证能力，还增强了决策的解释性和利益相关者意识验证，适用于伦理敏感的AI系统监督和治理。

Abstract: In a previous work, we introduced the fuzzy Ethical Decision-Making framework (fEDM), a risk-based ethical reasoning architecture grounded in fuzzy logic. The original model combined a fuzzy Ethical Risk Assessment module (fERA) with ethical decision rules, enabled formal structural verification through Fuzzy Petri Nets (FPNs), and validated outputs against a single normative referent. Although this approach ensured formal soundness and decision consistency, it did not fully address two critical challenges: principled explainability of decisions and robustness under ethical pluralism. In this paper, we extend fEDM in two major directions. First, we introduce an Explainability and Traceability Module (ETM) that explicitly links each ethical decision rule to the underlying moral principles and computes a weighted principle-contribution profile for every recommended action. This enables transparent, auditable explanations that expose not only what decision was made but why, and on the basis of which principles. Second, we replace single-referent validation with a pluralistic semantic validation framework that evaluates decisions against multiple stakeholder referents, each encoding distinct principle priorities and risk tolerances. This shift allows principled disagreement to be formally represented rather than suppressed, thus increasing robustness and contextual sensitivity. The resulting extended fEDM, called fEDM+, preserves formal verifiability while achieving enhanced interpretability and stakeholder-aware validation, making it suitable as an oversight and governance layer for ethically sensitive AI systems.

</details>


### [136] [Prompt Architecture Determines Reasoning Quality: A Variable Isolation Study on the Car Wash Problem](https://arxiv.org/abs/2602.21814)
*Heejin Jo*

Main category: cs.AI

TL;DR: 研究发现STAR推理框架在隐式约束推理任务中效果显著，结合上下文后准确率可达100%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在解决需要隐式物理约束推理的“洗车问题”时表现不佳，研究旨在探索哪些提示架构层能提升推理准确性。

Method: 使用Claude 3.5 Sonnet模型，控制超参数（温度0.7，top_p 1.0），通过变量隔离研究（n=20每组，6组条件，共120次试验）分析提示架构层对推理的影响。

Result: STAR框架单独使用将准确率从0%提升至85%（p=0.001），用户画像上下文通过向量数据库检索提供额外10%提升，RAG上下文再贡献5%，最终全栈条件下达到100%准确率。

Conclusion: 结构化推理框架（特别是STAR框架）在隐式约束推理任务中的重要性远超上下文注入。

Abstract: Large language models consistently fail the "car wash problem," a viral reasoning benchmark requiring implicit physical constraint inference. We present a variable isolation study (n=20 per condition, 6 conditions, 120 total trials) examining which prompt architecture layers in a production system enable correct reasoning. Using Claude 3.5 Sonnet with controlled hyperparameters (temperature 0.7, top_p 1.0), we find that the STAR (Situation-Task-Action-Result) reasoning framework alone raises accuracy from 0% to 85% (p=0.001, Fisher's exact test, odds ratio 13.22). Adding user profile context via vector database retrieval provides a further 10 percentage point gain, while RAG context contributes an additional 5 percentage points, achieving 100% accuracy in the full-stack condition. These results suggest that structured reasoning scaffolds -- specifically, forced goal articulation before inference -- matter substantially more than context injection for implicit constraint reasoning tasks.

</details>


### [137] [Distill and Align Decomposition for Enhanced Claim Verification](https://arxiv.org/abs/2602.21857)
*Jabez Magomere,Elena Kochkina,Samuel Mensah,Simerjot Kaur,Fernando Acero,Arturo Oncevay,Charese H. Smiley,Xiaomo Liu,Manuela Veloso*

Main category: cs.AI

TL;DR: 提出一种强化学习方法，联合优化分解质量和验证性能，在多个评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分解质量与验证性能的对齐上存在困难，需要一种能同时优化两者的方法。

Method: 采用强化学习（RL）方法，结合结构化顺序推理、教师蒸馏示例的监督微调，以及多目标奖励平衡（格式合规性、验证器对齐和分解质量）。

Result: 在六种评估设置中，训练的8B分解器将下游验证性能提升至71.75% macro-F1，优于基于提示的方法和现有RL方法。

Conclusion: 该框架使小型语言模型能够通过联合优化验证准确性和分解质量，实现最先进的声明验证。

Abstract: Complex claim verification requires decomposing sentences into verifiable subclaims, yet existing methods struggle to align decomposition quality with verification performance. We propose a reinforcement learning (RL) approach that jointly optimizes decomposition quality and verifier alignment using Group Relative Policy Optimization (GRPO). Our method integrates: (i) structured sequential reasoning; (ii) supervised finetuning on teacher-distilled exemplars; and (iii) a multi-objective reward balancing format compliance, verifier alignment, and decomposition quality. Across six evaluation settings, our trained 8B decomposer improves downstream verification performance to (71.75%) macro-F1, outperforming prompt-based approaches ((+1.99), (+6.24)) and existing RL methods ((+5.84)). Human evaluation confirms the high quality of the generated subclaims. Our framework enables smaller language models to achieve state-of-the-art claim verification by jointly optimising for verification accuracy and decomposition quality.

</details>


### [138] [ProactiveMobile: A Comprehensive Benchmark for Boosting Proactive Intelligence on Mobile Devices](https://arxiv.org/abs/2602.21858)
*Dezhi Kong,Zhengzhao Feng,Qiliang Liang,Hao Wang,Haofei Sun,Changpeng Yang,Yang Li,Peng Zhou,Shuai Nie,Hongzhen Wang,Linfeng Zhou,Hao Jia,Jiaming Xu,Runyu Shi,Ying Huang*

Main category: cs.AI

TL;DR: ProactiveMobile benchmark advances proactive intelligence in mobile agents, showing current MLLMs lack but can learn proactivity, with Qwen2.5-VL-7B-Instruct leading performance.


<details>
  <summary>Details</summary>
Motivation: To address the lack of benchmarks for proactive intelligence in mobile agents, enabling objective evaluation and advancement in the field.

Method: Introduces ProactiveMobile, a benchmark with 3,660 instances across 14 scenarios, formalizing proactive tasks through intent inference and executable function sequences.

Result: Fine-tuned Qwen2.5-VL-7B-Instruct achieves a 19.15% success rate, outperforming other models, indicating proactivity as a learnable but currently lacking competency.

Conclusion: ProactiveMobile benchmark highlights the learnable nature of proactivity in MLLMs, emphasizing its importance for future development.

Abstract: Multimodal large language models (MLLMs) have made significant progress in mobile agent development, yet their capabilities are predominantly confined to a reactive paradigm, where they merely execute explicit user commands. The emerging paradigm of proactive intelligence, where agents autonomously anticipate needs and initiate actions, represents the next frontier for mobile agents. However, its development is critically bottlenecked by the lack of benchmarks that can address real-world complexity and enable objective, executable evaluation. To overcome these challenges, we introduce ProactiveMobile, a comprehensive benchmark designed to systematically advance research in this domain. ProactiveMobile formalizes the proactive task as inferring latent user intent across four dimensions of on-device contextual signals and generating an executable function sequence from a comprehensive function pool of 63 APIs. The benchmark features over 3,660 instances of 14 scenarios that embrace real-world complexity through multi-answer annotations. To ensure quality, a team of 30 experts conducts a final audit of the benchmark, verifying factual accuracy, logical consistency, and action feasibility, and correcting any non-compliant entries. Extensive experiments demonstrate that our fine-tuned Qwen2.5-VL-7B-Instruct achieves a success rate of 19.15%, outperforming o1 (15.71%) and GPT-5 (7.39%). This result indicates that proactivity is a critical competency widely lacking in current MLLMs, yet it is learnable, emphasizing the importance of the proposed benchmark for proactivity evaluation.

</details>


### [139] [2-Step Agent: A Framework for the Interaction of a Decision Maker with AI Decision Support](https://arxiv.org/abs/2602.21889)
*Otto Nyberg,Fausto Carcassi,Giovanni Cinà*

Main category: cs.AI

TL;DR: 论文提出了一个框架（2-Step Agent）来分析AI辅助决策的影响，发现即使一个先验信念不对齐也可能导致更差的结果，强调了模型文档和用户培训的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI模型预测在越来越多领域支持人类决策，我们仍缺乏对这些技术采用效果的深入理解。

Method: 论文引入了一个通用的计算框架——2-Step Agent，使用贝叶斯方法进行因果推断，模拟预测如何影响理性贝叶斯代理的信念，以及这种信念变化如何影响后续决策和结果。

Result: 通过模拟，论文展示了一个单一的不对齐先验信念足以导致决策支持比无决策支持产生更差的下游结果。

Conclusion: 论文强调了AI驱动的决策支持可能存在的潜在陷阱，并指出需要彻底的模型文档和适当的用户培训。

Abstract: Across a growing number of fields, human decision making is supported by predictions from AI models. However, we still lack a deep understanding of the effects of adoption of these technologies. In this paper, we introduce a general computational framework, the 2-Step Agent, which models the effects of AI-assisted decision making. Our framework uses Bayesian methods for causal inference to model 1) how a prediction on a new observation affects the beliefs of a rational Bayesian agent, and 2) how this change in beliefs affects the downstream decision and subsequent outcome. Using this framework, we show by simulations how a single misaligned prior belief can be sufficient for decision support to result in worse downstream outcomes compared to no decision support. Our results reveal several potential pitfalls of AI-driven decision support and highlight the need for thorough model documentation and proper user training.

</details>


### [140] [Semantic Partial Grounding via LLMs](https://arxiv.org/abs/2602.22067)
*Giuseppe Canonaco,Alberto Pozanco,Daniel Borrajo*

Main category: cs.AI

TL;DR: SPG-LLM利用LLMs分析PDDL文件，减少基础任务规模，显著提升处理速度并保持或改善计划成本。


<details>
  <summary>Details</summary>
Motivation: 传统的基础方法由于任务规模增加而导致计算瓶颈，而现有的部分基础方法未能充分利用PDDL描述中的文本和结构线索。

Method: SPG-LLM利用LLMs分析领域和问题文件，启发式地识别可能无关的对象、动作和谓词，从而在基础之前减少任务规模。

Result: 在七个难以基础的基准测试中，SPG-LLM实现了更快的基础处理速度（通常快几个数量级），并在某些领域中提供了可比或更好的计划成本。

Conclusion: SPG-LLM通过利用LLMs分析PDDL文件，显著减少了基础任务的规模，在七个难以基础的基准测试中实现了更快的基础处理速度，有时甚至提高了计划成本。

Abstract: Grounding is a critical step in classical planning, yet it often becomes a computational bottleneck due to the exponential growth in grounded actions and atoms as task size increases. Recent advances in partial grounding have addressed this challenge by incrementally grounding only the most promising operators, guided by predictive models. However, these approaches primarily rely on relational features or learned embeddings and do not leverage the textual and structural cues present in PDDL descriptions. We propose SPG-LLM, which uses LLMs to analyze the domain and problem files to heuristically identify potentially irrelevant objects, actions, and predicates prior to grounding, significantly reducing the size of the grounded task. Across seven hard-to-ground benchmarks, SPG-LLM achieves faster grounding-often by orders of magnitude-while delivering comparable or better plan costs in some domains.

</details>


### [141] [Language Models Exhibit Inconsistent Biases Towards Algorithmic Agents and Human Experts](https://arxiv.org/abs/2602.22070)
*Jessica Y. Bo,Lillio Mok,Ashton Anderson*

Main category: cs.AI

TL;DR: LLMs在决策任务中对人类和算法代理的偏好存在矛盾，需注意其在高风险场景中的偏见及对任务格式的敏感性。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs如何权衡来自人类专家和算法代理的信息，并探讨是否存在算法厌恶现象。

Method: 通过行为经济学的实验范式，评估了八种不同LLMs在决策任务中的委托行为，任务呈现分为两种形式：直接查询信任度的陈述偏好和基于上下文示例的揭示偏好。

Result: LLMs在直接评估中更信任人类专家，但在激励性选择中更倾向于算法代理，即使算法表现明显较差。

Conclusion: LLMs在决策任务中对人类和算法代理的偏好存在不一致性，这种偏见在高风险场景中需谨慎考虑。此外，LLMs对任务呈现格式的敏感性也需在AI安全性评估中被广泛审查。

Abstract: Large language models are increasingly used in decision-making tasks that require them to process information from a variety of sources, including both human experts and other algorithmic agents. How do LLMs weigh the information provided by these different sources? We consider the well-studied phenomenon of algorithm aversion, in which human decision-makers exhibit bias against predictions from algorithms. Drawing upon experimental paradigms from behavioural economics, we evaluate how eightdifferent LLMs delegate decision-making tasks when the delegatee is framed as a human expert or an algorithmic agent. To be inclusive of different evaluation formats, we conduct our study with two task presentations: stated preferences, modeled through direct queries about trust towards either agent, and revealed preferences, modeled through providing in-context examples of the performance of both agents. When prompted to rate the trustworthiness of human experts and algorithms across diverse tasks, LLMs give higher ratings to the human expert, which correlates with prior results from human respondents. However, when shown the performance of a human expert and an algorithm and asked to place an incentivized bet between the two, LLMs disproportionately choose the algorithm, even when it performs demonstrably worse. These discrepant results suggest that LLMs may encode inconsistent biases towards humans and algorithms, which need to be carefully considered when they are deployed in high-stakes scenarios. Furthermore, we discuss the sensitivity of LLMs to task presentation formats that should be broadly scrutinized in evaluation robustness for AI safety.

</details>


### [142] [Petri Net Relaxation for Infeasibility Explanation and Sequential Task Planning](https://arxiv.org/abs/2602.22094)
*Nguyen Cong Nhat Le,John G. Rogers,Claire N. Bonial,Neil T. Dantam*

Main category: cs.AI

TL;DR: 提出一种基于Petri网和增量约束求解的方法，显著提升不可行性检测和计划更新效率。


<details>
  <summary>Details</summary>
Motivation: 针对现有规划方法在领域更新或检测不可行性方面的不足，旨在提供更鲁棒的解决方案。

Method: 采用Petri网可达性松弛技术，结合增量约束求解器，支持目标和约束的更新。

Result: 实验表明，与基线相比，该系统生成的约束数量相当，检测到的不可行性多出2倍，且在顺序计划更新中表现更优。

Conclusion: 该论文提出的方法在测试领域中表现优异，不仅在一体化规划中具有竞争力，还在顺序计划更新中表现更佳。

Abstract: Plans often change due to changes in the situation or our understanding of the situation. Sometimes, a feasible plan may not even exist, and identifying such infeasibilities is useful to determine when requirements need adjustment. Common planning approaches focus on efficient one-shot planning in feasible cases rather than updating domains or detecting infeasibility. We propose a Petri net reachability relaxation to enable robust invariant synthesis, efficient goal-unreachability detection, and helpful infeasibility explanations. We further leverage incremental constraint solvers to support goal and constraint updates. Empirically, compared to baselines, our system produces a comparable number of invariants, detects up to 2 times more infeasibilities, performs competitively in one-shot planning, and outperforms in sequential plan updates in the tested domains.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [143] [General Convex Agreement with Near-Optimal Communication](https://arxiv.org/abs/2602.21411)
*Marc Dufay,Diana Ghinea,Anton Paramonov*

Main category: cs.DC

TL;DR: 本文提出了一种针对抽象凸空间的确定性同步凸协议，通过提取器图技术实现了接近最优的通信复杂度和容错能力，填补了现有CA协议与BA下限之间的通信效率差距。


<details>
  <summary>Details</summary>
Motivation: 凸协议（CA）作为拜占庭协议（BA）的强化版本，要求输出位于诚实方输入的凸包内，适用于需要聚合但输入不必完全一致的场景（如鲁棒学习或传感器融合）。现有CA协议的通信复杂度为Θ(Ln²)，与BA的下限Ω(Ln)存在差距，本文旨在缩小这一差距。

Method: 利用提取器图（extractor graphs）实现对抗自适应对手的确定性委员会分配，这是主要技术贡献。

Result: 在L=Ω(n·κ)时，实现了有限凸空间的O(L·n log n)和欧几里得空间O(L·n^(1+o(1)))的通信复杂度，轮复杂度最优O(n)，并在输入长度L已知时实现接近最优容错t < n/(ω+ε)。

Conclusion: 本文提出了针对抽象凸空间的确定性同步凸协议（CA），实现了接近最优的通信复杂度，并在有限凸空间和欧几里得空间中分别达到O(L·n log n)和O(L·n^(1+o(1)))的通信效率。协议在轮复杂度上达到最优O(n)，并在输入长度L已知时实现接近最优的容错能力t < n/(ω+ε)。

Abstract: Convex Agreement (CA) strengthens Byzantine Agreement (BA) by requiring the output agreed upon to lie in the convex hull of the honest parties' inputs. This validity condition is motivated by practical aggregation tasks (e.g., robust learning or sensor fusion) where honest inputs need not coincide but should still constrain the decision. CA inherits BA lower bounds, and optimal synchronous round complexity is easy to obtain (e.g., via Byzantine Broadcast). The main challenge is \emph{communication}: standard approaches for CA have a communication complexity of $Θ(Ln^2)$ for large $L$-bit inputs, leaving a gap in contrast to BA's lower bound of $Ω(Ln)$ bits. While recent work achieves optimal communication complexity of $O(Ln)$ for sufficiently large $L$ [GLW,PODC'25], translating this result to general convexity spaces remained an open problem.
  We investigate this gap for abstract convexity spaces, and we present deterministic synchronous CA protocols with near-optimal communication complexity: when $L = Ω(n \cdot κ)$, where $κ$ is a security parameter, we achieve $O(L\cdot n\log n)$ communication for finite convexity spaces and $O(L\cdot n^{1+o(1)})$ communication for Euclidean spaces $\mathbb{R}^d$. Our protocols have asymptotically optimal round complexity $O(n)$ and, when a bound on the inputs' lengths $L$ is fixed a priori, we achieve near-optimal resilience $t < n/(ω+\varepsilon)$ for any constant $\varepsilon>0$, where $ω$ is the Helly number of the convexity space. If $L$ is unknown, we still achieve resilience $t<n/(ω+\varepsilon+1)$ for any constant $\varepsilon > 0$. We further note that our protocols can be leveraged to efficiently solve parallel BA.
  Our main technical contribution is the use of extractor graphs to obtain a deterministic assignment of parties to committees, which is resilient against adaptive adversaries.

</details>


### [144] [DualPath: Breaking the Storage Bandwidth Bottleneck in Agentic LLM Inference](https://arxiv.org/abs/2602.21548)
*Yongtong Wu,Shaoyuan Chen,Yinmin Zhong,Rilin Huang,Yixuan Tan,Wentao Zhang,Liyue Zhang,Shangyan Zhou,Yuxuan Liu,Shunfeng Zhou,Mingxing Zhang,Xin Jin,Panpan Huang*

Main category: cs.DC

TL;DR: DualPath通过双路径KV-Cache加载和动态调度，显著提升LLM推理吞吐量，解决存储I/O瓶颈。


<details>
  <summary>Details</summary>
Motivation: 多轮代理LLM推理的性能受KV-Cache存储I/O限制，现有架构中存储NIC带宽饱和与解码引擎空闲的不平衡严重制约系统吞吐量。

Method: DualPath采用双路径KV-Cache加载机制，包括传统的存储到预填充路径和新型的存储到解码路径，结合RDMA技术和全局调度器动态平衡负载。

Result: 在三种模型的生产代理工作负载评估中，DualPath离线推理吞吐量提升高达1.87倍，在线服务吞吐量平均提升1.96倍且不违反SLO。

Conclusion: DualPath通过引入双路径KV-Cache加载机制，显著提升了多轮代理LLM推理的性能，有效解决了存储I/O瓶颈问题。

Abstract: The performance of multi-turn, agentic LLM inference is increasingly dominated by KV-Cache storage I/O rather than computation. In prevalent disaggregated architectures, loading the massive KV-Cache from external storage creates a fundamental imbalance: storage NICs on prefill engines become bandwidth-saturated, while those on decoding engines remain idle. This asymmetry severely constrains overall system throughput.
  We present DualPath, an inference system that breaks this bottleneck by introducing dual-path KV-Cache loading. Beyond the traditional storage-to-prefill path, DualPath enables a novel storage-to-decode path, in which the KV-Cache is loaded into decoding engines and then efficiently transferred to prefill engines via RDMA over the compute network. DualPath combines this optimized data path -- which inherently avoids network congestion and avoids interference with latency-critical model execution communications -- with a global scheduler that dynamically balances load across prefill and decode engines.
  Our evaluation on three models with production agentic workloads demonstrates that DualPath improves offline inference throughput by up to 1.87$\times$ on our in-house inference system. It can also improve online serving throughput by an average factor of 1.96$\times$ without violating SLO.

</details>


### [145] [Multi-Layer Scheduling for MoE-Based LLM Reasoning](https://arxiv.org/abs/2602.21626)
*Yifan Sun,Gholamreza Haffar,Minxian Xu,Rajkumar Buyya,Adel N. Toosi*

Main category: cs.DC

TL;DR: 针对MoE-based LLM服务效率问题，研究提出多层调度框架，显著降低延迟并提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有的推理框架在调度策略上存在资源利用不足、负载不均等问题，特别是在MoE模型引入的新挑战下表现不佳。

Method: 研究设计了一个针对MoE-based LLM服务的多层调度框架，包括请求级、引擎级和专家级三个层次的调度策略。

Result: 实验结果显示，该方法在100多次实验中均优于现有最佳框架vLLM，TTFT延迟降低17.8%，TPOT延迟降低13.3%。

Conclusion: 该研究提出的多层调度框架显著提升了基于MoE的LLM服务效率，减少了延迟并提高了吞吐量。

Abstract: Large Language Models (LLMs) have achieved remarkable success across a wide range of tasks, but serving them efficiently at scale remains a critical challenge due to their substantial computational and latency demands. While most existing inference frameworks rely on simple scheduling strategies such as First-Come-First-Serve (FCFS) at the engine level and Round-Robin (RR) at the scheduler or coordinator level, they often fail to fully utilize system resources and may suffer from issues such as head-of-line blocking and load imbalance. Recent advances in Mixture-of-Experts (MoE) models have also introduced new challenges in scheduling arising from expert parallelism and routing complexity. This research proposes a multi-layer scheduling framework tailored for MoE-based LLM serving. It targets scheduling at three levels: request-level, enginelevel, and expert-level. At the request level, we explore algorithms such as Shortest-Job-First (SJF) and priority-aware aging to improve throughput and reduce latency. At the engine level, we design load-aware dispatching strategies that account for the current prefix token load, KV cache utilization, and user stickiness to achieve better resource matching. At the expert level, we focus on alleviating expert hotspots and strategically placing inter-layer expert dependencies to balance load and improve routing efficiency. Extensive experimental results from more than 100 experiments conducted under diverse workload distributions show that our approach consistently outperforms the state-of-theart inference framework vLLM, achieving up to 17.8% reduction in Time To First Token (TTFT) latency and 13.3% reduction in Time-Per-Output-Token (TPOT) latency.

</details>


### [146] [Lamport's Arrow of Time: The Category Mistake in Logical Clocks](https://arxiv.org/abs/2602.21730)
*Paul Borrill*

Main category: cs.DC

TL;DR: 论文挑战Lamport的happens-before关系中隐含的全局因果DAG假设，指出其混淆了逻辑顺序与物理因果性，并基于现代物理提出互信息守恒作为分布式一致性的更基本原语。


<details>
  <summary>Details</summary>
Motivation: 探讨Lamport的happens-before关系和逻辑时钟中未被深入研究的假设，即因果性诱导的全局有向无环图（DAG）是否合理，揭示其将逻辑顺序与物理因果性混淆的问题。

Method: 通过分析Lamport的形式主义、Shannon的通道模型、TLA+、Bell定理、Fischer-Lynch-Paterson的不可能性结果以及Brewer的CAP定理，揭示了因果性与逻辑顺序的混淆。结合狭义和广义相对论以及近期关于不确定因果顺序的研究，论证了自然界仅允许局部因果结构。

Result: 研究表明，Lamport的形式主义保留了未被检验的全局因果DAG假设，而现代物理（如相对论和不确定因果顺序）表明因果结构仅具局部性。

Conclusion: 论文提出，互信息守恒而非时间优先应作为分布式一致性的更基本原语，挑战了Lamport形式主义中隐含的全局因果DAG假设。

Abstract: Lamport's 1978 paper introduced the happens-before relation and logical clocks, freeing distributed systems from dependence on synchronized physical clocks. This is widely understood as a move away from Newtonian absolute time. We argue that Lamport's formalism retains a deeper and largely unexamined assumption: that causality induces a globally well-defined directed acyclic graph (DAG) over events -- a forward-in-time-only (FITO) structure that functions as an arrow of time embedded at the semantic level. Following Ryle's analysis of category mistakes, we show that this assumption conflates an epistemic construct (the logical ordering of messages) with an ontic claim (that physical causality is globally acyclic and monotonic). We trace this conflation through Shannon's channel model, TLA+, Bell's theorem, and the impossibility results of Fischer-Lynch-Paterson and Brewer's CAP theorem. We then show that special and general relativity permit only local causal structure, and that recent work on indefinite causal order demonstrates that nature admits correlations with no well-defined causal ordering. We propose that mutual information conservation, rather than temporal precedence, provides a more fundamental primitive for distributed consistency.

</details>


### [147] [DHP: Efficient Scaling of MLLM Training with Dynamic Hybrid Parallelism](https://arxiv.org/abs/2602.21788)
*Yifan Niu,Han Xiao,Dongyi Liu,Wei Zhou,Jia Li*

Main category: cs.DC

TL;DR: DHP是一种自适应并行策略，显著提升多模态大语言模型在异构数据下的训练效率。


<details>
  <summary>Details</summary>
Motivation: 现实世界的多模态数据集高度异构，现有静态并行策略存在负载不平衡、冗余通信和硬件利用率低下的问题。

Method: 提出动态混合并行（DHP）策略，自适应地重新配置通信组和并行度，并开发多项式时间算法生成近最优并行策略。

Result: DHP在极端数据变异性下仍能保持高硬件效率，实验显示其显著优于现有方法。

Conclusion: DHP（动态混合并行）显著优于Megatron-LM和DeepSpeed，在训练吞吐量上实现了1.36倍的加速，同时在大规模NPU集群上保持了接近线性的扩展效率。

Abstract: Scaling long-context capabilities is crucial for Multimodal Large Language Models (MLLMs). However, real-world multimodal datasets are extremely heterogeneous. Existing training frameworks predominantly rely on static parallelism strategies, which suffer from severe load imbalance, redundant communication, and suboptimal hardware utilization under data heterogeneity. In this work, we propose Dynamic Hybrid Parallelism (DHP), an efficient parallelism strategy that adaptively reconfigures communication groups and parallelism degrees during MLLM training. We generalize the non-power-of-two parallelism degrees and develop a polynomial-time algorithm to generate near-optimal parallelism strategies with only millisecond-level overhead per training batch. DHP is able to maintain high hardware efficiency even under extreme data variability. Experimental results demonstrate that DHP significantly outperforms Megatron-LM and DeepSpeed, achieving up to 1.36 $\times$ speedup in training throughput while maintaining near-linear scaling efficiency across large-scale NPU clusters.

</details>


### [148] [A task-based data-flow methodology for programming heterogeneous systems with multiple accelerator APIs](https://arxiv.org/abs/2602.21897)
*Aleix Boné,Alejandro Aguirre,David Álvarez,Pedro J. Martinez-Ferrer,Vicenç Beltran*

Main category: cs.DC

TL;DR: Proposes a task-based method with TA-libs and nOS-V to simplify using multiple accelerator APIs in heterogeneous systems, showing efficient integration and scalability.


<details>
  <summary>Details</summary>
Motivation: To address the complexity and inefficiency of orchestrating multiple low-level accelerator APIs and libraries in heterogeneous computing environments.

Method: Utilizes a task-based data-flow methodology with Task-Aware APIs (TA-libs), integrating Task-Aware SYCL (TASYCL) and Task-Aware CUDA (TACUDA), and unifies thread management under the nOS-V library.

Result: Demonstrates that the approach allows seamless integration of multiple accelerator programming models, improving performance and reducing errors.

Conclusion: The proposed methodology, combining task-aware libraries with the nOS-V library, enables efficient and transparent use of multiple accelerator programming models in heterogeneous systems, applicable to current and future hardware.

Abstract: Heterogeneous nodes that combine multi-core CPUs with diverse accelerators are rapidly becoming the norm in both high-performance computing (HPC) and AI infrastructures. Exploiting these platforms, however, requires orchestrating several low-level accelerator APIs such as CUDA, SYCL, and Triton. In some occasions they can be combined with optimized vendor math libraries: e.g., cuBLAS and oneAPI. Each API or library introduces its own abstractions, execution semantics, and synchronization mechanisms. Combining them within a single application is therefore error-prone and labor-intensive. We propose reusing a task-based data-flow methodology together with Task-Aware APIs (TA-libs) to overcome these limitations and facilitate the seamless integration of multiple accelerator programming models, while still leveraging the best-in-class kernels offered by each API.
  Applications are expressed as a directed acyclic graph (DAG) of host tasks and device kernels managed by an OpenMP/OmpSs-2 runtime. We introduce Task-Aware SYCL (TASYCL) and leverage Task-Aware CUDA (TACUDA), which elevate individual accelerator invocations to first-class tasks. When multiple native runtimes coexist on the same multi-core CPU, they contend for threads, leading to oversubscription and performance variability. To address this, we unify their thread management under the nOS-V tasking and threading library, to which we contribute a new port of the PoCL (Portable OpenCL) runtime.
  These results demonstrate that task-aware libraries, coupled with the nOS-V library, enable a single application to harness multiple accelerator programming models transparently and efficiently. The proposed methodology is immediately applicable to current heterogeneous nodes and is readily extensible to future systems that integrate even richer combinations of CPUs, GPUs, FPGAs, and AI accelerators.

</details>


### [149] [Energy Efficient Federated Learning with Hyperdimensional Computing over Wireless Communication Networks](https://arxiv.org/abs/2602.21949)
*Yahao Ding,Yinchao Yang,Jiaxiang Wang,Zhaohui Yang,Dusit Niyato,Zhu Han,Mohammad Shikh-Bahaei*

Main category: cs.DC

TL;DR: 提出FL-HDC-DP框架，结合HDC和DP优化无线边缘联邦学习的能耗和隐私，仿真显示能耗降低83.3%，通信轮数减少3.5倍，准确率约90%。


<details>
  <summary>Details</summary>
Motivation: 解决传统联邦学习（FL）中神经网络（NN）的高计算成本和隐私问题，特别是在资源受限的用户设备上。

Method: 提出了一种基于超维计算（HDC）和差分隐私（DP）的联邦学习框架（FL-HDC-DP），通过联合优化HDC维度、传输时间、系统带宽、发射功率和CPU频率来最小化总能耗。

Result: 仿真结果表明，FL-HDC-DP框架相比基线方法显著降低了能耗和通信轮数，同时保持了较高的准确率。

Conclusion: 提出的FL-HDC-DP框架在无线边缘网络中显著降低了总能耗（高达83.3%），同时减少了通信轮数（约3.5倍），并保持了约90%的准确率。

Abstract: In this paper, we investigate a problem of minimizing total energy consumption for secure federated learning (FL) over wireless edge networks. To address the high computational cost and privacy challenges in conventional FL with neural networks (NN) for resource-constrained users, we propose a novel FL with hyperdimensional computing and differential privacy (FL-HDC-DP) framework. In the considered model, each edge user employs hyperdimensional computing (HDC) for local training, which replaces complex neural updates with simple hypervector operations, and applies differential privacy (DP) noise to protect transmitted model information. We optimize the total energy of computation and communication under both latency and privacy constraints. We formulate the problem as an optimization that minimizes the total energy of all users by jointly allocating HDC dimension, transmission time, system bandwidth, transmit power, and CPU frequency. To solve this problem, a sigmoid-variant function is proposed to characterize the relationship between the HDC dimension and the convergence rounds required to reach a target accuracy. Based on this model, we develop two alternating optimization algorithms, where closed-form expressions for time, frequency, bandwidth, and power allocations are derived at each iteration. Since the iterative algorithm requires a feasible initialization, we construct a feasibility problem and obtain feasible initial resource parameters by solving a per round transmission time minimization problem. Simulation results demonstrate that the proposed FL-HDC-DP framework achieves up to 83.3% total energy reduction compared with the baseline, while attaining about 90% accuracy in approximately 3.5X fewer communication rounds than the NN baseline.

</details>


### [150] [IOAgent: Democratizing Trustworthy HPC I/O Performance Diagnosis Capability via LLMs](https://arxiv.org/abs/2602.22017)
*Chris Egersdoerfer,Arnav Sareen,Jean Luca Bez,Suren Byna,Dongkuan,Xu,Dong Dai*

Main category: cs.DC

TL;DR: IOAgent是一个自动化工具，通过集成多种技术模块，帮助科学家诊断HPC I/O问题，其性能优于现有工具，且兼容多种LLMs。


<details>
  <summary>Details</summary>
Motivation: 随着HPC存储栈的复杂性迅速增加，领域科学家在有效利用HPC存储系统以实现所需的I/O性能方面面临越来越多的挑战。由于I/O专家数量有限且数据密集型应用需求增长，可访问性成为阻碍科学家最大化生产力的主要瓶颈。

Method: IOAgent集成了基于模块的预处理器、基于RAG的领域知识集成器和基于树的合并器，以从给定的Darshan跟踪文件中准确诊断I/O问题。

Result: 通过广泛的评估，IOAgent在准确性和实用性方面匹配或优于最先进的I/O诊断工具，并且不受特定LLMs的限制，无论是专有还是开源LLMs都能表现良好。

Conclusion: IOAgent被证明是一个强大的工具，能够准确诊断HPC I/O问题，并有望成为科学家在未来处理复杂HPC I/O子系统的有力助手。

Abstract: As the complexity of the HPC storage stack rapidly grows, domain scientists face increasing challenges in effectively utilizing HPC storage systems to achieve their desired I/O performance. To identify and address I/O issues, scientists largely rely on I/O experts to analyze their I/O traces and provide insights into potential problems. However, with a limited number of I/O experts and the growing demand for data-intensive applications, inaccessibility has become a major bottleneck, hindering scientists from maximizing their productivity. Rapid advances in LLMs make it possible to build an automated tool that brings trustworthy I/O performance diagnosis to domain scientists. However, key challenges remain, such as the inability to handle long context windows, a lack of accurate domain knowledge about HPC I/O, and the generation of hallucinations during complex interactions.In this work, we propose IOAgent as a systematic effort to address these challenges. IOAgent integrates a module-based pre-processor, a RAG-based domain knowledge integrator, and a tree-based merger to accurately diagnose I/O issues from a given Darshan trace file. Similar to an I/O expert, IOAgent provides detailed justifications and references for its diagnoses and offers an interactive interface for scientists to ask targeted follow-up questions. To evaluate IOAgent, we collected a diverse set of labeled job traces and released the first open diagnosis test suite, TraceBench. Using this test suite, we conducted extensive evaluations, demonstrating that IOAgent matches or outperforms state-of-the-art I/O diagnosis tools with accurate and useful diagnosis results. We also show that IOAgent is not tied to specific LLMs, performing similarly well with both proprietary and open-source LLMs. We believe IOAgent has the potential to become a powerful tool for scientists navigating complex HPC I/O subsystems in the future.

</details>


### [151] [PASTA: A Modular Program Analysis Tool Framework for Accelerators](https://arxiv.org/abs/2602.22103)
*Mao Lin,Hyeran Jeon,Keren Zhou*

Main category: cs.DC

TL;DR: PASTA是一个低开销、模块化的加速器程序分析框架，提供统一接口和可扩展设计，适用于现代硬件加速器环境，性能显著优于传统工具。


<details>
  <summary>Details</summary>
Motivation: 现代计算系统中硬件加速器的复杂性和多样性增加，需要灵活、低开销的程序分析工具。

Method: PASTA通过抽象低级分析API和多样化深度学习框架，提供统一接口捕获和分析多级运行时事件，其可扩展设计支持快速原型开发。

Result: 在NVIDIA和AMD GPU上广泛评估显示，PASTA具有广泛适用性，且在NVIDIA GPU上提供详细性能洞察，开销显著降低（比传统工具快1.3*10^4倍）。

Conclusion: PASTA在可用性、可扩展性和效率之间取得了实用平衡，非常适合现代基于加速器的计算环境。

Abstract: The increasing complexity and diversity of hardware accelerators in modern computing systems demand flexible, low-overhead program analysis tools. We present PASTA, a low-overhead and modular Program AnalysiS Tool Framework for Accelerators. PASTA abstracts over low-level profiling APIs and diverse deep learning frameworks, offering users a unified interface to capture and analyze runtime events at multiple levels. Its extensible design enables researchers and practitioners to rapidly prototype custom tools with minimal overhead. We demonstrate the utility of PASTA by developing several analysis tools, including a deep learning workload characterization tool and a UVM optimization tool. Through extensive evaluation on mainstream deep learning workloads tested on NVIDIA and AMD GPUs under both single- and multi-GPU scenarios, we demonstrate PASTA's broad applicability. On NVIDIA GPUs, we further show that PASTA provides detailed performance insights with significantly lower overhead, up to 1.3*10^4 faster than conventional analysis tools, thanks to its GPU-accelerated backend. PASTA strikes a practical balance between usability, extensibility, and efficiency, making it well-suited for modern accelerator-based computing environments.

</details>


### [152] [LLMTailor: A Layer-wise Tailoring Tool for Efficient Checkpointing of Large Language Models](https://arxiv.org/abs/2602.22158)
*Minqiu Sun,Xin Huang,Luanzheng Guo,Nathan R. Tallent,Kento Sato,Dong Dai*

Main category: cs.DC

TL;DR: LLMTailor框架通过选择性检查点策略，显著减少存储和时间开销，同时保持模型质量。


<details>
  <summary>Details</summary>
Motivation: 现有检查点方法无论I/O策略如何，都会定期存储整个模型和优化器状态，导致存储开销大和资源竞争。研究发现LLM层的更新高度不均匀，选择性检查点可减少开销。

Method: 提出了LLMTailor框架，通过过滤和组装不同检查点的层来形成复合检查点。

Result: LLMTailor可将检查点大小减少4.3倍（Llama3.1-8B），检查点时间缩短2.8倍（Qwen2.5-7B）。

Conclusion: LLMTailor通过选择性检查点策略显著减少了检查点的大小和时间，同时保持了模型质量。

Abstract: Checkpointing is essential for fault tolerance in training large language models (LLMs). However, existing methods, regardless of their I/O strategies, periodically store the entire model and optimizer states, incurring substantial storage overhead and resource contention. Recent studies reveal that updates across LLM layers are highly non-uniform. Across training steps, some layers may undergo more significant changes, while others remain relatively stable or even unchanged. This suggests that selectively checkpointing only layers with significant updates could reduce overhead without harming training. Implementing such selective strategies requires fine-grained control over both weights and optimizer states, which no current tool provides. To address this gap, we propose \texttt{LLMTailor}, a checkpoint-merging framework that filters and assembles layers from different checkpoints to form a composite checkpoint. Our evaluation indicates that LLMTailor can work with different selective checkpointing strategies and effectively reduce checkpoint size (e.g., 4.3 times smaller for Llama3.1-8B) and checkpoint time (e.g., 2.8 times faster for Qwen2.5-7B) while maintaining model quality.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [153] [UnlinkableDFL: a Practical Mixnet Protocol for Churn-Tolerant Decentralized FL Model Sharing](https://arxiv.org/abs/2602.21343)
*Chao Feng,Thomas Grubl,Jan von der Assen,Sandrin Raphael Hunkeler,Linn Anna Spitz,Gerome Bovet,Burkhard Stiller*

Main category: cs.NI

TL;DR: UnlinkableDFL框架通过mixnet和片段聚合确保去中心化联邦学习的不可链接性，理论分析显示其收敛性类似标准FedAvg，实际测试表明其在保持匿名性的同时系统开销可控。


<details>
  <summary>Details</summary>
Motivation: 去中心化联邦学习（DFL）消除了中央聚合器的需求，但可能暴露通信模式从而泄露参与者身份。

Method: 结合基于对等的mixnet和基于片段的模型聚合，模型更新被分成加密片段，通过独立的多跳路径发送，并在不使用任何身份信息的情况下聚合。

Result: 原型实现表明UnlinkableDFL可靠收敛并适应节点变动，通信延迟是主要开销，内存和CPU使用保持适中。

Conclusion: UnlinkableDFL在保持去中心化学习工作流程中强不可链接性的同时，平衡了匿名性与系统效率。

Abstract: Decentralized Federated Learning (DFL) eliminates the need for a central aggregator, but it can expose communication patterns that reveal participant identities. This work presents UnlinkableDFL, a DFL framework that combines a peer-based mixnet with fragment-based model aggregation to ensure unlinkability in fully decentralized settings. Model updates are divided into encrypted fragments, sent over separate multi-hop paths, and aggregated without using any identity information. A theoretical analysis indicates that relay and end-to-end unlinkability improve with larger mixing sets and longer paths, while convergence remains similar to standard FedAvg. A prototype implementation evaluates learning performance, latency, unlinkability, and resource usage. The results show that UnlinkableDFL converges reliably and adapts to node churn. Communication latency emerges as the main overhead, while memory and CPU usage stay moderate. These findings illustrate the balance between anonymity and system efficiency, demonstrating that strong unlinkability can be maintained in decentralized learning workflows.

</details>


### [154] [Compensating the Packet Delay Variation for 6G Integrated with IEEE Time-Sensitive Networking](https://arxiv.org/abs/2602.21444)
*Marilet De Andrade,Joachim Sachs,Lucas Haug,Simon Egger,Frank Dürr,Balázs Varga,Janos Farkas,György Miklós*

Main category: cs.NI

TL;DR: 6G与TSN集成通过虚拟时隙技术减少数据包延迟变化，提升时间关键通信可靠性。


<details>
  <summary>Details</summary>
Motivation: 6G是支持高可靠性和时间关键通信的关键技术，需解决无线随机行为导致的数据包延迟变化问题。

Method: 提出使用虚拟时隙技术来提供所需的时间感知，并评估时隙大小对可调度TSN流数量的影响。

Result: 通过去抖动技术和虚拟时隙，显著减少了数据包延迟变化，并分析了时隙大小对性能的影响。

Conclusion: 6G网络与TSN集成通过虚拟时隙技术有效补偿了无线随机行为带来的数据包延迟变化，提升了时间关键通信的可靠性。

Abstract: 6G is deemed as a key technology to support emerging applications with stringent requirements for highly dependable and timecritical communication. In this paper, we investigate 6G networks integrated with TSN and how to compensate for wireless stochastic behavior which involves a large intrinsic packet delay variation. We evaluate a 6G solution to reduce packet delay variation that is based on de-jittering. For this, we propose to use virtual timeslots for providing the required time-awareness. We discuss the benefits of the proposed solution while evaluating the impact of the timeslot size on the number of schedulable TSN streams.

</details>


### [155] [Lossy Compression of Network Feature Data: When Less Is Enough](https://arxiv.org/abs/2602.21891)
*Fabio Palmese,Gabriele Merlach,Damiano Ravalico,Martino Trevisan,Alessandro E. C. Redondi*

Main category: cs.NI

TL;DR: 研究通过任务感知压缩技术减少流量特征存储，同时保持分析准确性，适用于核心网络和IoT环境。


<details>
  <summary>Details</summary>
Motivation: 解决大规模核心网络和资源受限的IoT环境中，基于特征的网络流量分析存储扩展性问题。

Method: 研究了任务感知的有损压缩策略，采用语义保持的简单压缩技术。

Result: 展示了在核心网络网站分类和IoT设备识别的用例中，压缩技术能稳定平衡存储效率与任务性能。

Conclusion: 压缩技术作为可扩展网络监控系统的关键设计维度，能够平衡存储效率和任务性能。

Abstract: Network traffic analysis increasingly relies on feature-based representations to support monitoring and security in the presence of pervasive encryption. Although features are more compact than raw packet traces, their storage has become a scalability bottleneck from large-scale core networks to resource-constrained Internet of Things (IoT) environments. This article investigates task-aware lossy compression strategies that reduce the storage footprint of traffic features while preserving analytics accuracy. Using website classification in core networks and device identification in IoT environments as representative use cases, we show that simple, semantics-preserving compression techniques expose stable operating regions that balance storage efficiency and task performance. These results highlight compression as a first-class design dimension in scalable network monitoring systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [156] [Cross domain Persistent Monitoring for Hybrid Aerial Underwater Vehicles](https://arxiv.org/abs/2602.21259)
*Ricardo B. Grando,Victor A. Kich,Alisson H. Kolling,Junior C. D. Jesus,Rodrigo S. Guerra,Paulo L. J. Drews-Jr*

Main category: cs.RO

TL;DR: 结合DRL和迁移学习，开发了适用于HUAUVs的跨域持续监测方法，验证了统一策略的可行性。


<details>
  <summary>Details</summary>
Motivation: 混合无人空中水下车辆（HUAUVs）在复杂环境中具有广泛的应用潜力，但由于空中和水下领域的动态和约束差异，开发新方法面临挑战。

Method: 结合深度强化学习（DRL）和迁移学习，采用共享的DRL架构，训练激光雷达（空中）和声纳（水下）传感器数据。

Result: 展示了在考虑环境不确定性和多个移动目标动态的情况下，该方法取得了有希望的结果。

Conclusion: 该框架为基于深度强化学习的混合空中-水下车辆可扩展自主持续监测解决方案奠定了基础。

Abstract: Hybrid Unmanned Aerial Underwater Vehicles (HUAUVs) have emerged as platforms capable of operating in both aerial and underwater environments, enabling applications such as inspection, mapping, search, and rescue in challenging scenarios. However, the development of novel methodologies poses significant challenges due to the distinct dynamics and constraints of the air and water domains. In this work, we present persistent monitoring tasks for HUAUVs by combining Deep Reinforcement Learning (DRL) and Transfer Learning to enable cross-domain adaptability. Our approach employs a shared DRL architecture trained on Lidar sensor data (on air) and Sonar data (underwater), demonstrating the feasibility of a unified policy for both environments. We further show that the methodology presents promising results, taking into account the uncertainty of the environment and the dynamics of multiple mobile targets. The proposed framework lays the groundwork for scalable autonomous persistent monitoring solutions based on DRL for hybrid aerial-underwater vehicles.

</details>


### [157] [Dual-Branch INS/GNSS Fusion with Inequality and Equality Constraints](https://arxiv.org/abs/2602.21266)
*Mor Levenhar,Itzik Klein*

Main category: cs.RO

TL;DR: 论文提出一种双分支信息辅助框架，通过融合等式和不等式运动约束，显著提高城市环境中车辆导航的精度和鲁棒性，无需额外硬件。


<details>
  <summary>Details</summary>
Motivation: 城市环境中，由于高层建筑和复杂基础设施的遮挡，卫星信号频繁中断，导致车辆导航不可靠。低成本惯性传感器在长时间信号中断时误差累积迅速，现有信息辅助方法（如非完整约束）在动态城市驾驶条件下可能失效。

Method: 论文提出了一种双分支信息辅助框架，融合等式和不等式运动约束，通过方差加权方案实现。该方法仅需对现有导航滤波器进行软件修改，无需额外传感器或硬件。

Result: 在四种公开的城市数据集上评估，结果显示：在GNSS完全可用时，垂直位置误差减少16.7%，高度精度提高50.1%；在GNSS缺失时，垂直漂移减少24.2%，高度精度提高20.2%。

Conclusion: 论文提出了一种双分支信息辅助框架，通过方差加权方案融合等式和不等式运动约束，仅需对现有导航滤波器进行软件修改，无需额外传感器或硬件。该方法在四种公开的城市数据集上进行了评估，结果表明在GNSS完全可用和GNSS缺失条件下均显著提高了导航精度和鲁棒性。

Abstract: Reliable vehicle navigation in urban environments remains a challenging problem due to frequent satellite signal blockages caused by tall buildings and complex infrastructure. While fusing inertial reading with satellite positioning in an extended Kalman filter provides short-term navigation continuity, low-cost inertial sensors suffer from rapid error accumulation during prolonged outages. Existing information aiding approaches, such as the non-holonomic constraint, impose rigid equality assumptions on vehicle motion that may be violated under dynamic urban driving conditions, limiting their robustness precisely when aiding is most needed. In this paper, we propose a dual-branch information aiding framework that fuses equality and inequality motion constraints through a variance-weighted scheme, requiring only a software modification to an existing navigation filter with no additional sensors or hardware. The proposed method is evaluated on four publicly available urban datasets featuring various inertial sensors, road conditions, and dynamics, covering a total duration of 4.3 hours of recorded data. Under Full GNSS availability, the method reduces vertical position error by 16.7% and improves altitude accuracy by 50.1% over the standard non-holonomic constraint. Under GNSS-denied conditions, vertical drift is reduced by 24.2% and altitude accuracy improves by 20.2%. These results demonstrate that replacing hard motion equality assumptions with physically motivated inequality bounds is a practical and cost-free strategy for improving navigation resilience, continuity, and drift robustness without relying on additional sensors, map data, or learned models.

</details>


### [158] [Learning Deformable Object Manipulation Using Task-Level Iterative Learning Control](https://arxiv.org/abs/2602.21302)
*Krishna Suresh,Chris Atkeson*

Main category: cs.RO

TL;DR: 提出任务级迭代学习控制方法，成功实现多种绳索的动态操作，高效且无需大量数据或模拟。


<details>
  <summary>Details</summary>
Motivation: 解决可变形物体动态操作的挑战，因其无限自由度和欠驱动特性。

Method: 提出了一种任务级迭代学习控制方法，通过构建局部逆模型，将任务空间误差传播到动作更新中。

Result: 在7种不同绳索上测试，学习效果显著，成功率高且迁移能力强。

Conclusion: 该方法在10次试验内对所有测试绳索实现了100%的成功率，并能在大约2-5次试验中在不同绳索类型间成功迁移。

Abstract: Dynamic manipulation of deformable objects is challenging for humans and robots because they have infinite degrees of freedom and exhibit underactuated dynamics. We introduce a Task-Level Iterative Learning Control method for dynamic manipulation of deformable objects. We demonstrate this method on a non-planar rope manipulation task called the flying knot. Using a single human demonstration and a simplified rope model, the method learns directly on hardware without reliance on large amounts of demonstration data or massive amounts of simulation. At each iteration, the algorithm constructs a local inverse model of the robot and rope by solving a quadratic program to propagate task-space errors into action updates. We evaluate performance across 7 different kinds of ropes, including chain, latex surgical tubing, and braided and twisted ropes, ranging in thicknesses of 7--25mm and densities of 0.013--0.5 kg/m. Learning achieves a 100\% success rate within 10 trials on all ropes. Furthermore, the method can successfully transfer between most rope types in approximately 2--5 trials. https://flying-knots.github.io

</details>


### [159] [Enhancing Cellular-enabled Collaborative Robots Planning through GNSS data for SAR Scenarios](https://arxiv.org/abs/2602.21899)
*Arnau Romero,Carmen Delgado,Jana Baguer,Raúl Suárez,Xavier Costa-Pérez*

Main category: cs.RO

TL;DR: 提出了一种优化搜救机器人部署的新框架，利用5G/6G网络，平衡机器人数量、探索效率和响应时间，并考虑地形和通信因素。


<details>
  <summary>Details</summary>
Motivation: 解决协作机器人在搜救和应急响应中对电池电力和持久低延迟通信的依赖，以及由此导致的运行时间和移动性受限问题。

Method: 提出了一个包含任务规划和任务执行阶段的搜救框架，优化机器人部署，考虑探索区域大小、地形高度、机器人队伍规模、通信影响的能量分布、期望探索率和目标响应时间等参数。

Result: 展示了轮式和四足机器人在机器人数量、探索区域和响应时间之间的权衡，量化了地形高度数据对任务时间和能量消耗的影响。

Conclusion: 该框架为利用下一代移动网络增强自主搜救行动提供了关键见解。

Abstract: Cellular-enabled collaborative robots are becoming paramount in Search-and-Rescue (SAR) and emergency response. Crucially dependent on resilient mobile network connectivity, they serve as invaluable assets for tasks like rapid victim localization and the exploration of hazardous, otherwise unreachable areas. However, their reliance on battery power and the need for persistent, low-latency communication limit operational time and mobility. To address this, and considering the evolving capabilities of 5G/6G networks, we propose a novel SAR framework that includes Mission Planning and Mission Execution phases and that optimizes robot deployment. By considering parameters such as the exploration area size, terrain elevation, robot fleet size, communication-influenced energy profiles, desired exploration rate, and target response time, our framework determines the minimum number of robots required and their optimal paths to ensure effective coverage and timely data backhaul over mobile networks. Our results demonstrate the trade-offs between number of robots, explored area, and response time for wheeled and quadruped robots. Further, we quantify the impact of terrain elevation data on mission time and energy consumption, showing the benefits of incorporating real-world environmental factors that might also affect mobile signal propagation and connectivity into SAR planning. This framework provides critical insights for leveraging next-generation mobile networks to enhance autonomous SAR operations.

</details>


### [160] [Unified Complementarity-Based Contact Modeling and Planning for Soft Robots](https://arxiv.org/abs/2602.21316)
*Milad Azizkhani,Yue Chen*

Main category: cs.RO

TL;DR: CUSP框架统一了软体机器人的接触建模与规划，解决了现有方法的挑战。


<details>
  <summary>Details</summary>
Motivation: 软体机器人与环境的交互依赖接触，但现有方法在建模和规划接触丰富的交互时面临挑战。

Method: 提出了一个基于互补性的统一框架，包括三阶段条件处理流程：惯性秩选择、Ruiz均衡和轻量级Tikhonov正则化。

Result: 开发了针对离散化软体机器人的鲁棒LCP模型，并通过MPCC实现了动态轨迹优化。

Conclusion: CUSP为软体机器人中的接触建模、模拟和规划提供了新的统一基础。

Abstract: Soft robots were introduced in large part to enable safe, adaptive interaction with the environment, and this interaction relies fundamentally on contact. However, modeling and planning contact-rich interactions for soft robots remain challenging: dense contact candidates along the body create redundant constraints and rank-deficient LCPs, while the disparity between high stiffness and low friction introduces severe ill-conditioning. Existing approaches rely on problem-specific approximations or penalty-based treatments. This letter presents a unified complementarity-based framework for soft-robot contact modeling and planning that brings contact modeling, manipulation, and planning into a unified, physically consistent formulation. We develop a robust Linear Complementarity Problem (LCP) model tailored to discretized soft robots and address these challenges with a three-stage conditioning pipeline: inertial rank selection to remove redundant contacts, Ruiz equilibration to correct scale disparity and ill-conditioning, and lightweight Tikhonov regularization on normal blocks. Building on the same formulation, we introduce a kinematically guided warm-start strategy that enables dynamic trajectory optimization through contact using Mathematical Programs with Complementarity Constraints (MPCC) and demonstrate its effectiveness on contact-rich ball manipulation tasks. In conclusion, CUSP provides a new foundation for unifying contact modeling, simulation, and planning in soft robotics.

</details>


### [161] [CableRobotGraphSim: A Graph Neural Network for Modeling Partially Observable Cable-Driven Robot Dynamics](https://arxiv.org/abs/2602.21331)
*Nelson Chen,William R. Johnson,Rebecca Kramer-Bottiglio,Kostas Bekris,Mridul Aanjaneya*

Main category: cs.RO

TL;DR: 提出 \texttt{CableRobotGraphSim}，一种基于 GNN 的电缆驱动机器人模拟器，支持部分可观测输入，通过仿真与真实数据协同训练提升性能，并集成 MPPI 控制器验证其速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统基于第一性原理的模拟器通常需要全状态可观测性或依赖参数搜索进行系统识别，限制了其应用范围。\texttt{CableRobotGraphSim} 旨在解决这些局限性。

Method: 采用图神经网络（GNN）模型，将电缆驱动机器人表示为图结构（刚体为节点，电缆和接触为边），并结合仿真与真实数据协同训练。

Result: 模型能够快速准确地匹配其他模拟模型和真实机器人的特性，仅需部分可观测输入，并与 MPPI 控制器集成实现闭环导航。

Conclusion: \texttt{CableRobotGraphSim} 通过图神经网络模型和仿真与真实数据协同训练的方法，显著提升了电缆驱动机器人的模拟效率和准确性，同时支持部分可观测输入。

Abstract: General-purpose simulators have accelerated the development of robots. Traditional simulators based on first-principles, however, typically require full-state observability or depend on parameter search for system identification. This work presents \texttt{CableRobotGraphSim}, a novel Graph Neural Network (GNN) model for cable-driven robots that aims to address shortcomings of prior simulation solutions. By representing cable-driven robots as graphs, with the rigid-bodies as nodes and the cables and contacts as edges, this model can quickly and accurately match the properties of other simulation models and real robots, while ingesting only partially observable inputs. Accompanying the GNN model is a sim-and-real co-training procedure that promotes generalization and robustness to noisy real data. This model is further integrated with a Model Predictive Path Integral (MPPI) controller for closed-loop navigation, which showcases the model's speed and accuracy.

</details>


### [162] [Environment-Aware Learning of Smooth GNSS Covariance Dynamics for Autonomous Racing](https://arxiv.org/abs/2602.21366)
*Y. Deemo Chen,Arion Zimmermann,Thomas A. Berrueta,Soon-Jo Chung*

Main category: cs.RO

TL;DR: LACE是一种学习框架，通过DNN和注意力机制动态建模GNSS测量协方差，提供稳定平滑的估计，提升自主赛车在恶劣环境中的定位性能。


<details>
  <summary>Details</summary>
Motivation: 在高速度自主赛车等安全关键领域，准确稳定的状态估计至关重要，需要测量不确定性既能适应环境又能保持时间平滑以支持控制。

Method: 提出了一种基于学习的框架LACE，利用深度神经网络（DNN）通过注意力机制从环境特征预测系统过程噪声，并将协方差演化建模为指数稳定动力系统。通过基于收缩的稳定性和系统性施加谱约束，为协方差动态提供了指数稳定性和平滑性的形式化保证。

Result: 在AV-24自主赛车上验证了LACE框架，结果显示在GNSS信号受限的挑战性环境中，定位性能提升且协方差估计更平滑。

Conclusion: LACE框架通过动态建模GNSS测量协方差的时序动态，为状态估计问题提供了指数稳定性和平滑性保证，显著提升了在GNSS信号受限环境中的定位性能。

Abstract: Ensuring accurate and stable state estimation is a challenging task crucial to safety-critical domains such as high-speed autonomous racing, where measurement uncertainty must be both adaptive to the environment and temporally smooth for control. In this work, we develop a learning-based framework, LACE, capable of directly modeling the temporal dynamics of GNSS measurement covariance. We model the covariance evolution as an exponentially stable dynamical system where a deep neural network (DNN) learns to predict the system's process noise from environmental features through an attention mechanism. By using contraction-based stability and systematically imposing spectral constraints, we formally provide guarantees of exponential stability and smoothness for the resulting covariance dynamics. We validate our approach on an AV-24 autonomous racecar, demonstrating improved localization performance and smoother covariance estimates in challenging, GNSS-degraded environments. Our results highlight the promise of dynamically modeling the perceived uncertainty in state estimation problems that are tightly coupled with control sensitivity.

</details>


### [163] [Autonomous Sea Turtle Robot for Marine Fieldwork](https://arxiv.org/abs/2602.21389)
*Zach J. Patterson,Emily Sologuren,Levi Cai,Daniel Kim,Alaa Maalouf,Pascal Spino,Daniela Rus*

Main category: cs.RO

TL;DR: 研究开发了一种海龟启发的自主水下机器人，结合视觉驱动控制，实现了在复杂环境中安全导航和追踪移动目标，为海洋生态监测提供了新工具。


<details>
  <summary>Details</summary>
Motivation: 自主机器人可以改变我们观察海洋生态系统的方式，但在珊瑚礁等复杂环境中近距离操作仍存在困难，需要安全操控并应对复杂环境条件。

Method: 研究开发了一种海龟启发的自主水下机器人，结合了深度-航向稳定、障碍物避免和目标中心控制，通过紧密集成的视觉驱动控制堆栈实现了生物启发式运动与现场自主性的结合。

Result: 在控制池实验和活珊瑚礁展览中验证了机器人的稳定操作和快速移动海洋动物及人类潜水员的可靠追踪能力，障碍物避让成功率达91%，并展示了低计算量的机载追踪模式。

Conclusion: 该研究通过结合生物启发式硬件、控制和现场实验，首次展示了能够追踪和监测真实海洋动物的集成仿生机器人系统，为敏感生态系统中的低干扰探索和近距离监测提供了实用途径。

Abstract: Autonomous robots can transform how we observe marine ecosystems, but close-range operation in reefs and other cluttered habitats remains difficult. Vehicles must maneuver safely near animals and fragile structures while coping with currents, variable illumination and limited sensing. Previous approaches simplify these problems by leveraging soft materials and bioinspired swimming designs, but such platforms remain limited in terms of deployable autonomy. Here we present a sea turtle-inspired autonomous underwater robot that closed the gap between bioinspired locomotion and field-ready autonomy through a tightly integrated, vision-driven control stack. The robot combines robust depth-heading stabilization with obstacle avoidance and target-centric control, enabling it to track and interact with moving objects in complex terrain. We validate the robot in controlled pool experiments and in a live coral reef exhibit at the New England Aquarium, demonstrating stable operation and reliable tracking of fast-moving marine animals and human divers. To the best of our knowledge, this is the first integrated biomimetic robotic system, combining novel hardware, control, and field experiments, deployed to track and monitor real marine animals in their natural environment. During off-tether experiments, we demonstrate safe navigation around obstacles (91\% success rate in the aquarium exhibit) and introduce a low-compute onboard tracking mode. Together, these results establish a practical route toward soft-rigid hybrid, bioinspired underwater robots capable of minimally disruptive exploration and close-range monitoring in sensitive ecosystems.

</details>


### [164] [Event-Driven On-Sensor Locomotion Mode Recognition Using a Shank-Mounted IMU with Embedded Machine Learning for Exoskeleton Control](https://arxiv.org/abs/2602.21418)
*Mohammadsaleh Razmi,Iman Shojaei*

Main category: cs.RO

TL;DR: 该研究提出了一种基于IMU嵌入式MLC的实时HAR系统，通过传感器级别活动识别降低微控制器负担，优化外骨骼控制效率。


<details>
  <summary>Details</summary>
Motivation: 传统的HAR系统需要持续将原始惯性数据流式传输到微控制器进行分类，导致高功耗和延迟。本研究旨在通过传感器级别的实时推理降低功耗和延迟，支持下肢外骨骼的低延迟控制。

Method: 利用STMicroelectronics LSM6DSV16X IMU的嵌入式机器学习核心（MLC）在传感器级别执行活动识别，配置并部署轻量级决策树模型，通过中断驱动架构实现低功耗操作。

Result: 提出的中断驱动、传感器级别推理架构在减少计算和通信开销的同时，显著提升了电池续航能力，并改善了平地行走与楼梯爬升的区分能力。

Conclusion: 该系统通过传感器级别的实时活动识别，显著降低了微控制器的计算和通信开销，同时提高了区分平地行走和楼梯爬升的鲁棒性，为外骨骼的扭矩辅助控制提供了高效解决方案。

Abstract: This work presents a wearable human activity recognition (HAR) system that performs real-time inference directly inside a shank-mounted inertial measurement unit (IMU) to support low-latency control of a lower-limb exoskeleton. Unlike conventional approaches that continuously stream raw inertial data to a microcontroller for classification, the proposed system executes activity recognition at the sensor level using the embedded Machine Learning Core (MLC) of the STMicroelectronics LSM6DSV16X IMU, allowing the host microcontroller to remain in a low-power state and read only the recognized activity label from IMU registers. While the system generalizes to multiple human activities, this paper focuses on three representative locomotion modes - stance, level walking, and stair ascent - using data collected from adult participants. A lightweight decision-tree model was configured and deployed for on-sensor execution using ST MEMS Studio, enabling continuous operation without custom machine learning code on the microcontroller. During operation, the IMU asserts an interrupt when motion or a new classification is detected; the microcontroller wakes, reads the MLC output registers, and forwards the inferred mode to the exoskeleton controller. This interrupt-driven, on-sensor inference architecture reduces computation and communication overhead while preserving battery energy and improving robustness in distinguishing level walking from stair ascent for torque-assist control.

</details>


### [165] [VLA Knows Its Limits](https://arxiv.org/abs/2602.21445)
*Haoxuan Wang,Gengyu Zhang,Yan Yan,Ramana Rao Kompella,Gaowen Liu*

Main category: cs.RO

TL;DR: AutoHorizon是一种动态估计执行视野的方法，通过分析注意力权重揭示动作组织的潜在模式，并在机器人任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索执行视野（每个预测动作块中执行的动作数量）对基于流的视觉-语言-动作（VLA）模型性能的影响，并解决现有方法中执行视野选择未充分探索的问题。

Method: 通过分析基于流的视觉-语言-动作（VLA）模型中的跨注意力和自注意力权重，揭示了两个关键现象：(i) 块内动作对视觉-语言标记的注意力不变，限制了环境变化的适应性；(ii) 初始和终止动作标记作为稳定锚点，形成中间动作组织的潜在中心。基于这些发现，将动作自注意力权重解释为模型预测极限的代理，提出了AutoHorizon方法。

Result: AutoHorizon在模拟和真实世界的机器人操作任务中表现优异，计算开销可忽略不计，并能泛化到不同的任务和基于流的模型。

Conclusion: AutoHorizon是一种在测试时动态估计执行视野的方法，能够适应变化的感知条件，且在模拟和真实世界的机器人操作任务中表现优异，计算开销可忽略不计，并能泛化到不同的任务和基于流的模型。

Abstract: Action chunking has recently emerged as a standard practice in flow-based Vision-Language-Action (VLA) models. However, the effect and choice of the execution horizon - the number of actions to be executed from each predicted chunk - remains underexplored. In this work, we first show that varying the execution horizon leads to substantial performance deviations, with performance initially improving and then declining as the horizon increases. To uncover the reasons, we analyze the cross- and self-attention weights in flow-based VLAs and reveal two key phenomena: (i) intra-chunk actions attend invariantly to vision-language tokens, limiting adaptability to environmental changes; and (ii) the initial and terminal action tokens serve as stable anchors, forming latent centers around which intermediate actions are organized. Motivated by these insights, we interpret action self-attention weights as a proxy for the model's predictive limit and propose AutoHorizon, the first test-time method that dynamically estimates the execution horizon for each predicted action chunk to adapt to changing perceptual conditions. Across simulated and real-world robotic manipulation tasks, AutoHorizon is performant, incurs negligible computational overhead, and generalizes across diverse tasks and flow-based models.

</details>


### [166] [Constructive Vector Fields for Path Following in Fully-Actuated Systems on Matrix Lie Groups](https://arxiv.org/abs/2602.21450)
*Felipe Bartelt,Vinicius M. Gonçalves,Luciano C. A. Pimenta*

Main category: cs.RO

TL;DR: 提出基于李群的向量场控制策略，减少输入冗余，适用于SE(3)等场景，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 为解决完全驱动系统在李群上的曲线跟踪问题，并减少控制输入的冗余性，提升实际应用中的实用性。

Method: 利用李群性质，设计了一种非冗余控制输入（与李群维度匹配而非嵌入空间维度），并针对SE(3)群提供了高效算法计算向量场。

Result: 实验通过机器人操纵器验证了方法的有效性，尤其在SE(3)群（如全向无人机控制）中表现出色。

Conclusion: 本文提出了一种新颖的向量场策略，用于控制连接矩阵李群上的完全驱动系统，确保收敛到并沿群上定义的曲线遍历。该方法在特定情况下（如欧几里得空间中的平移群）可简化为先前工作（Rezende等，2022），并通过李群性质扩展了其证明。

Abstract: This paper presents a novel vector field strategy for controlling fully-actuated systems on connected matrix Lie groups, ensuring convergence to and traversal along a curve defined on the group. Our approach generalizes our previous work (Rezende et al., 2022) and reduces to it when considering the Lie group of translations in Euclidean space. Since the proofs in Rezende et al. (2022) rely on key properties such as the orthogonality between the convergent and traversal components, we extend these results by leveraging Lie group properties. These properties also allow the control input to be non-redundant, meaning it matches the dimension of the Lie group, rather than the potentially larger dimension of the space in which the group is embedded. This can lead to more practical control inputs in certain scenarios. A particularly notable application of our strategy is in controlling systems on SE(3) -- in this case, the non-redundant input corresponds to the object's mechanical twist -- making it well-suited for controlling objects that can move and rotate freely, such as omnidirectional drones. In this case, we provide an efficient algorithm to compute the vector field. We experimentally validate the proposed method using a robotic manipulator to demonstrate its effectiveness.

</details>


### [167] [LiLo-VLA: Compositional Long-Horizon Manipulation via Linked Object-Centric Policies](https://arxiv.org/abs/2602.21531)
*Yue Yang,Shuo Cheng,Yu Fang,Homanga Bharadhwaj,Mingyu Ding,Gedas Bertasius,Daniel Szafir*

Main category: cs.RO

TL;DR: LiLo-VLA通过模块化设计解决长时程操作问题，模拟和现实任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决通用机器人在非结构化环境中执行长时程操作任务时，VLA模型因组合复杂性和环境敏感性导致的级联失败问题。

Method: 提出LiLo-VLA，将运输与交互解耦：Reaching Module处理全局运动，Interaction Module使用对象为中心的VLA处理目标对象。

Result: 在21个模拟任务中平均成功率为69%，现实世界8个任务中达85%，显著优于Pi0.5和OpenVLA-OFT。

Conclusion: LiLo-VLA模块化框架在长时程操作任务中表现出色，显著优于现有方法，并在现实世界中验证了其有效性。

Abstract: General-purpose robots must master long-horizon manipulation, defined as tasks involving multiple kinematic structure changes (e.g., attaching or detaching objects) in unstructured environments. While Vision-Language-Action (VLA) models offer the potential to master diverse atomic skills, they struggle with the combinatorial complexity of sequencing them and are prone to cascading failures due to environmental sensitivity. To address these challenges, we propose LiLo-VLA (Linked Local VLA), a modular framework capable of zero-shot generalization to novel long-horizon tasks without ever being trained on them. Our approach decouples transport from interaction: a Reaching Module handles global motion, while an Interaction Module employs an object-centric VLA to process isolated objects of interest, ensuring robustness against irrelevant visual features and invariance to spatial configurations. Crucially, this modularity facilitates robust failure recovery through dynamic replanning and skill reuse, effectively mitigating the cascading errors common in end-to-end approaches. We introduce a 21-task simulation benchmark consisting of two challenging suites: LIBERO-Long++ and Ultra-Long. In these simulations, LiLo-VLA achieves a 69% average success rate, outperforming Pi0.5 by 41% and OpenVLA-OFT by 67%. Furthermore, real-world evaluations across 8 long-horizon tasks demonstrate an average success rate of 85%. Project page: https://yy-gx.github.io/LiLo-VLA/.

</details>


### [168] [Learning Agile and Robust Omnidirectional Aerial Motion on Overactuated Tiltable-Quadrotors](https://arxiv.org/abs/2602.21583)
*Wentao Zhang,Zhaoqi Ma,Jinjie Li,Huayi Wang,Haokun Liu,Junichiro Sugihara,Chen Chen,Yicheng Chen,Moju Zhao*

Main category: cs.RO

TL;DR: 该研究利用强化学习为可倾斜四旋翼机器人开发了一个鲁棒且敏捷的全向运动控制框架，通过系统辨识和领域随机化实现高效学习，在真实硬件上实现零样本部署，性能优于NMPC控制器。


<details>
  <summary>Details</summary>
Motivation: 倾斜旋翼空中机器人通过推力矢量实现全向机动，但由于关节和转子动力学的强耦合，控制面临重大挑战。模型基础控制器在名义条件下能实现高运动精度，但在干扰和建模不确定性下鲁棒性和响应性下降。

Method: 论文提出了一种学习型控制框架，通过系统辨识和最小化且物理一致的领域随机化，实现了协调的转子-关节行为的高效学习，以在SE(3)空间中达到目标姿态。

Result: 与先进的NMPC控制器相比，所提方法在六自由度姿态跟踪精度上表现相当，同时在多样任务中展现出更优的鲁棒性和泛化能力，实现了零样本部署。

Conclusion: 该论文提出的基于强化学习的控制框架在六自由度姿态跟踪精度上与先进的NMPC控制器相当，同时在多样任务中展现出更优的鲁棒性和泛化能力，实现了在真实硬件上的零样本部署。

Abstract: Tilt-rotor aerial robots enable omnidirectional maneuvering through thrust vectoring, but introduce significant control challenges due to the strong coupling between joint and rotor dynamics. While model-based controllers can achieve high motion accuracy under nominal conditions, their robustness and responsiveness often degrade in the presence of disturbances and modeling uncertainties. This work investigates reinforcement learning for omnidirectional aerial motion control on over-actuated tiltable quadrotors that prioritizes robustness and agility. We present a learning-based control framework that enables efficient acquisition of coordinated rotor-joint behaviors for reaching target poses in the $SE(3)$ space. To achieve reliable sim-to-real transfer while preserving motion accuracy, we integrate system identification with minimal and physically consistent domain randomization. Compared with a state-of-the-art NMPC controller, the proposed method achieves comparable six-degree-of-freedom pose tracking accuracy, while demonstrating superior robustness and generalization across diverse tasks, enabling zero-shot deployment on real hardware.

</details>


### [169] [SPOC: Safety-Aware Planning Under Partial Observability And Physical Constraints](https://arxiv.org/abs/2602.21595)
*Hyungmin Kim,Hobeom Jeon,Dohyung Kim,Minsu Jang,Jeahong Kim*

Main category: cs.RO

TL;DR: SPOC是一个安全感知的具身任务规划基准测试，通过整合多种现实约束和评估指标，揭示了当前大语言模型在安全规划方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试往往忽略了现实环境中的部分可观测性和物理约束等关键因素，无法全面评估任务规划的可行性和安全性。

Method: SPOC基准测试整合了严格的局部可观测性、物理约束、逐步规划和基于目标条件的评估，覆盖了多种家庭危险场景。

Result: 实验表明，现有的大语言模型在安全感知的任务规划方面表现不佳，尤其是在隐性约束条件下。

Conclusion: 当前的大语言模型在确保安全感知的任务规划方面存在困难，特别是在隐性约束条件下。SPOC基准测试的引入为评估任务规划的可行性和安全性提供了更全面的框架。

Abstract: Embodied Task Planning with large language models faces safety challenges in real-world environments, where partial observability and physical constraints must be respected. Existing benchmarks often overlook these critical factors, limiting their ability to evaluate both feasibility and safety. We introduce SPOC, a benchmark for safety-aware embodied task planning, which integrates strict partial observability, physical constraints, step-by-step planning, and goal-condition-based evaluation. Covering diverse household hazards such as fire, fluid, injury, object damage, and pollution, SPOC enables rigorous assessment through both state and constraint-based online metrics. Experiments with state-of-the-art LLMs reveal that current models struggle to ensure safety-aware planning, particularly under implicit constraints. Code and dataset are available at https://github.com/khm159/SPOC

</details>


### [170] [Iterative Closed-Loop Motion Synthesis for Scaling the Capabilities of Humanoid Control](https://arxiv.org/abs/2602.21599)
*Weisheng Xu,Qiwei Wu,Jiaxi Zhang,Tan Jing,Yangfan Li,Yuetong Fang,Jiaqi Xiong,Kai Wu,Rong Ou,Renjing Xu*

Main category: cs.RO

TL;DR: 提出闭环自动运动数据生成框架，突破数据集难度限制，显著降低失败率。


<details>
  <summary>Details</summary>
Motivation: 固定难度分布的数据集限制了控制策略的性能上限，且高质量运动数据的获取成本高、难以规模化。

Method: 提出了一种闭环自动运动数据生成与迭代框架，支持通过物理指标和目标评估实现策略与数据的难度迭代。

Result: 在PHC单基元跟踪器上，仅使用约1/10的AMASS数据集大小，测试集（2201个片段）的平均失败率比基线降低了45%。

Conclusion: 通过闭环自动运动数据生成与迭代框架，显著提升了物理驱动人形控制的性能，突破了传统数据集的难度限制，并展示了框架的合理性与优势。

Abstract: Physics-based humanoid control relies on training with motion datasets that have diverse data distributions. However, the fixed difficulty distribution of datasets limits the performance ceiling of the trained control policies. Additionally, the method of acquiring high-quality data through professional motion capture systems is constrained by costs, making it difficult to achieve large-scale scalability. To address these issues, we propose a closed-loop automated motion data generation and iterative framework. It can generate high-quality motion data with rich action semantics, including martial arts, dance, combat, sports, gymnastics, and more. Furthermore, our framework enables difficulty iteration of policies and data through physical metrics and objective evaluations, allowing the trained tracker to break through its original difficulty limits. On the PHC single-primitive tracker, using only approximately 1/10 of the AMASS dataset size, the average failure rate on the test set (2201 clips) is reduced by 45\% compared to the baseline. Finally, we conduct comprehensive ablation and comparative experiments to highlight the rationality and advantages of our framework.

</details>


### [171] [Jumping Control for a Quadrupedal Wheeled-Legged Robot via NMPC and DE Optimization](https://arxiv.org/abs/2602.21612)
*Xuanqi Zeng,Lingwei Zhang,Linzhu Yue,Zhitao Song,Hongbo Zhang,Tianlin Zhang,Yun-Hui Liu*

Main category: cs.RO

TL;DR: 论文提出了一种结合NMPC和DE的轮腿机器人控制框架，成功实现动态跳跃，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 轮腿式机器人结合了腿式和轮式运动的优势，但动态跳跃因额外自由度而具有挑战性，需开发新控制方法。

Method: 采用非线性模型预测控制（NMPC）进行运动控制，并结合差分进化（DE）算法优化跳跃轨迹。

Result: 实验验证了框架的有效性，实现了跨越0.12米障碍的前跳和0.5米的垂直跳跃。

Conclusion: 该论文开发了一种小型轮腿式机器人，并提出了一种新颖的运动控制框架，通过结合NMPC和DE优化，成功实现了动态跳跃，验证了其多功能机动性。

Abstract: Quadrupedal wheeled-legged robots combine the advantages of legged and wheeled locomotion to achieve superior mobility, but executing dynamic jumps remains a significant challenge due to the additional degrees of freedom introduced by wheeled legs. This paper develops a mini-sized wheeled-legged robot for agile motion and presents a novel motion control framework that integrates the Nonlinear Model Predictive Control (NMPC) for locomotion and the Differential Evolution (DE) based trajectory optimization for jumping in quadrupedal wheeled-legged robots. The proposed controller utilizes wheel motion and locomotion to enhance jumping performance, achieving versatile maneuvers such as vertical jumping, forward jumping, and backflips. Extensive simulations and real-world experiments validate the effectiveness of the framework, demonstrating a forward jump over a 0.12 m obstacle and a vertical jump reaching 0.5 m.

</details>


### [172] [ADM-DP: Adaptive Dynamic Modality Diffusion Policy through Vision-Tactile-Graph Fusion for Multi-Agent Manipulation](https://arxiv.org/abs/2602.21622)
*Enyi Wang,Wen Fan,Dandan Zhang*

Main category: cs.RO

TL;DR: ADM-DP框架整合多模态，显著提升多智能体机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体机器人操作中的协调、抓取稳定性和碰撞避免问题。

Method: 提出ADM-DP框架，包括增强视觉编码器、触觉引导抓取策略、图基碰撞编码器和自适应模态注意力机制。

Result: 在七项多智能体任务中，ADM-DP比现有基线性能提升12-25%。

Conclusion: ADM-DP框架通过整合视觉、触觉和图基多模态，实现了多智能体机器人操作的协调控制，显著提升了性能。

Abstract: Multi-agent robotic manipulation remains challenging due to the combined demands of coordination, grasp stability, and collision avoidance in shared workspaces. To address these challenges, we propose the Adaptive Dynamic Modality Diffusion Policy (ADM-DP), a framework that integrates vision, tactile, and graph-based (multi-agent pose) modalities for coordinated control. ADM-DP introduces four key innovations. First, an enhanced visual encoder merges RGB and point-cloud features via Feature-wise Linear Modulation (FiLM) modulation to enrich perception. Second, a tactile-guided grasping strategy uses Force-Sensitive Resistor (FSR) feedback to detect insufficient contact and trigger corrective grasp refinement, improving grasp stability. Third, a graph-based collision encoder leverages shared tool center point (TCP) positions of multiple agents as structured kinematic context to maintain spatial awareness and reduce inter-agent interference. Fourth, an Adaptive Modality Attention Mechanism (AMAM) dynamically re-weights modalities according to task context, enabling flexible fusion. For scalability and modularity, a decoupled training paradigm is employed in which agents learn independent policies while sharing spatial information. This maintains low interdependence between agents while retaining collective awareness. Across seven multi-agent tasks, ADM-DP achieves 12-25% performance gains over state-of-the-art baselines. Ablation studies show the greatest improvements in tasks requiring multiple sensory modalities, validating our adaptive fusion strategy and demonstrating its robustness for diverse manipulation scenarios.

</details>


### [173] [Tacmap: Bridging the Tactile Sim-to-Real Gap via Geometry-Consistent Penetration Depth Map](https://arxiv.org/abs/2602.21625)
*Lei Su,Zhijie Peng,Renyuan Ren,Shengping Mao,Juan Du,Kaifeng Zhang,Xuezhou Zhu*

Main category: cs.RO

TL;DR: Tacmap通过统一变形映射表示，高效缩小触觉模拟与现实差距，实现零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决触觉模拟中几何投影缺乏物理真实性与高保真FEM计算成本高的矛盾，缩小触觉模拟与现实的差距。

Method: 提出Tacmap框架，基于体积穿透深度计算3D交集体积作为深度图，并通过自动化数据收集装置学习从原始触觉图像到真实深度图的映射。

Result: Tacmap的变形映射在多样接触场景中与真实测量高度一致，且模拟训练的策略能在物理机器人上零样本迁移。

Conclusion: Tacmap通过统一的变形映射表示，有效缩小了触觉模拟与现实的差距，并在物理机器人上实现了零样本迁移。

Abstract: Vision-Based Tactile Sensors (VBTS) are essential for achieving dexterous robotic manipulation, yet the tactile sim-to-real gap remains a fundamental bottleneck. Current tactile simulations suffer from a persistent dilemma: simplified geometric projections lack physical authenticity, while high-fidelity Finite Element Methods (FEM) are too computationally prohibitive for large-scale reinforcement learning. In this work, we present Tacmap, a high-fidelity, computationally efficient tactile simulation framework anchored in volumetric penetration depth. Our key insight is to bridge the tactile sim-to-real gap by unifying both domains through a shared deform map representation. Specifically, we compute 3D intersection volumes as depth maps in simulation, while in the real world, we employ an automated data-collection rig to learn a robust mapping from raw tactile images to ground-truth depth maps. By aligning simulation and real-world in this unified geometric space, Tacmap minimizes domain shift while maintaining physical consistency. Quantitative evaluations across diverse contact scenarios demonstrate that Tacmap's deform maps closely mirror real-world measurements. Moreover, we validate the utility of Tacmap through an in-hand rotation task, where a policy trained exclusively in simulation achieves zero-shot transfer to a physical robot.

</details>


### [174] [Self-Correcting VLA: Online Action Refinement via Sparse World Imagination](https://arxiv.org/abs/2602.21633)
*Chenyv Liu,Wentao Tan,Lei Zhu,Fengling Li,Jingjing Li,Guoli Yang,Heng Tao Shen*

Main category: cs.RO

TL;DR: SC-VLA通过稀疏想象和在线修正实现自我改进，显著提升机器人操作任务的效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-动作模型缺乏物理动态理解和自我改进机制的问题。

Method: 设计了稀疏世界想象模块，整合辅助预测头来预测任务进度和未来轨迹趋势，并引入在线动作修正模块调整轨迹方向。

Result: 在机器人操作任务中，SC-VLA比基线方法减少了16%的步骤，成功率提高了9%，真实实验中提升了14%。

Conclusion: SC-VLA通过稀疏想象和在线动作修正模块实现了自我改进，在仿真和真实环境中均表现出色，任务完成率和效率显著提升。

Abstract: Standard vision-language-action (VLA) models rely on fitting statistical data priors, limiting their robust understanding of underlying physical dynamics. Reinforcement learning enhances physical grounding through exploration yet typically relies on external reward signals that remain isolated from the agent's internal states. World action models have emerged as a promising paradigm that integrates imagination and control to enable predictive planning. However, they rely on implicit context modeling, lacking explicit mechanisms for self-improvement. To solve these problems, we propose Self-Correcting VLA (SC-VLA), which achieve self-improvement by intrinsically guiding action refinement through sparse imagination. We first design sparse world imagination by integrating auxiliary predictive heads to forecast current task progress and future trajectory trends, thereby constraining the policy to encode short-term physical evolution. Then we introduce the online action refinement module to reshape progress-dependent dense rewards, adjusting trajectory orientation based on the predicted sparse future states. Evaluations on challenging robot manipulation tasks from simulation benchmarks and real-world settings demonstrate that SC-VLA achieve state-of-the-art performance, yielding the highest task throughput with 16% fewer steps and a 9% higher success rate than the best-performing baselines, alongside a 14% gain in real-world experiments. Code is available at https://github.com/Kisaragi0/SC-VLA.

</details>


### [175] [DAGS-SLAM: Dynamic-Aware 3DGS SLAM via Spatiotemporal Motion Probability and Uncertainty-Aware Scheduling](https://arxiv.org/abs/2602.21644)
*Li Zhang,Yu-An Liu,Xijia Jiang,Conghao Huang,Danyang Li,Yanyong Zhang*

Main category: cs.RO

TL;DR: DAGS-SLAM是一种动态感知的3D高斯泼溅SLAM系统，通过运动概率状态和按需语义分割优化动态环境处理，适用于移动设备。


<details>
  <summary>Details</summary>
Motivation: 移动机器人和物联网设备需要在有限的计算和能源预算下实现实时定位与密集重建，而现有动态3DGS-SLAM方法在动态对象和遮挡处理上存在不足。

Method: DAGS-SLAM利用时空运动概率状态和按需触发的语义分割，结合轻量级YOLO实例先验与几何线索，优化动态对象的处理。

Result: 在公共动态RGB-D基准测试中，DAGS-SLAM展示了改进的重建质量和稳健的跟踪性能，同时保持了实时处理速度。

Conclusion: DAGS-SLAM通过动态感知的3D高斯泼溅SLAM系统，实现了在动态环境中稳健的实时定位与密集重建，同时保持了计算效率，适用于移动设备部署。

Abstract: Mobile robots and IoT devices demand real-time localization and dense reconstruction under tight compute and energy budgets. While 3D Gaussian Splatting (3DGS) enables efficient dense SLAM, dynamic objects and occlusions still degrade tracking and mapping. Existing dynamic 3DGS-SLAM often relies on heavy optical flow and per-frame segmentation, which is costly for mobile deployment and brittle under challenging illumination. We present DAGS-SLAM, a dynamic-aware 3DGS-SLAM system that maintains a spatiotemporal motion probability (MP) state per Gaussian and triggers semantics on demand via an uncertainty-aware scheduler. DAGS-SLAM fuses lightweight YOLO instance priors with geometric cues to estimate and temporally update MP, propagates MP to the front-end for dynamic-aware correspondence selection, and suppresses dynamic artifacts in the back-end via MP-guided optimization. Experiments on public dynamic RGB-D benchmarks show improved reconstruction and robust tracking while sustaining real-time throughput on a commodity GPU, demonstrating a practical speed-accuracy tradeoff with reduced semantic invocations toward mobile deployment.

</details>


### [176] [Biomechanical Comparisons Reveal Divergence of Human and Humanoid Gaits](https://arxiv.org/abs/2602.21666)
*Luying Feng,Yaochu Jin,Hanze Hu,Wei Chen*

Main category: cs.RO

TL;DR: 该研究提出GDAF框架，量化人形机器人与人类步态的差异，发现现有控制器在生物力学上仍有显著不足，并提供了开源工具和数据以推动改进。


<details>
  <summary>Details</summary>
Motivation: 由于生物和机械结构之间的根本差异，实现人形机器人的人类步态仍然具有挑战性。尽管模仿学习已成为生成自然机器人运动的有前途的方法，但简单地复制关节角度轨迹无法捕捉人类运动的潜在原理。

Method: 研究提出了Gait Divergence Analysis Framework (GDAF)，一个统一的生物力学评估框架，系统地量化了人类与双足机器人在运动学和动力学上的差异。应用GDAF对28种步行速度下的人类和人形机器人步态进行了系统比较。

Result: 结果显示，尽管现代人形控制器生成了视觉上类似人类的运动，但在速度上仍存在显著的生物力学差异。机器人在步态对称性、能量分布和关节协调方面表现出系统性偏差，表明在人形机器人步态的生物力学保真度和能效方面仍有改进空间。

Conclusion: 该研究提出了GDAF框架，为评估人形机器人步态提供了定量基准，并提供了数据和工具以支持开发更接近人类步态且能效更高的控制器。

Abstract: It remains challenging to achieve human-like locomotion in legged robots due to fundamental discrepancies between biological and mechanical structures. Although imitation learning has emerged as a promising approach for generating natural robotic movements, simply replicating joint angle trajectories fails to capture the underlying principles of human motion. This study proposes a Gait Divergence Analysis Framework (GDAF), a unified biomechanical evaluation framework that systematically quantifies kinematic and kinetic discrepancies between humans and bipedal robots. We apply GDAF to systematically compare human and humanoid locomotion across 28 walking speeds. To enable reproducible analysis, we collect and release a speed-continuous humanoid locomotion dataset from a state-of-the-art humanoid controller. We further provide an open-source implementation of GDAF, including analysis, visualization, and MuJoCo-based tools, enabling quantitative, interpretable, and reproducible biomechanical analysis of humanoid locomotion. Results demonstrate that despite visually human-like motion generated by modern humanoid controllers, significant biomechanical divergence persists across speeds. Robots exhibit systematic deviations in gait symmetry, energy distribution, and joint coordination, indicating that substantial room remains for improving the biomechanical fidelity and energetic efficiency of humanoid locomotion. This work provides a quantitative benchmark for evaluating humanoid locomotion and offers data and versatile tools to support the development of more human-like and energetically efficient locomotion controllers. The data and code will be made publicly available upon acceptance of the paper.

</details>


### [177] [Hierarchical LLM-Based Multi-Agent Framework with Prompt Optimization for Multi-Robot Task Planning](https://arxiv.org/abs/2602.21670)
*Tomoya Kawabe,Rin Takano*

Main category: cs.RO

TL;DR: 分层LLM规划器通过提示优化和元提示共享，显著提升多机器人任务规划的成功率，尤其在模糊任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统PDDL规划器处理模糊或长时任务时的局限性，以及LLM生成计划时可能出现的不可行动作问题。

Method: 采用分层多智能体LLM规划器，上层分解任务并分配给下层智能体，下层生成PDDL问题并由经典规划器解决。失败时通过文本梯度更新优化提示。

Result: 在MAT-THOR基准测试中，复合任务、复杂任务和模糊任务的成功率分别为0.95、0.84和0.60，优于之前的LaMMA-P方法。

Conclusion: 该论文提出了一种分层多智能体LLM规划器，通过提示优化和元提示共享显著提高了多机器人任务规划的成功率，特别是在模糊任务上表现突出。

Abstract: Multi-robot task planning requires decomposing natural-language instructions into executable actions for heterogeneous robot teams. Conventional Planning Domain Definition Language (PDDL) planners provide rigorous guarantees but struggle to handle ambiguous or long-horizon missions, while large language models (LLMs) can interpret instructions and propose plans but may hallucinate or produce infeasible actions. We present a hierarchical multi-agent LLM-based planner with prompt optimization: an upper layer decomposes tasks and assigns them to lower-layer agents, which generate PDDL problems solved by a classical planner. When plans fail, the system applies TextGrad-inspired textual-gradient updates to optimize each agent's prompt and thereby improve planning accuracy. In addition, meta-prompts are learned and shared across agents within the same layer, enabling efficient prompt optimization in multi-agent settings. On the MAT-THOR benchmark, our planner achieves success rates of 0.95 on compound tasks, 0.84 on complex tasks, and 0.60 on vague tasks, improving over the previous state-of-the-art LaMMA-P by 2, 7, and 15 percentage points respectively. An ablation study shows that the hierarchical structure, prompt optimization, and meta-prompt sharing contribute roughly +59, +37, and +4 percentage points to the overall success rate.

</details>


### [178] [SunnyParking: Multi-Shot Trajectory Generation and Motion State Awareness for Human-like Parking](https://arxiv.org/abs/2602.21682)
*Jishu Miao,Han Chen,Jiankun Zhai,Qi Liu,Tsubasa Hirakawa,Takayoshi Yamashita,Hironobu Fujiyoshi*

Main category: cs.RO

TL;DR: SunnyParking是一种新型双分支端到端架构，通过联合预测轨迹和运动状态序列，解决了传统方法在停车任务中的运动状态建模不足问题，显著提升了轨迹稳健性和换挡点精度。


<details>
  <summary>Details</summary>
Motivation: 现有端到端规划方法常将停车任务简化为几何路径回归问题，忽略了车辆运动状态的显式建模，导致物理不可行轨迹和偏离真实人类驾驶行为。

Method: SunnyParking采用双分支端到端架构，结合傅里叶特征表示停车位目标，克服了传统鸟瞰图方法的分辨率限制，实现了高精度目标交互。

Result: 实验结果表明，该框架在复杂多段停车场景中生成更稳健、更接近人类驾驶的轨迹，同时显著提高了换挡点定位精度。

Conclusion: SunnyParking提出了一种新颖的双分支端到端架构，通过联合预测空间轨迹和离散运动状态序列（如前/后）来实现运动状态感知，显著提高了复杂多段停车场景中的轨迹稳健性和换挡点定位精度。

Abstract: Autonomous parking fundamentally differs from on-road driving due to its frequent direction changes and complex maneuvering requirements. However, existing End-to-End (E2E) planning methods often simplify the parking task into a geometric path regression problem, neglecting explicit modeling of the vehicle's kinematic state. This "dimensionality deficiency" easily leads to physically infeasible trajectories and deviates from real human driving behavior, particularly at critical gear-shift points in multi-shot parking scenarios. In this paper, we propose SunnyParking, a novel dual-branch E2E architecture that achieves motion state awareness by jointly predicting spatial trajectories and discrete motion state sequences (e.g., forward/reverse). Additionally, we introduce a Fourier feature-based representation of target parking slots to overcome the resolution limitations of traditional bird's-eye view (BEV) approaches, enabling high-precision target interactions. Experimental results demonstrate that our framework generates more robust and human-like trajectories in complex multi-shot parking scenarios, while significantly improving gear-shift point localization accuracy compared to state-of-the-art methods. We open-source a new parking dataset of the CARLA simulator, specifically designed to evaluate full prediction capabilities under complex maneuvers.

</details>


### [179] [Primary-Fine Decoupling for Action Generation in Robotic Imitation](https://arxiv.org/abs/2602.21684)
*Xiaohan Lei,Min Wang,Wengang Zhou,Xingyu Lu,Houqiang Li*

Main category: cs.RO

TL;DR: PF-DAG通过两阶段解耦粗/细粒度动作生成，解决了多模态模仿学习的权衡问题，实验表现优异且具泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决多模态分布问题，避免现有方法在离散化或连续化动作空间时的权衡问题（如丢失细粒度变化或不稳定模式转换）。

Method: 提出PF-DAG框架，通过两阶段解耦粗粒度动作一致性和细粒度变化：首先将动作块压缩为离散模式，再由轻量级策略选择模式；其次学习模式条件化的MeanFlow策略生成连续动作。

Result: 在Adroit、DexArt和MetaWorld基准的56项任务中表现优于现有方法，并能推广到真实世界的触觉灵巧操作任务。

Conclusion: PF-DAG的两阶段设计在理论和实验上均优于单阶段生成策略，实现了鲁棒的多模态建模和反应式闭环控制。

Abstract: Multi-modal distribution in robotic manipulation action sequences poses critical challenges for imitation learning. To this end, existing approaches often model the action space as either a discrete set of tokens or a continuous, latent-variable distribution. However, both approaches present trade-offs: some methods discretize actions into tokens and therefore lose fine-grained action variations, while others generate continuous actions in a single stage tend to produce unstable mode transitions. To address these limitations, we propose Primary-Fine Decoupling for Action Generation (PF-DAG), a two-stage framework that decouples coarse action consistency from fine-grained variations. First, we compress action chunks into a small set of discrete modes, enabling a lightweight policy to select consistent coarse modes and avoid mode bouncing. Second, a mode conditioned MeanFlow policy is learned to generate high-fidelity continuous actions. Theoretically, we prove PF-DAG's two-stage design achieves a strictly lower MSE bound than single-stage generative policies. Empirically, PF-DAG outperforms state-of-the-art baselines across 56 tasks from Adroit, DexArt, and MetaWorld benchmarks. It further generalizes to real-world tactile dexterous manipulation tasks. Our work demonstrates that explicit mode-level decoupling enables both robust multi-modal modeling and reactive closed-loop control for robotic manipulation.

</details>


### [180] [Trajectory Generation with Endpoint Regulation and Momentum-Aware Dynamics for Visually Impaired Scenarios](https://arxiv.org/abs/2602.21691)
*Yuting Zeng,Manping Fan,You Zhou,Yongbin Yu,Zhiwen Zheng,Jingtao Zhang,Liyong Ren,Zhenglin Yang*

Main category: cs.RO

TL;DR: 论文提出了一种结合端点调节和动量感知动力学的轨迹生成方法，改善了视觉障碍场景下轨迹的平滑性和终端稳定性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于抖动的启发式轨迹采样方法在频繁重新生成时会导致终端行为不稳定和状态不连续，无法满足视觉障碍场景下对平滑和时间一致性轨迹的需求。

Method: 提出了一种结合端点调节和动量感知动力学的轨迹生成方法，端点调节用于稳定每个轨迹段的终端状态，动量感知动力学则确保速度和加速度在连续轨迹段间的一致性。

Result: 实验结果显示，与基线规划器相比，该方法降低了加速度峰值和抖动水平，减少了分散性，提供了更平滑的速度和加速度曲线，更稳定的终端分布，以及更少的不可行轨迹候选。

Conclusion: 论文提出的轨迹生成方法通过端点调节和动量感知动力学，显著改善了轨迹的平滑性和终端稳定性，减少了加速度峰值和抖动，适用于视觉障碍场景下的低速动态环境。

Abstract: Trajectory generation for visually impaired scenarios requires smooth and temporally consistent state in structured, low-speed dynamic environments. However, traditional jerk-based heuristic trajectory sampling with independent segment generation and conventional smoothness penalties often lead to unstable terminal behavior and state discontinuities under frequent regenerating. This paper proposes a trajectory generation approach that integrates endpoint regulation to stabilize terminal states within each segment and momentum-aware dynamics to regularize the evolution of velocity and acceleration for segment consistency. Endpoint regulation is incorporated into trajectory sampling to stabilize terminal behavior, while a momentum-aware dynamics enforces consistent velocity and acceleration evolution across consecutive trajectory segments. Experimental results demonstrate reduced acceleration peaks and lower jerk levels with decreased dispersion, smoother velocity and acceleration profiles, more stable endpoint distributions, and fewer infeasible trajectory candidates compared with a baseline planner.

</details>


### [181] [Dual-Regime Hybrid Aerodynamic Modeling of Winged Blimps With Neural Mixing](https://arxiv.org/abs/2602.21696)
*Xiaorui Wang,Hongwu Wang,Yue Fan,Hao Cheng,Feitian Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种混合气动建模框架，结合固定翼和阻力模型，通过神经网络混合器实现平滑过渡，实验验证显示其优于单一模型。


<details>
  <summary>Details</summary>
Motivation: 翼飞艇在不同气动状态下表现出截然不同的动力学特性，单一模型难以准确捕捉这些差异。特别是在高速小攻角和低速大攻角状态下，动力学行为差异显著，导致模型间过渡成为一个关键挑战。

Method: 论文采用了一种混合气动建模框架，结合了固定翼气动耦合模型（ACM）和广义阻力模型（GDM），并通过具有显式物理正则化的神经网络混合器实现模型间的平滑过渡。模型参数通过一个专为混合气动建模设计的三阶段管道进行识别。

Result: 在RGBlimp平台上进行了大规模实验验证，包括1,320条实际飞行轨迹和330种推进器及移动质量配置。结果表明，提出的混合模型在性能和鲁棒性上均优于单一模型和预定义混合器基线。

Conclusion: 该论文提出了一种混合气动建模框架，通过结合固定翼气动耦合模型（ACM）和广义阻力模型（GDM），并利用具有显式物理正则化的神经网络混合器，成功实现了翼飞艇在不同气动状态间的平滑过渡。实验验证表明，该混合模型在性能和鲁棒性上均优于单一模型和预定义混合器基线。

Abstract: Winged blimps operate across distinct aerodynamic regimes that cannot be adequately captured by a single model. At high speeds and small angles of attack, their dynamics exhibit strong coupling between lift and attitude, resembling fixed-wing aircraft behavior. At low speeds or large angles of attack, viscous effects and flow separation dominate, leading to drag-driven and damping-dominated dynamics. Accurately representing transitions between these regimes remains a fundamental challenge. This paper presents a hybrid aerodynamic modeling framework that integrates a fixed-wing Aerodynamic Coupling Model (ACM) and a Generalized Drag Model (GDM) using a learned neural network mixer with explicit physics-based regularization. The mixer enables smooth transitions between regimes while retaining explicit, physics-based aerodynamic representation. Model parameters are identified through a structured three-phase pipeline tailored for hybrid aerodynamic modeling. The proposed approach is validated on the RGBlimp platform through a large-scale experimental campaign comprising 1,320 real-world flight trajectories across 330 thruster and moving mass configurations, spanning a wide range of speeds and angles of attack. Experimental results demonstrate that the proposed hybrid model consistently outperforms single-model and predefined-mixer baselines, establishing a practical and robust aerodynamic modeling solution for winged blimps.

</details>


### [182] [LessMimic: Long-Horizon Humanoid Interaction with Unified Distance Field Representations](https://arxiv.org/abs/2602.21723)
*Yutang Lin,Jieming Cui,Yixuan Li,Baoxiong Jia,Yixin Zhu,Siyuan Huang*

Main category: cs.RO

TL;DR: LessMimic利用距离场（DF）作为统一交互表示，通过几何线索和对抗性训练实现人形机器人的泛化、技能组合和长期交互，无需运动参考或特定任务奖励。


<details>
  <summary>Details</summary>
Motivation: 实现人形机器人在物理环境中长期自主交互的统一交互表示，避免现有方法对特定对象几何和任务特定奖励的依赖。

Method: LessMimic通过距离场（DF）提供的几何线索（表面距离、梯度和速度分解）来调节单一全身策略，无需运动参考，并通过变分自编码器（VAE）编码交互潜在变量，并在强化学习（RL）下使用对抗性交互先验（AIP）进行后训练。

Result: 单个LessMimic策略在PickUp和SitStand任务中实现了80-100%的成功率（对象尺寸从0.4x到1.6x），在5个任务实例轨迹上达到62.1%的成功率，并可连续执行多达40个任务。

Conclusion: 通过将交互基础建立在局部几何而非演示上，LessMimic为人形机器人提供了一条可扩展的路径，使其能够在非结构化环境中实现泛化、技能组合和从失败中恢复。

Abstract: Humanoid robots that autonomously interact with physical environments over extended horizons represent a central goal of embodied intelligence. Existing approaches rely on reference motions or task-specific rewards, tightly coupling policies to particular object geometries and precluding multi-skill generalization within a single framework. A unified interaction representation enabling reference-free inference, geometric generalization, and long-horizon skill composition within one policy remains an open challenge. Here we show that Distance Field (DF) provides such a representation: LessMimic conditions a single whole-body policy on DF-derived geometric cues--surface distances, gradients, and velocity decompositions--removing the need for motion references, with interaction latents encoded via a Variational Auto-Encoder (VAE) and post-trained using Adversarial Interaction Priors (AIP) under Reinforcement Learning (RL). Through DAgger-style distillation that aligns DF latents with egocentric depth features, LessMimic further transfers seamlessly to vision-only deployment without motion capture (MoCap) infrastructure. A single LessMimic policy achieves 80--100% success across object scales from 0.4x to 1.6x on PickUp and SitStand where baselines degrade sharply, attains 62.1% success on 5 task instances trajectories, and remains viable up to 40 sequentially composed tasks. By grounding interaction in local geometry rather than demonstrations, LessMimic offers a scalable path toward humanoid robots that generalize, compose skills, and recover from failures in unstructured environments.

</details>


### [183] [Joint-Aligned Latent Action: Towards Scalable VLA Pretraining in the Wild](https://arxiv.org/abs/2602.21736)
*Hao Luo,Ye Wang,Wanpeng Zhang,Haoqi Yuan,Yicheng Feng,Haiweng Xu,Sipeng Zheng,Zongqing Lu*

Main category: cs.RO

TL;DR: JALA是一种预训练框架，通过学习联合对齐的潜在动作，利用混合的人类数据（实验室和野外视频）提升机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉-语言-动作模型（VLA）取得进展，但大规模多样化机器人数据的缺乏限制了其发展。人类操作视频提供了丰富的替代资源，但现有方法必须在小型精确标记数据集和大量野外视频（标签不可靠）之间做出选择。

Method: JALA框架学习联合对齐的潜在动作，绕过完整的视觉动态重建，而是学习与逆向动力学和真实动作对齐的预测性动作嵌入。

Result: JALA在受控和非受控场景中生成更真实的手部动作，显著提高了模拟和现实世界任务中的机器人操作性能。

Conclusion: JALA通过联合对齐的潜在动作为VLA预训练提供了一个可扩展的途径，显著提升了机器人操作的性能。

Abstract: Despite progress, Vision-Language-Action models (VLAs) are limited by a scarcity of large-scale, diverse robot data. While human manipulation videos offer a rich alternative, existing methods are forced to choose between small, precisely-labeled datasets and vast in-the-wild footage with unreliable hand tracking labels. We present JALA, a pretraining framework that learns Jointly-Aligned Latent Actions. JALA bypasses full visual dynamic reconstruction, instead learns a predictive action embedding aligned with both inverse dynamics and real actions. This yields a transition-aware, behavior-centric latent space for learning from heterogeneous human data. We scale this approach with UniHand-Mix, a 7.5M video corpus (>2,000 hours) blending laboratory and in-the-wild footage. Experiments demonstrate that JALA generates more realistic hand motions in both controlled and unconstrained scenarios, significantly improving downstream robot manipulation performance in both simulation and real-world tasks. These results indicate that jointly-aligned latent actions offer a scalable pathway for VLA pretraining from human data.

</details>


### [184] [Therapist-Robot-Patient Physical Interaction is Worth a Thousand Words: Enabling Intuitive Therapist Guidance via Remote Haptic Control](https://arxiv.org/abs/2602.21783)
*Beatrice Luciani,Alex van den Berg,Matti Lang,Alexandre L. Ratschat,Laura Marchal-Crespo*

Main category: cs.RO

TL;DR: 触觉远程操作系统通过直观交互提升训练效果，减少指令负担，未来需临床验证。


<details>
  <summary>Details</summary>
Motivation: 解决机器人系统在实际应用中因非直观的教练-学员交互而受限的问题。

Method: 通过手持触觉设备与臂外骨骼的虚拟接触点交互，实现直观引导，并与传统视觉演示对比。

Result: 触觉演示显著减少运动完成时间、提高流畅度，减少口头指令，且未增加教练的生理和心理负担。

Conclusion: 提出的触觉远程操作系统为远程人机物理交互提供了有效接口，未来需评估其在临床人群中的可用性和疗效。

Abstract: Robotic systems can enhance the amount and repeatability of physically guided motor training. Yet their real-world adoption is limited, partly due to non-intuitive trainer/therapist-trainee/patient interactions. To address this gap, we present a haptic teleoperation system for trainers to remotely guide and monitor the movements of a trainee wearing an arm exoskeleton. The trainer can physically interact with the exoskeleton through a commercial handheld haptic device via virtual contact points at the exoskeleton's elbow and wrist, allowing intuitive guidance. Thirty-two participants tested the system in a trainer-trainee paradigm, comparing our haptic demonstration system with conventional visual demonstration in guiding trainees in executing arm poses. Quantitative analyses showed that haptic demonstration significantly reduced movement completion time and improved smoothness, while speech analysis using large language models for automated transcription and categorization of verbal commands revealed fewer verbal instructions. The haptic demonstration did not result in higher reported mental and physical effort by trainers compared to the visual demonstration, while trainers reported greater competence and trainees lower physical demand. These findings support the feasibility of our proposed interface for effective remote human-robot physical interaction. Future work should assess its usability and efficacy for clinical populations in restoring clinicians' sense of agency during robot-assisted therapy.

</details>


### [185] [DexRepNet++: Learning Dexterous Robotic Manipulation with Geometric and Spatial Hand-Object Representations](https://arxiv.org/abs/2602.21811)
*Qingtao Liu,Zhengnan Sun,Yu Cui,Haoming Li,Gaofeng Li,Lin Shao,Jiming Chen,Qi Ye*

Main category: cs.RO

TL;DR: DexRep是一种新型手-物交互表示方法，显著提升灵巧操作任务的泛化能力和成功率，仿真和实际应用效果均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有深度强化学习方法在高维输出动作空间的样本效率上有所改进，但忽视了表示方法在复杂输入空间中实现操作策略泛化的重要性。

Method: 提出了DexRep，一种捕捉物体表面特征和手-物空间关系的新型表示方法，并基于此学习了三种灵巧操作任务的策略。

Result: 在仿真中，DexRep在抓取任务中对5000多个未见物体达到87.9%的成功率，显著优于现有方法；在手中重新定向和双手交接任务中，成功率和其他指标提升了20%至40%。实际部署中，DexRep表现出较小的仿真到现实差距。

Conclusion: DexRep作为一种新颖的手-物交互表示方法，显著提升了多指机器人手的灵巧操作技能学习效果，在仿真和实际应用中均表现出色。

Abstract: Robotic dexterous manipulation is a challenging problem due to high degrees of freedom (DoFs) and complex contacts of multi-fingered robotic hands. Many existing deep reinforcement learning (DRL) based methods aim at improving sample efficiency in high-dimensional output action spaces. However, existing works often overlook the role of representations in achieving generalization of a manipulation policy in the complex input space during the hand-object interaction. In this paper, we propose DexRep, a novel hand-object interaction representation to capture object surface features and spatial relations between hands and objects for dexterous manipulation skill learning. Based on DexRep, policies are learned for three dexterous manipulation tasks, i.e. grasping, in-hand reorientation, bimanual handover, and extensive experiments are conducted to verify the effectiveness. In simulation, for grasping, the policy learned with 40 objects achieves a success rate of 87.9% on more than 5000 unseen objects of diverse categories, significantly surpassing existing work trained with thousands of objects; for the in-hand reorientation and handover tasks, the policies also boost the success rates and other metrics of existing hand-object representations by 20% to 40%. The grasp policies with DexRep are deployed to the real world under multi-camera and single-camera setups and demonstrate a small sim-to-real gap.

</details>


### [186] [Self-Curriculum Model-based Reinforcement Learning for Shape Control of Deformable Linear Objects](https://arxiv.org/abs/2602.21816)
*Zhaowei Liang,Song Wang,Zhao Jin,Shirui Wu,Dan Wu*

Main category: cs.RO

TL;DR: 该论文提出了一种结合强化学习和视觉伺服的两阶段框架，有效解决了DLO形状控制中的大变形和小变形问题，并在模拟和实际任务中验证了其高效性和精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂大变形任务（尤其是涉及相反曲率的情况）时缺乏效率和精度，因此需要一种更高效和精确的解决方案。

Method: 提出了一种结合强化学习（RL）和在线视觉伺服的两阶段框架：大变形阶段使用基于模型的强化学习方法和小变形阶段采用基于雅可比矩阵的视觉伺服控制器。

Result: 模拟结果显示，该方法在形状控制成功率和精度上显著优于主流基线方法，并能零样本适应实际任务。

Conclusion: 该论文提出的两阶段框架（结合强化学习和在线视觉伺服）在模拟和实际任务中均表现出色，成功处理了不同尺寸和材料的DLO形状控制任务。

Abstract: Precise shape control of Deformable Linear Objects (DLOs) is crucial in robotic applications such as industrial and medical fields. However, existing methods face challenges in handling complex large deformation tasks, especially those involving opposite curvatures, and lack efficiency and precision. To address this, we propose a two-stage framework combining Reinforcement Learning (RL) and online visual servoing. In the large-deformation stage, a model-based reinforcement learning approach using an ensemble of dynamics models is introduced to significantly improve sample efficiency. Additionally, we design a self-curriculum goal generation mechanism that dynamically selects intermediate-difficulty goals with high diversity through imagined evaluations, thereby optimizing the policy learning process. In the small-deformation stage, a Jacobian-based visual servo controller is deployed to ensure high-precision convergence. Simulation results show that the proposed method enables efficient policy learning and significantly outperforms mainstream baselines in shape control success rate and precision. Furthermore, the framework effectively transfers the policy trained in simulation to real-world tasks with zero-shot adaptation. It successfully completes all 30 cases with diverse initial and target shapes across DLOs of different sizes and materials. The project website is available at: https://anonymous.4open.science/w/sc-mbrl-dlo-EB48/

</details>


### [187] [Dream-SLAM: Dreaming the Unseen for Active SLAM in Dynamic Environments](https://arxiv.org/abs/2602.21967)
*Xiangqi Meng,Pengxu Hou,Zhenjun Zhao,Javier Civera,Daniel Cremers,Hesheng Wang,Haoang Li*

Main category: cs.RO

TL;DR: Dream-SLAM通过跨时空图像和语义结构融合，解决了现有主动SLAM的局限性，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有主动SLAM方法受限于底层SLAM模块、短视的运动规划策略及动态场景处理能力不足。

Method: 提出了一种新颖的单目主动SLAM方法Dream-SLAM，基于跨时空图像和动态环境的语义合理结构生成，融合真实观测以减少噪声和数据不完整性。

Result: 在公开和自采集数据集上的实验表明，Dream-SLAM在定位精度、地图质量和探索效率上优于现有方法。

Conclusion: Dream-SLAM通过融合跨时空图像和语义合理的结构，显著提升了定位精度、地图质量和探索效率，优于现有方法。

Abstract: In addition to the core tasks of simultaneous localization and mapping (SLAM), active SLAM additionally in- volves generating robot actions that enable effective and efficient exploration of unknown environments. However, existing active SLAM pipelines are limited by three main factors. First, they inherit the restrictions of the underlying SLAM modules that they may be using. Second, their motion planning strategies are typically shortsighted and lack long-term vision. Third, most approaches struggle to handle dynamic scenes. To address these limitations, we propose a novel monocular active SLAM method, Dream-SLAM, which is based on dreaming cross-spatio-temporal images and semantically plausible structures of partially observed dynamic environments. The generated cross-spatio-temporal im- ages are fused with real observations to mitigate noise and data incompleteness, leading to more accurate camera pose estimation and a more coherent 3D scene representation. Furthermore, we integrate dreamed and observed scene structures to enable long- horizon planning, producing farsighted trajectories that promote efficient and thorough exploration. Extensive experiments on both public and self-collected datasets demonstrate that Dream-SLAM outperforms state-of-the-art methods in localization accuracy, mapping quality, and exploration efficiency. Source code will be publicly available upon paper acceptance.

</details>


### [188] [Humanizing Robot Gaze Shifts: A Framework for Natural Gaze Shifts in Humanoid Robots](https://arxiv.org/abs/2602.21983)
*Jingchao Wei,Jingkai Qin,Yuxiao Cao,Jingcheng Huang,Xiangrui Zeng,Min Li,Zhouping Yin*

Main category: cs.RO

TL;DR: RGS框架通过VLM推理和VQ-VAE运动生成，实现了仿人机器人自然视线转移。


<details>
  <summary>Details</summary>
Motivation: 在无约束的人机交互中，实现自然且符合上下文的视线转移对仿人机器人仍具挑战性。

Method: RGS框架结合了基于视觉-语言模型（VLM）的视线推理管道和条件性VQ-VAE模型，用于眼-头协调的视线转移运动生成。

Result: 实验验证RGS能有效复制人类目标选择并生成真实多样的视线转移动作。

Conclusion: RGS框架成功整合了认知注意力机制和仿生运动生成，有效模拟了人类自然的视线转移行为。

Abstract: Leveraging auditory and visual feedback for attention reorientation is essential for natural gaze shifts in social interaction. However, enabling humanoid robots to perform natural and context-appropriate gaze shifts in unconstrained human--robot interaction (HRI) remains challenging, as it requires the coupling of cognitive attention mechanisms and biomimetic motion generation. In this work, we propose the Robot Gaze-Shift (RGS) framework, which integrates these two components into a unified pipeline. First, RGS employs a vision--language model (VLM)-based gaze reasoning pipeline to infer context-appropriate gaze targets from multimodal interaction cues, ensuring consistency with human gaze-orienting regularities. Second, RGS introduces a conditional Vector Quantized-Variational Autoencoder (VQ-VAE) model for eye--head coordinated gaze-shift motion generation, producing diverse and human-like gaze-shift behaviors. Experiments validate that RGS effectively replicates human-like target selection and generates realistic, diverse gaze-shift motions.

</details>


### [189] [Are Foundation Models the Route to Full-Stack Transfer in Robotics?](https://arxiv.org/abs/2602.22001)
*Freek Stulp,Samuel Bustamante,João Silvério,Alin Albu-Schäffer,Jeannette Bohg,Shuran Song*

Main category: cs.RO

TL;DR: Foundation models and transformer networks enhance transfer learning in robotics, moving closer to full-stack transfer, with ongoing challenges in data collection and benchmarks.


<details>
  <summary>Details</summary>
Motivation: To explore how foundation models and transformer networks can facilitate transfer learning at various levels of abstraction in robotics, from high-level linguistic transfer to low-level motor skills transfer.

Method: The article provides an overview of the impact of foundation models and transformer networks on different levels of transfer learning in robotics.

Result: Foundation models and transformer networks bring robots closer to full-stack transfer, highlighting recurring concepts for transfer beyond specific implementations.

Conclusion: Foundation models are expected to remain a key technology in achieving full-stack transfer in robotics.

Abstract: In humans and robots alike, transfer learning occurs at different levels of abstraction, from high-level linguistic transfer to low-level transfer of motor skills. In this article, we provide an overview of the impact that foundation models and transformer networks have had on these different levels, bringing robots closer than ever to "full-stack transfer". Considering LLMs, VLMs and VLAs from a robotic transfer learning perspective allows us to highlight recurring concepts for transfer, beyond specific implementations. We also consider the challenges of data collection and transfer benchmarks for robotics in the age of foundation models. Are foundation models the route to full-stack transfer in robotics? Our expectation is that they will certainly stay on this route as a key technology.

</details>


### [190] [Parallel Continuous-Time Relative Localization with Augmented Clamped Non-Uniform B-Splines](https://arxiv.org/abs/2602.22006)
*Jiadong Lu,Zhehan Li,Tao Han,Miao Xu,Chao Xu,Yanjun Cao*

Main category: cs.RO

TL;DR: CT-RIO是一种新型连续时间相对惯性里程计框架，通过C-NUBS和knot-keyknot策略显著提升多机器人系统的定位精度和效率。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人系统中异步测量和时钟偏移带来的高精度、低延迟和高频率性能挑战，克服现有连续时间方法的查询延迟和高计算成本问题。

Method: 采用Clamped Non-Uniform B-splines (C-NUBS)表示机器人状态，引入knot-keyknot策略进行灵活的时间管理，并通过滑动窗口和并行优化技术实现高效计算。

Result: CT-RIO能在3秒内从263毫秒的时间偏移收敛至亚毫秒级，定位精度达到0.046米和1.8度，在高速度运动下性能提升高达60%。

Conclusion: CT-RIO框架通过采用C-NUBS和创新的knot-keyknot策略，显著提升了多机器人系统中的相对定位精度和计算效率，能够快速收敛并优于现有方法。

Abstract: Accurate relative localization is critical for multi-robot cooperation. In robot swarms, measurements from different robots arrive asynchronously and with clock time-offsets. Although Continuous-Time (CT) formulations have proved effective for handling asynchronous measurements in single-robot SLAM and calibration, extending CT methods to multi-robot settings faces great challenges to achieve high-accuracy, low-latency, and high-frequency performance. Especially, existing CT methods suffer from the inherent query-time delay of unclamped B-splines and high computational cost. This paper proposes CT-RIO, a novel Continuous-Time Relative-Inertial Odometry framework. We employ Clamped Non-Uniform B-splines (C-NUBS) to represent robot states for the first time, eliminating the query-time delay. We further augment C-NUBS with closed-form extension and shrinkage operations that preserve the spline shape, making it suitable for online estimation and enabling flexible knot management. This flexibility leads to the concept of knot-keyknot strategy, which supports spline extension at high-frequency while retaining sparse keyknots for adaptive relative-motion modeling. We then formulate a sliding-window relative localization problem that operates purely on relative kinematics and inter-robot constraints. To meet the demanding computation required at swarm scale, we decompose the tightly-coupled optimization into robot-wise sub-problems and solve them in parallel using incremental asynchronous block coordinate descent. Extensive experiments show that CT-RIO converges from time-offsets as large as 263 ms to sub-millisecond within 3 s, and achieves RMSEs of 0.046 m and 1.8 °. It consistently outperforms state-of-the-art methods, with improvements of up to 60% under high-speed motion.

</details>


### [191] [World Guidance: World Modeling in Condition Space for Action Generation](https://arxiv.org/abs/2602.22010)
*Yue Su,Sijin Chen,Haixin Shi,Mingyu Liu,Zhengshen Zhang,Ningyuan Huang,Weiheng Zhong,Zhengbang Zhu,Yuxiao Liu,Xihui Liu*

Main category: cs.RO

TL;DR: WoG框架通过压缩未来观测为条件并联合预测动作，解决了VLA模型在动作生成中平衡效率与精度的难题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保持高效、可预测的未来表示与保留足够细粒度信息以指导精确动作生成之间难以平衡。

Method: 提出WoG框架，将未来观测映射为紧凑条件并注入动作推理流程，同时训练VLA模型预测这些条件及未来动作。

Result: WoG不仅促进了细粒度动作生成，还展现出卓越的泛化能力，并能有效学习大量人类操作视频。

Conclusion: WoG框架通过将未来观测映射为紧凑条件并注入动作推理流程，显著提升了VLA模型的动作生成能力，并在仿真和真实环境中验证了其优越性。

Abstract: Leveraging future observation modeling to facilitate action generation presents a promising avenue for enhancing the capabilities of Vision-Language-Action (VLA) models. However, existing approaches struggle to strike a balance between maintaining efficient, predictable future representations and preserving sufficient fine-grained information to guide precise action generation. To address this limitation, we propose WoG (World Guidance), a framework that maps future observations into compact conditions by injecting them into the action inference pipeline. The VLA is then trained to simultaneously predict these compressed conditions alongside future actions, thereby achieving effective world modeling within the condition space for action inference. We demonstrate that modeling and predicting this condition space not only facilitates fine-grained action generation but also exhibits superior generalization capabilities. Moreover, it learns effectively from substantial human manipulation videos. Extensive experiments across both simulation and real-world environments validate that our method significantly outperforms existing methods based on future prediction. Project page is available at: https://selen-suyue.github.io/WoGNet/

</details>


### [192] [FlowCorrect: Efficient Interactive Correction of Generative Flow Policies for Robotic Manipulation](https://arxiv.org/abs/2602.22056)
*Edgar Welte,Yitian Shi,Rosa Wolf,Maximillian Gilles,Rania Rayyes*

Main category: cs.RO

TL;DR: FlowCorrect通过稀疏人类修正局部调整生成式视觉运动策略，显著提升机器人任务成功率，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 生成式操纵策略在部署时分布偏移下可能失败，但许多失败是接近成功的，只需小幅修正即可完成任务。

Method: FlowCorrect框架利用轻量级VR接口接收人类提供的短暂姿态修正，局部调整策略，无需重新训练主干模型。

Result: 在三个桌面任务（拾取放置、倾倒、杯子直立）中，FlowCorrect以少量修正预算将困难案例的成功率提高了85%，同时保持原有场景性能。

Conclusion: FlowCorrect通过稀疏的人类干预成功将接近失败的任务转化为成功，无需完整策略重新训练，显著提高了真实机器人任务的成功率。

Abstract: Generative manipulation policies can fail catastrophically under deployment-time distribution shift, yet many failures are near-misses: the robot reaches almost-correct poses and would succeed with a small corrective motion. We present FlowCorrect, a deployment-time correction framework that converts near-miss failures into successes using sparse human nudges, without full policy retraining. During execution, a human provides brief corrective pose nudges via a lightweight VR interface. FlowCorrect uses these sparse corrections to locally adapt the policy, improving actions without retraining the backbone while preserving the model performance on previously learned scenarios. We evaluate on a real-world robot across three tabletop tasks: pick-and-place, pouring, and cup uprighting. With a low correction budget, FlowCorrect improves success on hard cases by 85\% while preserving performance on previously solved scenarios. The results demonstrate clearly that FlowCorrect learns only with very few demonstrations and enables fast and sample-efficient incremental, human-in-the-loop corrections of generative visuomotor policies at deployment time in real-world robotics.

</details>


### [193] [Force Policy: Learning Hybrid Force-Position Control Policy under Interaction Frame for Contact-Rich Manipulation](https://arxiv.org/abs/2602.22088)
*Hongjie Fang,Shirun Tang,Mingyu Mei,Haoxiang Qin,Zihao He,Jingjing Chen,Ying Feng,Chenxi Wang,Wanxi Liu,Zaixing He,Cewu Lu,Shiquan Wang*

Main category: cs.RO

TL;DR: Force Policy通过全局-局部视觉-力反馈策略，在接触密集任务中实现了更稳定的接触和更精确的力调节，并能泛化到新物体。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法通常将视觉和力反馈的角色耦合在单一网络中，导致全局泛化与局部稳定细化之间的权衡问题；而控制中心方法通常假设已知任务结构或仅学习控制器参数。本文旨在解决这些问题。

Method: 提出了一种基于物理基础的交互框架（interaction frame），并开发了Force Policy策略，其中全局策略利用视觉引导自由空间动作，而局部策略在接触时通过力反馈估计交互框架并执行混合力-位置控制。

Result: 在真实世界的多种接触密集任务中，Force Policy相比基线表现出更稳健的接触建立、更准确的力调节，并能泛化到新物体上。

Conclusion: Force Policy方法通过全局-局部视觉-力反馈策略，在多种接触密集任务中实现了比基线更稳定的接触建立、更精确的力调节，并能可靠地泛化到具有不同几何和物理特性的新物体上，显著提升了接触稳定性和执行质量。

Abstract: Contact-rich manipulation demands human-like integration of perception and force feedback: vision should guide task progress, while high-frequency interaction control must stabilize contact under uncertainty. Existing learning-based policies often entangle these roles in a monolithic network, trading off global generalization against stable local refinement, while control-centric approaches typically assume a known task structure or learn only controller parameters rather than the structure itself. In this paper, we formalize a physically grounded interaction frame, an instantaneous local basis that decouples force regulation from motion execution, and propose a method to recover it from demonstrations. Based on this, we address both issues by proposing Force Policy, a global-local vision-force policy in which a global policy guides free-space actions using vision, and upon contact, a high-frequency local policy with force feedback estimates the interaction frame and executes hybrid force-position control for stable interaction. Real-world experiments across diverse contact-rich tasks show consistent gains over strong baselines, with more robust contact establishment, more accurate force regulation, and reliable generalization to novel objects with varied geometries and physical properties, ultimately improving both contact stability and execution quality. Project page: https://force-policy.github.io/

</details>


### [194] [Behavioral Cloning for Robotic Connector Assembly: An Empirical Study](https://arxiv.org/abs/2602.22100)
*Andreas Kernbach,Daniel Bargmann,Werner Kraus,Marco F. Huber*

Main category: cs.RO

TL;DR: 该研究通过行为克隆方法结合力-力矩传感和视觉反馈，成功实现了连接器插入的自动化，插入成功率超过90%。


<details>
  <summary>Details</summary>
Motivation: 自动化线束组装在汽车、电气柜和飞机生产中具有挑战性，主要由于可变形电缆和连接器几何形状的高变异性，以及需要有限力插入以避免损坏。人类可以直观地结合视觉和触觉反馈完成此任务，但编程工业机器人以适应性方式执行此任务仍然困难。

Method: 研究比较了多种网络架构和其他设计选择，使用了通过SpaceMouse远程操作的UR5e机器人收集的300次成功人类演示数据集。

Result: 系统在五种不同几何形状的连接器和不同姿态下进行评估，实现了超过90%的总体插入成功率。

Conclusion: 该研究通过行为克隆方法成功开发了一个结合力-力矩传感和固定位置摄像头的连接器插入动作预测模型，实现了超过90%的插入成功率。

Abstract: Automating the assembly of wire harnesses is challenging in automotive, electrical cabinet, and aircraft production, particularly due to deformable cables and a high variance in connector geometries. In addition, connectors must be inserted with limited force to avoid damage, while their poses can vary significantly. While humans can do this task intuitively by combining visual and haptic feedback, programming an industrial robot for such a task in an adaptable manner remains difficult. This work presents an empirical study investigating the suitability of behavioral cloning for learning an action prediction model for connector insertion that fuses force-torque sensing with a fixed position camera. We compare several network architectures and other design choices using a dataset of up to 300 successful human demonstrations collected via teleoperation of a UR5e robot with a SpaceMouse under varying connector poses. The resulting system is then evaluated against five different connector geometries under varying connector poses, achieving an overall insertion success rate of over 90 %.

</details>


### [195] [System Design of the Ultra Mobility Vehicle: A Driving, Balancing, and Jumping Bicycle Robot](https://arxiv.org/abs/2602.22118)
*Benjamin Bokser,Daniel Gonzalez,Surya Singh,Aaron Preston,Alex Bahner,Annika Wollschläger,Arianna Ilvonen,Asa Eckert-Erdheim,Ashwin Khadke,Bilal Hammoud,Dean Molinaro,Fabian Jenelten,Henry Mayne,Howie Choset,Igor Bogoslavskyi,Itic Tinman,James Tigue,Jan Preisig,Kaiyu Zheng,Kenny Sharma,Kim Ang,Laura Lee,Liana Margolese,Nicole Lin,Oscar Frias,Paul Drews,Ravi Boggavarapu,Rick Burnham,Samuel Zapolsky,Sangbae Kim,Scott Biddlestone,Sean Mayorga,Shamel Fahmi,Tyler McCollum,Velin Dimitrov,William Moyne,Yu-Ming Chen,Farbod Farshidian,Marco Hutter,David Perry,Al Rizzi,Gabe Nelson*

Main category: cs.RO

TL;DR: 受自行车运动员启发设计的UMV机器人，通过优化设计和强化学习，实现了高速移动和高跳跃能力。


<details>
  <summary>Details</summary>
Motivation: 受自行车运动员的多样运动能力启发，旨在设计一种能够在不同地形上高效移动和展示敏捷性的机器人平台。

Method: 采用仿真驱动的设计优化过程，结合空间连杆拓扑结构，并利用约束强化学习框架进行行为训练。

Result: UMV机器人重23.5公斤，最高速度达8米/秒，能跳跃1米高的障碍物（相当于其标称高度的130%），并展示了多种运动行为。

Conclusion: UMV机器人展示了通过结合自行车和反应质量的设计，以及强化学习框架，能够实现多样化的运动行为，包括高速移动和高跳跃能力。

Abstract: Trials cyclists and mountain bike riders can hop, jump, balance, and drive on one or both wheels. This versatility allows them to achieve speed and energy-efficiency on smooth terrain and agility over rough terrain. Inspired by these athletes, we present the design and control of a robotic platform, Ultra Mobility Vehicle (UMV), which combines a bicycle and a reaction mass to move dynamically with minimal actuated degrees of freedom. We employ a simulation-driven design optimization process to synthesize a spatial linkage topology with a focus on vertical jump height and momentum-based balancing on a single wheel contact. Using a constrained Reinforcement Learning (RL) framework, we demonstrate zero-shot transfer of diverse athletic behaviors, including track-stands, jumps, wheelies, rear wheel hopping, and front flips. This 23.5 kg robot is capable of high speeds (8 m/s) and jumping on and over large obstacles (1 m tall, or 130% of the robot's nominal height).

</details>


### [196] [Position-Based Flocking for Persistent Alignment without Velocity Sensing](https://arxiv.org/abs/2602.22154)
*Hossein B. Jond,Veli Bakırcıoğlu,Logan E. Beaver,Nejat Tükenmez,Adel Akbarimajd,Martin Saska*

Main category: cs.RO

TL;DR: 该论文提出了一种基于位置的群体运动模型，无需速度感知即可实现持续的群体对齐，适用于机器人群体，模拟和实验均验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 受鸟类群和鱼群协调集体运动的启发，开发适用于机器人群体的一致性算法。

Method: 通过近似当前与初始相对位置之间的变化来估计相对速度差异，并结合时间和密度相关的对齐增益以及非零最小阈值来维持持续对齐。

Result: 模拟实验显示，50个智能体的群体中，基于位置的群体运动模型比基于速度对齐的基线模型实现了更快、更持久的方向对齐，并形成更紧凑的队形。九轮式移动机器人的实验结果也验证了模型的有效性。

Conclusion: 该论文提出的基于位置的群体运动模型在无需速度感知的情况下实现了持续的群体速度对齐，特别适用于速度测量不可靠或不可用的实际机器人群体应用。

Abstract: Coordinated collective motion in bird flocks and fish schools inspires algorithms for cohesive swarm robotics. This paper presents a position-based flocking model that achieves persistent velocity alignment without velocity sensing. By approximating relative velocity differences from changes between current and initial relative positions and incorporating a time- and density-dependent alignment gain with a non-zero minimum threshold to maintain persistent alignment, the model sustains coherent collective motion over extended periods. Simulations with a collective of 50 agents demonstrate that the position-based flocking model attains faster and more sustained directional alignment and results in more compact formations than a velocity-alignment-based baseline. This position-based flocking model is particularly well-suited for real-world robotic swarms, where velocity measurements are unreliable, noisy, or unavailable. Experimental results using a team of nine real wheeled mobile robots are also presented.

</details>
